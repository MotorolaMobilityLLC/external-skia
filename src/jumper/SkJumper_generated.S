# Copyright 2017 Google Inc.
#
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

# This file is generated semi-automatically with this command:
#   $ src/jumper/build_stages.py

#if defined(__MACH__)
    #define HIDDEN .private_extern
    #define FUNCTION(name)
    #define BALIGN4  .align 2
    #define BALIGN16 .align 4
    #define BALIGN32 .align 5
#else
    .section .note.GNU-stack,"",%progbits
    #define HIDDEN .hidden
    #define FUNCTION(name) .type name,%function
    #define BALIGN4  .balign 4
    #define BALIGN16 .balign 16
    #define BALIGN32 .balign 32
#endif
.text
#if defined(__aarch64__)
BALIGN4

HIDDEN _sk_start_pipeline_aarch64
.globl _sk_start_pipeline_aarch64
FUNCTION(_sk_start_pipeline_aarch64)
_sk_start_pipeline_aarch64:
  .long  0xa9bd5bf7                          // stp           x23, x22, [sp, #-48]!
  .long  0xa90153f5                          // stp           x21, x20, [sp, #16]
  .long  0xa9027bf3                          // stp           x19, x30, [sp, #32]
  .long  0xaa0103f4                          // mov           x20, x1
  .long  0xf8408697                          // ldr           x23, [x20], #8
  .long  0xaa0003f5                          // mov           x21, x0
  .long  0xaa0303f3                          // mov           x19, x3
  .long  0x910012a8                          // add           x8, x21, #0x4
  .long  0xeb13011f                          // cmp           x8, x19
  .long  0xaa0203f6                          // mov           x22, x2
  .long  0x54000069                          // b.ls          34 <sk_start_pipeline_aarch64+0x34>  // b.plast
  .long  0xaa1503e0                          // mov           x0, x21
  .long  0x14000012                          // b             78 <sk_start_pipeline_aarch64+0x78>
  .long  0x6f00e400                          // movi          v0.2d, #0x0
  .long  0x6f00e401                          // movi          v1.2d, #0x0
  .long  0x6f00e402                          // movi          v2.2d, #0x0
  .long  0x6f00e403                          // movi          v3.2d, #0x0
  .long  0x6f00e404                          // movi          v4.2d, #0x0
  .long  0x6f00e405                          // movi          v5.2d, #0x0
  .long  0x6f00e406                          // movi          v6.2d, #0x0
  .long  0x6f00e407                          // movi          v7.2d, #0x0
  .long  0xaa1503e0                          // mov           x0, x21
  .long  0xaa1403e1                          // mov           x1, x20
  .long  0xaa1603e2                          // mov           x2, x22
  .long  0xd63f02e0                          // blr           x23
  .long  0x910012a0                          // add           x0, x21, #0x4
  .long  0x910022a8                          // add           x8, x21, #0x8
  .long  0xeb13011f                          // cmp           x8, x19
  .long  0xaa0003f5                          // mov           x21, x0
  .long  0x54fffe09                          // b.ls          34 <sk_start_pipeline_aarch64+0x34>  // b.plast
  .long  0xa9427bf3                          // ldp           x19, x30, [sp, #32]
  .long  0xa94153f5                          // ldp           x21, x20, [sp, #16]
  .long  0xa8c35bf7                          // ldp           x23, x22, [sp], #48
  .long  0xd65f03c0                          // ret

HIDDEN _sk_just_return_aarch64
.globl _sk_just_return_aarch64
FUNCTION(_sk_just_return_aarch64)
_sk_just_return_aarch64:
  .long  0xd65f03c0                          // ret

HIDDEN _sk_seed_shader_aarch64
.globl _sk_seed_shader_aarch64
FUNCTION(_sk_seed_shader_aarch64)
_sk_seed_shader_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x3dc00046                          // ldr           q6, [x2]
  .long  0x4e040c00                          // dup           v0.4s, w0
  .long  0x4f0167e7                          // movi          v7.4s, #0x3f, lsl #24
  .long  0x4d40c901                          // ld1r          {v1.4s}, [x8]
  .long  0x4e21d800                          // scvtf         v0.4s, v0.4s
  .long  0x4e27d400                          // fadd          v0.4s, v0.4s, v7.4s
  .long  0x4f03f602                          // fmov          v2.4s, #1.000000000000000000e+00
  .long  0x4e21d821                          // scvtf         v1.4s, v1.4s
  .long  0x6f00e403                          // movi          v3.2d, #0x0
  .long  0x6f00e404                          // movi          v4.2d, #0x0
  .long  0x6f00e405                          // movi          v5.2d, #0x0
  .long  0x4e26d400                          // fadd          v0.4s, v0.4s, v6.4s
  .long  0x6f00e406                          // movi          v6.2d, #0x0
  .long  0x4e27d421                          // fadd          v1.4s, v1.4s, v7.4s
  .long  0x6f00e407                          // movi          v7.2d, #0x0
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_constant_color_aarch64
.globl _sk_constant_color_aarch64
FUNCTION(_sk_constant_color_aarch64)
_sk_constant_color_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xaa0803ea                          // mov           x10, x8
  .long  0x4ddfc940                          // ld1r          {v0.4s}, [x10], #4
  .long  0x91002109                          // add           x9, x8, #0x8
  .long  0x91003108                          // add           x8, x8, #0xc
  .long  0x4d40c922                          // ld1r          {v2.4s}, [x9]
  .long  0x4d40c903                          // ld1r          {v3.4s}, [x8]
  .long  0x4d40c941                          // ld1r          {v1.4s}, [x10]
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_clear_aarch64
.globl _sk_clear_aarch64
FUNCTION(_sk_clear_aarch64)
_sk_clear_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x6f00e400                          // movi          v0.2d, #0x0
  .long  0x6f00e401                          // movi          v1.2d, #0x0
  .long  0x6f00e402                          // movi          v2.2d, #0x0
  .long  0x6f00e403                          // movi          v3.2d, #0x0
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_srcatop_aarch64
.globl _sk_srcatop_aarch64
FUNCTION(_sk_srcatop_aarch64)
_sk_srcatop_aarch64:
  .long  0x4f03f610                          // fmov          v16.4s, #1.000000000000000000e+00
  .long  0x6e27dc00                          // fmul          v0.4s, v0.4s, v7.4s
  .long  0x6e27dc21                          // fmul          v1.4s, v1.4s, v7.4s
  .long  0x6e27dc42                          // fmul          v2.4s, v2.4s, v7.4s
  .long  0x4ea3d610                          // fsub          v16.4s, v16.4s, v3.4s
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4e30cc80                          // fmla          v0.4s, v4.4s, v16.4s
  .long  0x4e30cca1                          // fmla          v1.4s, v5.4s, v16.4s
  .long  0x4e30ccc2                          // fmla          v2.4s, v6.4s, v16.4s
  .long  0x6e27de10                          // fmul          v16.4s, v16.4s, v7.4s
  .long  0x4e23ccf0                          // fmla          v16.4s, v7.4s, v3.4s
  .long  0x4eb01e03                          // mov           v3.16b, v16.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_dstatop_aarch64
.globl _sk_dstatop_aarch64
FUNCTION(_sk_dstatop_aarch64)
_sk_dstatop_aarch64:
  .long  0x4f03f610                          // fmov          v16.4s, #1.000000000000000000e+00
  .long  0x4ea7d610                          // fsub          v16.4s, v16.4s, v7.4s
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x6e20de00                          // fmul          v0.4s, v16.4s, v0.4s
  .long  0x6e21de01                          // fmul          v1.4s, v16.4s, v1.4s
  .long  0x6e22de02                          // fmul          v2.4s, v16.4s, v2.4s
  .long  0x6e23de10                          // fmul          v16.4s, v16.4s, v3.4s
  .long  0x4e23ccf0                          // fmla          v16.4s, v7.4s, v3.4s
  .long  0x4e23cc80                          // fmla          v0.4s, v4.4s, v3.4s
  .long  0x4e23cca1                          // fmla          v1.4s, v5.4s, v3.4s
  .long  0x4e23ccc2                          // fmla          v2.4s, v6.4s, v3.4s
  .long  0x4eb01e03                          // mov           v3.16b, v16.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_srcin_aarch64
.globl _sk_srcin_aarch64
FUNCTION(_sk_srcin_aarch64)
_sk_srcin_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x6e27dc00                          // fmul          v0.4s, v0.4s, v7.4s
  .long  0x6e27dc21                          // fmul          v1.4s, v1.4s, v7.4s
  .long  0x6e27dc42                          // fmul          v2.4s, v2.4s, v7.4s
  .long  0x6e27dc63                          // fmul          v3.4s, v3.4s, v7.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_dstin_aarch64
.globl _sk_dstin_aarch64
FUNCTION(_sk_dstin_aarch64)
_sk_dstin_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x6e24dc60                          // fmul          v0.4s, v3.4s, v4.4s
  .long  0x6e25dc61                          // fmul          v1.4s, v3.4s, v5.4s
  .long  0x6e26dc62                          // fmul          v2.4s, v3.4s, v6.4s
  .long  0x6e27dc63                          // fmul          v3.4s, v3.4s, v7.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_srcout_aarch64
.globl _sk_srcout_aarch64
FUNCTION(_sk_srcout_aarch64)
_sk_srcout_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4f03f610                          // fmov          v16.4s, #1.000000000000000000e+00
  .long  0x4ea7d610                          // fsub          v16.4s, v16.4s, v7.4s
  .long  0x6e20de00                          // fmul          v0.4s, v16.4s, v0.4s
  .long  0x6e21de01                          // fmul          v1.4s, v16.4s, v1.4s
  .long  0x6e22de02                          // fmul          v2.4s, v16.4s, v2.4s
  .long  0x6e23de03                          // fmul          v3.4s, v16.4s, v3.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_dstout_aarch64
.globl _sk_dstout_aarch64
FUNCTION(_sk_dstout_aarch64)
_sk_dstout_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4f03f600                          // fmov          v0.4s, #1.000000000000000000e+00
  .long  0x4ea3d403                          // fsub          v3.4s, v0.4s, v3.4s
  .long  0x6e24dc60                          // fmul          v0.4s, v3.4s, v4.4s
  .long  0x6e25dc61                          // fmul          v1.4s, v3.4s, v5.4s
  .long  0x6e26dc62                          // fmul          v2.4s, v3.4s, v6.4s
  .long  0x6e27dc63                          // fmul          v3.4s, v3.4s, v7.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_srcover_aarch64
.globl _sk_srcover_aarch64
FUNCTION(_sk_srcover_aarch64)
_sk_srcover_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4f03f610                          // fmov          v16.4s, #1.000000000000000000e+00
  .long  0x4ea3d610                          // fsub          v16.4s, v16.4s, v3.4s
  .long  0x4e24ce00                          // fmla          v0.4s, v16.4s, v4.4s
  .long  0x4e25ce01                          // fmla          v1.4s, v16.4s, v5.4s
  .long  0x4e26ce02                          // fmla          v2.4s, v16.4s, v6.4s
  .long  0x4e27ce03                          // fmla          v3.4s, v16.4s, v7.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_dstover_aarch64
.globl _sk_dstover_aarch64
FUNCTION(_sk_dstover_aarch64)
_sk_dstover_aarch64:
  .long  0x4f03f611                          // fmov          v17.4s, #1.000000000000000000e+00
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4ea41c90                          // mov           v16.16b, v4.16b
  .long  0x4ea7d634                          // fsub          v20.4s, v17.4s, v7.4s
  .long  0x4ea51cb1                          // mov           v17.16b, v5.16b
  .long  0x4ea61cd2                          // mov           v18.16b, v6.16b
  .long  0x4ea71cf3                          // mov           v19.16b, v7.16b
  .long  0x4e20ce90                          // fmla          v16.4s, v20.4s, v0.4s
  .long  0x4e21ce91                          // fmla          v17.4s, v20.4s, v1.4s
  .long  0x4e22ce92                          // fmla          v18.4s, v20.4s, v2.4s
  .long  0x4e23ce93                          // fmla          v19.4s, v20.4s, v3.4s
  .long  0x4eb01e00                          // mov           v0.16b, v16.16b
  .long  0x4eb11e21                          // mov           v1.16b, v17.16b
  .long  0x4eb21e42                          // mov           v2.16b, v18.16b
  .long  0x4eb31e63                          // mov           v3.16b, v19.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_modulate_aarch64
.globl _sk_modulate_aarch64
FUNCTION(_sk_modulate_aarch64)
_sk_modulate_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x6e24dc00                          // fmul          v0.4s, v0.4s, v4.4s
  .long  0x6e25dc21                          // fmul          v1.4s, v1.4s, v5.4s
  .long  0x6e26dc42                          // fmul          v2.4s, v2.4s, v6.4s
  .long  0x6e27dc63                          // fmul          v3.4s, v3.4s, v7.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_multiply_aarch64
.globl _sk_multiply_aarch64
FUNCTION(_sk_multiply_aarch64)
_sk_multiply_aarch64:
  .long  0x4f03f610                          // fmov          v16.4s, #1.000000000000000000e+00
  .long  0x4ea7d613                          // fsub          v19.4s, v16.4s, v7.4s
  .long  0x4ea3d614                          // fsub          v20.4s, v16.4s, v3.4s
  .long  0x6e20de70                          // fmul          v16.4s, v19.4s, v0.4s
  .long  0x6e21de71                          // fmul          v17.4s, v19.4s, v1.4s
  .long  0x6e22de72                          // fmul          v18.4s, v19.4s, v2.4s
  .long  0x6e23de73                          // fmul          v19.4s, v19.4s, v3.4s
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4e34cc90                          // fmla          v16.4s, v4.4s, v20.4s
  .long  0x4e34ccb1                          // fmla          v17.4s, v5.4s, v20.4s
  .long  0x4e34ccd2                          // fmla          v18.4s, v6.4s, v20.4s
  .long  0x4e34ccf3                          // fmla          v19.4s, v7.4s, v20.4s
  .long  0x4e20cc90                          // fmla          v16.4s, v4.4s, v0.4s
  .long  0x4e21ccb1                          // fmla          v17.4s, v5.4s, v1.4s
  .long  0x4e22ccd2                          // fmla          v18.4s, v6.4s, v2.4s
  .long  0x4e23ccf3                          // fmla          v19.4s, v7.4s, v3.4s
  .long  0x4eb01e00                          // mov           v0.16b, v16.16b
  .long  0x4eb11e21                          // mov           v1.16b, v17.16b
  .long  0x4eb21e42                          // mov           v2.16b, v18.16b
  .long  0x4eb31e63                          // mov           v3.16b, v19.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_plus__aarch64
.globl _sk_plus__aarch64
FUNCTION(_sk_plus__aarch64)
_sk_plus__aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4e24d400                          // fadd          v0.4s, v0.4s, v4.4s
  .long  0x4e25d421                          // fadd          v1.4s, v1.4s, v5.4s
  .long  0x4e26d442                          // fadd          v2.4s, v2.4s, v6.4s
  .long  0x4e27d463                          // fadd          v3.4s, v3.4s, v7.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_screen_aarch64
.globl _sk_screen_aarch64
FUNCTION(_sk_screen_aarch64)
_sk_screen_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4e24d410                          // fadd          v16.4s, v0.4s, v4.4s
  .long  0x4e25d431                          // fadd          v17.4s, v1.4s, v5.4s
  .long  0x4e26d452                          // fadd          v18.4s, v2.4s, v6.4s
  .long  0x4e27d473                          // fadd          v19.4s, v3.4s, v7.4s
  .long  0x4ea4cc10                          // fmls          v16.4s, v0.4s, v4.4s
  .long  0x4ea5cc31                          // fmls          v17.4s, v1.4s, v5.4s
  .long  0x4ea6cc52                          // fmls          v18.4s, v2.4s, v6.4s
  .long  0x4ea7cc73                          // fmls          v19.4s, v3.4s, v7.4s
  .long  0x4eb01e00                          // mov           v0.16b, v16.16b
  .long  0x4eb11e21                          // mov           v1.16b, v17.16b
  .long  0x4eb21e42                          // mov           v2.16b, v18.16b
  .long  0x4eb31e63                          // mov           v3.16b, v19.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_xor__aarch64
.globl _sk_xor__aarch64
FUNCTION(_sk_xor__aarch64)
_sk_xor__aarch64:
  .long  0x4f03f610                          // fmov          v16.4s, #1.000000000000000000e+00
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4ea7d611                          // fsub          v17.4s, v16.4s, v7.4s
  .long  0x4ea3d610                          // fsub          v16.4s, v16.4s, v3.4s
  .long  0x6e20de20                          // fmul          v0.4s, v17.4s, v0.4s
  .long  0x6e21de21                          // fmul          v1.4s, v17.4s, v1.4s
  .long  0x6e22de22                          // fmul          v2.4s, v17.4s, v2.4s
  .long  0x6e23de23                          // fmul          v3.4s, v17.4s, v3.4s
  .long  0x4e30cc80                          // fmla          v0.4s, v4.4s, v16.4s
  .long  0x4e30cca1                          // fmla          v1.4s, v5.4s, v16.4s
  .long  0x4e30ccc2                          // fmla          v2.4s, v6.4s, v16.4s
  .long  0x4e30cce3                          // fmla          v3.4s, v7.4s, v16.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_darken_aarch64
.globl _sk_darken_aarch64
FUNCTION(_sk_darken_aarch64)
_sk_darken_aarch64:
  .long  0x6e27dc10                          // fmul          v16.4s, v0.4s, v7.4s
  .long  0x6e24dc71                          // fmul          v17.4s, v3.4s, v4.4s
  .long  0x6e27dc32                          // fmul          v18.4s, v1.4s, v7.4s
  .long  0x6e25dc73                          // fmul          v19.4s, v3.4s, v5.4s
  .long  0x4e31f610                          // fmax          v16.4s, v16.4s, v17.4s
  .long  0x4e24d400                          // fadd          v0.4s, v0.4s, v4.4s
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x6e27dc51                          // fmul          v17.4s, v2.4s, v7.4s
  .long  0x4e33f652                          // fmax          v18.4s, v18.4s, v19.4s
  .long  0x6e26dc73                          // fmul          v19.4s, v3.4s, v6.4s
  .long  0x4eb0d400                          // fsub          v0.4s, v0.4s, v16.4s
  .long  0x4f03f610                          // fmov          v16.4s, #1.000000000000000000e+00
  .long  0x4e33f631                          // fmax          v17.4s, v17.4s, v19.4s
  .long  0x4e25d421                          // fadd          v1.4s, v1.4s, v5.4s
  .long  0x4e26d442                          // fadd          v2.4s, v2.4s, v6.4s
  .long  0x4ea3d610                          // fsub          v16.4s, v16.4s, v3.4s
  .long  0x4eb2d421                          // fsub          v1.4s, v1.4s, v18.4s
  .long  0x4eb1d442                          // fsub          v2.4s, v2.4s, v17.4s
  .long  0x4e27ce03                          // fmla          v3.4s, v16.4s, v7.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_lighten_aarch64
.globl _sk_lighten_aarch64
FUNCTION(_sk_lighten_aarch64)
_sk_lighten_aarch64:
  .long  0x6e27dc10                          // fmul          v16.4s, v0.4s, v7.4s
  .long  0x6e24dc71                          // fmul          v17.4s, v3.4s, v4.4s
  .long  0x6e27dc32                          // fmul          v18.4s, v1.4s, v7.4s
  .long  0x6e25dc73                          // fmul          v19.4s, v3.4s, v5.4s
  .long  0x4eb1f610                          // fmin          v16.4s, v16.4s, v17.4s
  .long  0x4e24d400                          // fadd          v0.4s, v0.4s, v4.4s
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x6e27dc51                          // fmul          v17.4s, v2.4s, v7.4s
  .long  0x4eb3f652                          // fmin          v18.4s, v18.4s, v19.4s
  .long  0x6e26dc73                          // fmul          v19.4s, v3.4s, v6.4s
  .long  0x4eb0d400                          // fsub          v0.4s, v0.4s, v16.4s
  .long  0x4f03f610                          // fmov          v16.4s, #1.000000000000000000e+00
  .long  0x4eb3f631                          // fmin          v17.4s, v17.4s, v19.4s
  .long  0x4e25d421                          // fadd          v1.4s, v1.4s, v5.4s
  .long  0x4e26d442                          // fadd          v2.4s, v2.4s, v6.4s
  .long  0x4ea3d610                          // fsub          v16.4s, v16.4s, v3.4s
  .long  0x4eb2d421                          // fsub          v1.4s, v1.4s, v18.4s
  .long  0x4eb1d442                          // fsub          v2.4s, v2.4s, v17.4s
  .long  0x4e27ce03                          // fmla          v3.4s, v16.4s, v7.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_difference_aarch64
.globl _sk_difference_aarch64
FUNCTION(_sk_difference_aarch64)
_sk_difference_aarch64:
  .long  0x6e27dc10                          // fmul          v16.4s, v0.4s, v7.4s
  .long  0x6e24dc71                          // fmul          v17.4s, v3.4s, v4.4s
  .long  0x6e27dc32                          // fmul          v18.4s, v1.4s, v7.4s
  .long  0x6e25dc73                          // fmul          v19.4s, v3.4s, v5.4s
  .long  0x4eb1f610                          // fmin          v16.4s, v16.4s, v17.4s
  .long  0x4eb3f652                          // fmin          v18.4s, v18.4s, v19.4s
  .long  0x4e24d400                          // fadd          v0.4s, v0.4s, v4.4s
  .long  0x4e30d610                          // fadd          v16.4s, v16.4s, v16.4s
  .long  0x6e27dc51                          // fmul          v17.4s, v2.4s, v7.4s
  .long  0x6e26dc73                          // fmul          v19.4s, v3.4s, v6.4s
  .long  0x4eb0d400                          // fsub          v0.4s, v0.4s, v16.4s
  .long  0x4e25d421                          // fadd          v1.4s, v1.4s, v5.4s
  .long  0x4e32d650                          // fadd          v16.4s, v18.4s, v18.4s
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4eb3f631                          // fmin          v17.4s, v17.4s, v19.4s
  .long  0x4eb0d421                          // fsub          v1.4s, v1.4s, v16.4s
  .long  0x4f03f610                          // fmov          v16.4s, #1.000000000000000000e+00
  .long  0x4e26d442                          // fadd          v2.4s, v2.4s, v6.4s
  .long  0x4e31d631                          // fadd          v17.4s, v17.4s, v17.4s
  .long  0x4ea3d610                          // fsub          v16.4s, v16.4s, v3.4s
  .long  0x4eb1d442                          // fsub          v2.4s, v2.4s, v17.4s
  .long  0x4e27ce03                          // fmla          v3.4s, v16.4s, v7.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_exclusion_aarch64
.globl _sk_exclusion_aarch64
FUNCTION(_sk_exclusion_aarch64)
_sk_exclusion_aarch64:
  .long  0x4e24d410                          // fadd          v16.4s, v0.4s, v4.4s
  .long  0x6e24dc00                          // fmul          v0.4s, v0.4s, v4.4s
  .long  0x4e20d400                          // fadd          v0.4s, v0.4s, v0.4s
  .long  0x4ea0d600                          // fsub          v0.4s, v16.4s, v0.4s
  .long  0x4e25d430                          // fadd          v16.4s, v1.4s, v5.4s
  .long  0x6e25dc21                          // fmul          v1.4s, v1.4s, v5.4s
  .long  0x4e21d421                          // fadd          v1.4s, v1.4s, v1.4s
  .long  0x4ea1d601                          // fsub          v1.4s, v16.4s, v1.4s
  .long  0x4e26d450                          // fadd          v16.4s, v2.4s, v6.4s
  .long  0x6e26dc42                          // fmul          v2.4s, v2.4s, v6.4s
  .long  0x4e22d442                          // fadd          v2.4s, v2.4s, v2.4s
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4ea2d602                          // fsub          v2.4s, v16.4s, v2.4s
  .long  0x4f03f610                          // fmov          v16.4s, #1.000000000000000000e+00
  .long  0x4ea3d610                          // fsub          v16.4s, v16.4s, v3.4s
  .long  0x4e27ce03                          // fmla          v3.4s, v16.4s, v7.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_colorburn_aarch64
.globl _sk_colorburn_aarch64
FUNCTION(_sk_colorburn_aarch64)
_sk_colorburn_aarch64:
  .long  0x4ea4d4f3                          // fsub          v19.4s, v7.4s, v4.4s
  .long  0x6e23de73                          // fmul          v19.4s, v19.4s, v3.4s
  .long  0x4f03f611                          // fmov          v17.4s, #1.000000000000000000e+00
  .long  0x6e20fe73                          // fdiv          v19.4s, v19.4s, v0.4s
  .long  0x4ea7d634                          // fsub          v20.4s, v17.4s, v7.4s
  .long  0x4eb3f4f3                          // fmin          v19.4s, v7.4s, v19.4s
  .long  0x6e20de95                          // fmul          v21.4s, v20.4s, v0.4s
  .long  0x4eb3d4f3                          // fsub          v19.4s, v7.4s, v19.4s
  .long  0x4e24d6b6                          // fadd          v22.4s, v21.4s, v4.4s
  .long  0x4e33cc75                          // fmla          v21.4s, v3.4s, v19.4s
  .long  0x4ea5d4f3                          // fsub          v19.4s, v7.4s, v5.4s
  .long  0x6e23de73                          // fmul          v19.4s, v19.4s, v3.4s
  .long  0x6e21fe73                          // fdiv          v19.4s, v19.4s, v1.4s
  .long  0x4ea0d812                          // fcmeq         v18.4s, v0.4s, #0.0
  .long  0x4eb3f4f3                          // fmin          v19.4s, v7.4s, v19.4s
  .long  0x6e751c12                          // bsl           v18.16b, v0.16b, v21.16b
  .long  0x6e21de80                          // fmul          v0.4s, v20.4s, v1.4s
  .long  0x4eb3d4f3                          // fsub          v19.4s, v7.4s, v19.4s
  .long  0x4e25d415                          // fadd          v21.4s, v0.4s, v5.4s
  .long  0x4e33cc60                          // fmla          v0.4s, v3.4s, v19.4s
  .long  0x4ea0d833                          // fcmeq         v19.4s, v1.4s, #0.0
  .long  0x6e601c33                          // bsl           v19.16b, v1.16b, v0.16b
  .long  0x4ea6d4e0                          // fsub          v0.4s, v7.4s, v6.4s
  .long  0x6e23dc00                          // fmul          v0.4s, v0.4s, v3.4s
  .long  0x6e22fc00                          // fdiv          v0.4s, v0.4s, v2.4s
  .long  0x4ea0f4e0                          // fmin          v0.4s, v7.4s, v0.4s
  .long  0x6e22de81                          // fmul          v1.4s, v20.4s, v2.4s
  .long  0x4ea0d4e0                          // fsub          v0.4s, v7.4s, v0.4s
  .long  0x4e26d434                          // fadd          v20.4s, v1.4s, v6.4s
  .long  0x4e20cc61                          // fmla          v1.4s, v3.4s, v0.4s
  .long  0x4ea0d840                          // fcmeq         v0.4s, v2.4s, #0.0
  .long  0x4ea3d631                          // fsub          v17.4s, v17.4s, v3.4s
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4e27e490                          // fcmeq         v16.4s, v4.4s, v7.4s
  .long  0x6e611c40                          // bsl           v0.16b, v2.16b, v1.16b
  .long  0x4e31cc92                          // fmla          v18.4s, v4.4s, v17.4s
  .long  0x4e27e4a1                          // fcmeq         v1.4s, v5.4s, v7.4s
  .long  0x4e27e4c2                          // fcmeq         v2.4s, v6.4s, v7.4s
  .long  0x4e31ccb3                          // fmla          v19.4s, v5.4s, v17.4s
  .long  0x4e31ccc0                          // fmla          v0.4s, v6.4s, v17.4s
  .long  0x6e721ed0                          // bsl           v16.16b, v22.16b, v18.16b
  .long  0x6e731ea1                          // bsl           v1.16b, v21.16b, v19.16b
  .long  0x6e601e82                          // bsl           v2.16b, v20.16b, v0.16b
  .long  0x4e27ce23                          // fmla          v3.4s, v17.4s, v7.4s
  .long  0x4eb01e00                          // mov           v0.16b, v16.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_colordodge_aarch64
.globl _sk_colordodge_aarch64
FUNCTION(_sk_colordodge_aarch64)
_sk_colordodge_aarch64:
  .long  0x4f03f612                          // fmov          v18.4s, #1.000000000000000000e+00
  .long  0x6e24dc71                          // fmul          v17.4s, v3.4s, v4.4s
  .long  0x4ea0d474                          // fsub          v20.4s, v3.4s, v0.4s
  .long  0x6e25dc75                          // fmul          v21.4s, v3.4s, v5.4s
  .long  0x4ea1d476                          // fsub          v22.4s, v3.4s, v1.4s
  .long  0x4ea7d657                          // fsub          v23.4s, v18.4s, v7.4s
  .long  0x6e34fe31                          // fdiv          v17.4s, v17.4s, v20.4s
  .long  0x6e36feb4                          // fdiv          v20.4s, v21.4s, v22.4s
  .long  0x6e20def5                          // fmul          v21.4s, v23.4s, v0.4s
  .long  0x4eb1f4f1                          // fmin          v17.4s, v7.4s, v17.4s
  .long  0x4e23e413                          // fcmeq         v19.4s, v0.4s, v3.4s
  .long  0x4e24d6b6                          // fadd          v22.4s, v21.4s, v4.4s
  .long  0x4e31cc75                          // fmla          v21.4s, v3.4s, v17.4s
  .long  0x6e751c13                          // bsl           v19.16b, v0.16b, v21.16b
  .long  0x6e21dee0                          // fmul          v0.4s, v23.4s, v1.4s
  .long  0x4eb4f4f4                          // fmin          v20.4s, v7.4s, v20.4s
  .long  0x4e25d415                          // fadd          v21.4s, v0.4s, v5.4s
  .long  0x4e34cc60                          // fmla          v0.4s, v3.4s, v20.4s
  .long  0x4e23e434                          // fcmeq         v20.4s, v1.4s, v3.4s
  .long  0x6e601c34                          // bsl           v20.16b, v1.16b, v0.16b
  .long  0x6e26dc60                          // fmul          v0.4s, v3.4s, v6.4s
  .long  0x4ea2d461                          // fsub          v1.4s, v3.4s, v2.4s
  .long  0x6e21fc00                          // fdiv          v0.4s, v0.4s, v1.4s
  .long  0x6e22dee1                          // fmul          v1.4s, v23.4s, v2.4s
  .long  0x4ea0f4e0                          // fmin          v0.4s, v7.4s, v0.4s
  .long  0x4e26d437                          // fadd          v23.4s, v1.4s, v6.4s
  .long  0x4e20cc61                          // fmla          v1.4s, v3.4s, v0.4s
  .long  0x4e23e440                          // fcmeq         v0.4s, v2.4s, v3.4s
  .long  0x6e611c40                          // bsl           v0.16b, v2.16b, v1.16b
  .long  0x4ea3d641                          // fsub          v1.4s, v18.4s, v3.4s
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4ea0d890                          // fcmeq         v16.4s, v4.4s, #0.0
  .long  0x4ea0d8b1                          // fcmeq         v17.4s, v5.4s, #0.0
  .long  0x4e21cc93                          // fmla          v19.4s, v4.4s, v1.4s
  .long  0x4e21ccb4                          // fmla          v20.4s, v5.4s, v1.4s
  .long  0x4ea0d8c2                          // fcmeq         v2.4s, v6.4s, #0.0
  .long  0x4e21ccc0                          // fmla          v0.4s, v6.4s, v1.4s
  .long  0x6e731ed0                          // bsl           v16.16b, v22.16b, v19.16b
  .long  0x6e741eb1                          // bsl           v17.16b, v21.16b, v20.16b
  .long  0x6e601ee2                          // bsl           v2.16b, v23.16b, v0.16b
  .long  0x4e27cc23                          // fmla          v3.4s, v1.4s, v7.4s
  .long  0x4eb01e00                          // mov           v0.16b, v16.16b
  .long  0x4eb11e21                          // mov           v1.16b, v17.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_hardlight_aarch64
.globl _sk_hardlight_aarch64
FUNCTION(_sk_hardlight_aarch64)
_sk_hardlight_aarch64:
  .long  0x4ea4d4f4                          // fsub          v20.4s, v7.4s, v4.4s
  .long  0x4ea0d475                          // fsub          v21.4s, v3.4s, v0.4s
  .long  0x6e34deb4                          // fmul          v20.4s, v21.4s, v20.4s
  .long  0x4e20d411                          // fadd          v17.4s, v0.4s, v0.4s
  .long  0x6e24dc12                          // fmul          v18.4s, v0.4s, v4.4s
  .long  0x6e27dc73                          // fmul          v19.4s, v3.4s, v7.4s
  .long  0x4e34d694                          // fadd          v20.4s, v20.4s, v20.4s
  .long  0x6e31e471                          // fcmge         v17.4s, v3.4s, v17.4s
  .long  0x4e32d652                          // fadd          v18.4s, v18.4s, v18.4s
  .long  0x4eb4d674                          // fsub          v20.4s, v19.4s, v20.4s
  .long  0x6e741e51                          // bsl           v17.16b, v18.16b, v20.16b
  .long  0x4ea5d4f2                          // fsub          v18.4s, v7.4s, v5.4s
  .long  0x4ea1d474                          // fsub          v20.4s, v3.4s, v1.4s
  .long  0x6e32de92                          // fmul          v18.4s, v20.4s, v18.4s
  .long  0x4e21d436                          // fadd          v22.4s, v1.4s, v1.4s
  .long  0x6e25dc35                          // fmul          v21.4s, v1.4s, v5.4s
  .long  0x4e32d652                          // fadd          v18.4s, v18.4s, v18.4s
  .long  0x6e36e476                          // fcmge         v22.4s, v3.4s, v22.4s
  .long  0x4e35d6b5                          // fadd          v21.4s, v21.4s, v21.4s
  .long  0x4eb2d672                          // fsub          v18.4s, v19.4s, v18.4s
  .long  0x4f03f610                          // fmov          v16.4s, #1.000000000000000000e+00
  .long  0x6e721eb6                          // bsl           v22.16b, v21.16b, v18.16b
  .long  0x4ea6d4f2                          // fsub          v18.4s, v7.4s, v6.4s
  .long  0x4ea2d475                          // fsub          v21.4s, v3.4s, v2.4s
  .long  0x6e32deb2                          // fmul          v18.4s, v21.4s, v18.4s
  .long  0x4ea7d615                          // fsub          v21.4s, v16.4s, v7.4s
  .long  0x4e22d454                          // fadd          v20.4s, v2.4s, v2.4s
  .long  0x6e20dea0                          // fmul          v0.4s, v21.4s, v0.4s
  .long  0x6e21dea1                          // fmul          v1.4s, v21.4s, v1.4s
  .long  0x6e22deb5                          // fmul          v21.4s, v21.4s, v2.4s
  .long  0x6e26dc42                          // fmul          v2.4s, v2.4s, v6.4s
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4e32d652                          // fadd          v18.4s, v18.4s, v18.4s
  .long  0x4ea3d610                          // fsub          v16.4s, v16.4s, v3.4s
  .long  0x6e34e474                          // fcmge         v20.4s, v3.4s, v20.4s
  .long  0x4e22d442                          // fadd          v2.4s, v2.4s, v2.4s
  .long  0x4eb2d672                          // fsub          v18.4s, v19.4s, v18.4s
  .long  0x4e30cc80                          // fmla          v0.4s, v4.4s, v16.4s
  .long  0x4e30cca1                          // fmla          v1.4s, v5.4s, v16.4s
  .long  0x4e30ccd5                          // fmla          v21.4s, v6.4s, v16.4s
  .long  0x6e721c54                          // bsl           v20.16b, v2.16b, v18.16b
  .long  0x4e31d400                          // fadd          v0.4s, v0.4s, v17.4s
  .long  0x4e36d421                          // fadd          v1.4s, v1.4s, v22.4s
  .long  0x4e34d6a2                          // fadd          v2.4s, v21.4s, v20.4s
  .long  0x4e27ce03                          // fmla          v3.4s, v16.4s, v7.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_overlay_aarch64
.globl _sk_overlay_aarch64
FUNCTION(_sk_overlay_aarch64)
_sk_overlay_aarch64:
  .long  0x4ea4d4f4                          // fsub          v20.4s, v7.4s, v4.4s
  .long  0x4ea0d475                          // fsub          v21.4s, v3.4s, v0.4s
  .long  0x6e34deb4                          // fmul          v20.4s, v21.4s, v20.4s
  .long  0x4e24d491                          // fadd          v17.4s, v4.4s, v4.4s
  .long  0x6e24dc12                          // fmul          v18.4s, v0.4s, v4.4s
  .long  0x6e27dc73                          // fmul          v19.4s, v3.4s, v7.4s
  .long  0x4e34d694                          // fadd          v20.4s, v20.4s, v20.4s
  .long  0x6e31e4f1                          // fcmge         v17.4s, v7.4s, v17.4s
  .long  0x4e32d652                          // fadd          v18.4s, v18.4s, v18.4s
  .long  0x4eb4d674                          // fsub          v20.4s, v19.4s, v20.4s
  .long  0x6e741e51                          // bsl           v17.16b, v18.16b, v20.16b
  .long  0x4ea5d4f2                          // fsub          v18.4s, v7.4s, v5.4s
  .long  0x4ea1d474                          // fsub          v20.4s, v3.4s, v1.4s
  .long  0x6e32de92                          // fmul          v18.4s, v20.4s, v18.4s
  .long  0x4e25d4b6                          // fadd          v22.4s, v5.4s, v5.4s
  .long  0x6e25dc35                          // fmul          v21.4s, v1.4s, v5.4s
  .long  0x4e32d652                          // fadd          v18.4s, v18.4s, v18.4s
  .long  0x6e36e4f6                          // fcmge         v22.4s, v7.4s, v22.4s
  .long  0x4e35d6b5                          // fadd          v21.4s, v21.4s, v21.4s
  .long  0x4eb2d672                          // fsub          v18.4s, v19.4s, v18.4s
  .long  0x4f03f610                          // fmov          v16.4s, #1.000000000000000000e+00
  .long  0x6e721eb6                          // bsl           v22.16b, v21.16b, v18.16b
  .long  0x4ea6d4f2                          // fsub          v18.4s, v7.4s, v6.4s
  .long  0x4ea2d475                          // fsub          v21.4s, v3.4s, v2.4s
  .long  0x6e32deb2                          // fmul          v18.4s, v21.4s, v18.4s
  .long  0x4ea7d615                          // fsub          v21.4s, v16.4s, v7.4s
  .long  0x4e26d4d4                          // fadd          v20.4s, v6.4s, v6.4s
  .long  0x6e20dea0                          // fmul          v0.4s, v21.4s, v0.4s
  .long  0x6e21dea1                          // fmul          v1.4s, v21.4s, v1.4s
  .long  0x6e22deb5                          // fmul          v21.4s, v21.4s, v2.4s
  .long  0x6e26dc42                          // fmul          v2.4s, v2.4s, v6.4s
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4e32d652                          // fadd          v18.4s, v18.4s, v18.4s
  .long  0x4ea3d610                          // fsub          v16.4s, v16.4s, v3.4s
  .long  0x6e34e4f4                          // fcmge         v20.4s, v7.4s, v20.4s
  .long  0x4e22d442                          // fadd          v2.4s, v2.4s, v2.4s
  .long  0x4eb2d672                          // fsub          v18.4s, v19.4s, v18.4s
  .long  0x4e30cc80                          // fmla          v0.4s, v4.4s, v16.4s
  .long  0x4e30cca1                          // fmla          v1.4s, v5.4s, v16.4s
  .long  0x4e30ccd5                          // fmla          v21.4s, v6.4s, v16.4s
  .long  0x6e721c54                          // bsl           v20.16b, v2.16b, v18.16b
  .long  0x4e31d400                          // fadd          v0.4s, v0.4s, v17.4s
  .long  0x4e36d421                          // fadd          v1.4s, v1.4s, v22.4s
  .long  0x4e34d6a2                          // fadd          v2.4s, v21.4s, v20.4s
  .long  0x4e27ce03                          // fmla          v3.4s, v16.4s, v7.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_softlight_aarch64
.globl _sk_softlight_aarch64
FUNCTION(_sk_softlight_aarch64)
_sk_softlight_aarch64:
  .long  0x4ea0c8f5                          // fcmgt         v21.4s, v7.4s, #0.0
  .long  0x6e27fc96                          // fdiv          v22.4s, v4.4s, v7.4s
  .long  0x6e27fcb8                          // fdiv          v24.4s, v5.4s, v7.4s
  .long  0x6e27fcd9                          // fdiv          v25.4s, v6.4s, v7.4s
  .long  0x4e351ed6                          // and           v22.16b, v22.16b, v21.16b
  .long  0x4e351f18                          // and           v24.16b, v24.16b, v21.16b
  .long  0x4e351f35                          // and           v21.16b, v25.16b, v21.16b
  .long  0x6ea1dad9                          // frsqrte       v25.4s, v22.4s
  .long  0x6e39df3d                          // fmul          v29.4s, v25.4s, v25.4s
  .long  0x4ebdfedd                          // frsqrts       v29.4s, v22.4s, v29.4s
  .long  0x6e3ddf39                          // fmul          v25.4s, v25.4s, v29.4s
  .long  0x4ea1db3d                          // frecpe        v29.4s, v25.4s
  .long  0x6ea0fada                          // fneg          v26.4s, v22.4s
  .long  0x6ea1db1b                          // frsqrte       v27.4s, v24.4s
  .long  0x4e3dff39                          // frecps        v25.4s, v25.4s, v29.4s
  .long  0x4e3dcf3a                          // fmla          v26.4s, v25.4s, v29.4s
  .long  0x6e3bdf7d                          // fmul          v29.4s, v27.4s, v27.4s
  .long  0x4ebdff1d                          // frsqrts       v29.4s, v24.4s, v29.4s
  .long  0x6e3ddf7b                          // fmul          v27.4s, v27.4s, v29.4s
  .long  0x4ea1db7d                          // frecpe        v29.4s, v27.4s
  .long  0x6ea0fb1c                          // fneg          v28.4s, v24.4s
  .long  0x6ea1dab9                          // frsqrte       v25.4s, v21.4s
  .long  0x4e3dff7b                          // frecps        v27.4s, v27.4s, v29.4s
  .long  0x4e3dcf7c                          // fmla          v28.4s, v27.4s, v29.4s
  .long  0x6e39df3d                          // fmul          v29.4s, v25.4s, v25.4s
  .long  0x4ebdfebd                          // frsqrts       v29.4s, v21.4s, v29.4s
  .long  0x6e3ddf39                          // fmul          v25.4s, v25.4s, v29.4s
  .long  0x4ea1db3d                          // frecpe        v29.4s, v25.4s
  .long  0x6ea0fabb                          // fneg          v27.4s, v21.4s
  .long  0x4e3dff39                          // frecps        v25.4s, v25.4s, v29.4s
  .long  0x4e3dcf3b                          // fmla          v27.4s, v25.4s, v29.4s
  .long  0x4e36d6d9                          // fadd          v25.4s, v22.4s, v22.4s
  .long  0x4f07f613                          // fmov          v19.4s, #-1.000000000000000000e+00
  .long  0x4e39d739                          // fadd          v25.4s, v25.4s, v25.4s
  .long  0x4e24d497                          // fadd          v23.4s, v4.4s, v4.4s
  .long  0x4e33d6dd                          // fadd          v29.4s, v22.4s, v19.4s
  .long  0x4e39cf39                          // fmla          v25.4s, v25.4s, v25.4s
  .long  0x4f00f794                          // fmov          v20.4s, #7.000000000000000000e+00
  .long  0x6e39dfb9                          // fmul          v25.4s, v29.4s, v25.4s
  .long  0x4e37d6f7                          // fadd          v23.4s, v23.4s, v23.4s
  .long  0x6e37e4f7                          // fcmge         v23.4s, v7.4s, v23.4s
  .long  0x4e36ce99                          // fmla          v25.4s, v20.4s, v22.4s
  .long  0x6e7a1f37                          // bsl           v23.16b, v25.16b, v26.16b
  .long  0x4e38d719                          // fadd          v25.4s, v24.4s, v24.4s
  .long  0x4e39d739                          // fadd          v25.4s, v25.4s, v25.4s
  .long  0x4e33d71a                          // fadd          v26.4s, v24.4s, v19.4s
  .long  0x4e39cf39                          // fmla          v25.4s, v25.4s, v25.4s
  .long  0x6e39df59                          // fmul          v25.4s, v26.4s, v25.4s
  .long  0x4e25d4ba                          // fadd          v26.4s, v5.4s, v5.4s
  .long  0x4e3ad75a                          // fadd          v26.4s, v26.4s, v26.4s
  .long  0x6e3ae4fa                          // fcmge         v26.4s, v7.4s, v26.4s
  .long  0x4e38ce99                          // fmla          v25.4s, v20.4s, v24.4s
  .long  0x6e7c1f3a                          // bsl           v26.16b, v25.16b, v28.16b
  .long  0x4e35d6bc                          // fadd          v28.4s, v21.4s, v21.4s
  .long  0x4e3cd79c                          // fadd          v28.4s, v28.4s, v28.4s
  .long  0x4e33d6b3                          // fadd          v19.4s, v21.4s, v19.4s
  .long  0x4e3ccf9c                          // fmla          v28.4s, v28.4s, v28.4s
  .long  0x6e3cde73                          // fmul          v19.4s, v19.4s, v28.4s
  .long  0x4e35ce93                          // fmla          v19.4s, v20.4s, v21.4s
  .long  0x4e26d4d4                          // fadd          v20.4s, v6.4s, v6.4s
  .long  0x4e34d694                          // fadd          v20.4s, v20.4s, v20.4s
  .long  0x4f03f612                          // fmov          v18.4s, #1.000000000000000000e+00
  .long  0x6e34e4f4                          // fcmge         v20.4s, v7.4s, v20.4s
  .long  0x4e20d411                          // fadd          v17.4s, v0.4s, v0.4s
  .long  0x6e7b1e74                          // bsl           v20.16b, v19.16b, v27.16b
  .long  0x4ea7d65b                          // fsub          v27.4s, v18.4s, v7.4s
  .long  0x4ea31c70                          // mov           v16.16b, v3.16b
  .long  0x4e21d43d                          // fadd          v29.4s, v1.4s, v1.4s
  .long  0x4e22d45c                          // fadd          v28.4s, v2.4s, v2.4s
  .long  0x6e20df60                          // fmul          v0.4s, v27.4s, v0.4s
  .long  0x6e21df61                          // fmul          v1.4s, v27.4s, v1.4s
  .long  0x6e22df62                          // fmul          v2.4s, v27.4s, v2.4s
  .long  0x4ea3d63b                          // fsub          v27.4s, v17.4s, v3.4s
  .long  0x4eb6d656                          // fsub          v22.4s, v18.4s, v22.4s
  .long  0x4ea31c79                          // mov           v25.16b, v3.16b
  .long  0x4e3bced0                          // fmla          v16.4s, v22.4s, v27.4s
  .long  0x4ea3d7b6                          // fsub          v22.4s, v29.4s, v3.4s
  .long  0x4eb8d658                          // fsub          v24.4s, v18.4s, v24.4s
  .long  0x4ea31c73                          // mov           v19.16b, v3.16b
  .long  0x4e36cf19                          // fmla          v25.4s, v24.4s, v22.4s
  .long  0x4ea3d798                          // fsub          v24.4s, v28.4s, v3.4s
  .long  0x4eb5d655                          // fsub          v21.4s, v18.4s, v21.4s
  .long  0x4e38ceb3                          // fmla          v19.4s, v21.4s, v24.4s
  .long  0x6e27df7b                          // fmul          v27.4s, v27.4s, v7.4s
  .long  0x6e27ded6                          // fmul          v22.4s, v22.4s, v7.4s
  .long  0x6e27df18                          // fmul          v24.4s, v24.4s, v7.4s
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x6e37df77                          // fmul          v23.4s, v27.4s, v23.4s
  .long  0x6e3aded6                          // fmul          v22.4s, v22.4s, v26.4s
  .long  0x6e34df14                          // fmul          v20.4s, v24.4s, v20.4s
  .long  0x4ea3d652                          // fsub          v18.4s, v18.4s, v3.4s
  .long  0x6e31e471                          // fcmge         v17.4s, v3.4s, v17.4s
  .long  0x6e3de475                          // fcmge         v21.4s, v3.4s, v29.4s
  .long  0x6e3ce47c                          // fcmge         v28.4s, v3.4s, v28.4s
  .long  0x6e24de10                          // fmul          v16.4s, v16.4s, v4.4s
  .long  0x6e25df39                          // fmul          v25.4s, v25.4s, v5.4s
  .long  0x6e26de73                          // fmul          v19.4s, v19.4s, v6.4s
  .long  0x4e23cc97                          // fmla          v23.4s, v4.4s, v3.4s
  .long  0x4e23ccb6                          // fmla          v22.4s, v5.4s, v3.4s
  .long  0x4e23ccd4                          // fmla          v20.4s, v6.4s, v3.4s
  .long  0x4e32cc80                          // fmla          v0.4s, v4.4s, v18.4s
  .long  0x4e32cca1                          // fmla          v1.4s, v5.4s, v18.4s
  .long  0x4e32ccc2                          // fmla          v2.4s, v6.4s, v18.4s
  .long  0x6e771e11                          // bsl           v17.16b, v16.16b, v23.16b
  .long  0x6e761f35                          // bsl           v21.16b, v25.16b, v22.16b
  .long  0x6e741e7c                          // bsl           v28.16b, v19.16b, v20.16b
  .long  0x4e31d400                          // fadd          v0.4s, v0.4s, v17.4s
  .long  0x4e35d421                          // fadd          v1.4s, v1.4s, v21.4s
  .long  0x4e3cd442                          // fadd          v2.4s, v2.4s, v28.4s
  .long  0x4e27ce43                          // fmla          v3.4s, v18.4s, v7.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_clamp_0_aarch64
.globl _sk_clamp_0_aarch64
FUNCTION(_sk_clamp_0_aarch64)
_sk_clamp_0_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x6f00e410                          // movi          v16.2d, #0x0
  .long  0x4e30f400                          // fmax          v0.4s, v0.4s, v16.4s
  .long  0x4e30f421                          // fmax          v1.4s, v1.4s, v16.4s
  .long  0x4e30f442                          // fmax          v2.4s, v2.4s, v16.4s
  .long  0x4e30f463                          // fmax          v3.4s, v3.4s, v16.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_clamp_1_aarch64
.globl _sk_clamp_1_aarch64
FUNCTION(_sk_clamp_1_aarch64)
_sk_clamp_1_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4f03f610                          // fmov          v16.4s, #1.000000000000000000e+00
  .long  0x4eb0f400                          // fmin          v0.4s, v0.4s, v16.4s
  .long  0x4eb0f421                          // fmin          v1.4s, v1.4s, v16.4s
  .long  0x4eb0f442                          // fmin          v2.4s, v2.4s, v16.4s
  .long  0x4eb0f463                          // fmin          v3.4s, v3.4s, v16.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_clamp_a_aarch64
.globl _sk_clamp_a_aarch64
FUNCTION(_sk_clamp_a_aarch64)
_sk_clamp_a_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4f03f610                          // fmov          v16.4s, #1.000000000000000000e+00
  .long  0x4eb0f463                          // fmin          v3.4s, v3.4s, v16.4s
  .long  0x4ea3f400                          // fmin          v0.4s, v0.4s, v3.4s
  .long  0x4ea3f421                          // fmin          v1.4s, v1.4s, v3.4s
  .long  0x4ea3f442                          // fmin          v2.4s, v2.4s, v3.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_set_rgb_aarch64
.globl _sk_set_rgb_aarch64
FUNCTION(_sk_set_rgb_aarch64)
_sk_set_rgb_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xaa0803e9                          // mov           x9, x8
  .long  0x4ddfc920                          // ld1r          {v0.4s}, [x9], #4
  .long  0x91002108                          // add           x8, x8, #0x8
  .long  0x4d40c902                          // ld1r          {v2.4s}, [x8]
  .long  0x4d40c921                          // ld1r          {v1.4s}, [x9]
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_swap_rb_aarch64
.globl _sk_swap_rb_aarch64
FUNCTION(_sk_swap_rb_aarch64)
_sk_swap_rb_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4ea01c10                          // mov           v16.16b, v0.16b
  .long  0x4ea21c40                          // mov           v0.16b, v2.16b
  .long  0x4eb01e02                          // mov           v2.16b, v16.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_swap_aarch64
.globl _sk_swap_aarch64
FUNCTION(_sk_swap_aarch64)
_sk_swap_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4ea31c70                          // mov           v16.16b, v3.16b
  .long  0x4ea21c51                          // mov           v17.16b, v2.16b
  .long  0x4ea11c32                          // mov           v18.16b, v1.16b
  .long  0x4ea01c13                          // mov           v19.16b, v0.16b
  .long  0x4ea41c80                          // mov           v0.16b, v4.16b
  .long  0x4ea51ca1                          // mov           v1.16b, v5.16b
  .long  0x4ea61cc2                          // mov           v2.16b, v6.16b
  .long  0x4ea71ce3                          // mov           v3.16b, v7.16b
  .long  0x4eb31e64                          // mov           v4.16b, v19.16b
  .long  0x4eb21e45                          // mov           v5.16b, v18.16b
  .long  0x4eb11e26                          // mov           v6.16b, v17.16b
  .long  0x4eb01e07                          // mov           v7.16b, v16.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_move_src_dst_aarch64
.globl _sk_move_src_dst_aarch64
FUNCTION(_sk_move_src_dst_aarch64)
_sk_move_src_dst_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4ea01c04                          // mov           v4.16b, v0.16b
  .long  0x4ea11c25                          // mov           v5.16b, v1.16b
  .long  0x4ea21c46                          // mov           v6.16b, v2.16b
  .long  0x4ea31c67                          // mov           v7.16b, v3.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_move_dst_src_aarch64
.globl _sk_move_dst_src_aarch64
FUNCTION(_sk_move_dst_src_aarch64)
_sk_move_dst_src_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4ea41c80                          // mov           v0.16b, v4.16b
  .long  0x4ea51ca1                          // mov           v1.16b, v5.16b
  .long  0x4ea61cc2                          // mov           v2.16b, v6.16b
  .long  0x4ea71ce3                          // mov           v3.16b, v7.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_premul_aarch64
.globl _sk_premul_aarch64
FUNCTION(_sk_premul_aarch64)
_sk_premul_aarch64:
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x6e23dc00                          // fmul          v0.4s, v0.4s, v3.4s
  .long  0x6e23dc21                          // fmul          v1.4s, v1.4s, v3.4s
  .long  0x6e23dc42                          // fmul          v2.4s, v2.4s, v3.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_unpremul_aarch64
.globl _sk_unpremul_aarch64
FUNCTION(_sk_unpremul_aarch64)
_sk_unpremul_aarch64:
  .long  0x4f03f611                          // fmov          v17.4s, #1.000000000000000000e+00
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4ea0d870                          // fcmeq         v16.4s, v3.4s, #0.0
  .long  0x6e23fe31                          // fdiv          v17.4s, v17.4s, v3.4s
  .long  0x4e701e30                          // bic           v16.16b, v17.16b, v16.16b
  .long  0x6e20de00                          // fmul          v0.4s, v16.4s, v0.4s
  .long  0x6e21de01                          // fmul          v1.4s, v16.4s, v1.4s
  .long  0x6e22de02                          // fmul          v2.4s, v16.4s, v2.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_from_srgb_aarch64
.globl _sk_from_srgb_aarch64
FUNCTION(_sk_from_srgb_aarch64)
_sk_from_srgb_aarch64:
  .long  0x52a7d328                          // mov           w8, #0x3e990000
  .long  0x72933348                          // movk          w8, #0x999a
  .long  0x4e040d10                          // dup           v16.4s, w8
  .long  0x52a7e648                          // mov           w8, #0x3f320000
  .long  0x7291eb88                          // movk          w8, #0x8f5c
  .long  0x4e040d11                          // dup           v17.4s, w8
  .long  0x52a76468                          // mov           w8, #0x3b230000
  .long  0x729ae148                          // movk          w8, #0xd70a
  .long  0x4e040d12                          // dup           v18.4s, w8
  .long  0x52a7b3c8                          // mov           w8, #0x3d9e0000
  .long  0x72907228                          // movk          w8, #0x8391
  .long  0x6e22dc54                          // fmul          v20.4s, v2.4s, v2.4s
  .long  0x4eb11e35                          // mov           v21.16b, v17.16b
  .long  0x4eb11e37                          // mov           v23.16b, v17.16b
  .long  0x4e22ce11                          // fmla          v17.4s, v16.4s, v2.4s
  .long  0x4eb21e56                          // mov           v22.16b, v18.16b
  .long  0x4eb21e58                          // mov           v24.16b, v18.16b
  .long  0x4e34ce32                          // fmla          v18.4s, v17.4s, v20.4s
  .long  0x4e040d11                          // dup           v17.4s, w8
  .long  0x52a7ac28                          // mov           w8, #0x3d610000
  .long  0x6e20dc13                          // fmul          v19.4s, v0.4s, v0.4s
  .long  0x7288f5c8                          // movk          w8, #0x47ae
  .long  0x4e20ce15                          // fmla          v21.4s, v16.4s, v0.4s
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x6e21dc34                          // fmul          v20.4s, v1.4s, v1.4s
  .long  0x4e33ceb6                          // fmla          v22.4s, v21.4s, v19.4s
  .long  0x4e040d13                          // dup           v19.4s, w8
  .long  0x4e21ce17                          // fmla          v23.4s, v16.4s, v1.4s
  .long  0x6e31dc15                          // fmul          v21.4s, v0.4s, v17.4s
  .long  0x6ea0e660                          // fcmgt         v0.4s, v19.4s, v0.4s
  .long  0x6e31dc30                          // fmul          v16.4s, v1.4s, v17.4s
  .long  0x6ea1e661                          // fcmgt         v1.4s, v19.4s, v1.4s
  .long  0x6e31dc51                          // fmul          v17.4s, v2.4s, v17.4s
  .long  0x6ea2e662                          // fcmgt         v2.4s, v19.4s, v2.4s
  .long  0x4e34cef8                          // fmla          v24.4s, v23.4s, v20.4s
  .long  0x6e761ea0                          // bsl           v0.16b, v21.16b, v22.16b
  .long  0x6e781e01                          // bsl           v1.16b, v16.16b, v24.16b
  .long  0x6e721e22                          // bsl           v2.16b, v17.16b, v18.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_to_srgb_aarch64
.globl _sk_to_srgb_aarch64
FUNCTION(_sk_to_srgb_aarch64)
_sk_to_srgb_aarch64:
  .long  0x52a828e8                          // mov           w8, #0x41470000
  .long  0x728b8528                          // movk          w8, #0x5c29
  .long  0x4e040d12                          // dup           v18.4s, w8
  .long  0x52a7e608                          // mov           w8, #0x3f300000
  .long  0x728df9c8                          // movk          w8, #0x6fce
  .long  0x6ea1d811                          // frsqrte       v17.4s, v0.4s
  .long  0x4e040d13                          // dup           v19.4s, w8
  .long  0x52b7b948                          // mov           w8, #0xbdca0000
  .long  0x728af508                          // movk          w8, #0x57a8
  .long  0x6ea1d834                          // frsqrte       v20.4s, v1.4s
  .long  0x6e31de36                          // fmul          v22.4s, v17.4s, v17.4s
  .long  0x4e040d10                          // dup           v16.4s, w8
  .long  0x52a77188                          // mov           w8, #0x3b8c0000
  .long  0x6ea1d855                          // frsqrte       v21.4s, v2.4s
  .long  0x6e34de98                          // fmul          v24.4s, v20.4s, v20.4s
  .long  0x4eb6fc16                          // frsqrts       v22.4s, v0.4s, v22.4s
  .long  0x729ce088                          // movk          w8, #0xe704
  .long  0x6e35deb9                          // fmul          v25.4s, v21.4s, v21.4s
  .long  0x4eb8fc38                          // frsqrts       v24.4s, v1.4s, v24.4s
  .long  0x6e36de31                          // fmul          v17.4s, v17.4s, v22.4s
  .long  0x4e040d17                          // dup           v23.4s, w8
  .long  0x4eb9fc59                          // frsqrts       v25.4s, v2.4s, v25.4s
  .long  0x6e38de94                          // fmul          v20.4s, v20.4s, v24.4s
  .long  0x4ea1da36                          // frecpe        v22.4s, v17.4s
  .long  0x6e32dc1a                          // fmul          v26.4s, v0.4s, v18.4s
  .long  0x6ea0e6e0                          // fcmgt         v0.4s, v23.4s, v0.4s
  .long  0x6e32dc3c                          // fmul          v28.4s, v1.4s, v18.4s
  .long  0x6ea1e6e1                          // fcmgt         v1.4s, v23.4s, v1.4s
  .long  0x6e32dc52                          // fmul          v18.4s, v2.4s, v18.4s
  .long  0x6ea2e6e2                          // fcmgt         v2.4s, v23.4s, v2.4s
  .long  0x6e39deb5                          // fmul          v21.4s, v21.4s, v25.4s
  .long  0x4ea1da97                          // frecpe        v23.4s, v20.4s
  .long  0x4e36fe39                          // frecps        v25.4s, v17.4s, v22.4s
  .long  0x4ea1dab8                          // frecpe        v24.4s, v21.4s
  .long  0x6e39ded6                          // fmul          v22.4s, v22.4s, v25.4s
  .long  0x4e37fe99                          // frecps        v25.4s, v20.4s, v23.4s
  .long  0x4eb01e1b                          // mov           v27.16b, v16.16b
  .long  0x6e39def7                          // fmul          v23.4s, v23.4s, v25.4s
  .long  0x4e38feb9                          // frecps        v25.4s, v21.4s, v24.4s
  .long  0x6e39df18                          // fmul          v24.4s, v24.4s, v25.4s
  .long  0x4eb01e19                          // mov           v25.16b, v16.16b
  .long  0x4e36ce7b                          // fmla          v27.4s, v19.4s, v22.4s
  .long  0x6ea1da36                          // frsqrte       v22.4s, v17.4s
  .long  0x4e37ce79                          // fmla          v25.4s, v19.4s, v23.4s
  .long  0x6ea1da97                          // frsqrte       v23.4s, v20.4s
  .long  0x4e38ce70                          // fmla          v16.4s, v19.4s, v24.4s
  .long  0x6e36ded8                          // fmul          v24.4s, v22.4s, v22.4s
  .long  0x6ea1dab3                          // frsqrte       v19.4s, v21.4s
  .long  0x4eb8fe31                          // frsqrts       v17.4s, v17.4s, v24.4s
  .long  0x6e37def8                          // fmul          v24.4s, v23.4s, v23.4s
  .long  0x4eb8fe94                          // frsqrts       v20.4s, v20.4s, v24.4s
  .long  0x6e33de78                          // fmul          v24.4s, v19.4s, v19.4s
  .long  0x52a7da48                          // mov           w8, #0x3ed20000
  .long  0x4eb8feb5                          // frsqrts       v21.4s, v21.4s, v24.4s
  .long  0x7290f848                          // movk          w8, #0x87c2
  .long  0x6e31ded1                          // fmul          v17.4s, v22.4s, v17.4s
  .long  0x6e34def4                          // fmul          v20.4s, v23.4s, v20.4s
  .long  0x6e35de73                          // fmul          v19.4s, v19.4s, v21.4s
  .long  0x4e040d15                          // dup           v21.4s, w8
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4e31cebb                          // fmla          v27.4s, v21.4s, v17.4s
  .long  0x4f03f611                          // fmov          v17.4s, #1.000000000000000000e+00
  .long  0x4e34ceb9                          // fmla          v25.4s, v21.4s, v20.4s
  .long  0x4e33ceb0                          // fmla          v16.4s, v21.4s, v19.4s
  .long  0x4ebbf633                          // fmin          v19.4s, v17.4s, v27.4s
  .long  0x4eb9f634                          // fmin          v20.4s, v17.4s, v25.4s
  .long  0x4eb0f630                          // fmin          v16.4s, v17.4s, v16.4s
  .long  0x6e731f40                          // bsl           v0.16b, v26.16b, v19.16b
  .long  0x6e741f81                          // bsl           v1.16b, v28.16b, v20.16b
  .long  0x6e701e42                          // bsl           v2.16b, v18.16b, v16.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_rgb_to_hsl_aarch64
.globl _sk_rgb_to_hsl_aarch64
FUNCTION(_sk_rgb_to_hsl_aarch64)
_sk_rgb_to_hsl_aarch64:
  .long  0x4e21f410                          // fmax          v16.4s, v0.4s, v1.4s
  .long  0x4ea1f411                          // fmin          v17.4s, v0.4s, v1.4s
  .long  0x6ea1e454                          // fcmgt         v20.4s, v2.4s, v1.4s
  .long  0x4f00f715                          // fmov          v21.4s, #6.000000000000000000e+00
  .long  0x4e22f610                          // fmax          v16.4s, v16.4s, v2.4s
  .long  0x4ea2f631                          // fmin          v17.4s, v17.4s, v2.4s
  .long  0x4f03f612                          // fmov          v18.4s, #1.000000000000000000e+00
  .long  0x4e341eb4                          // and           v20.16b, v21.16b, v20.16b
  .long  0x4eb1d615                          // fsub          v21.4s, v16.4s, v17.4s
  .long  0x4ea2d433                          // fsub          v19.4s, v1.4s, v2.4s
  .long  0x4ea0d456                          // fsub          v22.4s, v2.4s, v0.4s
  .long  0x4f026417                          // movi          v23.4s, #0x40, lsl #24
  .long  0x6e35fe42                          // fdiv          v2.4s, v18.4s, v21.4s
  .long  0x4ea1d418                          // fsub          v24.4s, v0.4s, v1.4s
  .long  0x4f00f619                          // fmov          v25.4s, #4.000000000000000000e+00
  .long  0x4f0167fa                          // movi          v26.4s, #0x3f, lsl #24
  .long  0x4eb0d6f2                          // fsub          v18.4s, v23.4s, v16.4s
  .long  0x4e36cc57                          // fmla          v23.4s, v2.4s, v22.4s
  .long  0x4e31e616                          // fcmeq         v22.4s, v16.4s, v17.4s
  .long  0x4e20e600                          // fcmeq         v0.4s, v16.4s, v0.4s
  .long  0x4e21e601                          // fcmeq         v1.4s, v16.4s, v1.4s
  .long  0x4e31d610                          // fadd          v16.4s, v16.4s, v17.4s
  .long  0x52a7c548                          // mov           w8, #0x3e2a0000
  .long  0x4e33cc54                          // fmla          v20.4s, v2.4s, v19.4s
  .long  0x4e38cc59                          // fmla          v25.4s, v2.4s, v24.4s
  .long  0x6e3ade02                          // fmul          v2.4s, v16.4s, v26.4s
  .long  0x72955568                          // movk          w8, #0xaaab
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4eb1d651                          // fsub          v17.4s, v18.4s, v17.4s
  .long  0x6ebae452                          // fcmgt         v18.4s, v2.4s, v26.4s
  .long  0x6e791ee1                          // bsl           v1.16b, v23.16b, v25.16b
  .long  0x4e040d13                          // dup           v19.4s, w8
  .long  0x6e701e32                          // bsl           v18.16b, v17.16b, v16.16b
  .long  0x6e611e80                          // bsl           v0.16b, v20.16b, v1.16b
  .long  0x6e32fea1                          // fdiv          v1.4s, v21.4s, v18.4s
  .long  0x6e33dc00                          // fmul          v0.4s, v0.4s, v19.4s
  .long  0x4e761c00                          // bic           v0.16b, v0.16b, v22.16b
  .long  0x4e761c21                          // bic           v1.16b, v1.16b, v22.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_hsl_to_rgb_aarch64
.globl _sk_hsl_to_rgb_aarch64
FUNCTION(_sk_hsl_to_rgb_aarch64)
_sk_hsl_to_rgb_aarch64:
  .long  0x52a7d548                          // mov           w8, #0x3eaa0000
  .long  0x72955568                          // movk          w8, #0xaaab
  .long  0x4e040d17                          // dup           v23.4s, w8
  .long  0x52a7c548                          // mov           w8, #0x3e2a0000
  .long  0x72955568                          // movk          w8, #0xaaab
  .long  0x4e040d13                          // dup           v19.4s, w8
  .long  0x52a7e548                          // mov           w8, #0x3f2a0000
  .long  0x4f03f612                          // fmov          v18.4s, #1.000000000000000000e+00
  .long  0x4f07f616                          // fmov          v22.4s, #-1.000000000000000000e+00
  .long  0x72955568                          // movk          w8, #0xaaab
  .long  0x4e22d435                          // fadd          v21.4s, v1.4s, v2.4s
  .long  0x4e040d1a                          // dup           v26.4s, w8
  .long  0x52b7d548                          // mov           w8, #0xbeaa0000
  .long  0x6eb2e41d                          // fcmgt         v29.4s, v0.4s, v18.4s
  .long  0x4e36d41e                          // fadd          v30.4s, v0.4s, v22.4s
  .long  0x4f0167f1                          // movi          v17.4s, #0x3f, lsl #24
  .long  0x4ea0d830                          // fcmeq         v16.4s, v1.4s, #0.0
  .long  0x4ea0e819                          // fcmlt         v25.4s, v0.4s, #0.0
  .long  0x72955568                          // movk          w8, #0xaaab
  .long  0x4e32d43c                          // fadd          v28.4s, v1.4s, v18.4s
  .long  0x4ea2cc35                          // fmls          v21.4s, v1.4s, v2.4s
  .long  0x4e32d401                          // fadd          v1.4s, v0.4s, v18.4s
  .long  0x6e601fdd                          // bsl           v29.16b, v30.16b, v0.16b
  .long  0x4e37d417                          // fadd          v23.4s, v0.4s, v23.4s
  .long  0x6ea2e63b                          // fcmgt         v27.4s, v17.4s, v2.4s
  .long  0x4e040d1e                          // dup           v30.4s, w8
  .long  0x6e22df9c                          // fmul          v28.4s, v28.4s, v2.4s
  .long  0x6e7d1c39                          // bsl           v25.16b, v1.16b, v29.16b
  .long  0x6eb2e6e1                          // fcmgt         v1.4s, v23.4s, v18.4s
  .long  0x4e36d6fd                          // fadd          v29.4s, v23.4s, v22.4s
  .long  0x4e3ed41e                          // fadd          v30.4s, v0.4s, v30.4s
  .long  0x6e751f9b                          // bsl           v27.16b, v28.16b, v21.16b
  .long  0x4ea0eaf5                          // fcmlt         v21.4s, v23.4s, #0.0
  .long  0x4e32d6fc                          // fadd          v28.4s, v23.4s, v18.4s
  .long  0x6e771fa1                          // bsl           v1.16b, v29.16b, v23.16b
  .long  0x4f026414                          // movi          v20.4s, #0x40, lsl #24
  .long  0x6e611f95                          // bsl           v21.16b, v28.16b, v1.16b
  .long  0x4e32d7c1                          // fadd          v1.4s, v30.4s, v18.4s
  .long  0x6eb2e7d2                          // fcmgt         v18.4s, v30.4s, v18.4s
  .long  0x4e36d7d6                          // fadd          v22.4s, v30.4s, v22.4s
  .long  0x6ea0fb7c                          // fneg          v28.4s, v27.4s
  .long  0x4ea0ebdd                          // fcmlt         v29.4s, v30.4s, #0.0
  .long  0x6e7e1ed2                          // bsl           v18.16b, v22.16b, v30.16b
  .long  0x4e22ce9c                          // fmla          v28.4s, v20.4s, v2.4s
  .long  0x4f00f718                          // fmov          v24.4s, #6.000000000000000000e+00
  .long  0x6e721c3d                          // bsl           v29.16b, v1.16b, v18.16b
  .long  0x4ebcd761                          // fsub          v1.4s, v27.4s, v28.4s
  .long  0x4eb5d752                          // fsub          v18.4s, v26.4s, v21.4s
  .long  0x4ebc1f94                          // mov           v20.16b, v28.16b
  .long  0x6e38dc38                          // fmul          v24.4s, v1.4s, v24.4s
  .long  0x4eb9d756                          // fsub          v22.4s, v26.4s, v25.4s
  .long  0x4ebc1f9f                          // mov           v31.16b, v28.16b
  .long  0x4e32cf14                          // fmla          v20.4s, v24.4s, v18.4s
  .long  0x4ebc1f81                          // mov           v1.16b, v28.16b
  .long  0x4ebc1f92                          // mov           v18.16b, v28.16b
  .long  0x4e38cc1f                          // fmla          v31.4s, v0.4s, v24.4s
  .long  0x4e36cf01                          // fmla          v1.4s, v24.4s, v22.4s
  .long  0x4ebdd740                          // fsub          v0.4s, v26.4s, v29.4s
  .long  0x4e3ecf12                          // fmla          v18.4s, v24.4s, v30.4s
  .long  0x4ebc1f96                          // mov           v22.16b, v28.16b
  .long  0x6eb5e75e                          // fcmgt         v30.4s, v26.4s, v21.4s
  .long  0x4e20cf16                          // fmla          v22.4s, v24.4s, v0.4s
  .long  0x6e7c1e9e                          // bsl           v30.16b, v20.16b, v28.16b
  .long  0x6eb9e754                          // fcmgt         v20.4s, v26.4s, v25.4s
  .long  0x6ebde75a                          // fcmgt         v26.4s, v26.4s, v29.4s
  .long  0x6e7c1c34                          // bsl           v20.16b, v1.16b, v28.16b
  .long  0x6e7c1eda                          // bsl           v26.16b, v22.16b, v28.16b
  .long  0x4e37cf1c                          // fmla          v28.4s, v24.4s, v23.4s
  .long  0x6eb9e637                          // fcmgt         v23.4s, v17.4s, v25.4s
  .long  0x6eb5e678                          // fcmgt         v24.4s, v19.4s, v21.4s
  .long  0x6eb5e635                          // fcmgt         v21.4s, v17.4s, v21.4s
  .long  0x6ebde631                          // fcmgt         v17.4s, v17.4s, v29.4s
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x6eb9e676                          // fcmgt         v22.4s, v19.4s, v25.4s
  .long  0x6ebde673                          // fcmgt         v19.4s, v19.4s, v29.4s
  .long  0x6e7a1f71                          // bsl           v17.16b, v27.16b, v26.16b
  .long  0x6e7e1f75                          // bsl           v21.16b, v27.16b, v30.16b
  .long  0x6e741f77                          // bsl           v23.16b, v27.16b, v20.16b
  .long  0x6e711e53                          // bsl           v19.16b, v18.16b, v17.16b
  .long  0x4eb01e00                          // mov           v0.16b, v16.16b
  .long  0x4eb01e01                          // mov           v1.16b, v16.16b
  .long  0x6e751f98                          // bsl           v24.16b, v28.16b, v21.16b
  .long  0x6e771ff6                          // bsl           v22.16b, v31.16b, v23.16b
  .long  0x6e731c50                          // bsl           v16.16b, v2.16b, v19.16b
  .long  0x6e781c40                          // bsl           v0.16b, v2.16b, v24.16b
  .long  0x6e761c41                          // bsl           v1.16b, v2.16b, v22.16b
  .long  0x4eb01e02                          // mov           v2.16b, v16.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_scale_1_float_aarch64
.globl _sk_scale_1_float_aarch64
FUNCTION(_sk_scale_1_float_aarch64)
_sk_scale_1_float_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xbd400110                          // ldr           s16, [x8]
  .long  0x4f909000                          // fmul          v0.4s, v0.4s, v16.s[0]
  .long  0x4f909021                          // fmul          v1.4s, v1.4s, v16.s[0]
  .long  0x4f909042                          // fmul          v2.4s, v2.4s, v16.s[0]
  .long  0x4f909063                          // fmul          v3.4s, v3.4s, v16.s[0]
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_scale_u8_aarch64
.globl _sk_scale_u8_aarch64
FUNCTION(_sk_scale_u8_aarch64)
_sk_scale_u8_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x52a77009                          // mov           w9, #0x3b800000
  .long  0x72901029                          // movk          w9, #0x8081
  .long  0x4e040d30                          // dup           v16.4s, w9
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x8b000108                          // add           x8, x8, x0
  .long  0x39400109                          // ldrb          w9, [x8]
  .long  0x3940050a                          // ldrb          w10, [x8, #1]
  .long  0x3940090b                          // ldrb          w11, [x8, #2]
  .long  0x39400d08                          // ldrb          w8, [x8, #3]
  .long  0x4e021d31                          // mov           v17.h[0], w9
  .long  0x4e061d51                          // mov           v17.h[1], w10
  .long  0x4e0a1d71                          // mov           v17.h[2], w11
  .long  0x4e0e1d11                          // mov           v17.h[3], w8
  .long  0x2f10a631                          // uxtl          v17.4s, v17.4h
  .long  0x6e21da31                          // ucvtf         v17.4s, v17.4s
  .long  0x6e30de30                          // fmul          v16.4s, v17.4s, v16.4s
  .long  0x6e20de00                          // fmul          v0.4s, v16.4s, v0.4s
  .long  0x6e21de01                          // fmul          v1.4s, v16.4s, v1.4s
  .long  0x6e22de02                          // fmul          v2.4s, v16.4s, v2.4s
  .long  0x6e23de03                          // fmul          v3.4s, v16.4s, v3.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_lerp_1_float_aarch64
.globl _sk_lerp_1_float_aarch64
FUNCTION(_sk_lerp_1_float_aarch64)
_sk_lerp_1_float_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x4ea4d411                          // fsub          v17.4s, v0.4s, v4.4s
  .long  0x4ea41c80                          // mov           v0.16b, v4.16b
  .long  0x4ea5d432                          // fsub          v18.4s, v1.4s, v5.4s
  .long  0xbd400110                          // ldr           s16, [x8]
  .long  0x4ea51ca1                          // mov           v1.16b, v5.16b
  .long  0x4f901220                          // fmla          v0.4s, v17.4s, v16.s[0]
  .long  0x4ea6d451                          // fsub          v17.4s, v2.4s, v6.4s
  .long  0x4f901241                          // fmla          v1.4s, v18.4s, v16.s[0]
  .long  0x4ea61cc2                          // mov           v2.16b, v6.16b
  .long  0x4ea7d472                          // fsub          v18.4s, v3.4s, v7.4s
  .long  0x4ea71ce3                          // mov           v3.16b, v7.16b
  .long  0x4f901222                          // fmla          v2.4s, v17.4s, v16.s[0]
  .long  0x4f901243                          // fmla          v3.4s, v18.4s, v16.s[0]
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_lerp_u8_aarch64
.globl _sk_lerp_u8_aarch64
FUNCTION(_sk_lerp_u8_aarch64)
_sk_lerp_u8_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x52a77009                          // mov           w9, #0x3b800000
  .long  0x72901029                          // movk          w9, #0x8081
  .long  0x4e040d30                          // dup           v16.4s, w9
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x4ea4d412                          // fsub          v18.4s, v0.4s, v4.4s
  .long  0x8b000108                          // add           x8, x8, x0
  .long  0x3940010a                          // ldrb          w10, [x8]
  .long  0x39400509                          // ldrb          w9, [x8, #1]
  .long  0x3940090b                          // ldrb          w11, [x8, #2]
  .long  0x39400d08                          // ldrb          w8, [x8, #3]
  .long  0x4e021d51                          // mov           v17.h[0], w10
  .long  0x4e061d31                          // mov           v17.h[1], w9
  .long  0x4e0a1d71                          // mov           v17.h[2], w11
  .long  0x4e0e1d11                          // mov           v17.h[3], w8
  .long  0x2f10a620                          // uxtl          v0.4s, v17.4h
  .long  0x6e21d800                          // ucvtf         v0.4s, v0.4s
  .long  0x6e30dc10                          // fmul          v16.4s, v0.4s, v16.4s
  .long  0x4ea41c80                          // mov           v0.16b, v4.16b
  .long  0x4ea5d431                          // fsub          v17.4s, v1.4s, v5.4s
  .long  0x4ea51ca1                          // mov           v1.16b, v5.16b
  .long  0x4e32ce00                          // fmla          v0.4s, v16.4s, v18.4s
  .long  0x4ea6d452                          // fsub          v18.4s, v2.4s, v6.4s
  .long  0x4e31ce01                          // fmla          v1.4s, v16.4s, v17.4s
  .long  0x4ea61cc2                          // mov           v2.16b, v6.16b
  .long  0x4ea7d471                          // fsub          v17.4s, v3.4s, v7.4s
  .long  0x4ea71ce3                          // mov           v3.16b, v7.16b
  .long  0x4e32ce02                          // fmla          v2.4s, v16.4s, v18.4s
  .long  0x4e31ce03                          // fmla          v3.4s, v16.4s, v17.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_lerp_565_aarch64
.globl _sk_lerp_565_aarch64
FUNCTION(_sk_lerp_565_aarch64)
_sk_lerp_565_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xd37ff809                          // lsl           x9, x0, #1
  .long  0x4f072710                          // movi          v16.4s, #0xf8, lsl #8
  .long  0x4ea4d413                          // fsub          v19.4s, v0.4s, v4.4s
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0xfc696903                          // ldr           d3, [x8, x9]
  .long  0x52a6f088                          // mov           w8, #0x37840000
  .long  0x72842108                          // movk          w8, #0x2108
  .long  0x4e040d11                          // dup           v17.4s, w8
  .long  0x2f10a463                          // uxtl          v3.4s, v3.4h
  .long  0x321b17e8                          // orr           w8, wzr, #0x7e0
  .long  0x4e301c60                          // and           v0.16b, v3.16b, v16.16b
  .long  0x4e040d12                          // dup           v18.4s, w8
  .long  0x52a74048                          // mov           w8, #0x3a020000
  .long  0x4e21d800                          // scvtf         v0.4s, v0.4s
  .long  0x72810428                          // movk          w8, #0x821
  .long  0x6e31dc10                          // fmul          v16.4s, v0.4s, v17.4s
  .long  0x4ea41c80                          // mov           v0.16b, v4.16b
  .long  0x4e33ce00                          // fmla          v0.4s, v16.4s, v19.4s
  .long  0x4f0007f0                          // movi          v16.4s, #0x1f
  .long  0x4e040d11                          // dup           v17.4s, w8
  .long  0x52a7a088                          // mov           w8, #0x3d040000
  .long  0x4e321c72                          // and           v18.16b, v3.16b, v18.16b
  .long  0x72842108                          // movk          w8, #0x2108
  .long  0x4e301c63                          // and           v3.16b, v3.16b, v16.16b
  .long  0x4ea6d450                          // fsub          v16.4s, v2.4s, v6.4s
  .long  0x4e21da42                          // scvtf         v2.4s, v18.4s
  .long  0x6e31dc51                          // fmul          v17.4s, v2.4s, v17.4s
  .long  0x4e040d02                          // dup           v2.4s, w8
  .long  0x4e21d863                          // scvtf         v3.4s, v3.4s
  .long  0x4ea5d433                          // fsub          v19.4s, v1.4s, v5.4s
  .long  0x4ea51ca1                          // mov           v1.16b, v5.16b
  .long  0x6e22dc63                          // fmul          v3.4s, v3.4s, v2.4s
  .long  0x4ea61cc2                          // mov           v2.16b, v6.16b
  .long  0x4e33ce21                          // fmla          v1.4s, v17.4s, v19.4s
  .long  0x4e30cc62                          // fmla          v2.4s, v3.4s, v16.4s
  .long  0x4f03f603                          // fmov          v3.4s, #1.000000000000000000e+00
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_load_tables_aarch64
.globl _sk_load_tables_aarch64
FUNCTION(_sk_load_tables_aarch64)
_sk_load_tables_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xd37ef409                          // lsl           x9, x0, #2
  .long  0x6f00e620                          // movi          v0.2d, #0xff000000ff
  .long  0x52a7700b                          // mov           w11, #0x3b800000
  .long  0xa940310a                          // ldp           x10, x12, [x8]
  .long  0x7290102b                          // movk          w11, #0x8081
  .long  0x4e040d63                          // dup           v3.4s, w11
  .long  0x3ce96942                          // ldr           q2, [x10, x9]
  .long  0xa9412109                          // ldp           x9, x8, [x8, #16]
  .long  0x4e201c41                          // and           v1.16b, v2.16b, v0.16b
  .long  0x1e26002e                          // fmov          w14, s1
  .long  0x6f380450                          // ushr          v16.4s, v2.4s, #8
  .long  0x6f300451                          // ushr          v17.4s, v2.4s, #16
  .long  0x8b2e498e                          // add           x14, x12, w14, uxtw #2
  .long  0x0e0c3c2a                          // mov           w10, v1.s[1]
  .long  0x0e143c2b                          // mov           w11, v1.s[2]
  .long  0x0e1c3c2d                          // mov           w13, v1.s[3]
  .long  0x4e201e01                          // and           v1.16b, v16.16b, v0.16b
  .long  0x4e201e30                          // and           v16.16b, v17.16b, v0.16b
  .long  0x0d4081c0                          // ld1           {v0.s}[0], [x14]
  .long  0x8b2a498a                          // add           x10, x12, w10, uxtw #2
  .long  0xbc6b5991                          // ldr           s17, [x12, w11, uxtw #2]
  .long  0xbc6d5992                          // ldr           s18, [x12, w13, uxtw #2]
  .long  0x0e0c3c2b                          // mov           w11, v1.s[1]
  .long  0x0e143c2c                          // mov           w12, v1.s[2]
  .long  0x0e1c3c2d                          // mov           w13, v1.s[3]
  .long  0x1e26002e                          // fmov          w14, s1
  .long  0x8b2e492e                          // add           x14, x9, w14, uxtw #2
  .long  0xbc6c5933                          // ldr           s19, [x9, w12, uxtw #2]
  .long  0xbc6d5934                          // ldr           s20, [x9, w13, uxtw #2]
  .long  0x8b2b4929                          // add           x9, x9, w11, uxtw #2
  .long  0x1e26020b                          // fmov          w11, s16
  .long  0x6f280442                          // ushr          v2.4s, v2.4s, #24
  .long  0x0d409140                          // ld1           {v0.s}[1], [x10]
  .long  0x4e21d842                          // scvtf         v2.4s, v2.4s
  .long  0x8b2b490a                          // add           x10, x8, w11, uxtw #2
  .long  0x0d4081c1                          // ld1           {v1.s}[0], [x14]
  .long  0x6e23dc43                          // fmul          v3.4s, v2.4s, v3.4s
  .long  0x0d408142                          // ld1           {v2.s}[0], [x10]
  .long  0x0e0c3e0f                          // mov           w15, v16.s[1]
  .long  0x0e143e0c                          // mov           w12, v16.s[2]
  .long  0x8b2f490a                          // add           x10, x8, w15, uxtw #2
  .long  0x0e1c3e0d                          // mov           w13, v16.s[3]
  .long  0xbc6c5910                          // ldr           s16, [x8, w12, uxtw #2]
  .long  0x0d409121                          // ld1           {v1.s}[1], [x9]
  .long  0x0d409142                          // ld1           {v2.s}[1], [x10]
  .long  0x6e140620                          // mov           v0.s[2], v17.s[0]
  .long  0xbc6d5911                          // ldr           s17, [x8, w13, uxtw #2]
  .long  0x6e140661                          // mov           v1.s[2], v19.s[0]
  .long  0x6e140602                          // mov           v2.s[2], v16.s[0]
  .long  0x6e1c0640                          // mov           v0.s[3], v18.s[0]
  .long  0x6e1c0681                          // mov           v1.s[3], v20.s[0]
  .long  0x6e1c0622                          // mov           v2.s[3], v17.s[0]
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_load_tables_u16_be_aarch64
.globl _sk_load_tables_u16_be_aarch64
FUNCTION(_sk_load_tables_u16_be_aarch64)
_sk_load_tables_u16_be_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x52a6f00a                          // mov           w10, #0x37800000
  .long  0x7280100a                          // movk          w10, #0x80
  .long  0x4e040d50                          // dup           v16.4s, w10
  .long  0xa9402d09                          // ldp           x9, x11, [x8]
  .long  0x8b000d29                          // add           x9, x9, x0, lsl #3
  .long  0x0c400520                          // ld4           {v0.4h-v3.4h}, [x9]
  .long  0xa9412109                          // ldp           x9, x8, [x8, #16]
  .long  0x2f07b7e0                          // bic           v0.4h, #0xff, lsl #8
  .long  0x2f10a411                          // uxtl          v17.4s, v0.4h
  .long  0x2f07b7e1                          // bic           v1.4h, #0xff, lsl #8
  .long  0x1e26022e                          // fmov          w14, s17
  .long  0x0e0c3e2a                          // mov           w10, v17.s[1]
  .long  0x0e143e2c                          // mov           w12, v17.s[2]
  .long  0x0e1c3e2d                          // mov           w13, v17.s[3]
  .long  0x8b2e496e                          // add           x14, x11, w14, uxtw #2
  .long  0x2f10a431                          // uxtl          v17.4s, v1.4h
  .long  0x2f07b7e2                          // bic           v2.4h, #0xff, lsl #8
  .long  0x2f10a453                          // uxtl          v19.4s, v2.4h
  .long  0x2f180462                          // ushr          v2.4h, v3.4h, #8
  .long  0x0d4081c0                          // ld1           {v0.s}[0], [x14]
  .long  0x0f185474                          // shl           v20.4h, v3.4h, #8
  .long  0x0ea21e82                          // orr           v2.8b, v20.8b, v2.8b
  .long  0x8b2a496a                          // add           x10, x11, w10, uxtw #2
  .long  0x1e26022e                          // fmov          w14, s17
  .long  0x1e26026f                          // fmov          w15, s19
  .long  0x2f10a442                          // uxtl          v2.4s, v2.4h
  .long  0x8b2e492e                          // add           x14, x9, w14, uxtw #2
  .long  0x0d409140                          // ld1           {v0.s}[1], [x10]
  .long  0x8b2f490a                          // add           x10, x8, w15, uxtw #2
  .long  0x6e21d842                          // ucvtf         v2.4s, v2.4s
  .long  0x0d4081c1                          // ld1           {v1.s}[0], [x14]
  .long  0x6e30dc43                          // fmul          v3.4s, v2.4s, v16.4s
  .long  0x0d408142                          // ld1           {v2.s}[0], [x10]
  .long  0xbc6c5972                          // ldr           s18, [x11, w12, uxtw #2]
  .long  0xbc6d5975                          // ldr           s21, [x11, w13, uxtw #2]
  .long  0x0e0c3e2b                          // mov           w11, v17.s[1]
  .long  0x0e143e2c                          // mov           w12, v17.s[2]
  .long  0x0e1c3e2d                          // mov           w13, v17.s[3]
  .long  0x8b2b492b                          // add           x11, x9, w11, uxtw #2
  .long  0xbc6c5931                          // ldr           s17, [x9, w12, uxtw #2]
  .long  0xbc6d5936                          // ldr           s22, [x9, w13, uxtw #2]
  .long  0x0e0c3e69                          // mov           w9, v19.s[1]
  .long  0x0e143e6c                          // mov           w12, v19.s[2]
  .long  0x8b294909                          // add           x9, x8, w9, uxtw #2
  .long  0x0e1c3e6d                          // mov           w13, v19.s[3]
  .long  0xbc6c5913                          // ldr           s19, [x8, w12, uxtw #2]
  .long  0x0d409161                          // ld1           {v1.s}[1], [x11]
  .long  0x0d409122                          // ld1           {v2.s}[1], [x9]
  .long  0xbc6d5910                          // ldr           s16, [x8, w13, uxtw #2]
  .long  0x6e140640                          // mov           v0.s[2], v18.s[0]
  .long  0x6e140621                          // mov           v1.s[2], v17.s[0]
  .long  0x6e140662                          // mov           v2.s[2], v19.s[0]
  .long  0x6e1c06a0                          // mov           v0.s[3], v21.s[0]
  .long  0x6e1c06c1                          // mov           v1.s[3], v22.s[0]
  .long  0x6e1c0602                          // mov           v2.s[3], v16.s[0]
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_load_tables_rgb_u16_be_aarch64
.globl _sk_load_tables_rgb_u16_be_aarch64
FUNCTION(_sk_load_tables_rgb_u16_be_aarch64)
_sk_load_tables_rgb_u16_be_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x321f07ea                          // orr           w10, wzr, #0x6
  .long  0xa9402d09                          // ldp           x9, x11, [x8]
  .long  0x9b0a2409                          // madd          x9, x0, x10, x9
  .long  0x0c404521                          // ld3           {v1.4h-v3.4h}, [x9]
  .long  0xa9412109                          // ldp           x9, x8, [x8, #16]
  .long  0x2f07b7e1                          // bic           v1.4h, #0xff, lsl #8
  .long  0x2f10a420                          // uxtl          v0.4s, v1.4h
  .long  0x2f07b7e2                          // bic           v2.4h, #0xff, lsl #8
  .long  0x1e26000e                          // fmov          w14, s0
  .long  0x0e143c0c                          // mov           w12, v0.s[2]
  .long  0x8b2e496e                          // add           x14, x11, w14, uxtw #2
  .long  0x2f10a450                          // uxtl          v16.4s, v2.4h
  .long  0x0e0c3c0a                          // mov           w10, v0.s[1]
  .long  0x0e1c3c0d                          // mov           w13, v0.s[3]
  .long  0xbc6c5971                          // ldr           s17, [x11, w12, uxtw #2]
  .long  0x0d4081c0                          // ld1           {v0.s}[0], [x14]
  .long  0x0e143e0c                          // mov           w12, v16.s[2]
  .long  0x1e26020e                          // fmov          w14, s16
  .long  0x2f07b7e3                          // bic           v3.4h, #0xff, lsl #8
  .long  0x8b2a496a                          // add           x10, x11, w10, uxtw #2
  .long  0xbc6d5972                          // ldr           s18, [x11, w13, uxtw #2]
  .long  0x0e0c3e0b                          // mov           w11, v16.s[1]
  .long  0x0e1c3e0d                          // mov           w13, v16.s[3]
  .long  0xbc6c5930                          // ldr           s16, [x9, w12, uxtw #2]
  .long  0x8b2e492c                          // add           x12, x9, w14, uxtw #2
  .long  0x2f10a462                          // uxtl          v2.4s, v3.4h
  .long  0xbc6d5923                          // ldr           s3, [x9, w13, uxtw #2]
  .long  0x0d408181                          // ld1           {v1.s}[0], [x12]
  .long  0x0e143c4c                          // mov           w12, v2.s[2]
  .long  0x1e26004d                          // fmov          w13, s2
  .long  0xbc6c5913                          // ldr           s19, [x8, w12, uxtw #2]
  .long  0x8b2d490c                          // add           x12, x8, w13, uxtw #2
  .long  0x8b2b492b                          // add           x11, x9, w11, uxtw #2
  .long  0x0e0c3c49                          // mov           w9, v2.s[1]
  .long  0x0d409140                          // ld1           {v0.s}[1], [x10]
  .long  0x0e1c3c4a                          // mov           w10, v2.s[3]
  .long  0x0d408182                          // ld1           {v2.s}[0], [x12]
  .long  0x8b294909                          // add           x9, x8, w9, uxtw #2
  .long  0x0d409161                          // ld1           {v1.s}[1], [x11]
  .long  0x6e140620                          // mov           v0.s[2], v17.s[0]
  .long  0x0d409122                          // ld1           {v2.s}[1], [x9]
  .long  0xbc6a5911                          // ldr           s17, [x8, w10, uxtw #2]
  .long  0x6e140601                          // mov           v1.s[2], v16.s[0]
  .long  0x6e1c0640                          // mov           v0.s[3], v18.s[0]
  .long  0x6e140662                          // mov           v2.s[2], v19.s[0]
  .long  0x6e1c0461                          // mov           v1.s[3], v3.s[0]
  .long  0x6e1c0622                          // mov           v2.s[3], v17.s[0]
  .long  0x4f03f603                          // fmov          v3.4s, #1.000000000000000000e+00
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_byte_tables_aarch64
.globl _sk_byte_tables_aarch64
FUNCTION(_sk_byte_tables_aarch64)
_sk_byte_tables_aarch64:
  .long  0xd10083ff                          // sub           sp, sp, #0x20
  .long  0xaa0103e8                          // mov           x8, x1
  .long  0x91002109                          // add           x9, x8, #0x8
  .long  0xa9014ff4                          // stp           x20, x19, [sp, #16]
  .long  0xf90007e9                          // str           x9, [sp, #8]
  .long  0xf8410429                          // ldr           x9, [x1], #16
  .long  0x52a86fea                          // mov           w10, #0x437f0000
  .long  0x4e040d51                          // dup           v17.4s, w10
  .long  0x52a7700b                          // mov           w11, #0x3b800000
  .long  0xa9405126                          // ldp           x6, x20, [x9]
  .long  0x6e31dc00                          // fmul          v0.4s, v0.4s, v17.4s
  .long  0x7290102b                          // movk          w11, #0x8081
  .long  0x6e21a800                          // fcvtnu        v0.4s, v0.4s
  .long  0x4e040d70                          // dup           v16.4s, w11
  .long  0x0e0c3c0a                          // mov           w10, v0.s[1]
  .long  0x0e143c0b                          // mov           w11, v0.s[2]
  .long  0x0e1c3c0c                          // mov           w12, v0.s[3]
  .long  0x1e26000d                          // fmov          w13, s0
  .long  0x386d48cd                          // ldrb          w13, [x6, w13, uxtw]
  .long  0x386a48ca                          // ldrb          w10, [x6, w10, uxtw]
  .long  0x386b48cb                          // ldrb          w11, [x6, w11, uxtw]
  .long  0x386c48cc                          // ldrb          w12, [x6, w12, uxtw]
  .long  0xa9412526                          // ldp           x6, x9, [x9, #16]
  .long  0x6e31dc42                          // fmul          v2.4s, v2.4s, v17.4s
  .long  0x6e31dc21                          // fmul          v1.4s, v1.4s, v17.4s
  .long  0x6e31dc63                          // fmul          v3.4s, v3.4s, v17.4s
  .long  0x6e21a842                          // fcvtnu        v2.4s, v2.4s
  .long  0x6e21a821                          // fcvtnu        v1.4s, v1.4s
  .long  0x6e21a863                          // fcvtnu        v3.4s, v3.4s
  .long  0x0e0c3c52                          // mov           w18, v2.s[1]
  .long  0x0e143c43                          // mov           w3, v2.s[2]
  .long  0x0e1c3c44                          // mov           w4, v2.s[3]
  .long  0x1e260045                          // fmov          w5, s2
  .long  0x1e260031                          // fmov          w17, s1
  .long  0x386548c5                          // ldrb          w5, [x6, w5, uxtw]
  .long  0x387248d2                          // ldrb          w18, [x6, w18, uxtw]
  .long  0x386348c3                          // ldrb          w3, [x6, w3, uxtw]
  .long  0x386448c4                          // ldrb          w4, [x6, w4, uxtw]
  .long  0x1e260066                          // fmov          w6, s3
  .long  0x0e0c3c2e                          // mov           w14, v1.s[1]
  .long  0x0e0c3c67                          // mov           w7, v3.s[1]
  .long  0x38714a91                          // ldrb          w17, [x20, w17, uxtw]
  .long  0x38664926                          // ldrb          w6, [x9, w6, uxtw]
  .long  0x0e143c2f                          // mov           w15, v1.s[2]
  .long  0x0e1c3c30                          // mov           w16, v1.s[3]
  .long  0x0e143c73                          // mov           w19, v3.s[2]
  .long  0x386e4a8e                          // ldrb          w14, [x20, w14, uxtw]
  .long  0x38674927                          // ldrb          w7, [x9, w7, uxtw]
  .long  0x386f4a8f                          // ldrb          w15, [x20, w15, uxtw]
  .long  0x38704a90                          // ldrb          w16, [x20, w16, uxtw]
  .long  0x0e1c3c74                          // mov           w20, v3.s[3]
  .long  0x38734933                          // ldrb          w19, [x9, w19, uxtw]
  .long  0x38744929                          // ldrb          w9, [x9, w20, uxtw]
  .long  0x4e021da0                          // mov           v0.h[0], w13
  .long  0x4e021e21                          // mov           v1.h[0], w17
  .long  0x4e021ca2                          // mov           v2.h[0], w5
  .long  0x4e021cc3                          // mov           v3.h[0], w6
  .long  0x4e061d40                          // mov           v0.h[1], w10
  .long  0x4e061dc1                          // mov           v1.h[1], w14
  .long  0x4e061e42                          // mov           v2.h[1], w18
  .long  0x4e061ce3                          // mov           v3.h[1], w7
  .long  0x4e0a1d60                          // mov           v0.h[2], w11
  .long  0x4e0a1de1                          // mov           v1.h[2], w15
  .long  0x4e0a1c62                          // mov           v2.h[2], w3
  .long  0x4e0a1e63                          // mov           v3.h[2], w19
  .long  0x4e0e1d80                          // mov           v0.h[3], w12
  .long  0x4e0e1e01                          // mov           v1.h[3], w16
  .long  0x4e0e1c82                          // mov           v2.h[3], w4
  .long  0x4e0e1d23                          // mov           v3.h[3], w9
  .long  0xf9400505                          // ldr           x5, [x8, #8]
  .long  0x2f07b7e0                          // bic           v0.4h, #0xff, lsl #8
  .long  0x2f07b7e1                          // bic           v1.4h, #0xff, lsl #8
  .long  0x2f07b7e2                          // bic           v2.4h, #0xff, lsl #8
  .long  0x2f07b7e3                          // bic           v3.4h, #0xff, lsl #8
  .long  0xa9414ff4                          // ldp           x20, x19, [sp, #16]
  .long  0x2f10a400                          // uxtl          v0.4s, v0.4h
  .long  0x2f10a421                          // uxtl          v1.4s, v1.4h
  .long  0x2f10a442                          // uxtl          v2.4s, v2.4h
  .long  0x2f10a463                          // uxtl          v3.4s, v3.4h
  .long  0x6e21d800                          // ucvtf         v0.4s, v0.4s
  .long  0x6e21d821                          // ucvtf         v1.4s, v1.4s
  .long  0x6e21d842                          // ucvtf         v2.4s, v2.4s
  .long  0x6e21d863                          // ucvtf         v3.4s, v3.4s
  .long  0x6e30dc00                          // fmul          v0.4s, v0.4s, v16.4s
  .long  0x6e30dc21                          // fmul          v1.4s, v1.4s, v16.4s
  .long  0x6e30dc42                          // fmul          v2.4s, v2.4s, v16.4s
  .long  0x6e30dc63                          // fmul          v3.4s, v3.4s, v16.4s
  .long  0x910083ff                          // add           sp, sp, #0x20
  .long  0xd61f00a0                          // br            x5

HIDDEN _sk_byte_tables_rgb_aarch64
.globl _sk_byte_tables_rgb_aarch64
FUNCTION(_sk_byte_tables_rgb_aarch64)
_sk_byte_tables_rgb_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x52a77009                          // mov           w9, #0x3b800000
  .long  0x72901029                          // movk          w9, #0x8081
  .long  0x4e040d30                          // dup           v16.4s, w9
  .long  0xb9401909                          // ldr           w9, [x8, #24]
  .long  0xa9402d0a                          // ldp           x10, x11, [x8]
  .long  0xf9400908                          // ldr           x8, [x8, #16]
  .long  0x51000529                          // sub           w9, w9, #0x1
  .long  0x4e040d31                          // dup           v17.4s, w9
  .long  0x4e21da31                          // scvtf         v17.4s, v17.4s
  .long  0x6e21de21                          // fmul          v1.4s, v17.4s, v1.4s
  .long  0x6e20de20                          // fmul          v0.4s, v17.4s, v0.4s
  .long  0x6e22de22                          // fmul          v2.4s, v17.4s, v2.4s
  .long  0x6e21a821                          // fcvtnu        v1.4s, v1.4s
  .long  0x6e21a800                          // fcvtnu        v0.4s, v0.4s
  .long  0x6e21a842                          // fcvtnu        v2.4s, v2.4s
  .long  0x0e0c3c2f                          // mov           w15, v1.s[1]
  .long  0x0e143c30                          // mov           w16, v1.s[2]
  .long  0x0e1c3c31                          // mov           w17, v1.s[3]
  .long  0x1e260032                          // fmov          w18, s1
  .long  0x1e26000e                          // fmov          w14, s0
  .long  0x38724972                          // ldrb          w18, [x11, w18, uxtw]
  .long  0x386f496f                          // ldrb          w15, [x11, w15, uxtw]
  .long  0x38704970                          // ldrb          w16, [x11, w16, uxtw]
  .long  0x3871496b                          // ldrb          w11, [x11, w17, uxtw]
  .long  0x1e260051                          // fmov          w17, s2
  .long  0x0e0c3c09                          // mov           w9, v0.s[1]
  .long  0x386e494e                          // ldrb          w14, [x10, w14, uxtw]
  .long  0x0e0c3c44                          // mov           w4, v2.s[1]
  .long  0x38714911                          // ldrb          w17, [x8, w17, uxtw]
  .long  0x0e143c0c                          // mov           w12, v0.s[2]
  .long  0x0e1c3c0d                          // mov           w13, v0.s[3]
  .long  0x0e143c45                          // mov           w5, v2.s[2]
  .long  0x38694949                          // ldrb          w9, [x10, w9, uxtw]
  .long  0x38644904                          // ldrb          w4, [x8, w4, uxtw]
  .long  0x386c494c                          // ldrb          w12, [x10, w12, uxtw]
  .long  0x386d494a                          // ldrb          w10, [x10, w13, uxtw]
  .long  0x0e1c3c4d                          // mov           w13, v2.s[3]
  .long  0x38654905                          // ldrb          w5, [x8, w5, uxtw]
  .long  0x386d4908                          // ldrb          w8, [x8, w13, uxtw]
  .long  0x4e021dc0                          // mov           v0.h[0], w14
  .long  0x4e021e41                          // mov           v1.h[0], w18
  .long  0x4e021e22                          // mov           v2.h[0], w17
  .long  0x4e061d20                          // mov           v0.h[1], w9
  .long  0x4e061de1                          // mov           v1.h[1], w15
  .long  0x4e061c82                          // mov           v2.h[1], w4
  .long  0x4e0a1d80                          // mov           v0.h[2], w12
  .long  0x4e0a1e01                          // mov           v1.h[2], w16
  .long  0x4e0a1ca2                          // mov           v2.h[2], w5
  .long  0x4e0e1d40                          // mov           v0.h[3], w10
  .long  0x4e0e1d61                          // mov           v1.h[3], w11
  .long  0x4e0e1d02                          // mov           v2.h[3], w8
  .long  0x2f07b7e0                          // bic           v0.4h, #0xff, lsl #8
  .long  0x2f07b7e1                          // bic           v1.4h, #0xff, lsl #8
  .long  0x2f07b7e2                          // bic           v2.4h, #0xff, lsl #8
  .long  0x2f10a400                          // uxtl          v0.4s, v0.4h
  .long  0x2f10a421                          // uxtl          v1.4s, v1.4h
  .long  0x2f10a442                          // uxtl          v2.4s, v2.4h
  .long  0x6e21d800                          // ucvtf         v0.4s, v0.4s
  .long  0x6e21d821                          // ucvtf         v1.4s, v1.4s
  .long  0x6e21d842                          // ucvtf         v2.4s, v2.4s
  .long  0x6e30dc00                          // fmul          v0.4s, v0.4s, v16.4s
  .long  0x6e30dc21                          // fmul          v1.4s, v1.4s, v16.4s
  .long  0x6e30dc42                          // fmul          v2.4s, v2.4s, v16.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_table_r_aarch64
.globl _sk_table_r_aarch64
FUNCTION(_sk_table_r_aarch64)
_sk_table_r_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xb9400909                          // ldr           w9, [x8, #8]
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x51000529                          // sub           w9, w9, #0x1
  .long  0x4e040d30                          // dup           v16.4s, w9
  .long  0x4e21da10                          // scvtf         v16.4s, v16.4s
  .long  0x6e20de00                          // fmul          v0.4s, v16.4s, v0.4s
  .long  0x6e21a810                          // fcvtnu        v16.4s, v0.4s
  .long  0x1e26020b                          // fmov          w11, s16
  .long  0x8b2b490b                          // add           x11, x8, w11, uxtw #2
  .long  0x0d408160                          // ld1           {v0.s}[0], [x11]
  .long  0x0e0c3e09                          // mov           w9, v16.s[1]
  .long  0x0e143e0a                          // mov           w10, v16.s[2]
  .long  0x8b294909                          // add           x9, x8, w9, uxtw #2
  .long  0x0e1c3e0b                          // mov           w11, v16.s[3]
  .long  0xbc6a5910                          // ldr           s16, [x8, w10, uxtw #2]
  .long  0x0d409120                          // ld1           {v0.s}[1], [x9]
  .long  0xbc6b5911                          // ldr           s17, [x8, w11, uxtw #2]
  .long  0x6e140600                          // mov           v0.s[2], v16.s[0]
  .long  0x6e1c0620                          // mov           v0.s[3], v17.s[0]
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_table_g_aarch64
.globl _sk_table_g_aarch64
FUNCTION(_sk_table_g_aarch64)
_sk_table_g_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xb9400909                          // ldr           w9, [x8, #8]
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x51000529                          // sub           w9, w9, #0x1
  .long  0x4e040d30                          // dup           v16.4s, w9
  .long  0x4e21da10                          // scvtf         v16.4s, v16.4s
  .long  0x6e21de01                          // fmul          v1.4s, v16.4s, v1.4s
  .long  0x6e21a830                          // fcvtnu        v16.4s, v1.4s
  .long  0x1e26020b                          // fmov          w11, s16
  .long  0x8b2b490b                          // add           x11, x8, w11, uxtw #2
  .long  0x0d408161                          // ld1           {v1.s}[0], [x11]
  .long  0x0e0c3e09                          // mov           w9, v16.s[1]
  .long  0x0e143e0a                          // mov           w10, v16.s[2]
  .long  0x8b294909                          // add           x9, x8, w9, uxtw #2
  .long  0x0e1c3e0b                          // mov           w11, v16.s[3]
  .long  0xbc6a5910                          // ldr           s16, [x8, w10, uxtw #2]
  .long  0x0d409121                          // ld1           {v1.s}[1], [x9]
  .long  0xbc6b5911                          // ldr           s17, [x8, w11, uxtw #2]
  .long  0x6e140601                          // mov           v1.s[2], v16.s[0]
  .long  0x6e1c0621                          // mov           v1.s[3], v17.s[0]
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_table_b_aarch64
.globl _sk_table_b_aarch64
FUNCTION(_sk_table_b_aarch64)
_sk_table_b_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xb9400909                          // ldr           w9, [x8, #8]
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x51000529                          // sub           w9, w9, #0x1
  .long  0x4e040d30                          // dup           v16.4s, w9
  .long  0x4e21da10                          // scvtf         v16.4s, v16.4s
  .long  0x6e22de02                          // fmul          v2.4s, v16.4s, v2.4s
  .long  0x6e21a850                          // fcvtnu        v16.4s, v2.4s
  .long  0x1e26020b                          // fmov          w11, s16
  .long  0x8b2b490b                          // add           x11, x8, w11, uxtw #2
  .long  0x0d408162                          // ld1           {v2.s}[0], [x11]
  .long  0x0e0c3e09                          // mov           w9, v16.s[1]
  .long  0x0e143e0a                          // mov           w10, v16.s[2]
  .long  0x8b294909                          // add           x9, x8, w9, uxtw #2
  .long  0x0e1c3e0b                          // mov           w11, v16.s[3]
  .long  0xbc6a5910                          // ldr           s16, [x8, w10, uxtw #2]
  .long  0x0d409122                          // ld1           {v2.s}[1], [x9]
  .long  0xbc6b5911                          // ldr           s17, [x8, w11, uxtw #2]
  .long  0x6e140602                          // mov           v2.s[2], v16.s[0]
  .long  0x6e1c0622                          // mov           v2.s[3], v17.s[0]
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_table_a_aarch64
.globl _sk_table_a_aarch64
FUNCTION(_sk_table_a_aarch64)
_sk_table_a_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xb9400909                          // ldr           w9, [x8, #8]
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x51000529                          // sub           w9, w9, #0x1
  .long  0x4e040d30                          // dup           v16.4s, w9
  .long  0x4e21da10                          // scvtf         v16.4s, v16.4s
  .long  0x6e23de03                          // fmul          v3.4s, v16.4s, v3.4s
  .long  0x6e21a870                          // fcvtnu        v16.4s, v3.4s
  .long  0x1e26020b                          // fmov          w11, s16
  .long  0x8b2b490b                          // add           x11, x8, w11, uxtw #2
  .long  0x0d408163                          // ld1           {v3.s}[0], [x11]
  .long  0x0e0c3e09                          // mov           w9, v16.s[1]
  .long  0x0e143e0a                          // mov           w10, v16.s[2]
  .long  0x8b294909                          // add           x9, x8, w9, uxtw #2
  .long  0x0e1c3e0b                          // mov           w11, v16.s[3]
  .long  0xbc6a5910                          // ldr           s16, [x8, w10, uxtw #2]
  .long  0x0d409123                          // ld1           {v3.s}[1], [x9]
  .long  0xbc6b5911                          // ldr           s17, [x8, w11, uxtw #2]
  .long  0x6e140603                          // mov           v3.s[2], v16.s[0]
  .long  0x6e1c0623                          // mov           v3.s[3], v17.s[0]
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_parametric_r_aarch64
.globl _sk_parametric_r_aarch64
FUNCTION(_sk_parametric_r_aarch64)
_sk_parametric_r_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x4f016696                          // movi          v22.4s, #0x34, lsl #24
  .long  0x91004109                          // add           x9, x8, #0x10
  .long  0x9100610a                          // add           x10, x8, #0x18
  .long  0x4d40c932                          // ld1r          {v18.4s}, [x9]
  .long  0xaa0803e9                          // mov           x9, x8
  .long  0xbd400d11                          // ldr           s17, [x8, #12]
  .long  0x4d40c950                          // ld1r          {v16.4s}, [x10]
  .long  0x4ddfc933                          // ld1r          {v19.4s}, [x9], #4
  .long  0x9100210a                          // add           x10, x8, #0x8
  .long  0x4d40c954                          // ld1r          {v20.4s}, [x10]
  .long  0x4f911010                          // fmla          v16.4s, v0.4s, v17.s[0]
  .long  0xbd400135                          // ldr           s21, [x9]
  .long  0x52b85f09                          // mov           w9, #0xc2f80000
  .long  0x728e6ee9                          // movk          w9, #0x7377
  .long  0x4e040d37                          // dup           v23.4s, w9
  .long  0x52a7f7e9                          // mov           w9, #0x3fbf0000
  .long  0x7297eea9                          // movk          w9, #0xbf75
  .long  0x4f951014                          // fmla          v20.4s, v0.4s, v21.s[0]
  .long  0x6e20e640                          // fcmge         v0.4s, v18.4s, v0.4s
  .long  0x4e040d32                          // dup           v18.4s, w9
  .long  0x52a7d689                          // mov           w9, #0x3eb40000
  .long  0x4f03d7f1                          // movi          v17.4s, #0x7f, msl #16
  .long  0x72889f29                          // movk          w9, #0x44f9
  .long  0x4e21da95                          // scvtf         v21.4s, v20.4s
  .long  0x4e311e91                          // and           v17.16b, v20.16b, v17.16b
  .long  0x4e040d34                          // dup           v20.4s, w9
  .long  0x52a7fb89                          // mov           w9, #0x3fdc0000
  .long  0x4e35ced7                          // fmla          v23.4s, v22.4s, v21.4s
  .long  0x729d3469                          // movk          w9, #0xe9a3
  .long  0x4f0177f1                          // orr           v17.4s, #0x3f, lsl #24
  .long  0x4eb2ce37                          // fmls          v23.4s, v17.4s, v18.4s
  .long  0x4e040d32                          // dup           v18.4s, w9
  .long  0x52a85e49                          // mov           w9, #0x42f20000
  .long  0x72918a29                          // movk          w9, #0x8c51
  .long  0x4e34d631                          // fadd          v17.4s, v17.4s, v20.4s
  .long  0x4e040d34                          // dup           v20.4s, w9
  .long  0x52a7f7c9                          // mov           w9, #0x3fbe0000
  .long  0x729791a9                          // movk          w9, #0xbc8d
  .long  0x6e31fe51                          // fdiv          v17.4s, v18.4s, v17.4s
  .long  0x4e040d32                          // dup           v18.4s, w9
  .long  0x52a81349                          // mov           w9, #0x409a0000
  .long  0x4eb1d6f1                          // fsub          v17.4s, v23.4s, v17.4s
  .long  0x729ebf09                          // movk          w9, #0xf5f8
  .long  0x6e31de71                          // fmul          v17.4s, v19.4s, v17.4s
  .long  0x4e040d35                          // dup           v21.4s, w9
  .long  0x52a83ba9                          // mov           w9, #0x41dd0000
  .long  0x4e219a33                          // frintm        v19.4s, v17.4s
  .long  0x729a5fc9                          // movk          w9, #0xd2fe
  .long  0x4e34d634                          // fadd          v20.4s, v17.4s, v20.4s
  .long  0x4eb3d631                          // fsub          v17.4s, v17.4s, v19.4s
  .long  0x4eb2ce34                          // fmls          v20.4s, v17.4s, v18.4s
  .long  0x4eb1d6b1                          // fsub          v17.4s, v21.4s, v17.4s
  .long  0x4e040d35                          // dup           v21.4s, w9
  .long  0x91005108                          // add           x8, x8, #0x14
  .long  0x6e31feb1                          // fdiv          v17.4s, v21.4s, v17.4s
  .long  0x4e31d691                          // fadd          v17.4s, v20.4s, v17.4s
  .long  0x4d40c914                          // ld1r          {v20.4s}, [x8]
  .long  0x4f026573                          // movi          v19.4s, #0x4b, lsl #24
  .long  0x6e33de31                          // fmul          v17.4s, v17.4s, v19.4s
  .long  0x6e21aa31                          // fcvtnu        v17.4s, v17.4s
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x4e34d631                          // fadd          v17.4s, v17.4s, v20.4s
  .long  0x6f00e412                          // movi          v18.2d, #0x0
  .long  0x6e711e00                          // bsl           v0.16b, v16.16b, v17.16b
  .long  0x4f03f615                          // fmov          v21.4s, #1.000000000000000000e+00
  .long  0x4e32f400                          // fmax          v0.4s, v0.4s, v18.4s
  .long  0x4eb5f400                          // fmin          v0.4s, v0.4s, v21.4s
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_parametric_g_aarch64
.globl _sk_parametric_g_aarch64
FUNCTION(_sk_parametric_g_aarch64)
_sk_parametric_g_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x4f016696                          // movi          v22.4s, #0x34, lsl #24
  .long  0x91004109                          // add           x9, x8, #0x10
  .long  0x9100610a                          // add           x10, x8, #0x18
  .long  0x4d40c932                          // ld1r          {v18.4s}, [x9]
  .long  0xaa0803e9                          // mov           x9, x8
  .long  0xbd400d11                          // ldr           s17, [x8, #12]
  .long  0x4d40c950                          // ld1r          {v16.4s}, [x10]
  .long  0x4ddfc933                          // ld1r          {v19.4s}, [x9], #4
  .long  0x9100210a                          // add           x10, x8, #0x8
  .long  0x4d40c954                          // ld1r          {v20.4s}, [x10]
  .long  0x4f911030                          // fmla          v16.4s, v1.4s, v17.s[0]
  .long  0xbd400135                          // ldr           s21, [x9]
  .long  0x52b85f09                          // mov           w9, #0xc2f80000
  .long  0x728e6ee9                          // movk          w9, #0x7377
  .long  0x4e040d37                          // dup           v23.4s, w9
  .long  0x52a7f7e9                          // mov           w9, #0x3fbf0000
  .long  0x7297eea9                          // movk          w9, #0xbf75
  .long  0x4f951034                          // fmla          v20.4s, v1.4s, v21.s[0]
  .long  0x6e21e641                          // fcmge         v1.4s, v18.4s, v1.4s
  .long  0x4e040d32                          // dup           v18.4s, w9
  .long  0x52a7d689                          // mov           w9, #0x3eb40000
  .long  0x4f03d7f1                          // movi          v17.4s, #0x7f, msl #16
  .long  0x72889f29                          // movk          w9, #0x44f9
  .long  0x4e21da95                          // scvtf         v21.4s, v20.4s
  .long  0x4e311e91                          // and           v17.16b, v20.16b, v17.16b
  .long  0x4e040d34                          // dup           v20.4s, w9
  .long  0x52a7fb89                          // mov           w9, #0x3fdc0000
  .long  0x4e35ced7                          // fmla          v23.4s, v22.4s, v21.4s
  .long  0x729d3469                          // movk          w9, #0xe9a3
  .long  0x4f0177f1                          // orr           v17.4s, #0x3f, lsl #24
  .long  0x4eb2ce37                          // fmls          v23.4s, v17.4s, v18.4s
  .long  0x4e040d32                          // dup           v18.4s, w9
  .long  0x52a85e49                          // mov           w9, #0x42f20000
  .long  0x72918a29                          // movk          w9, #0x8c51
  .long  0x4e34d631                          // fadd          v17.4s, v17.4s, v20.4s
  .long  0x4e040d34                          // dup           v20.4s, w9
  .long  0x52a7f7c9                          // mov           w9, #0x3fbe0000
  .long  0x729791a9                          // movk          w9, #0xbc8d
  .long  0x6e31fe51                          // fdiv          v17.4s, v18.4s, v17.4s
  .long  0x4e040d32                          // dup           v18.4s, w9
  .long  0x52a81349                          // mov           w9, #0x409a0000
  .long  0x4eb1d6f1                          // fsub          v17.4s, v23.4s, v17.4s
  .long  0x729ebf09                          // movk          w9, #0xf5f8
  .long  0x6e31de71                          // fmul          v17.4s, v19.4s, v17.4s
  .long  0x4e040d35                          // dup           v21.4s, w9
  .long  0x52a83ba9                          // mov           w9, #0x41dd0000
  .long  0x4e219a33                          // frintm        v19.4s, v17.4s
  .long  0x729a5fc9                          // movk          w9, #0xd2fe
  .long  0x4e34d634                          // fadd          v20.4s, v17.4s, v20.4s
  .long  0x4eb3d631                          // fsub          v17.4s, v17.4s, v19.4s
  .long  0x4eb2ce34                          // fmls          v20.4s, v17.4s, v18.4s
  .long  0x4eb1d6b1                          // fsub          v17.4s, v21.4s, v17.4s
  .long  0x4e040d35                          // dup           v21.4s, w9
  .long  0x91005108                          // add           x8, x8, #0x14
  .long  0x6e31feb1                          // fdiv          v17.4s, v21.4s, v17.4s
  .long  0x4e31d691                          // fadd          v17.4s, v20.4s, v17.4s
  .long  0x4d40c914                          // ld1r          {v20.4s}, [x8]
  .long  0x4f026573                          // movi          v19.4s, #0x4b, lsl #24
  .long  0x6e33de31                          // fmul          v17.4s, v17.4s, v19.4s
  .long  0x6e21aa31                          // fcvtnu        v17.4s, v17.4s
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x4e34d631                          // fadd          v17.4s, v17.4s, v20.4s
  .long  0x6f00e412                          // movi          v18.2d, #0x0
  .long  0x6e711e01                          // bsl           v1.16b, v16.16b, v17.16b
  .long  0x4f03f615                          // fmov          v21.4s, #1.000000000000000000e+00
  .long  0x4e32f421                          // fmax          v1.4s, v1.4s, v18.4s
  .long  0x4eb5f421                          // fmin          v1.4s, v1.4s, v21.4s
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_parametric_b_aarch64
.globl _sk_parametric_b_aarch64
FUNCTION(_sk_parametric_b_aarch64)
_sk_parametric_b_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x4f016696                          // movi          v22.4s, #0x34, lsl #24
  .long  0x91004109                          // add           x9, x8, #0x10
  .long  0x9100610a                          // add           x10, x8, #0x18
  .long  0x4d40c932                          // ld1r          {v18.4s}, [x9]
  .long  0xaa0803e9                          // mov           x9, x8
  .long  0xbd400d11                          // ldr           s17, [x8, #12]
  .long  0x4d40c950                          // ld1r          {v16.4s}, [x10]
  .long  0x4ddfc933                          // ld1r          {v19.4s}, [x9], #4
  .long  0x9100210a                          // add           x10, x8, #0x8
  .long  0x4d40c954                          // ld1r          {v20.4s}, [x10]
  .long  0x4f911050                          // fmla          v16.4s, v2.4s, v17.s[0]
  .long  0xbd400135                          // ldr           s21, [x9]
  .long  0x52b85f09                          // mov           w9, #0xc2f80000
  .long  0x728e6ee9                          // movk          w9, #0x7377
  .long  0x4e040d37                          // dup           v23.4s, w9
  .long  0x52a7f7e9                          // mov           w9, #0x3fbf0000
  .long  0x7297eea9                          // movk          w9, #0xbf75
  .long  0x4f951054                          // fmla          v20.4s, v2.4s, v21.s[0]
  .long  0x6e22e642                          // fcmge         v2.4s, v18.4s, v2.4s
  .long  0x4e040d32                          // dup           v18.4s, w9
  .long  0x52a7d689                          // mov           w9, #0x3eb40000
  .long  0x4f03d7f1                          // movi          v17.4s, #0x7f, msl #16
  .long  0x72889f29                          // movk          w9, #0x44f9
  .long  0x4e21da95                          // scvtf         v21.4s, v20.4s
  .long  0x4e311e91                          // and           v17.16b, v20.16b, v17.16b
  .long  0x4e040d34                          // dup           v20.4s, w9
  .long  0x52a7fb89                          // mov           w9, #0x3fdc0000
  .long  0x4e35ced7                          // fmla          v23.4s, v22.4s, v21.4s
  .long  0x729d3469                          // movk          w9, #0xe9a3
  .long  0x4f0177f1                          // orr           v17.4s, #0x3f, lsl #24
  .long  0x4eb2ce37                          // fmls          v23.4s, v17.4s, v18.4s
  .long  0x4e040d32                          // dup           v18.4s, w9
  .long  0x52a85e49                          // mov           w9, #0x42f20000
  .long  0x72918a29                          // movk          w9, #0x8c51
  .long  0x4e34d631                          // fadd          v17.4s, v17.4s, v20.4s
  .long  0x4e040d34                          // dup           v20.4s, w9
  .long  0x52a7f7c9                          // mov           w9, #0x3fbe0000
  .long  0x729791a9                          // movk          w9, #0xbc8d
  .long  0x6e31fe51                          // fdiv          v17.4s, v18.4s, v17.4s
  .long  0x4e040d32                          // dup           v18.4s, w9
  .long  0x52a81349                          // mov           w9, #0x409a0000
  .long  0x4eb1d6f1                          // fsub          v17.4s, v23.4s, v17.4s
  .long  0x729ebf09                          // movk          w9, #0xf5f8
  .long  0x6e31de71                          // fmul          v17.4s, v19.4s, v17.4s
  .long  0x4e040d35                          // dup           v21.4s, w9
  .long  0x52a83ba9                          // mov           w9, #0x41dd0000
  .long  0x4e219a33                          // frintm        v19.4s, v17.4s
  .long  0x729a5fc9                          // movk          w9, #0xd2fe
  .long  0x4e34d634                          // fadd          v20.4s, v17.4s, v20.4s
  .long  0x4eb3d631                          // fsub          v17.4s, v17.4s, v19.4s
  .long  0x4eb2ce34                          // fmls          v20.4s, v17.4s, v18.4s
  .long  0x4eb1d6b1                          // fsub          v17.4s, v21.4s, v17.4s
  .long  0x4e040d35                          // dup           v21.4s, w9
  .long  0x91005108                          // add           x8, x8, #0x14
  .long  0x6e31feb1                          // fdiv          v17.4s, v21.4s, v17.4s
  .long  0x4e31d691                          // fadd          v17.4s, v20.4s, v17.4s
  .long  0x4d40c914                          // ld1r          {v20.4s}, [x8]
  .long  0x4f026573                          // movi          v19.4s, #0x4b, lsl #24
  .long  0x6e33de31                          // fmul          v17.4s, v17.4s, v19.4s
  .long  0x6e21aa31                          // fcvtnu        v17.4s, v17.4s
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x4e34d631                          // fadd          v17.4s, v17.4s, v20.4s
  .long  0x6f00e412                          // movi          v18.2d, #0x0
  .long  0x6e711e02                          // bsl           v2.16b, v16.16b, v17.16b
  .long  0x4f03f615                          // fmov          v21.4s, #1.000000000000000000e+00
  .long  0x4e32f442                          // fmax          v2.4s, v2.4s, v18.4s
  .long  0x4eb5f442                          // fmin          v2.4s, v2.4s, v21.4s
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_parametric_a_aarch64
.globl _sk_parametric_a_aarch64
FUNCTION(_sk_parametric_a_aarch64)
_sk_parametric_a_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x4f016696                          // movi          v22.4s, #0x34, lsl #24
  .long  0x91004109                          // add           x9, x8, #0x10
  .long  0x9100610a                          // add           x10, x8, #0x18
  .long  0x4d40c932                          // ld1r          {v18.4s}, [x9]
  .long  0xaa0803e9                          // mov           x9, x8
  .long  0xbd400d11                          // ldr           s17, [x8, #12]
  .long  0x4d40c950                          // ld1r          {v16.4s}, [x10]
  .long  0x4ddfc933                          // ld1r          {v19.4s}, [x9], #4
  .long  0x9100210a                          // add           x10, x8, #0x8
  .long  0x4d40c954                          // ld1r          {v20.4s}, [x10]
  .long  0x4f911070                          // fmla          v16.4s, v3.4s, v17.s[0]
  .long  0xbd400135                          // ldr           s21, [x9]
  .long  0x52b85f09                          // mov           w9, #0xc2f80000
  .long  0x728e6ee9                          // movk          w9, #0x7377
  .long  0x4e040d37                          // dup           v23.4s, w9
  .long  0x52a7f7e9                          // mov           w9, #0x3fbf0000
  .long  0x7297eea9                          // movk          w9, #0xbf75
  .long  0x4f951074                          // fmla          v20.4s, v3.4s, v21.s[0]
  .long  0x6e23e643                          // fcmge         v3.4s, v18.4s, v3.4s
  .long  0x4e040d32                          // dup           v18.4s, w9
  .long  0x52a7d689                          // mov           w9, #0x3eb40000
  .long  0x4f03d7f1                          // movi          v17.4s, #0x7f, msl #16
  .long  0x72889f29                          // movk          w9, #0x44f9
  .long  0x4e21da95                          // scvtf         v21.4s, v20.4s
  .long  0x4e311e91                          // and           v17.16b, v20.16b, v17.16b
  .long  0x4e040d34                          // dup           v20.4s, w9
  .long  0x52a7fb89                          // mov           w9, #0x3fdc0000
  .long  0x4e35ced7                          // fmla          v23.4s, v22.4s, v21.4s
  .long  0x729d3469                          // movk          w9, #0xe9a3
  .long  0x4f0177f1                          // orr           v17.4s, #0x3f, lsl #24
  .long  0x4eb2ce37                          // fmls          v23.4s, v17.4s, v18.4s
  .long  0x4e040d32                          // dup           v18.4s, w9
  .long  0x52a85e49                          // mov           w9, #0x42f20000
  .long  0x72918a29                          // movk          w9, #0x8c51
  .long  0x4e34d631                          // fadd          v17.4s, v17.4s, v20.4s
  .long  0x4e040d34                          // dup           v20.4s, w9
  .long  0x52a7f7c9                          // mov           w9, #0x3fbe0000
  .long  0x729791a9                          // movk          w9, #0xbc8d
  .long  0x6e31fe51                          // fdiv          v17.4s, v18.4s, v17.4s
  .long  0x4e040d32                          // dup           v18.4s, w9
  .long  0x52a81349                          // mov           w9, #0x409a0000
  .long  0x4eb1d6f1                          // fsub          v17.4s, v23.4s, v17.4s
  .long  0x729ebf09                          // movk          w9, #0xf5f8
  .long  0x6e31de71                          // fmul          v17.4s, v19.4s, v17.4s
  .long  0x4e040d35                          // dup           v21.4s, w9
  .long  0x52a83ba9                          // mov           w9, #0x41dd0000
  .long  0x4e219a33                          // frintm        v19.4s, v17.4s
  .long  0x729a5fc9                          // movk          w9, #0xd2fe
  .long  0x4e34d634                          // fadd          v20.4s, v17.4s, v20.4s
  .long  0x4eb3d631                          // fsub          v17.4s, v17.4s, v19.4s
  .long  0x4eb2ce34                          // fmls          v20.4s, v17.4s, v18.4s
  .long  0x4eb1d6b1                          // fsub          v17.4s, v21.4s, v17.4s
  .long  0x4e040d35                          // dup           v21.4s, w9
  .long  0x91005108                          // add           x8, x8, #0x14
  .long  0x6e31feb1                          // fdiv          v17.4s, v21.4s, v17.4s
  .long  0x4e31d691                          // fadd          v17.4s, v20.4s, v17.4s
  .long  0x4d40c914                          // ld1r          {v20.4s}, [x8]
  .long  0x4f026573                          // movi          v19.4s, #0x4b, lsl #24
  .long  0x6e33de31                          // fmul          v17.4s, v17.4s, v19.4s
  .long  0x6e21aa31                          // fcvtnu        v17.4s, v17.4s
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x4e34d631                          // fadd          v17.4s, v17.4s, v20.4s
  .long  0x6f00e412                          // movi          v18.2d, #0x0
  .long  0x6e711e03                          // bsl           v3.16b, v16.16b, v17.16b
  .long  0x4f03f615                          // fmov          v21.4s, #1.000000000000000000e+00
  .long  0x4e32f463                          // fmax          v3.4s, v3.4s, v18.4s
  .long  0x4eb5f463                          // fmin          v3.4s, v3.4s, v21.4s
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_lab_to_xyz_aarch64
.globl _sk_lab_to_xyz_aarch64
FUNCTION(_sk_lab_to_xyz_aarch64)
_sk_lab_to_xyz_aarch64:
  .long  0x52a85908                          // mov           w8, #0x42c80000
  .long  0x4e040d10                          // dup           v16.4s, w8
  .long  0x52a86fe8                          // mov           w8, #0x437f0000
  .long  0x4f066471                          // movi          v17.4s, #0xc3, lsl #24
  .long  0x4e040d13                          // dup           v19.4s, w8
  .long  0x52a781a8                          // mov           w8, #0x3c0d0000
  .long  0x7287b968                          // movk          w8, #0x3dcb
  .long  0x4eb11e34                          // mov           v20.16b, v17.16b
  .long  0x4e21ce74                          // fmla          v20.4s, v19.4s, v1.4s
  .long  0x4e040d01                          // dup           v1.4s, w8
  .long  0x52a76068                          // mov           w8, #0x3b030000
  .long  0x72824de8                          // movk          w8, #0x126f
  .long  0x4e22ce71                          // fmla          v17.4s, v19.4s, v2.4s
  .long  0x4e040d02                          // dup           v2.4s, w8
  .long  0x52a77468                          // mov           w8, #0x3ba30000
  .long  0x729ae148                          // movk          w8, #0xd70a
  .long  0x4e040d13                          // dup           v19.4s, w8
  .long  0x52a78228                          // mov           w8, #0x3c110000
  .long  0x4f01f612                          // fmov          v18.4s, #1.600000000000000000e+01
  .long  0x72831848                          // movk          w8, #0x18c2
  .long  0x4e20ce12                          // fmla          v18.4s, v16.4s, v0.4s
  .long  0x4e040d00                          // dup           v0.4s, w8
  .long  0x52b7c1a8                          // mov           w8, #0xbe0d0000
  .long  0x7287b968                          // movk          w8, #0x3dcb
  .long  0x6e21de41                          // fmul          v1.4s, v18.4s, v1.4s
  .long  0x4e040d10                          // dup           v16.4s, w8
  .long  0x52a7c068                          // mov           w8, #0x3e030000
  .long  0x4ea11c32                          // mov           v18.16b, v1.16b
  .long  0x72900a08                          // movk          w8, #0x8050
  .long  0x4eb3ce32                          // fmls          v18.4s, v17.4s, v19.4s
  .long  0x6e21dc31                          // fmul          v17.4s, v1.4s, v1.4s
  .long  0x4ea11c35                          // mov           v21.16b, v1.16b
  .long  0x4e30d433                          // fadd          v19.4s, v1.4s, v16.4s
  .long  0x6e31dc31                          // fmul          v17.4s, v1.4s, v17.4s
  .long  0x4e34cc55                          // fmla          v21.4s, v2.4s, v20.4s
  .long  0x4e040d02                          // dup           v2.4s, w8
  .long  0x6e22de73                          // fmul          v19.4s, v19.4s, v2.4s
  .long  0x6ea0e621                          // fcmgt         v1.4s, v17.4s, v0.4s
  .long  0x6e731e21                          // bsl           v1.16b, v17.16b, v19.16b
  .long  0x6e32de51                          // fmul          v17.4s, v18.4s, v18.4s
  .long  0x4e30d653                          // fadd          v19.4s, v18.4s, v16.4s
  .long  0x6e31de51                          // fmul          v17.4s, v18.4s, v17.4s
  .long  0x52a7eec8                          // mov           w8, #0x3f760000
  .long  0x6e22de72                          // fmul          v18.4s, v19.4s, v2.4s
  .long  0x6ea0e633                          // fcmgt         v19.4s, v17.4s, v0.4s
  .long  0x729ae3e8                          // movk          w8, #0xd71f
  .long  0x6e721e33                          // bsl           v19.16b, v17.16b, v18.16b
  .long  0x6e35deb2                          // fmul          v18.4s, v21.4s, v21.4s
  .long  0x4e040d11                          // dup           v17.4s, w8
  .long  0x52a7ea68                          // mov           w8, #0x3f530000
  .long  0x4e30d6b0                          // fadd          v16.4s, v21.4s, v16.4s
  .long  0x6e32deb2                          // fmul          v18.4s, v21.4s, v18.4s
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x72881ec8                          // movk          w8, #0x40f6
  .long  0x6e22de02                          // fmul          v2.4s, v16.4s, v2.4s
  .long  0x6ea0e640                          // fcmgt         v0.4s, v18.4s, v0.4s
  .long  0x4e040d14                          // dup           v20.4s, w8
  .long  0x6e621e40                          // bsl           v0.16b, v18.16b, v2.16b
  .long  0x6e31dc00                          // fmul          v0.4s, v0.4s, v17.4s
  .long  0x6e34de62                          // fmul          v2.4s, v19.4s, v20.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_load_a8_aarch64
.globl _sk_load_a8_aarch64
FUNCTION(_sk_load_a8_aarch64)
_sk_load_a8_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x52a77009                          // mov           w9, #0x3b800000
  .long  0x72901029                          // movk          w9, #0x8081
  .long  0x4e040d22                          // dup           v2.4s, w9
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x6f00e400                          // movi          v0.2d, #0x0
  .long  0x6f00e401                          // movi          v1.2d, #0x0
  .long  0x8b000108                          // add           x8, x8, x0
  .long  0x3940010a                          // ldrb          w10, [x8]
  .long  0x3940050b                          // ldrb          w11, [x8, #1]
  .long  0x3940090c                          // ldrb          w12, [x8, #2]
  .long  0x39400d08                          // ldrb          w8, [x8, #3]
  .long  0x4e021d43                          // mov           v3.h[0], w10
  .long  0x4e061d63                          // mov           v3.h[1], w11
  .long  0x4e0a1d83                          // mov           v3.h[2], w12
  .long  0x4e0e1d03                          // mov           v3.h[3], w8
  .long  0x2f10a463                          // uxtl          v3.4s, v3.4h
  .long  0x6e21d863                          // ucvtf         v3.4s, v3.4s
  .long  0x6e22dc63                          // fmul          v3.4s, v3.4s, v2.4s
  .long  0x6f00e402                          // movi          v2.2d, #0x0
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_gather_a8_aarch64
.globl _sk_gather_a8_aarch64
FUNCTION(_sk_gather_a8_aarch64)
_sk_gather_a8_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x4ea1b821                          // fcvtzs        v1.4s, v1.4s
  .long  0x4ea1b800                          // fcvtzs        v0.4s, v0.4s
  .long  0x91004109                          // add           x9, x8, #0x10
  .long  0x4d40c922                          // ld1r          {v2.4s}, [x9]
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x52a77009                          // mov           w9, #0x3b800000
  .long  0x72901029                          // movk          w9, #0x8081
  .long  0x4ea19440                          // mla           v0.4s, v2.4s, v1.4s
  .long  0x1e26000c                          // fmov          w12, s0
  .long  0x4e040d23                          // dup           v3.4s, w9
  .long  0x0e0c3c09                          // mov           w9, v0.s[1]
  .long  0x386c490c                          // ldrb          w12, [x8, w12, uxtw]
  .long  0x0e143c0a                          // mov           w10, v0.s[2]
  .long  0x38694909                          // ldrb          w9, [x8, w9, uxtw]
  .long  0x0e1c3c0b                          // mov           w11, v0.s[3]
  .long  0x386a490a                          // ldrb          w10, [x8, w10, uxtw]
  .long  0x386b4908                          // ldrb          w8, [x8, w11, uxtw]
  .long  0x4e021d82                          // mov           v2.h[0], w12
  .long  0x4e061d22                          // mov           v2.h[1], w9
  .long  0x4e0a1d42                          // mov           v2.h[2], w10
  .long  0x4e0e1d02                          // mov           v2.h[3], w8
  .long  0x2f07b7e2                          // bic           v2.4h, #0xff, lsl #8
  .long  0x2f10a442                          // uxtl          v2.4s, v2.4h
  .long  0x6e21d842                          // ucvtf         v2.4s, v2.4s
  .long  0x6f00e400                          // movi          v0.2d, #0x0
  .long  0x6f00e401                          // movi          v1.2d, #0x0
  .long  0x6e23dc43                          // fmul          v3.4s, v2.4s, v3.4s
  .long  0x6f00e402                          // movi          v2.2d, #0x0
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_store_a8_aarch64
.globl _sk_store_a8_aarch64
FUNCTION(_sk_store_a8_aarch64)
_sk_store_a8_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x52a86fe9                          // mov           w9, #0x437f0000
  .long  0x4e040d30                          // dup           v16.4s, w9
  .long  0x6e30dc70                          // fmul          v16.4s, v3.4s, v16.4s
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x6e21aa10                          // fcvtnu        v16.4s, v16.4s
  .long  0x0e612a10                          // xtn           v16.4h, v16.4s
  .long  0x0e0e3e09                          // umov          w9, v16.h[3]
  .long  0x8b000108                          // add           x8, x8, x0
  .long  0x39000d09                          // strb          w9, [x8, #3]
  .long  0x0e0a3e09                          // umov          w9, v16.h[2]
  .long  0x39000909                          // strb          w9, [x8, #2]
  .long  0x0e063e09                          // umov          w9, v16.h[1]
  .long  0x39000509                          // strb          w9, [x8, #1]
  .long  0x0e023e09                          // umov          w9, v16.h[0]
  .long  0x39000109                          // strb          w9, [x8]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_load_g8_aarch64
.globl _sk_load_g8_aarch64
FUNCTION(_sk_load_g8_aarch64)
_sk_load_g8_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x52a77009                          // mov           w9, #0x3b800000
  .long  0x72901029                          // movk          w9, #0x8081
  .long  0x4e040d20                          // dup           v0.4s, w9
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x4f03f603                          // fmov          v3.4s, #1.000000000000000000e+00
  .long  0x8b000108                          // add           x8, x8, x0
  .long  0x3940010a                          // ldrb          w10, [x8]
  .long  0x39400509                          // ldrb          w9, [x8, #1]
  .long  0x3940090b                          // ldrb          w11, [x8, #2]
  .long  0x39400d08                          // ldrb          w8, [x8, #3]
  .long  0x4e021d41                          // mov           v1.h[0], w10
  .long  0x4e061d21                          // mov           v1.h[1], w9
  .long  0x4e0a1d61                          // mov           v1.h[2], w11
  .long  0x4e0e1d01                          // mov           v1.h[3], w8
  .long  0x2f10a421                          // uxtl          v1.4s, v1.4h
  .long  0x6e21d821                          // ucvtf         v1.4s, v1.4s
  .long  0x6e20dc20                          // fmul          v0.4s, v1.4s, v0.4s
  .long  0x4ea01c01                          // mov           v1.16b, v0.16b
  .long  0x4ea01c02                          // mov           v2.16b, v0.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_gather_g8_aarch64
.globl _sk_gather_g8_aarch64
FUNCTION(_sk_gather_g8_aarch64)
_sk_gather_g8_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x4ea1b821                          // fcvtzs        v1.4s, v1.4s
  .long  0x4ea1b800                          // fcvtzs        v0.4s, v0.4s
  .long  0x91004109                          // add           x9, x8, #0x10
  .long  0x4d40c922                          // ld1r          {v2.4s}, [x9]
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x52a77009                          // mov           w9, #0x3b800000
  .long  0x72901029                          // movk          w9, #0x8081
  .long  0x4ea19440                          // mla           v0.4s, v2.4s, v1.4s
  .long  0x1e26000c                          // fmov          w12, s0
  .long  0x4e040d23                          // dup           v3.4s, w9
  .long  0x0e0c3c09                          // mov           w9, v0.s[1]
  .long  0x386c490c                          // ldrb          w12, [x8, w12, uxtw]
  .long  0x0e143c0a                          // mov           w10, v0.s[2]
  .long  0x38694909                          // ldrb          w9, [x8, w9, uxtw]
  .long  0x0e1c3c0b                          // mov           w11, v0.s[3]
  .long  0x386a490a                          // ldrb          w10, [x8, w10, uxtw]
  .long  0x386b4908                          // ldrb          w8, [x8, w11, uxtw]
  .long  0x4e021d80                          // mov           v0.h[0], w12
  .long  0x4e061d20                          // mov           v0.h[1], w9
  .long  0x4e0a1d40                          // mov           v0.h[2], w10
  .long  0x4e0e1d00                          // mov           v0.h[3], w8
  .long  0x2f07b7e0                          // bic           v0.4h, #0xff, lsl #8
  .long  0x2f10a400                          // uxtl          v0.4s, v0.4h
  .long  0x6e21d800                          // ucvtf         v0.4s, v0.4s
  .long  0x6e23dc00                          // fmul          v0.4s, v0.4s, v3.4s
  .long  0x4f03f603                          // fmov          v3.4s, #1.000000000000000000e+00
  .long  0x4ea01c01                          // mov           v1.16b, v0.16b
  .long  0x4ea01c02                          // mov           v2.16b, v0.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_gather_i8_aarch64
.globl _sk_gather_i8_aarch64
FUNCTION(_sk_gather_i8_aarch64)
_sk_gather_i8_aarch64:
  .long  0xaa0103e8                          // mov           x8, x1
  .long  0xf8408429                          // ldr           x9, [x1], #8
  .long  0xb4000069                          // cbz           x9, 1d28 <sk_gather_i8_aarch64+0x14>
  .long  0xaa0903ea                          // mov           x10, x9
  .long  0x14000003                          // b             1d30 <sk_gather_i8_aarch64+0x1c>
  .long  0xf940050a                          // ldr           x10, [x8, #8]
  .long  0x91004101                          // add           x1, x8, #0x10
  .long  0xf8410548                          // ldr           x8, [x10], #16
  .long  0x4ea1b821                          // fcvtzs        v1.4s, v1.4s
  .long  0x4ea1b800                          // fcvtzs        v0.4s, v0.4s
  .long  0xf9400529                          // ldr           x9, [x9, #8]
  .long  0x4d40c942                          // ld1r          {v2.4s}, [x10]
  .long  0x6f00e623                          // movi          v3.2d, #0xff000000ff
  .long  0x4ea19440                          // mla           v0.4s, v2.4s, v1.4s
  .long  0x1e26000d                          // fmov          w13, s0
  .long  0x0e0c3c0a                          // mov           w10, v0.s[1]
  .long  0x386d490d                          // ldrb          w13, [x8, w13, uxtw]
  .long  0x0e143c0b                          // mov           w11, v0.s[2]
  .long  0x386a490a                          // ldrb          w10, [x8, w10, uxtw]
  .long  0x0e1c3c0c                          // mov           w12, v0.s[3]
  .long  0x386b490b                          // ldrb          w11, [x8, w11, uxtw]
  .long  0x386c4908                          // ldrb          w8, [x8, w12, uxtw]
  .long  0x4e021da0                          // mov           v0.h[0], w13
  .long  0x4e061d40                          // mov           v0.h[1], w10
  .long  0x4e0a1d60                          // mov           v0.h[2], w11
  .long  0x4e0e1d00                          // mov           v0.h[3], w8
  .long  0x2f10a400                          // uxtl          v0.4s, v0.4h
  .long  0x4e231c00                          // and           v0.16b, v0.16b, v3.16b
  .long  0x1e26000c                          // fmov          w12, s0
  .long  0x8b2c492c                          // add           x12, x9, w12, uxtw #2
  .long  0x0e0c3c08                          // mov           w8, v0.s[1]
  .long  0x0e143c0a                          // mov           w10, v0.s[2]
  .long  0x0e1c3c0b                          // mov           w11, v0.s[3]
  .long  0x0d408180                          // ld1           {v0.s}[0], [x12]
  .long  0x8b284928                          // add           x8, x9, w8, uxtw #2
  .long  0xb86a592a                          // ldr           w10, [x9, w10, uxtw #2]
  .long  0x52a7700c                          // mov           w12, #0x3b800000
  .long  0x0d409100                          // ld1           {v0.s}[1], [x8]
  .long  0xb86b5928                          // ldr           w8, [x9, w11, uxtw #2]
  .long  0x7290102c                          // movk          w12, #0x8081
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x4e141d40                          // mov           v0.s[2], w10
  .long  0x4e1c1d00                          // mov           v0.s[3], w8
  .long  0x4e231c01                          // and           v1.16b, v0.16b, v3.16b
  .long  0x6f380402                          // ushr          v2.4s, v0.4s, #8
  .long  0x6f300411                          // ushr          v17.4s, v0.4s, #16
  .long  0x4e040d90                          // dup           v16.4s, w12
  .long  0x6f280400                          // ushr          v0.4s, v0.4s, #24
  .long  0x4e21d821                          // scvtf         v1.4s, v1.4s
  .long  0x4e231c42                          // and           v2.16b, v2.16b, v3.16b
  .long  0x4e231e23                          // and           v3.16b, v17.16b, v3.16b
  .long  0x4e21d811                          // scvtf         v17.4s, v0.4s
  .long  0x6e30dc20                          // fmul          v0.4s, v1.4s, v16.4s
  .long  0x4e21d841                          // scvtf         v1.4s, v2.4s
  .long  0x4e21d862                          // scvtf         v2.4s, v3.4s
  .long  0x6e30dc21                          // fmul          v1.4s, v1.4s, v16.4s
  .long  0x6e30dc42                          // fmul          v2.4s, v2.4s, v16.4s
  .long  0x6e30de23                          // fmul          v3.4s, v17.4s, v16.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_load_565_aarch64
.globl _sk_load_565_aarch64
FUNCTION(_sk_load_565_aarch64)
_sk_load_565_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xd37ff809                          // lsl           x9, x0, #1
  .long  0x4f072701                          // movi          v1.4s, #0xf8, lsl #8
  .long  0x4f0007e3                          // movi          v3.4s, #0x1f
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0xfc696900                          // ldr           d0, [x8, x9]
  .long  0x321b17e8                          // orr           w8, wzr, #0x7e0
  .long  0x4e040d02                          // dup           v2.4s, w8
  .long  0x52a6f088                          // mov           w8, #0x37840000
  .long  0x72842108                          // movk          w8, #0x2108
  .long  0x2f10a400                          // uxtl          v0.4s, v0.4h
  .long  0x4e211c01                          // and           v1.16b, v0.16b, v1.16b
  .long  0x4e221c02                          // and           v2.16b, v0.16b, v2.16b
  .long  0x4e231c03                          // and           v3.16b, v0.16b, v3.16b
  .long  0x4e040d00                          // dup           v0.4s, w8
  .long  0x52a74048                          // mov           w8, #0x3a020000
  .long  0x72810428                          // movk          w8, #0x821
  .long  0x4e21d821                          // scvtf         v1.4s, v1.4s
  .long  0x6e20dc20                          // fmul          v0.4s, v1.4s, v0.4s
  .long  0x4e040d01                          // dup           v1.4s, w8
  .long  0x52a7a088                          // mov           w8, #0x3d040000
  .long  0x72842108                          // movk          w8, #0x2108
  .long  0x4e21d842                          // scvtf         v2.4s, v2.4s
  .long  0x6e21dc41                          // fmul          v1.4s, v2.4s, v1.4s
  .long  0x4e040d02                          // dup           v2.4s, w8
  .long  0x4e21d863                          // scvtf         v3.4s, v3.4s
  .long  0x6e22dc62                          // fmul          v2.4s, v3.4s, v2.4s
  .long  0x4f03f603                          // fmov          v3.4s, #1.000000000000000000e+00
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_gather_565_aarch64
.globl _sk_gather_565_aarch64
FUNCTION(_sk_gather_565_aarch64)
_sk_gather_565_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x4ea1b821                          // fcvtzs        v1.4s, v1.4s
  .long  0x4ea1b800                          // fcvtzs        v0.4s, v0.4s
  .long  0x91004109                          // add           x9, x8, #0x10
  .long  0x4d40c922                          // ld1r          {v2.4s}, [x9]
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x321b17e9                          // orr           w9, wzr, #0x7e0
  .long  0x4e040d23                          // dup           v3.4s, w9
  .long  0x4ea19440                          // mla           v0.4s, v2.4s, v1.4s
  .long  0x1e26000c                          // fmov          w12, s0
  .long  0x0e0c3c09                          // mov           w9, v0.s[1]
  .long  0x8b2c450c                          // add           x12, x8, w12, uxtw #1
  .long  0x0e143c0a                          // mov           w10, v0.s[2]
  .long  0x0e1c3c0b                          // mov           w11, v0.s[3]
  .long  0x0d404180                          // ld1           {v0.h}[0], [x12]
  .long  0x78695909                          // ldrh          w9, [x8, w9, uxtw #1]
  .long  0x786a590a                          // ldrh          w10, [x8, w10, uxtw #1]
  .long  0x786b5908                          // ldrh          w8, [x8, w11, uxtw #1]
  .long  0x4f072701                          // movi          v1.4s, #0xf8, lsl #8
  .long  0x4e061d20                          // mov           v0.h[1], w9
  .long  0x4e0a1d40                          // mov           v0.h[2], w10
  .long  0x4e0e1d00                          // mov           v0.h[3], w8
  .long  0x52a6f08b                          // mov           w11, #0x37840000
  .long  0x2f10a400                          // uxtl          v0.4s, v0.4h
  .long  0x7284210b                          // movk          w11, #0x2108
  .long  0x52a74049                          // mov           w9, #0x3a020000
  .long  0x4f0007e2                          // movi          v2.4s, #0x1f
  .long  0x4e211c01                          // and           v1.16b, v0.16b, v1.16b
  .long  0x72810429                          // movk          w9, #0x821
  .long  0x52a7a08a                          // mov           w10, #0x3d040000
  .long  0x4e231c03                          // and           v3.16b, v0.16b, v3.16b
  .long  0x4e221c02                          // and           v2.16b, v0.16b, v2.16b
  .long  0x4e040d60                          // dup           v0.4s, w11
  .long  0x4e21d821                          // scvtf         v1.4s, v1.4s
  .long  0x7284210a                          // movk          w10, #0x2108
  .long  0x6e20dc20                          // fmul          v0.4s, v1.4s, v0.4s
  .long  0x4e040d21                          // dup           v1.4s, w9
  .long  0x4e21d863                          // scvtf         v3.4s, v3.4s
  .long  0x6e21dc61                          // fmul          v1.4s, v3.4s, v1.4s
  .long  0x4e040d43                          // dup           v3.4s, w10
  .long  0x4e21d842                          // scvtf         v2.4s, v2.4s
  .long  0x6e23dc42                          // fmul          v2.4s, v2.4s, v3.4s
  .long  0x4f03f603                          // fmov          v3.4s, #1.000000000000000000e+00
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_store_565_aarch64
.globl _sk_store_565_aarch64
FUNCTION(_sk_store_565_aarch64)
_sk_store_565_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x52a84f8a                          // mov           w10, #0x427c0000
  .long  0x4f01f7f0                          // fmov          v16.4s, #3.100000000000000000e+01
  .long  0x4e040d52                          // dup           v18.4s, w10
  .long  0x6e30dc11                          // fmul          v17.4s, v0.4s, v16.4s
  .long  0x6e32dc32                          // fmul          v18.4s, v1.4s, v18.4s
  .long  0x6e21aa31                          // fcvtnu        v17.4s, v17.4s
  .long  0x6e21aa52                          // fcvtnu        v18.4s, v18.4s
  .long  0x6e30dc50                          // fmul          v16.4s, v2.4s, v16.4s
  .long  0x4f2b5631                          // shl           v17.4s, v17.4s, #11
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x4f255652                          // shl           v18.4s, v18.4s, #5
  .long  0x4eb11e51                          // orr           v17.16b, v18.16b, v17.16b
  .long  0x6e21aa10                          // fcvtnu        v16.4s, v16.4s
  .long  0x4eb01e30                          // orr           v16.16b, v17.16b, v16.16b
  .long  0xd37ff809                          // lsl           x9, x0, #1
  .long  0x0e612a10                          // xtn           v16.4h, v16.4s
  .long  0xfc296910                          // str           d16, [x8, x9]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_load_4444_aarch64
.globl _sk_load_4444_aarch64
FUNCTION(_sk_load_4444_aarch64)
_sk_load_4444_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xd37ff809                          // lsl           x9, x0, #1
  .long  0x4f072601                          // movi          v1.4s, #0xf0, lsl #8
  .long  0x4f0025e2                          // movi          v2.4s, #0xf, lsl #8
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x4f070603                          // movi          v3.4s, #0xf0
  .long  0x4f0005f0                          // movi          v16.4s, #0xf
  .long  0xfc696900                          // ldr           d0, [x8, x9]
  .long  0x52a6f108                          // mov           w8, #0x37880000
  .long  0x72911128                          // movk          w8, #0x8889
  .long  0x2f10a400                          // uxtl          v0.4s, v0.4h
  .long  0x4e211c01                          // and           v1.16b, v0.16b, v1.16b
  .long  0x4e221c02                          // and           v2.16b, v0.16b, v2.16b
  .long  0x4e231c03                          // and           v3.16b, v0.16b, v3.16b
  .long  0x4e301c10                          // and           v16.16b, v0.16b, v16.16b
  .long  0x4e040d00                          // dup           v0.4s, w8
  .long  0x52a73108                          // mov           w8, #0x39880000
  .long  0x72911128                          // movk          w8, #0x8889
  .long  0x4e21d821                          // scvtf         v1.4s, v1.4s
  .long  0x6e20dc20                          // fmul          v0.4s, v1.4s, v0.4s
  .long  0x4e040d01                          // dup           v1.4s, w8
  .long  0x52a77108                          // mov           w8, #0x3b880000
  .long  0x72911128                          // movk          w8, #0x8889
  .long  0x4e21d842                          // scvtf         v2.4s, v2.4s
  .long  0x6e21dc41                          // fmul          v1.4s, v2.4s, v1.4s
  .long  0x4e040d02                          // dup           v2.4s, w8
  .long  0x52a7b108                          // mov           w8, #0x3d880000
  .long  0x72911128                          // movk          w8, #0x8889
  .long  0x4e21d863                          // scvtf         v3.4s, v3.4s
  .long  0x6e22dc62                          // fmul          v2.4s, v3.4s, v2.4s
  .long  0x4e040d03                          // dup           v3.4s, w8
  .long  0x4e21da10                          // scvtf         v16.4s, v16.4s
  .long  0x6e23de03                          // fmul          v3.4s, v16.4s, v3.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_gather_4444_aarch64
.globl _sk_gather_4444_aarch64
FUNCTION(_sk_gather_4444_aarch64)
_sk_gather_4444_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x4ea1b821                          // fcvtzs        v1.4s, v1.4s
  .long  0x4ea1b800                          // fcvtzs        v0.4s, v0.4s
  .long  0x4f070603                          // movi          v3.4s, #0xf0
  .long  0x91004109                          // add           x9, x8, #0x10
  .long  0x4d40c922                          // ld1r          {v2.4s}, [x9]
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x4f0005f0                          // movi          v16.4s, #0xf
  .long  0x4ea19440                          // mla           v0.4s, v2.4s, v1.4s
  .long  0x1e26000c                          // fmov          w12, s0
  .long  0x0e0c3c09                          // mov           w9, v0.s[1]
  .long  0x8b2c450c                          // add           x12, x8, w12, uxtw #1
  .long  0x0e143c0a                          // mov           w10, v0.s[2]
  .long  0x0e1c3c0b                          // mov           w11, v0.s[3]
  .long  0x0d404180                          // ld1           {v0.h}[0], [x12]
  .long  0x78695909                          // ldrh          w9, [x8, w9, uxtw #1]
  .long  0x786a590a                          // ldrh          w10, [x8, w10, uxtw #1]
  .long  0x786b5908                          // ldrh          w8, [x8, w11, uxtw #1]
  .long  0x4f072601                          // movi          v1.4s, #0xf0, lsl #8
  .long  0x4e061d20                          // mov           v0.h[1], w9
  .long  0x4e0a1d40                          // mov           v0.h[2], w10
  .long  0x4e0e1d00                          // mov           v0.h[3], w8
  .long  0x52a6f10b                          // mov           w11, #0x37880000
  .long  0x2f10a400                          // uxtl          v0.4s, v0.4h
  .long  0x7291112b                          // movk          w11, #0x8889
  .long  0x4f0025e2                          // movi          v2.4s, #0xf, lsl #8
  .long  0x52a73109                          // mov           w9, #0x39880000
  .long  0x4e211c01                          // and           v1.16b, v0.16b, v1.16b
  .long  0x72911129                          // movk          w9, #0x8889
  .long  0x52a7710a                          // mov           w10, #0x3b880000
  .long  0x4e221c02                          // and           v2.16b, v0.16b, v2.16b
  .long  0x4e231c03                          // and           v3.16b, v0.16b, v3.16b
  .long  0x4e301c10                          // and           v16.16b, v0.16b, v16.16b
  .long  0x4e040d60                          // dup           v0.4s, w11
  .long  0x4e21d821                          // scvtf         v1.4s, v1.4s
  .long  0x7291112a                          // movk          w10, #0x8889
  .long  0x52a7b108                          // mov           w8, #0x3d880000
  .long  0x6e20dc20                          // fmul          v0.4s, v1.4s, v0.4s
  .long  0x4e040d21                          // dup           v1.4s, w9
  .long  0x4e21d842                          // scvtf         v2.4s, v2.4s
  .long  0x72911128                          // movk          w8, #0x8889
  .long  0x6e21dc41                          // fmul          v1.4s, v2.4s, v1.4s
  .long  0x4e040d42                          // dup           v2.4s, w10
  .long  0x4e21d863                          // scvtf         v3.4s, v3.4s
  .long  0x6e22dc62                          // fmul          v2.4s, v3.4s, v2.4s
  .long  0x4e040d03                          // dup           v3.4s, w8
  .long  0x4e21da10                          // scvtf         v16.4s, v16.4s
  .long  0x6e23de03                          // fmul          v3.4s, v16.4s, v3.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_store_4444_aarch64
.globl _sk_store_4444_aarch64
FUNCTION(_sk_store_4444_aarch64)
_sk_store_4444_aarch64:
  .long  0x4f01f5d0                          // fmov          v16.4s, #1.500000000000000000e+01
  .long  0x6e30dc11                          // fmul          v17.4s, v0.4s, v16.4s
  .long  0x6e30dc32                          // fmul          v18.4s, v1.4s, v16.4s
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x6e21aa31                          // fcvtnu        v17.4s, v17.4s
  .long  0x6e21aa52                          // fcvtnu        v18.4s, v18.4s
  .long  0x4f2c5631                          // shl           v17.4s, v17.4s, #12
  .long  0x4f285652                          // shl           v18.4s, v18.4s, #8
  .long  0x4eb11e51                          // orr           v17.16b, v18.16b, v17.16b
  .long  0x6e30dc52                          // fmul          v18.4s, v2.4s, v16.4s
  .long  0x6e21aa52                          // fcvtnu        v18.4s, v18.4s
  .long  0x6e30dc70                          // fmul          v16.4s, v3.4s, v16.4s
  .long  0x4f245652                          // shl           v18.4s, v18.4s, #4
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x4eb21e31                          // orr           v17.16b, v17.16b, v18.16b
  .long  0x6e21aa10                          // fcvtnu        v16.4s, v16.4s
  .long  0x4eb01e30                          // orr           v16.16b, v17.16b, v16.16b
  .long  0xd37ff809                          // lsl           x9, x0, #1
  .long  0x0e612a10                          // xtn           v16.4h, v16.4s
  .long  0xfc296910                          // str           d16, [x8, x9]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_load_8888_aarch64
.globl _sk_load_8888_aarch64
FUNCTION(_sk_load_8888_aarch64)
_sk_load_8888_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xd37ef409                          // lsl           x9, x0, #2
  .long  0x6f00e621                          // movi          v1.2d, #0xff000000ff
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x3ce96900                          // ldr           q0, [x8, x9]
  .long  0x52a77008                          // mov           w8, #0x3b800000
  .long  0x72901028                          // movk          w8, #0x8081
  .long  0x4e040d02                          // dup           v2.4s, w8
  .long  0x6f380410                          // ushr          v16.4s, v0.4s, #8
  .long  0x6f300411                          // ushr          v17.4s, v0.4s, #16
  .long  0x4e211c03                          // and           v3.16b, v0.16b, v1.16b
  .long  0x6f280400                          // ushr          v0.4s, v0.4s, #24
  .long  0x4e211e10                          // and           v16.16b, v16.16b, v1.16b
  .long  0x4e211e21                          // and           v1.16b, v17.16b, v1.16b
  .long  0x4e21d863                          // scvtf         v3.4s, v3.4s
  .long  0x4e21d811                          // scvtf         v17.4s, v0.4s
  .long  0x4e21da10                          // scvtf         v16.4s, v16.4s
  .long  0x4e21d832                          // scvtf         v18.4s, v1.4s
  .long  0x6e22dc60                          // fmul          v0.4s, v3.4s, v2.4s
  .long  0x6e22de23                          // fmul          v3.4s, v17.4s, v2.4s
  .long  0x6e22de01                          // fmul          v1.4s, v16.4s, v2.4s
  .long  0x6e22de42                          // fmul          v2.4s, v18.4s, v2.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_gather_8888_aarch64
.globl _sk_gather_8888_aarch64
FUNCTION(_sk_gather_8888_aarch64)
_sk_gather_8888_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x4ea1b821                          // fcvtzs        v1.4s, v1.4s
  .long  0x4ea1b800                          // fcvtzs        v0.4s, v0.4s
  .long  0x91004109                          // add           x9, x8, #0x10
  .long  0x4d40c922                          // ld1r          {v2.4s}, [x9]
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x4ea19440                          // mla           v0.4s, v2.4s, v1.4s
  .long  0x1e26000c                          // fmov          w12, s0
  .long  0x8b2c490c                          // add           x12, x8, w12, uxtw #2
  .long  0x0e0c3c09                          // mov           w9, v0.s[1]
  .long  0x0e143c0a                          // mov           w10, v0.s[2]
  .long  0x0e1c3c0b                          // mov           w11, v0.s[3]
  .long  0x0d408180                          // ld1           {v0.s}[0], [x12]
  .long  0x8b294909                          // add           x9, x8, w9, uxtw #2
  .long  0xb86a590a                          // ldr           w10, [x8, w10, uxtw #2]
  .long  0xb86b5908                          // ldr           w8, [x8, w11, uxtw #2]
  .long  0x0d409120                          // ld1           {v0.s}[1], [x9]
  .long  0x6f00e621                          // movi          v1.2d, #0xff000000ff
  .long  0x52a77009                          // mov           w9, #0x3b800000
  .long  0x72901029                          // movk          w9, #0x8081
  .long  0x4e141d40                          // mov           v0.s[2], w10
  .long  0x4e1c1d00                          // mov           v0.s[3], w8
  .long  0x6f380410                          // ushr          v16.4s, v0.4s, #8
  .long  0x6f300411                          // ushr          v17.4s, v0.4s, #16
  .long  0x4e211c03                          // and           v3.16b, v0.16b, v1.16b
  .long  0x6f280400                          // ushr          v0.4s, v0.4s, #24
  .long  0x4e211e10                          // and           v16.16b, v16.16b, v1.16b
  .long  0x4e211e21                          // and           v1.16b, v17.16b, v1.16b
  .long  0x4e040d22                          // dup           v2.4s, w9
  .long  0x4e21d863                          // scvtf         v3.4s, v3.4s
  .long  0x4e21d811                          // scvtf         v17.4s, v0.4s
  .long  0x4e21da10                          // scvtf         v16.4s, v16.4s
  .long  0x4e21d832                          // scvtf         v18.4s, v1.4s
  .long  0x6e22dc60                          // fmul          v0.4s, v3.4s, v2.4s
  .long  0x6e22de23                          // fmul          v3.4s, v17.4s, v2.4s
  .long  0x6e22de01                          // fmul          v1.4s, v16.4s, v2.4s
  .long  0x6e22de42                          // fmul          v2.4s, v18.4s, v2.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_store_8888_aarch64
.globl _sk_store_8888_aarch64
FUNCTION(_sk_store_8888_aarch64)
_sk_store_8888_aarch64:
  .long  0x52a86fea                          // mov           w10, #0x437f0000
  .long  0x4e040d50                          // dup           v16.4s, w10
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x6e30dc32                          // fmul          v18.4s, v1.4s, v16.4s
  .long  0x6e30dc11                          // fmul          v17.4s, v0.4s, v16.4s
  .long  0x6e21aa52                          // fcvtnu        v18.4s, v18.4s
  .long  0x6e21aa31                          // fcvtnu        v17.4s, v17.4s
  .long  0x4f285652                          // shl           v18.4s, v18.4s, #8
  .long  0x4eb11e51                          // orr           v17.16b, v18.16b, v17.16b
  .long  0x6e30dc52                          // fmul          v18.4s, v2.4s, v16.4s
  .long  0x6e30dc70                          // fmul          v16.4s, v3.4s, v16.4s
  .long  0x6e21aa52                          // fcvtnu        v18.4s, v18.4s
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x6e21aa10                          // fcvtnu        v16.4s, v16.4s
  .long  0x4f305652                          // shl           v18.4s, v18.4s, #16
  .long  0x4eb21e31                          // orr           v17.16b, v17.16b, v18.16b
  .long  0x4f385610                          // shl           v16.4s, v16.4s, #24
  .long  0xd37ef409                          // lsl           x9, x0, #2
  .long  0x4eb01e30                          // orr           v16.16b, v17.16b, v16.16b
  .long  0x3ca96910                          // str           q16, [x8, x9]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_load_f16_aarch64
.globl _sk_load_f16_aarch64
FUNCTION(_sk_load_f16_aarch64)
_sk_load_f16_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x8b000d08                          // add           x8, x8, x0, lsl #3
  .long  0x0c400510                          // ld4           {v16.4h-v19.4h}, [x8]
  .long  0x0e217a00                          // fcvtl         v0.4s, v16.4h
  .long  0x0e217a21                          // fcvtl         v1.4s, v17.4h
  .long  0x0e217a42                          // fcvtl         v2.4s, v18.4h
  .long  0x0e217a63                          // fcvtl         v3.4s, v19.4h
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_gather_f16_aarch64
.globl _sk_gather_f16_aarch64
FUNCTION(_sk_gather_f16_aarch64)
_sk_gather_f16_aarch64:
  .long  0xa9bf7bfd                          // stp           x29, x30, [sp, #-16]!
  .long  0xd100c3e9                          // sub           x9, sp, #0x30
  .long  0x910003fd                          // mov           x29, sp
  .long  0x927be93f                          // and           sp, x9, #0xffffffffffffffe0
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x4ea1b821                          // fcvtzs        v1.4s, v1.4s
  .long  0x4ea1b800                          // fcvtzs        v0.4s, v0.4s
  .long  0x91004109                          // add           x9, x8, #0x10
  .long  0x4d40c922                          // ld1r          {v2.4s}, [x9]
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x4ea19440                          // mla           v0.4s, v2.4s, v1.4s
  .long  0x0e143c0a                          // mov           w10, v0.s[2]
  .long  0x1e26000c                          // fmov          w12, s0
  .long  0x8b2c4d0c                          // add           x12, x8, w12, uxtw #3
  .long  0x8b2a4d0a                          // add           x10, x8, w10, uxtw #3
  .long  0x0e0c3c09                          // mov           w9, v0.s[1]
  .long  0x0e1c3c0b                          // mov           w11, v0.s[3]
  .long  0x0d408540                          // ld1           {v0.d}[0], [x10]
  .long  0x0d408581                          // ld1           {v1.d}[0], [x12]
  .long  0x8b294d09                          // add           x9, x8, w9, uxtw #3
  .long  0x8b2b4d08                          // add           x8, x8, w11, uxtw #3
  .long  0x4d408500                          // ld1           {v0.d}[1], [x8]
  .long  0x4d408521                          // ld1           {v1.d}[1], [x9]
  .long  0x910003e8                          // mov           x8, sp
  .long  0xad0003e1                          // stp           q1, q0, [sp]
  .long  0x0c400510                          // ld4           {v16.4h-v19.4h}, [x8]
  .long  0xf9400428                          // ldr           x8, [x1, #8]
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0x0e217a00                          // fcvtl         v0.4s, v16.4h
  .long  0x0e217a21                          // fcvtl         v1.4s, v17.4h
  .long  0x0e217a42                          // fcvtl         v2.4s, v18.4h
  .long  0x0e217a63                          // fcvtl         v3.4s, v19.4h
  .long  0xd63f0100                          // blr           x8
  .long  0x910003bf                          // mov           sp, x29
  .long  0xa8c17bfd                          // ldp           x29, x30, [sp], #16
  .long  0xd65f03c0                          // ret

HIDDEN _sk_store_f16_aarch64
.globl _sk_store_f16_aarch64
FUNCTION(_sk_store_f16_aarch64)
_sk_store_f16_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x0e216810                          // fcvtn         v16.4h, v0.4s
  .long  0x0e216831                          // fcvtn         v17.4h, v1.4s
  .long  0x0e216852                          // fcvtn         v18.4h, v2.4s
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x0e216873                          // fcvtn         v19.4h, v3.4s
  .long  0x8b000d08                          // add           x8, x8, x0, lsl #3
  .long  0x0c000510                          // st4           {v16.4h-v19.4h}, [x8]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_load_u16_be_aarch64
.globl _sk_load_u16_be_aarch64
FUNCTION(_sk_load_u16_be_aarch64)
_sk_load_u16_be_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x8b000d08                          // add           x8, x8, x0, lsl #3
  .long  0x0c400500                          // ld4           {v0.4h-v3.4h}, [x8]
  .long  0x52a6f008                          // mov           w8, #0x37800000
  .long  0x72801008                          // movk          w8, #0x80
  .long  0x0f185410                          // shl           v16.4h, v0.4h, #8
  .long  0x2f180411                          // ushr          v17.4h, v0.4h, #8
  .long  0x0f185432                          // shl           v18.4h, v1.4h, #8
  .long  0x2f180433                          // ushr          v19.4h, v1.4h, #8
  .long  0x0f185454                          // shl           v20.4h, v2.4h, #8
  .long  0x2f180455                          // ushr          v21.4h, v2.4h, #8
  .long  0x0f185476                          // shl           v22.4h, v3.4h, #8
  .long  0x2f180460                          // ushr          v0.4h, v3.4h, #8
  .long  0x0eb11e01                          // orr           v1.8b, v16.8b, v17.8b
  .long  0x0eb31e42                          // orr           v2.8b, v18.8b, v19.8b
  .long  0x0eb51e90                          // orr           v16.8b, v20.8b, v21.8b
  .long  0x0ea01ec0                          // orr           v0.8b, v22.8b, v0.8b
  .long  0x2f10a421                          // uxtl          v1.4s, v1.4h
  .long  0x2f10a442                          // uxtl          v2.4s, v2.4h
  .long  0x2f10a610                          // uxtl          v16.4s, v16.4h
  .long  0x2f10a400                          // uxtl          v0.4s, v0.4h
  .long  0x4e040d03                          // dup           v3.4s, w8
  .long  0x6e21d821                          // ucvtf         v1.4s, v1.4s
  .long  0x6e21d842                          // ucvtf         v2.4s, v2.4s
  .long  0x6e21da10                          // ucvtf         v16.4s, v16.4s
  .long  0x6e21d811                          // ucvtf         v17.4s, v0.4s
  .long  0x6e23dc20                          // fmul          v0.4s, v1.4s, v3.4s
  .long  0x6e23dc41                          // fmul          v1.4s, v2.4s, v3.4s
  .long  0x6e23de02                          // fmul          v2.4s, v16.4s, v3.4s
  .long  0x6e23de23                          // fmul          v3.4s, v17.4s, v3.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_load_rgb_u16_be_aarch64
.globl _sk_load_rgb_u16_be_aarch64
FUNCTION(_sk_load_rgb_u16_be_aarch64)
_sk_load_rgb_u16_be_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x321f07e9                          // orr           w9, wzr, #0x6
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x9b092008                          // madd          x8, x0, x9, x8
  .long  0x0c404500                          // ld3           {v0.4h-v2.4h}, [x8]
  .long  0x52a6f008                          // mov           w8, #0x37800000
  .long  0x72801008                          // movk          w8, #0x80
  .long  0x0f185403                          // shl           v3.4h, v0.4h, #8
  .long  0x2f180410                          // ushr          v16.4h, v0.4h, #8
  .long  0x0f185431                          // shl           v17.4h, v1.4h, #8
  .long  0x2f180432                          // ushr          v18.4h, v1.4h, #8
  .long  0x0f185453                          // shl           v19.4h, v2.4h, #8
  .long  0x2f180440                          // ushr          v0.4h, v2.4h, #8
  .long  0x0eb01c61                          // orr           v1.8b, v3.8b, v16.8b
  .long  0x0eb21e23                          // orr           v3.8b, v17.8b, v18.8b
  .long  0x0ea01e60                          // orr           v0.8b, v19.8b, v0.8b
  .long  0x2f10a421                          // uxtl          v1.4s, v1.4h
  .long  0x2f10a463                          // uxtl          v3.4s, v3.4h
  .long  0x2f10a400                          // uxtl          v0.4s, v0.4h
  .long  0x4e040d02                          // dup           v2.4s, w8
  .long  0x6e21d821                          // ucvtf         v1.4s, v1.4s
  .long  0x6e21d863                          // ucvtf         v3.4s, v3.4s
  .long  0x6e21d810                          // ucvtf         v16.4s, v0.4s
  .long  0x6e22dc20                          // fmul          v0.4s, v1.4s, v2.4s
  .long  0x6e22dc61                          // fmul          v1.4s, v3.4s, v2.4s
  .long  0x6e22de02                          // fmul          v2.4s, v16.4s, v2.4s
  .long  0x4f03f603                          // fmov          v3.4s, #1.000000000000000000e+00
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_store_u16_be_aarch64
.globl _sk_store_u16_be_aarch64
FUNCTION(_sk_store_u16_be_aarch64)
_sk_store_u16_be_aarch64:
  .long  0x52a8efe9                          // mov           w9, #0x477f0000
  .long  0x729fe009                          // movk          w9, #0xff00
  .long  0x4e040d30                          // dup           v16.4s, w9
  .long  0x6e30dc11                          // fmul          v17.4s, v0.4s, v16.4s
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x6e21aa31                          // fcvtnu        v17.4s, v17.4s
  .long  0x0e612a31                          // xtn           v17.4h, v17.4s
  .long  0x6e30dc32                          // fmul          v18.4s, v1.4s, v16.4s
  .long  0x0f185633                          // shl           v19.4h, v17.4h, #8
  .long  0x2f180631                          // ushr          v17.4h, v17.4h, #8
  .long  0x6e21aa52                          // fcvtnu        v18.4s, v18.4s
  .long  0x0eb11e75                          // orr           v21.8b, v19.8b, v17.8b
  .long  0x6e30dc51                          // fmul          v17.4s, v2.4s, v16.4s
  .long  0x0e612a52                          // xtn           v18.4h, v18.4s
  .long  0x6e30dc70                          // fmul          v16.4s, v3.4s, v16.4s
  .long  0x6e21aa31                          // fcvtnu        v17.4s, v17.4s
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x0f185654                          // shl           v20.4h, v18.4h, #8
  .long  0x2f180652                          // ushr          v18.4h, v18.4h, #8
  .long  0x6e21aa10                          // fcvtnu        v16.4s, v16.4s
  .long  0x0e612a31                          // xtn           v17.4h, v17.4s
  .long  0x0eb21e96                          // orr           v22.8b, v20.8b, v18.8b
  .long  0x0e612a10                          // xtn           v16.4h, v16.4s
  .long  0x0f185632                          // shl           v18.4h, v17.4h, #8
  .long  0x2f180631                          // ushr          v17.4h, v17.4h, #8
  .long  0x0eb11e57                          // orr           v23.8b, v18.8b, v17.8b
  .long  0x0f185611                          // shl           v17.4h, v16.4h, #8
  .long  0x2f180610                          // ushr          v16.4h, v16.4h, #8
  .long  0x8b000d08                          // add           x8, x8, x0, lsl #3
  .long  0x0eb01e38                          // orr           v24.8b, v17.8b, v16.8b
  .long  0x0c000515                          // st4           {v21.4h-v24.4h}, [x8]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_load_f32_aarch64
.globl _sk_load_f32_aarch64
FUNCTION(_sk_load_f32_aarch64)
_sk_load_f32_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x8b001108                          // add           x8, x8, x0, lsl #4
  .long  0x4c400900                          // ld4           {v0.4s-v3.4s}, [x8]
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_store_f32_aarch64
.globl _sk_store_f32_aarch64
FUNCTION(_sk_store_f32_aarch64)
_sk_store_f32_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0xf9400108                          // ldr           x8, [x8]
  .long  0x8b001108                          // add           x8, x8, x0, lsl #4
  .long  0x4c000900                          // st4           {v0.4s-v3.4s}, [x8]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_clamp_x_aarch64
.globl _sk_clamp_x_aarch64
FUNCTION(_sk_clamp_x_aarch64)
_sk_clamp_x_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x6f00e411                          // movi          v17.2d, #0x0
  .long  0x4e20f620                          // fmax          v0.4s, v17.4s, v0.4s
  .long  0x6f07e7f1                          // movi          v17.2d, #0xffffffffffffffff
  .long  0x4d40c910                          // ld1r          {v16.4s}, [x8]
  .long  0x4eb18610                          // add           v16.4s, v16.4s, v17.4s
  .long  0x4eb0f400                          // fmin          v0.4s, v0.4s, v16.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_clamp_y_aarch64
.globl _sk_clamp_y_aarch64
FUNCTION(_sk_clamp_y_aarch64)
_sk_clamp_y_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x6f00e411                          // movi          v17.2d, #0x0
  .long  0x4e21f621                          // fmax          v1.4s, v17.4s, v1.4s
  .long  0x6f07e7f1                          // movi          v17.2d, #0xffffffffffffffff
  .long  0x4d40c910                          // ld1r          {v16.4s}, [x8]
  .long  0x4eb18610                          // add           v16.4s, v16.4s, v17.4s
  .long  0x4eb0f421                          // fmin          v1.4s, v1.4s, v16.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_repeat_x_aarch64
.globl _sk_repeat_x_aarch64
FUNCTION(_sk_repeat_x_aarch64)
_sk_repeat_x_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x6f07e7f1                          // movi          v17.2d, #0xffffffffffffffff
  .long  0xbd400110                          // ldr           s16, [x8]
  .long  0x4e040612                          // dup           v18.4s, v16.s[0]
  .long  0x4eb18651                          // add           v17.4s, v18.4s, v17.4s
  .long  0x6e32fc12                          // fdiv          v18.4s, v0.4s, v18.4s
  .long  0x4e219a52                          // frintm        v18.4s, v18.4s
  .long  0x4f905240                          // fmls          v0.4s, v18.4s, v16.s[0]
  .long  0x4eb1f400                          // fmin          v0.4s, v0.4s, v17.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_repeat_y_aarch64
.globl _sk_repeat_y_aarch64
FUNCTION(_sk_repeat_y_aarch64)
_sk_repeat_y_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x6f07e7f1                          // movi          v17.2d, #0xffffffffffffffff
  .long  0xbd400110                          // ldr           s16, [x8]
  .long  0x4e040612                          // dup           v18.4s, v16.s[0]
  .long  0x4eb18651                          // add           v17.4s, v18.4s, v17.4s
  .long  0x6e32fc32                          // fdiv          v18.4s, v1.4s, v18.4s
  .long  0x4e219a52                          // frintm        v18.4s, v18.4s
  .long  0x4f905241                          // fmls          v1.4s, v18.4s, v16.s[0]
  .long  0x4eb1f421                          // fmin          v1.4s, v1.4s, v17.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_mirror_x_aarch64
.globl _sk_mirror_x_aarch64
FUNCTION(_sk_mirror_x_aarch64)
_sk_mirror_x_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xbd400110                          // ldr           s16, [x8]
  .long  0x4e040611                          // dup           v17.4s, v16.s[0]
  .long  0x1e302a10                          // fadd          s16, s16, s16
  .long  0x4eb1d400                          // fsub          v0.4s, v0.4s, v17.4s
  .long  0x4e040612                          // dup           v18.4s, v16.s[0]
  .long  0x6e32fc12                          // fdiv          v18.4s, v0.4s, v18.4s
  .long  0x4e219a52                          // frintm        v18.4s, v18.4s
  .long  0x4f905240                          // fmls          v0.4s, v18.4s, v16.s[0]
  .long  0x6f07e7f0                          // movi          v16.2d, #0xffffffffffffffff
  .long  0x4eb1d400                          // fsub          v0.4s, v0.4s, v17.4s
  .long  0x4eb08630                          // add           v16.4s, v17.4s, v16.4s
  .long  0x4ea0f800                          // fabs          v0.4s, v0.4s
  .long  0x4eb0f400                          // fmin          v0.4s, v0.4s, v16.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_mirror_y_aarch64
.globl _sk_mirror_y_aarch64
FUNCTION(_sk_mirror_y_aarch64)
_sk_mirror_y_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xbd400110                          // ldr           s16, [x8]
  .long  0x4e040611                          // dup           v17.4s, v16.s[0]
  .long  0x1e302a10                          // fadd          s16, s16, s16
  .long  0x4eb1d421                          // fsub          v1.4s, v1.4s, v17.4s
  .long  0x4e040612                          // dup           v18.4s, v16.s[0]
  .long  0x6e32fc32                          // fdiv          v18.4s, v1.4s, v18.4s
  .long  0x4e219a52                          // frintm        v18.4s, v18.4s
  .long  0x4f905241                          // fmls          v1.4s, v18.4s, v16.s[0]
  .long  0x6f07e7f0                          // movi          v16.2d, #0xffffffffffffffff
  .long  0x4eb1d421                          // fsub          v1.4s, v1.4s, v17.4s
  .long  0x4eb08630                          // add           v16.4s, v17.4s, v16.4s
  .long  0x4ea0f821                          // fabs          v1.4s, v1.4s
  .long  0x4eb0f421                          // fmin          v1.4s, v1.4s, v16.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_luminance_to_alpha_aarch64
.globl _sk_luminance_to_alpha_aarch64
FUNCTION(_sk_luminance_to_alpha_aarch64)
_sk_luminance_to_alpha_aarch64:
  .long  0x52a7cb28                          // mov           w8, #0x3e590000
  .long  0x72967a08                          // movk          w8, #0xb3d0
  .long  0x4e040d11                          // dup           v17.4s, w8
  .long  0x52a7e6e8                          // mov           w8, #0x3f370000
  .long  0x7282eb28                          // movk          w8, #0x1759
  .long  0x4ea01c10                          // mov           v16.16b, v0.16b
  .long  0x4e040d00                          // dup           v0.4s, w8
  .long  0x52a7b268                          // mov           w8, #0x3d930000
  .long  0xf8408423                          // ldr           x3, [x1], #8
  .long  0x729bb308                          // movk          w8, #0xdd98
  .long  0x6e20dc23                          // fmul          v3.4s, v1.4s, v0.4s
  .long  0x4e30ce23                          // fmla          v3.4s, v17.4s, v16.4s
  .long  0x4e040d10                          // dup           v16.4s, w8
  .long  0x6f00e400                          // movi          v0.2d, #0x0
  .long  0x6f00e401                          // movi          v1.2d, #0x0
  .long  0x4e22ce03                          // fmla          v3.4s, v16.4s, v2.4s
  .long  0x6f00e402                          // movi          v2.2d, #0x0
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_matrix_2x3_aarch64
.globl _sk_matrix_2x3_aarch64
FUNCTION(_sk_matrix_2x3_aarch64)
_sk_matrix_2x3_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xaa0803e9                          // mov           x9, x8
  .long  0x9100410a                          // add           x10, x8, #0x10
  .long  0x4ddfc932                          // ld1r          {v18.4s}, [x9], #4
  .long  0x4d40c950                          // ld1r          {v16.4s}, [x10]
  .long  0x2d415113                          // ldp           s19, s20, [x8, #8]
  .long  0x9100510a                          // add           x10, x8, #0x14
  .long  0x4d40c951                          // ld1r          {v17.4s}, [x10]
  .long  0x4f931030                          // fmla          v16.4s, v1.4s, v19.s[0]
  .long  0xbd400133                          // ldr           s19, [x9]
  .long  0x4f941031                          // fmla          v17.4s, v1.4s, v20.s[0]
  .long  0x4e20ce50                          // fmla          v16.4s, v18.4s, v0.4s
  .long  0x4f931011                          // fmla          v17.4s, v0.4s, v19.s[0]
  .long  0x4eb01e00                          // mov           v0.16b, v16.16b
  .long  0x4eb11e21                          // mov           v1.16b, v17.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_matrix_3x4_aarch64
.globl _sk_matrix_3x4_aarch64
FUNCTION(_sk_matrix_3x4_aarch64)
_sk_matrix_3x4_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xaa0803e9                          // mov           x9, x8
  .long  0x9100910a                          // add           x10, x8, #0x24
  .long  0x4ddfc933                          // ld1r          {v19.4s}, [x9], #4
  .long  0x4d40c950                          // ld1r          {v16.4s}, [x10]
  .long  0x9100a10a                          // add           x10, x8, #0x28
  .long  0x4d40c951                          // ld1r          {v17.4s}, [x10]
  .long  0x9100b10a                          // add           x10, x8, #0x2c
  .long  0x2d435514                          // ldp           s20, s21, [x8, #24]
  .long  0xbd402116                          // ldr           s22, [x8, #32]
  .long  0x4d40c952                          // ld1r          {v18.4s}, [x10]
  .long  0x4f941050                          // fmla          v16.4s, v2.4s, v20.s[0]
  .long  0x4f951051                          // fmla          v17.4s, v2.4s, v21.s[0]
  .long  0x4f961052                          // fmla          v18.4s, v2.4s, v22.s[0]
  .long  0x2d425502                          // ldp           s2, s21, [x8, #16]
  .long  0x2d415d14                          // ldp           s20, s23, [x8, #8]
  .long  0x4f821031                          // fmla          v17.4s, v1.4s, v2.s[0]
  .long  0xbd400122                          // ldr           s2, [x9]
  .long  0x4f971030                          // fmla          v16.4s, v1.4s, v23.s[0]
  .long  0x4f951032                          // fmla          v18.4s, v1.4s, v21.s[0]
  .long  0x4e20ce70                          // fmla          v16.4s, v19.4s, v0.4s
  .long  0x4f941012                          // fmla          v18.4s, v0.4s, v20.s[0]
  .long  0x4f821011                          // fmla          v17.4s, v0.4s, v2.s[0]
  .long  0x4eb01e00                          // mov           v0.16b, v16.16b
  .long  0x4eb11e21                          // mov           v1.16b, v17.16b
  .long  0x4eb21e42                          // mov           v2.16b, v18.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_matrix_4x5_aarch64
.globl _sk_matrix_4x5_aarch64
FUNCTION(_sk_matrix_4x5_aarch64)
_sk_matrix_4x5_aarch64:
  .long  0xf9400029                          // ldr           x9, [x1]
  .long  0xaa0903e8                          // mov           x8, x9
  .long  0x9101012a                          // add           x10, x9, #0x40
  .long  0x4ddfc914                          // ld1r          {v20.4s}, [x8], #4
  .long  0x4d40c950                          // ld1r          {v16.4s}, [x10]
  .long  0x9101112a                          // add           x10, x9, #0x44
  .long  0x4d40c951                          // ld1r          {v17.4s}, [x10]
  .long  0x9101212a                          // add           x10, x9, #0x48
  .long  0x4d40c952                          // ld1r          {v18.4s}, [x10]
  .long  0x2d465533                          // ldp           s19, s21, [x9, #48]
  .long  0x2d475d36                          // ldp           s22, s23, [x9, #56]
  .long  0x9101312a                          // add           x10, x9, #0x4c
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x4f931070                          // fmla          v16.4s, v3.4s, v19.s[0]
  .long  0x4d40c953                          // ld1r          {v19.4s}, [x10]
  .long  0x4f951071                          // fmla          v17.4s, v3.4s, v21.s[0]
  .long  0x4f961072                          // fmla          v18.4s, v3.4s, v22.s[0]
  .long  0x2d445935                          // ldp           s21, s22, [x9, #32]
  .long  0x4f971073                          // fmla          v19.4s, v3.4s, v23.s[0]
  .long  0x2d455d23                          // ldp           s3, s23, [x9, #40]
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0x4f951050                          // fmla          v16.4s, v2.4s, v21.s[0]
  .long  0x4f961051                          // fmla          v17.4s, v2.4s, v22.s[0]
  .long  0x2d425935                          // ldp           s21, s22, [x9, #16]
  .long  0x4f971053                          // fmla          v19.4s, v2.4s, v23.s[0]
  .long  0x4f831052                          // fmla          v18.4s, v2.4s, v3.s[0]
  .long  0x2d410d22                          // ldp           s2, s3, [x9, #8]
  .long  0x4f951030                          // fmla          v16.4s, v1.4s, v21.s[0]
  .long  0x2d435d35                          // ldp           s21, s23, [x9, #24]
  .long  0x4f961031                          // fmla          v17.4s, v1.4s, v22.s[0]
  .long  0xbd400116                          // ldr           s22, [x8]
  .long  0x4e20ce90                          // fmla          v16.4s, v20.4s, v0.4s
  .long  0x4f951032                          // fmla          v18.4s, v1.4s, v21.s[0]
  .long  0x4f971033                          // fmla          v19.4s, v1.4s, v23.s[0]
  .long  0x4f821012                          // fmla          v18.4s, v0.4s, v2.s[0]
  .long  0x4f831013                          // fmla          v19.4s, v0.4s, v3.s[0]
  .long  0x4f961011                          // fmla          v17.4s, v0.4s, v22.s[0]
  .long  0x4eb01e00                          // mov           v0.16b, v16.16b
  .long  0x4eb11e21                          // mov           v1.16b, v17.16b
  .long  0x4eb21e42                          // mov           v2.16b, v18.16b
  .long  0x4eb31e63                          // mov           v3.16b, v19.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_matrix_perspective_aarch64
.globl _sk_matrix_perspective_aarch64
FUNCTION(_sk_matrix_perspective_aarch64)
_sk_matrix_perspective_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xaa0803e9                          // mov           x9, x8
  .long  0x9100510a                          // add           x10, x8, #0x14
  .long  0x4ddfc930                          // ld1r          {v16.4s}, [x9], #4
  .long  0x4d40c951                          // ld1r          {v17.4s}, [x10]
  .long  0x9100810a                          // add           x10, x8, #0x20
  .long  0x4d40c952                          // ld1r          {v18.4s}, [x10]
  .long  0x2d41d113                          // ldp           s19, s20, [x8, #12]
  .long  0x2d435915                          // ldp           s21, s22, [x8, #24]
  .long  0x91002108                          // add           x8, x8, #0x8
  .long  0x4f941031                          // fmla          v17.4s, v1.4s, v20.s[0]
  .long  0x4d40c914                          // ld1r          {v20.4s}, [x8]
  .long  0x4f961032                          // fmla          v18.4s, v1.4s, v22.s[0]
  .long  0xbd400136                          // ldr           s22, [x9]
  .long  0x4f951012                          // fmla          v18.4s, v0.4s, v21.s[0]
  .long  0x4f931011                          // fmla          v17.4s, v0.4s, v19.s[0]
  .long  0x4f961034                          // fmla          v20.4s, v1.4s, v22.s[0]
  .long  0x4ea1da41                          // frecpe        v1.4s, v18.4s
  .long  0x4e21fe52                          // frecps        v18.4s, v18.4s, v1.4s
  .long  0x6e32dc32                          // fmul          v18.4s, v1.4s, v18.4s
  .long  0x4e20ce14                          // fmla          v20.4s, v16.4s, v0.4s
  .long  0x6e32de21                          // fmul          v1.4s, v17.4s, v18.4s
  .long  0x6e32de80                          // fmul          v0.4s, v20.4s, v18.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_linear_gradient_aarch64
.globl _sk_linear_gradient_aarch64
FUNCTION(_sk_linear_gradient_aarch64)
_sk_linear_gradient_aarch64:
  .long  0xf9400029                          // ldr           x9, [x1]
  .long  0x91004128                          // add           x8, x9, #0x10
  .long  0x9100512a                          // add           x10, x9, #0x14
  .long  0x4d40c910                          // ld1r          {v16.4s}, [x8]
  .long  0x91006128                          // add           x8, x9, #0x18
  .long  0x4d40c941                          // ld1r          {v1.4s}, [x10]
  .long  0x9100712a                          // add           x10, x9, #0x1c
  .long  0x4d40c902                          // ld1r          {v2.4s}, [x8]
  .long  0xf9400128                          // ldr           x8, [x9]
  .long  0x4d40c943                          // ld1r          {v3.4s}, [x10]
  .long  0xb40006c8                          // cbz           x8, 28fc <sk_linear_gradient_aarch64+0x100>
  .long  0x6dbf23e9                          // stp           d9, d8, [sp, #-16]!
  .long  0xf9400529                          // ldr           x9, [x9, #8]
  .long  0x6f00e413                          // movi          v19.2d, #0x0
  .long  0x6f00e411                          // movi          v17.2d, #0x0
  .long  0x6f00e412                          // movi          v18.2d, #0x0
  .long  0x91004129                          // add           x9, x9, #0x10
  .long  0x6f00e414                          // movi          v20.2d, #0x0
  .long  0xd100412a                          // sub           x10, x9, #0x10
  .long  0x4d40c955                          // ld1r          {v21.4s}, [x10]
  .long  0xd100312b                          // sub           x11, x9, #0xc
  .long  0xd100212a                          // sub           x10, x9, #0x8
  .long  0x4d40c976                          // ld1r          {v22.4s}, [x11]
  .long  0xd100112b                          // sub           x11, x9, #0x4
  .long  0x4d40c957                          // ld1r          {v23.4s}, [x10]
  .long  0xaa0903ea                          // mov           x10, x9
  .long  0x4d40c978                          // ld1r          {v24.4s}, [x11]
  .long  0x4ddfc959                          // ld1r          {v25.4s}, [x10], #4
  .long  0x9100412b                          // add           x11, x9, #0x10
  .long  0x4ea31c7b                          // mov           v27.16b, v3.16b
  .long  0x6ea0e6a3                          // fcmgt         v3.4s, v21.4s, v0.4s
  .long  0x4d40c97a                          // ld1r          {v26.4s}, [x11]
  .long  0x4eb41e95                          // mov           v21.16b, v20.16b
  .long  0x4ea31c74                          // mov           v20.16b, v3.16b
  .long  0x9100212b                          // add           x11, x9, #0x8
  .long  0x4eb31e69                          // mov           v9.16b, v19.16b
  .long  0x4ea31c73                          // mov           v19.16b, v3.16b
  .long  0x6e771eb4                          // bsl           v20.16b, v21.16b, v23.16b
  .long  0x4d40c975                          // ld1r          {v21.4s}, [x11]
  .long  0x9100312b                          // add           x11, x9, #0xc
  .long  0x6e761d33                          // bsl           v19.16b, v9.16b, v22.16b
  .long  0x4d40c976                          // ld1r          {v22.4s}, [x11]
  .long  0x4d40c957                          // ld1r          {v23.4s}, [x10]
  .long  0x4eb21e5c                          // mov           v28.16b, v18.16b
  .long  0x4eb11e3d                          // mov           v29.16b, v17.16b
  .long  0x4eb01e1e                          // mov           v30.16b, v16.16b
  .long  0x4ea11c3f                          // mov           v31.16b, v1.16b
  .long  0x4ea21c48                          // mov           v8.16b, v2.16b
  .long  0x4ea31c72                          // mov           v18.16b, v3.16b
  .long  0x4ea31c71                          // mov           v17.16b, v3.16b
  .long  0x4ea31c70                          // mov           v16.16b, v3.16b
  .long  0x4ea31c61                          // mov           v1.16b, v3.16b
  .long  0x4ea31c62                          // mov           v2.16b, v3.16b
  .long  0x6e7a1f63                          // bsl           v3.16b, v27.16b, v26.16b
  .long  0x6e781f92                          // bsl           v18.16b, v28.16b, v24.16b
  .long  0x6e791fb1                          // bsl           v17.16b, v29.16b, v25.16b
  .long  0x6e751fe1                          // bsl           v1.16b, v31.16b, v21.16b
  .long  0x6e761d02                          // bsl           v2.16b, v8.16b, v22.16b
  .long  0xd1000508                          // sub           x8, x8, #0x1
  .long  0x6e771fd0                          // bsl           v16.16b, v30.16b, v23.16b
  .long  0x91009129                          // add           x9, x9, #0x24
  .long  0xb5fffaa8                          // cbnz          x8, 2844 <sk_linear_gradient_aarch64+0x48>
  .long  0x6cc123e9                          // ldp           d9, d8, [sp], #16
  .long  0x14000005                          // b             290c <sk_linear_gradient_aarch64+0x110>
  .long  0x6f00e414                          // movi          v20.2d, #0x0
  .long  0x6f00e412                          // movi          v18.2d, #0x0
  .long  0x6f00e411                          // movi          v17.2d, #0x0
  .long  0x6f00e413                          // movi          v19.2d, #0x0
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x4e20ce70                          // fmla          v16.4s, v19.4s, v0.4s
  .long  0x4e20ce81                          // fmla          v1.4s, v20.4s, v0.4s
  .long  0x4e20ce42                          // fmla          v2.4s, v18.4s, v0.4s
  .long  0x4e20ce23                          // fmla          v3.4s, v17.4s, v0.4s
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0x4eb01e00                          // mov           v0.16b, v16.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_linear_gradient_2stops_aarch64
.globl _sk_linear_gradient_2stops_aarch64
FUNCTION(_sk_linear_gradient_2stops_aarch64)
_sk_linear_gradient_2stops_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0xaa0803e9                          // mov           x9, x8
  .long  0x9100410a                          // add           x10, x8, #0x10
  .long  0x4ddfc931                          // ld1r          {v17.4s}, [x9], #4
  .long  0x4d40c950                          // ld1r          {v16.4s}, [x10]
  .long  0x9100510a                          // add           x10, x8, #0x14
  .long  0x4d40c941                          // ld1r          {v1.4s}, [x10]
  .long  0x9100610a                          // add           x10, x8, #0x18
  .long  0x4d40c942                          // ld1r          {v2.4s}, [x10]
  .long  0x9100710a                          // add           x10, x8, #0x1c
  .long  0x2d414d12                          // ldp           s18, s19, [x8, #8]
  .long  0x4d40c943                          // ld1r          {v3.4s}, [x10]
  .long  0x4e20ce30                          // fmla          v16.4s, v17.4s, v0.4s
  .long  0xbd400131                          // ldr           s17, [x9]
  .long  0x4f921002                          // fmla          v2.4s, v0.4s, v18.s[0]
  .long  0x4f931003                          // fmla          v3.4s, v0.4s, v19.s[0]
  .long  0x4f911001                          // fmla          v1.4s, v0.4s, v17.s[0]
  .long  0x4eb01e00                          // mov           v0.16b, v16.16b
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_save_xy_aarch64
.globl _sk_save_xy_aarch64
FUNCTION(_sk_save_xy_aarch64)
_sk_save_xy_aarch64:
  .long  0x4f0167f0                          // movi          v16.4s, #0x3f, lsl #24
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x4e30d411                          // fadd          v17.4s, v0.4s, v16.4s
  .long  0x4e30d430                          // fadd          v16.4s, v1.4s, v16.4s
  .long  0x4e219a32                          // frintm        v18.4s, v17.4s
  .long  0x4eb2d631                          // fsub          v17.4s, v17.4s, v18.4s
  .long  0x4e219a12                          // frintm        v18.4s, v16.4s
  .long  0x4eb2d610                          // fsub          v16.4s, v16.4s, v18.4s
  .long  0x3d800100                          // str           q0, [x8]
  .long  0x3d800901                          // str           q1, [x8, #32]
  .long  0x3d801111                          // str           q17, [x8, #64]
  .long  0x3d801910                          // str           q16, [x8, #96]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_accumulate_aarch64
.globl _sk_accumulate_aarch64
FUNCTION(_sk_accumulate_aarch64)
_sk_accumulate_aarch64:
  .long  0xa8c10c28                          // ldp           x8, x3, [x1], #16
  .long  0x3dc02110                          // ldr           q16, [x8, #128]
  .long  0x3dc02911                          // ldr           q17, [x8, #160]
  .long  0x6e31de10                          // fmul          v16.4s, v16.4s, v17.4s
  .long  0x4e30cc04                          // fmla          v4.4s, v0.4s, v16.4s
  .long  0x4e30cc25                          // fmla          v5.4s, v1.4s, v16.4s
  .long  0x4e30cc46                          // fmla          v6.4s, v2.4s, v16.4s
  .long  0x4e30cc67                          // fmla          v7.4s, v3.4s, v16.4s
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_bilinear_nx_aarch64
.globl _sk_bilinear_nx_aarch64
FUNCTION(_sk_bilinear_nx_aarch64)
_sk_bilinear_nx_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x4f03f611                          // fmov          v17.4s, #1.000000000000000000e+00
  .long  0x3dc01100                          // ldr           q0, [x8, #64]
  .long  0x3dc00110                          // ldr           q16, [x8]
  .long  0x4ea0d620                          // fsub          v0.4s, v17.4s, v0.4s
  .long  0x3d802100                          // str           q0, [x8, #128]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x4f0567e0                          // movi          v0.4s, #0xbf, lsl #24
  .long  0x4e20d600                          // fadd          v0.4s, v16.4s, v0.4s
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_bilinear_px_aarch64
.globl _sk_bilinear_px_aarch64
FUNCTION(_sk_bilinear_px_aarch64)
_sk_bilinear_px_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x3dc01100                          // ldr           q0, [x8, #64]
  .long  0x3dc00110                          // ldr           q16, [x8]
  .long  0x3d802100                          // str           q0, [x8, #128]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x4f0167e0                          // movi          v0.4s, #0x3f, lsl #24
  .long  0x4e20d600                          // fadd          v0.4s, v16.4s, v0.4s
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_bilinear_ny_aarch64
.globl _sk_bilinear_ny_aarch64
FUNCTION(_sk_bilinear_ny_aarch64)
_sk_bilinear_ny_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x4f03f611                          // fmov          v17.4s, #1.000000000000000000e+00
  .long  0x3dc01901                          // ldr           q1, [x8, #96]
  .long  0x3dc00910                          // ldr           q16, [x8, #32]
  .long  0x4ea1d621                          // fsub          v1.4s, v17.4s, v1.4s
  .long  0x3d802901                          // str           q1, [x8, #160]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x4f0567e1                          // movi          v1.4s, #0xbf, lsl #24
  .long  0x4e21d601                          // fadd          v1.4s, v16.4s, v1.4s
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_bilinear_py_aarch64
.globl _sk_bilinear_py_aarch64
FUNCTION(_sk_bilinear_py_aarch64)
_sk_bilinear_py_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x3dc01901                          // ldr           q1, [x8, #96]
  .long  0x3dc00910                          // ldr           q16, [x8, #32]
  .long  0x3d802901                          // str           q1, [x8, #160]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x4f0167e1                          // movi          v1.4s, #0x3f, lsl #24
  .long  0x4e21d601                          // fadd          v1.4s, v16.4s, v1.4s
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_bicubic_n3x_aarch64
.globl _sk_bicubic_n3x_aarch64
FUNCTION(_sk_bicubic_n3x_aarch64)
_sk_bicubic_n3x_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x52a7d8e9                          // mov           w9, #0x3ec70000
  .long  0x72838e49                          // movk          w9, #0x1c72
  .long  0x4e040d30                          // dup           v16.4s, w9
  .long  0x3dc01111                          // ldr           q17, [x8, #64]
  .long  0x52b7d549                          // mov           w9, #0xbeaa0000
  .long  0x4f03f600                          // fmov          v0.4s, #1.000000000000000000e+00
  .long  0x72955569                          // movk          w9, #0xaaab
  .long  0x4e040d32                          // dup           v18.4s, w9
  .long  0x4eb1d400                          // fsub          v0.4s, v0.4s, v17.4s
  .long  0x6e20dc11                          // fmul          v17.4s, v0.4s, v0.4s
  .long  0x4e20ce12                          // fmla          v18.4s, v16.4s, v0.4s
  .long  0x6e32de20                          // fmul          v0.4s, v17.4s, v18.4s
  .long  0x3dc00113                          // ldr           q19, [x8]
  .long  0x3d802100                          // str           q0, [x8, #128]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x4f07f700                          // fmov          v0.4s, #-1.500000000000000000e+00
  .long  0x4e20d660                          // fadd          v0.4s, v19.4s, v0.4s
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_bicubic_n1x_aarch64
.globl _sk_bicubic_n1x_aarch64
FUNCTION(_sk_bicubic_n1x_aarch64)
_sk_bicubic_n1x_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x52b7f2a9                          // mov           w9, #0xbf950000
  .long  0x4f03f600                          // fmov          v0.4s, #1.000000000000000000e+00
  .long  0x728aaaa9                          // movk          w9, #0x5555
  .long  0x3dc01110                          // ldr           q16, [x8, #64]
  .long  0x4f03f711                          // fmov          v17.4s, #1.500000000000000000e+00
  .long  0x4f0167f2                          // movi          v18.4s, #0x3f, lsl #24
  .long  0x4eb0d400                          // fsub          v0.4s, v0.4s, v16.4s
  .long  0x4e040d30                          // dup           v16.4s, w9
  .long  0x52a7ac69                          // mov           w9, #0x3d630000
  .long  0x7291c729                          // movk          w9, #0x8e39
  .long  0x4e20ce11                          // fmla          v17.4s, v16.4s, v0.4s
  .long  0x4e20ce32                          // fmla          v18.4s, v17.4s, v0.4s
  .long  0x4e040d31                          // dup           v17.4s, w9
  .long  0x4e20ce51                          // fmla          v17.4s, v18.4s, v0.4s
  .long  0x3dc00110                          // ldr           q16, [x8]
  .long  0x3d802111                          // str           q17, [x8, #128]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x4f0567e0                          // movi          v0.4s, #0xbf, lsl #24
  .long  0x4e20d600                          // fadd          v0.4s, v16.4s, v0.4s
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_bicubic_p1x_aarch64
.globl _sk_bicubic_p1x_aarch64
FUNCTION(_sk_bicubic_p1x_aarch64)
_sk_bicubic_p1x_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x52b7f2a9                          // mov           w9, #0xbf950000
  .long  0x728aaaa9                          // movk          w9, #0x5555
  .long  0x4f03f711                          // fmov          v17.4s, #1.500000000000000000e+00
  .long  0x3dc01112                          // ldr           q18, [x8, #64]
  .long  0x3dc00100                          // ldr           q0, [x8]
  .long  0x4e040d33                          // dup           v19.4s, w9
  .long  0x52a7ac69                          // mov           w9, #0x3d630000
  .long  0x4f0167f0                          // movi          v16.4s, #0x3f, lsl #24
  .long  0x7291c729                          // movk          w9, #0x8e39
  .long  0x4e32ce71                          // fmla          v17.4s, v19.4s, v18.4s
  .long  0x4e30d400                          // fadd          v0.4s, v0.4s, v16.4s
  .long  0x4e32ce30                          // fmla          v16.4s, v17.4s, v18.4s
  .long  0x4e040d31                          // dup           v17.4s, w9
  .long  0x4e32ce11                          // fmla          v17.4s, v16.4s, v18.4s
  .long  0x3d802111                          // str           q17, [x8, #128]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_bicubic_p3x_aarch64
.globl _sk_bicubic_p3x_aarch64
FUNCTION(_sk_bicubic_p3x_aarch64)
_sk_bicubic_p3x_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x52a7d8e9                          // mov           w9, #0x3ec70000
  .long  0x72838e49                          // movk          w9, #0x1c72
  .long  0x4e040d20                          // dup           v0.4s, w9
  .long  0x3dc01110                          // ldr           q16, [x8, #64]
  .long  0x52b7d549                          // mov           w9, #0xbeaa0000
  .long  0x72955569                          // movk          w9, #0xaaab
  .long  0x4e040d31                          // dup           v17.4s, w9
  .long  0x6e30de13                          // fmul          v19.4s, v16.4s, v16.4s
  .long  0x4e30cc11                          // fmla          v17.4s, v0.4s, v16.4s
  .long  0x6e31de60                          // fmul          v0.4s, v19.4s, v17.4s
  .long  0x3dc00112                          // ldr           q18, [x8]
  .long  0x3d802100                          // str           q0, [x8, #128]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x4f03f700                          // fmov          v0.4s, #1.500000000000000000e+00
  .long  0x4e20d640                          // fadd          v0.4s, v18.4s, v0.4s
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_bicubic_n3y_aarch64
.globl _sk_bicubic_n3y_aarch64
FUNCTION(_sk_bicubic_n3y_aarch64)
_sk_bicubic_n3y_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x52a7d8e9                          // mov           w9, #0x3ec70000
  .long  0x72838e49                          // movk          w9, #0x1c72
  .long  0x4e040d30                          // dup           v16.4s, w9
  .long  0x3dc01911                          // ldr           q17, [x8, #96]
  .long  0x52b7d549                          // mov           w9, #0xbeaa0000
  .long  0x4f03f601                          // fmov          v1.4s, #1.000000000000000000e+00
  .long  0x72955569                          // movk          w9, #0xaaab
  .long  0x4e040d32                          // dup           v18.4s, w9
  .long  0x4eb1d421                          // fsub          v1.4s, v1.4s, v17.4s
  .long  0x6e21dc31                          // fmul          v17.4s, v1.4s, v1.4s
  .long  0x4e21ce12                          // fmla          v18.4s, v16.4s, v1.4s
  .long  0x6e32de21                          // fmul          v1.4s, v17.4s, v18.4s
  .long  0x3dc00913                          // ldr           q19, [x8, #32]
  .long  0x3d802901                          // str           q1, [x8, #160]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x4f07f701                          // fmov          v1.4s, #-1.500000000000000000e+00
  .long  0x4e21d661                          // fadd          v1.4s, v19.4s, v1.4s
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_bicubic_n1y_aarch64
.globl _sk_bicubic_n1y_aarch64
FUNCTION(_sk_bicubic_n1y_aarch64)
_sk_bicubic_n1y_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x52b7f2a9                          // mov           w9, #0xbf950000
  .long  0x4f03f601                          // fmov          v1.4s, #1.000000000000000000e+00
  .long  0x728aaaa9                          // movk          w9, #0x5555
  .long  0x3dc01910                          // ldr           q16, [x8, #96]
  .long  0x4f03f711                          // fmov          v17.4s, #1.500000000000000000e+00
  .long  0x4f0167f2                          // movi          v18.4s, #0x3f, lsl #24
  .long  0x4eb0d421                          // fsub          v1.4s, v1.4s, v16.4s
  .long  0x4e040d30                          // dup           v16.4s, w9
  .long  0x52a7ac69                          // mov           w9, #0x3d630000
  .long  0x7291c729                          // movk          w9, #0x8e39
  .long  0x4e21ce11                          // fmla          v17.4s, v16.4s, v1.4s
  .long  0x4e21ce32                          // fmla          v18.4s, v17.4s, v1.4s
  .long  0x4e040d31                          // dup           v17.4s, w9
  .long  0x4e21ce51                          // fmla          v17.4s, v18.4s, v1.4s
  .long  0x3dc00910                          // ldr           q16, [x8, #32]
  .long  0x3d802911                          // str           q17, [x8, #160]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x4f0567e1                          // movi          v1.4s, #0xbf, lsl #24
  .long  0x4e21d601                          // fadd          v1.4s, v16.4s, v1.4s
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_bicubic_p1y_aarch64
.globl _sk_bicubic_p1y_aarch64
FUNCTION(_sk_bicubic_p1y_aarch64)
_sk_bicubic_p1y_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x52b7f2a9                          // mov           w9, #0xbf950000
  .long  0x728aaaa9                          // movk          w9, #0x5555
  .long  0x4f03f711                          // fmov          v17.4s, #1.500000000000000000e+00
  .long  0x3dc01912                          // ldr           q18, [x8, #96]
  .long  0x3dc00901                          // ldr           q1, [x8, #32]
  .long  0x4e040d33                          // dup           v19.4s, w9
  .long  0x52a7ac69                          // mov           w9, #0x3d630000
  .long  0x4f0167f0                          // movi          v16.4s, #0x3f, lsl #24
  .long  0x7291c729                          // movk          w9, #0x8e39
  .long  0x4e32ce71                          // fmla          v17.4s, v19.4s, v18.4s
  .long  0x4e30d421                          // fadd          v1.4s, v1.4s, v16.4s
  .long  0x4e32ce30                          // fmla          v16.4s, v17.4s, v18.4s
  .long  0x4e040d31                          // dup           v17.4s, w9
  .long  0x4e32ce11                          // fmla          v17.4s, v16.4s, v18.4s
  .long  0x3d802911                          // str           q17, [x8, #160]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_bicubic_p3y_aarch64
.globl _sk_bicubic_p3y_aarch64
FUNCTION(_sk_bicubic_p3y_aarch64)
_sk_bicubic_p3y_aarch64:
  .long  0xf9400028                          // ldr           x8, [x1]
  .long  0x52a7d8e9                          // mov           w9, #0x3ec70000
  .long  0x72838e49                          // movk          w9, #0x1c72
  .long  0x4e040d21                          // dup           v1.4s, w9
  .long  0x3dc01910                          // ldr           q16, [x8, #96]
  .long  0x52b7d549                          // mov           w9, #0xbeaa0000
  .long  0x72955569                          // movk          w9, #0xaaab
  .long  0x4e040d31                          // dup           v17.4s, w9
  .long  0x6e30de13                          // fmul          v19.4s, v16.4s, v16.4s
  .long  0x4e30cc31                          // fmla          v17.4s, v1.4s, v16.4s
  .long  0x6e31de61                          // fmul          v1.4s, v19.4s, v17.4s
  .long  0x3dc00912                          // ldr           q18, [x8, #32]
  .long  0x3d802901                          // str           q1, [x8, #160]
  .long  0xf9400423                          // ldr           x3, [x1, #8]
  .long  0x4f03f701                          // fmov          v1.4s, #1.500000000000000000e+00
  .long  0x4e21d641                          // fadd          v1.4s, v18.4s, v1.4s
  .long  0x91004021                          // add           x1, x1, #0x10
  .long  0xd61f0060                          // br            x3

HIDDEN _sk_callback_aarch64
.globl _sk_callback_aarch64
FUNCTION(_sk_callback_aarch64)
_sk_callback_aarch64:
  .long  0xd101c3ff                          // sub           sp, sp, #0x70
  .long  0xf90023f6                          // str           x22, [sp, #64]
  .long  0xa90553f5                          // stp           x21, x20, [sp, #80]
  .long  0xa9067bf3                          // stp           x19, x30, [sp, #96]
  .long  0xad011fe6                          // stp           q6, q7, [sp, #32]
  .long  0xad0017e4                          // stp           q4, q5, [sp]
  .long  0xaa0103f4                          // mov           x20, x1
  .long  0xf9400295                          // ldr           x21, [x20]
  .long  0xaa0003f6                          // mov           x22, x0
  .long  0x321e03e1                          // orr           w1, wzr, #0x4
  .long  0xaa0203f3                          // mov           x19, x2
  .long  0x910022a8                          // add           x8, x21, #0x8
  .long  0x4c000900                          // st4           {v0.4s-v3.4s}, [x8]
  .long  0xf94002a8                          // ldr           x8, [x21]
  .long  0xaa1503e0                          // mov           x0, x21
  .long  0xd63f0100                          // blr           x8
  .long  0xf94046a8                          // ldr           x8, [x21, #136]
  .long  0xf9400683                          // ldr           x3, [x20, #8]
  .long  0x91004281                          // add           x1, x20, #0x10
  .long  0xaa1603e0                          // mov           x0, x22
  .long  0x4c400900                          // ld4           {v0.4s-v3.4s}, [x8]
  .long  0xaa1303e2                          // mov           x2, x19
  .long  0xad4017e4                          // ldp           q4, q5, [sp]
  .long  0xad411fe6                          // ldp           q6, q7, [sp, #32]
  .long  0xa9467bf3                          // ldp           x19, x30, [sp, #96]
  .long  0xa94553f5                          // ldp           x21, x20, [sp, #80]
  .long  0xf94023f6                          // ldr           x22, [sp, #64]
  .long  0x9101c3ff                          // add           sp, sp, #0x70
  .long  0xd61f0060                          // br            x3
#elif defined(__arm__)
BALIGN4

HIDDEN _sk_start_pipeline_vfp4
.globl _sk_start_pipeline_vfp4
FUNCTION(_sk_start_pipeline_vfp4)
_sk_start_pipeline_vfp4:
  .long  0xe92d41f0                          // push          {r4, r5, r6, r7, r8, lr}
  .long  0xe1a04000                          // mov           r4, r0
  .long  0xe2840002                          // add           r0, r4, #2
  .long  0xe1a05003                          // mov           r5, r3
  .long  0xe1a08002                          // mov           r8, r2
  .long  0xe1a07001                          // mov           r7, r1
  .long  0xe1500005                          // cmp           r0, r5
  .long  0x8a000010                          // bhi           64 <sk_start_pipeline_vfp4+0x64>
  .long  0xe4976004                          // ldr           r6, [r7], #4
  .long  0xf2800010                          // vmov.i32      d0, #0
  .long  0xe1a00004                          // mov           r0, r4
  .long  0xf2801010                          // vmov.i32      d1, #0
  .long  0xe1a01007                          // mov           r1, r7
  .long  0xf2802010                          // vmov.i32      d2, #0
  .long  0xe1a02008                          // mov           r2, r8
  .long  0xf2803010                          // vmov.i32      d3, #0
  .long  0xf2804010                          // vmov.i32      d4, #0
  .long  0xf2805010                          // vmov.i32      d5, #0
  .long  0xf2806010                          // vmov.i32      d6, #0
  .long  0xf2807010                          // vmov.i32      d7, #0
  .long  0xe12fff36                          // blx           r6
  .long  0xe2840004                          // add           r0, r4, #4
  .long  0xe2844002                          // add           r4, r4, #2
  .long  0xe1500005                          // cmp           r0, r5
  .long  0x9affffef                          // bls           24 <sk_start_pipeline_vfp4+0x24>
  .long  0xe1a00004                          // mov           r0, r4
  .long  0xe8bd81f0                          // pop           {r4, r5, r6, r7, r8, pc}

HIDDEN _sk_just_return_vfp4
.globl _sk_just_return_vfp4
FUNCTION(_sk_just_return_vfp4)
_sk_just_return_vfp4:
  .long  0xe12fff1e                          // bx            lr

HIDDEN _sk_seed_shader_vfp4
.globl _sk_seed_shader_vfp4
FUNCTION(_sk_seed_shader_vfp4)
_sk_seed_shader_vfp4:
  .long  0xee800b90                          // vdup.32       d16, r0
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf3fb0620                          // vcvt.f32.s32  d16, d16
  .long  0xf2c3161f                          // vmov.i32      d17, #1056964608
  .long  0xedd23b00                          // vldr          d19, [r2]
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xf2872f10                          // vmov.f32      d2, #1
  .long  0xf3fb2622                          // vcvt.f32.s32  d18, d18
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf2400da1                          // vadd.f32      d16, d16, d17
  .long  0xf2803010                          // vmov.i32      d3, #0
  .long  0xf2804010                          // vmov.i32      d4, #0
  .long  0xf2021da1                          // vadd.f32      d1, d18, d17
  .long  0xf2000da3                          // vadd.f32      d0, d16, d19
  .long  0xf2805010                          // vmov.i32      d5, #0
  .long  0xf2806010                          // vmov.i32      d6, #0
  .long  0xf2807010                          // vmov.i32      d7, #0
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_constant_color_vfp4
.globl _sk_constant_color_vfp4
FUNCTION(_sk_constant_color_vfp4)
_sk_constant_color_vfp4:
  .long  0xe92d4010                          // push          {r4, lr}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe283400c                          // add           r4, r3, #12
  .long  0xe1a0e003                          // mov           lr, r3
  .long  0xe2833008                          // add           r3, r3, #8
  .long  0xf4ae0c9d                          // vld1.32       {d0[]}, [lr :32]!
  .long  0xf4a43c9f                          // vld1.32       {d3[]}, [r4 :32]
  .long  0xf4a32c9f                          // vld1.32       {d2[]}, [r3 :32]
  .long  0xf4ae1c9f                          // vld1.32       {d1[]}, [lr :32]
  .long  0xe8bd4010                          // pop           {r4, lr}
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_clear_vfp4
.globl _sk_clear_vfp4
FUNCTION(_sk_clear_vfp4)
_sk_clear_vfp4:
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2800010                          // vmov.i32      d0, #0
  .long  0xf2801010                          // vmov.i32      d1, #0
  .long  0xf2802010                          // vmov.i32      d2, #0
  .long  0xf2803010                          // vmov.i32      d3, #0
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_srcatop_vfp4
.globl _sk_srcatop_vfp4
FUNCTION(_sk_srcatop_vfp4)
_sk_srcatop_vfp4:
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2603d83                          // vsub.f32      d19, d16, d3
  .long  0xf3033d17                          // vmul.f32      d3, d3, d7
  .long  0xf3430d94                          // vmul.f32      d16, d19, d4
  .long  0xf3431d95                          // vmul.f32      d17, d19, d5
  .long  0xf3432d96                          // vmul.f32      d18, d19, d6
  .long  0xf2400c17                          // vfma.f32      d16, d0, d7
  .long  0xf2411c17                          // vfma.f32      d17, d1, d7
  .long  0xf2422c17                          // vfma.f32      d18, d2, d7
  .long  0xf2033c97                          // vfma.f32      d3, d19, d7
  .long  0xf22001b0                          // vorr          d0, d16, d16
  .long  0xf22111b1                          // vorr          d1, d17, d17
  .long  0xf22221b2                          // vorr          d2, d18, d18
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_dstatop_vfp4
.globl _sk_dstatop_vfp4
FUNCTION(_sk_dstatop_vfp4)
_sk_dstatop_vfp4:
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3431d15                          // vmul.f32      d17, d3, d5
  .long  0xf2604d87                          // vsub.f32      d20, d16, d7
  .long  0xf3430d14                          // vmul.f32      d16, d3, d4
  .long  0xf3432d16                          // vmul.f32      d18, d3, d6
  .long  0xf3433d17                          // vmul.f32      d19, d3, d7
  .long  0xf2440c90                          // vfma.f32      d16, d20, d0
  .long  0xf2441c91                          // vfma.f32      d17, d20, d1
  .long  0xf2442c92                          // vfma.f32      d18, d20, d2
  .long  0xf2443c93                          // vfma.f32      d19, d20, d3
  .long  0xf22001b0                          // vorr          d0, d16, d16
  .long  0xf22111b1                          // vorr          d1, d17, d17
  .long  0xf22221b2                          // vorr          d2, d18, d18
  .long  0xf22331b3                          // vorr          d3, d19, d19
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_srcin_vfp4
.globl _sk_srcin_vfp4
FUNCTION(_sk_srcin_vfp4)
_sk_srcin_vfp4:
  .long  0xf3000d17                          // vmul.f32      d0, d0, d7
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3011d17                          // vmul.f32      d1, d1, d7
  .long  0xf3022d17                          // vmul.f32      d2, d2, d7
  .long  0xf3033d17                          // vmul.f32      d3, d3, d7
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_dstin_vfp4
.globl _sk_dstin_vfp4
FUNCTION(_sk_dstin_vfp4)
_sk_dstin_vfp4:
  .long  0xf3030d14                          // vmul.f32      d0, d3, d4
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3031d15                          // vmul.f32      d1, d3, d5
  .long  0xf3032d16                          // vmul.f32      d2, d3, d6
  .long  0xf3033d17                          // vmul.f32      d3, d3, d7
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_srcout_vfp4
.globl _sk_srcout_vfp4
FUNCTION(_sk_srcout_vfp4)
_sk_srcout_vfp4:
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2600d87                          // vsub.f32      d16, d16, d7
  .long  0xf3000d90                          // vmul.f32      d0, d16, d0
  .long  0xf3001d91                          // vmul.f32      d1, d16, d1
  .long  0xf3002d92                          // vmul.f32      d2, d16, d2
  .long  0xf3003d93                          // vmul.f32      d3, d16, d3
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_dstout_vfp4
.globl _sk_dstout_vfp4
FUNCTION(_sk_dstout_vfp4)
_sk_dstout_vfp4:
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2600d83                          // vsub.f32      d16, d16, d3
  .long  0xf3000d94                          // vmul.f32      d0, d16, d4
  .long  0xf3001d95                          // vmul.f32      d1, d16, d5
  .long  0xf3002d96                          // vmul.f32      d2, d16, d6
  .long  0xf3003d97                          // vmul.f32      d3, d16, d7
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_srcover_vfp4
.globl _sk_srcover_vfp4
FUNCTION(_sk_srcover_vfp4)
_sk_srcover_vfp4:
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2600d83                          // vsub.f32      d16, d16, d3
  .long  0xf2040c30                          // vfma.f32      d0, d4, d16
  .long  0xf2051c30                          // vfma.f32      d1, d5, d16
  .long  0xf2062c30                          // vfma.f32      d2, d6, d16
  .long  0xf2073c30                          // vfma.f32      d3, d7, d16
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_dstover_vfp4
.globl _sk_dstover_vfp4
FUNCTION(_sk_dstover_vfp4)
_sk_dstover_vfp4:
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2651115                          // vorr          d17, d5, d5
  .long  0xf2604d87                          // vsub.f32      d20, d16, d7
  .long  0xf2640114                          // vorr          d16, d4, d4
  .long  0xf2662116                          // vorr          d18, d6, d6
  .long  0xf2673117                          // vorr          d19, d7, d7
  .long  0xf2400c34                          // vfma.f32      d16, d0, d20
  .long  0xf2411c34                          // vfma.f32      d17, d1, d20
  .long  0xf2422c34                          // vfma.f32      d18, d2, d20
  .long  0xf2433c34                          // vfma.f32      d19, d3, d20
  .long  0xf22001b0                          // vorr          d0, d16, d16
  .long  0xf22111b1                          // vorr          d1, d17, d17
  .long  0xf22221b2                          // vorr          d2, d18, d18
  .long  0xf22331b3                          // vorr          d3, d19, d19
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_modulate_vfp4
.globl _sk_modulate_vfp4
FUNCTION(_sk_modulate_vfp4)
_sk_modulate_vfp4:
  .long  0xf3000d14                          // vmul.f32      d0, d0, d4
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3011d15                          // vmul.f32      d1, d1, d5
  .long  0xf3022d16                          // vmul.f32      d2, d2, d6
  .long  0xf3033d17                          // vmul.f32      d3, d3, d7
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_multiply_vfp4
.globl _sk_multiply_vfp4
FUNCTION(_sk_multiply_vfp4)
_sk_multiply_vfp4:
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2601d87                          // vsub.f32      d17, d16, d7
  .long  0xf2600d83                          // vsub.f32      d16, d16, d3
  .long  0xf3412d90                          // vmul.f32      d18, d17, d0
  .long  0xf3403d94                          // vmul.f32      d19, d16, d4
  .long  0xf3414d91                          // vmul.f32      d20, d17, d1
  .long  0xf3405d95                          // vmul.f32      d21, d16, d5
  .long  0xf3416d92                          // vmul.f32      d22, d17, d2
  .long  0xf3418d93                          // vmul.f32      d24, d17, d3
  .long  0xf3407d96                          // vmul.f32      d23, d16, d6
  .long  0xf3409d97                          // vmul.f32      d25, d16, d7
  .long  0xf2430da2                          // vadd.f32      d16, d19, d18
  .long  0xf2451da4                          // vadd.f32      d17, d21, d20
  .long  0xf2472da6                          // vadd.f32      d18, d23, d22
  .long  0xf2493da8                          // vadd.f32      d19, d25, d24
  .long  0xf2400c14                          // vfma.f32      d16, d0, d4
  .long  0xf2411c15                          // vfma.f32      d17, d1, d5
  .long  0xf2422c16                          // vfma.f32      d18, d2, d6
  .long  0xf2433c17                          // vfma.f32      d19, d3, d7
  .long  0xf22001b0                          // vorr          d0, d16, d16
  .long  0xf22111b1                          // vorr          d1, d17, d17
  .long  0xf22221b2                          // vorr          d2, d18, d18
  .long  0xf22331b3                          // vorr          d3, d19, d19
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_plus__vfp4
.globl _sk_plus__vfp4
FUNCTION(_sk_plus__vfp4)
_sk_plus__vfp4:
  .long  0xf2000d04                          // vadd.f32      d0, d0, d4
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2011d05                          // vadd.f32      d1, d1, d5
  .long  0xf2022d06                          // vadd.f32      d2, d2, d6
  .long  0xf2033d07                          // vadd.f32      d3, d3, d7
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_screen_vfp4
.globl _sk_screen_vfp4
FUNCTION(_sk_screen_vfp4)
_sk_screen_vfp4:
  .long  0xf2400d04                          // vadd.f32      d16, d0, d4
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2411d05                          // vadd.f32      d17, d1, d5
  .long  0xf2422d06                          // vadd.f32      d18, d2, d6
  .long  0xf2433d07                          // vadd.f32      d19, d3, d7
  .long  0xf2600c14                          // vfms.f32      d16, d0, d4
  .long  0xf2611c15                          // vfms.f32      d17, d1, d5
  .long  0xf2622c16                          // vfms.f32      d18, d2, d6
  .long  0xf2633c17                          // vfms.f32      d19, d3, d7
  .long  0xf22001b0                          // vorr          d0, d16, d16
  .long  0xf22111b1                          // vorr          d1, d17, d17
  .long  0xf22221b2                          // vorr          d2, d18, d18
  .long  0xf22331b3                          // vorr          d3, d19, d19
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_xor__vfp4
.globl _sk_xor__vfp4
FUNCTION(_sk_xor__vfp4)
_sk_xor__vfp4:
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2603d83                          // vsub.f32      d19, d16, d3
  .long  0xf2604d87                          // vsub.f32      d20, d16, d7
  .long  0xf3430d94                          // vmul.f32      d16, d19, d4
  .long  0xf3431d95                          // vmul.f32      d17, d19, d5
  .long  0xf3432d96                          // vmul.f32      d18, d19, d6
  .long  0xf3433d97                          // vmul.f32      d19, d19, d7
  .long  0xf2440c90                          // vfma.f32      d16, d20, d0
  .long  0xf2441c91                          // vfma.f32      d17, d20, d1
  .long  0xf2442c92                          // vfma.f32      d18, d20, d2
  .long  0xf2443c93                          // vfma.f32      d19, d20, d3
  .long  0xf22001b0                          // vorr          d0, d16, d16
  .long  0xf22111b1                          // vorr          d1, d17, d17
  .long  0xf22221b2                          // vorr          d2, d18, d18
  .long  0xf22331b3                          // vorr          d3, d19, d19
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_darken_vfp4
.globl _sk_darken_vfp4
FUNCTION(_sk_darken_vfp4)
_sk_darken_vfp4:
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3431d14                          // vmul.f32      d17, d3, d4
  .long  0xf3402d17                          // vmul.f32      d18, d0, d7
  .long  0xf3433d15                          // vmul.f32      d19, d3, d5
  .long  0xf3414d17                          // vmul.f32      d20, d1, d7
  .long  0xf3435d16                          // vmul.f32      d21, d3, d6
  .long  0xf2600d83                          // vsub.f32      d16, d16, d3
  .long  0xf3426d17                          // vmul.f32      d22, d2, d7
  .long  0xf2421fa1                          // vmax.f32      d17, d18, d17
  .long  0xf2407d04                          // vadd.f32      d23, d0, d4
  .long  0xf2443fa3                          // vmax.f32      d19, d20, d19
  .long  0xf2412d05                          // vadd.f32      d18, d1, d5
  .long  0xf2424d06                          // vadd.f32      d20, d2, d6
  .long  0xf2465fa5                          // vmax.f32      d21, d22, d21
  .long  0xf2073c30                          // vfma.f32      d3, d7, d16
  .long  0xf2270da1                          // vsub.f32      d0, d23, d17
  .long  0xf2221da3                          // vsub.f32      d1, d18, d19
  .long  0xf2242da5                          // vsub.f32      d2, d20, d21
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_lighten_vfp4
.globl _sk_lighten_vfp4
FUNCTION(_sk_lighten_vfp4)
_sk_lighten_vfp4:
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3431d14                          // vmul.f32      d17, d3, d4
  .long  0xf3402d17                          // vmul.f32      d18, d0, d7
  .long  0xf3433d15                          // vmul.f32      d19, d3, d5
  .long  0xf3414d17                          // vmul.f32      d20, d1, d7
  .long  0xf3435d16                          // vmul.f32      d21, d3, d6
  .long  0xf2600d83                          // vsub.f32      d16, d16, d3
  .long  0xf3426d17                          // vmul.f32      d22, d2, d7
  .long  0xf2621fa1                          // vmin.f32      d17, d18, d17
  .long  0xf2407d04                          // vadd.f32      d23, d0, d4
  .long  0xf2643fa3                          // vmin.f32      d19, d20, d19
  .long  0xf2412d05                          // vadd.f32      d18, d1, d5
  .long  0xf2424d06                          // vadd.f32      d20, d2, d6
  .long  0xf2665fa5                          // vmin.f32      d21, d22, d21
  .long  0xf2073c30                          // vfma.f32      d3, d7, d16
  .long  0xf2270da1                          // vsub.f32      d0, d23, d17
  .long  0xf2221da3                          // vsub.f32      d1, d18, d19
  .long  0xf2242da5                          // vsub.f32      d2, d20, d21
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_difference_vfp4
.globl _sk_difference_vfp4
FUNCTION(_sk_difference_vfp4)
_sk_difference_vfp4:
  .long  0xf3430d14                          // vmul.f32      d16, d3, d4
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3401d17                          // vmul.f32      d17, d0, d7
  .long  0xf3432d15                          // vmul.f32      d18, d3, d5
  .long  0xf3413d17                          // vmul.f32      d19, d1, d7
  .long  0xf3434d16                          // vmul.f32      d20, d3, d6
  .long  0xf3425d17                          // vmul.f32      d21, d2, d7
  .long  0xf2c76f10                          // vmov.f32      d22, #1
  .long  0xf2610fa0                          // vmin.f32      d16, d17, d16
  .long  0xf2631fa2                          // vmin.f32      d17, d19, d18
  .long  0xf2662d83                          // vsub.f32      d18, d22, d3
  .long  0xf2653fa4                          // vmin.f32      d19, d21, d20
  .long  0xf2404d04                          // vadd.f32      d20, d0, d4
  .long  0xf2400da0                          // vadd.f32      d16, d16, d16
  .long  0xf2073c32                          // vfma.f32      d3, d7, d18
  .long  0xf2415d05                          // vadd.f32      d21, d1, d5
  .long  0xf2411da1                          // vadd.f32      d17, d17, d17
  .long  0xf2426d06                          // vadd.f32      d22, d2, d6
  .long  0xf2432da3                          // vadd.f32      d18, d19, d19
  .long  0xf2240da0                          // vsub.f32      d0, d20, d16
  .long  0xf2251da1                          // vsub.f32      d1, d21, d17
  .long  0xf2262da2                          // vsub.f32      d2, d22, d18
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_exclusion_vfp4
.globl _sk_exclusion_vfp4
FUNCTION(_sk_exclusion_vfp4)
_sk_exclusion_vfp4:
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3401d14                          // vmul.f32      d17, d0, d4
  .long  0xf3412d15                          // vmul.f32      d18, d1, d5
  .long  0xf3423d16                          // vmul.f32      d19, d2, d6
  .long  0xf2600d83                          // vsub.f32      d16, d16, d3
  .long  0xf2404d04                          // vadd.f32      d20, d0, d4
  .long  0xf2411da1                          // vadd.f32      d17, d17, d17
  .long  0xf2415d05                          // vadd.f32      d21, d1, d5
  .long  0xf2422da2                          // vadd.f32      d18, d18, d18
  .long  0xf2426d06                          // vadd.f32      d22, d2, d6
  .long  0xf2433da3                          // vadd.f32      d19, d19, d19
  .long  0xf2073c30                          // vfma.f32      d3, d7, d16
  .long  0xf2240da1                          // vsub.f32      d0, d20, d17
  .long  0xf2251da2                          // vsub.f32      d1, d21, d18
  .long  0xf2262da3                          // vsub.f32      d2, d22, d19
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_colorburn_vfp4
.globl _sk_colorburn_vfp4
FUNCTION(_sk_colorburn_vfp4)
_sk_colorburn_vfp4:
  .long  0xed2d8b08                          // vpush         {d8-d11}
  .long  0xf2670d04                          // vsub.f32      d16, d7, d4
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2671d06                          // vsub.f32      d17, d7, d6
  .long  0xf2672d05                          // vsub.f32      d18, d7, d5
  .long  0xf3008d93                          // vmul.f32      d8, d16, d3
  .long  0xf3019d93                          // vmul.f32      d9, d17, d3
  .long  0xf302ad93                          // vmul.f32      d10, d18, d3
  .long  0xf2c71f10                          // vmov.f32      d17, #1
  .long  0xeec8baa0                          // vdiv.f32      s23, s17, s1
  .long  0xee88ba00                          // vdiv.f32      s22, s16, s0
  .long  0xeec98aa2                          // vdiv.f32      s17, s19, s5
  .long  0xee898a02                          // vdiv.f32      s16, s18, s4
  .long  0xeeca9aa1                          // vdiv.f32      s19, s21, s3
  .long  0xee8a9a01                          // vdiv.f32      s18, s20, s2
  .long  0xf2672f08                          // vmin.f32      d18, d7, d8
  .long  0xf2673f09                          // vmin.f32      d19, d7, d9
  .long  0xf2670f0b                          // vmin.f32      d16, d7, d11
  .long  0xf2614d87                          // vsub.f32      d20, d17, d7
  .long  0xf2672d22                          // vsub.f32      d18, d7, d18
  .long  0xf2673d23                          // vsub.f32      d19, d7, d19
  .long  0xf2611d83                          // vsub.f32      d17, d17, d3
  .long  0xf2670d20                          // vsub.f32      d16, d7, d16
  .long  0xf3445d90                          // vmul.f32      d21, d20, d0
  .long  0xf3446d92                          // vmul.f32      d22, d20, d2
  .long  0xf3422d93                          // vmul.f32      d18, d18, d3
  .long  0xf3444d91                          // vmul.f32      d20, d20, d1
  .long  0xf3433d93                          // vmul.f32      d19, d19, d3
  .long  0xf3400d93                          // vmul.f32      d16, d16, d3
  .long  0xf3417d95                          // vmul.f32      d23, d17, d5
  .long  0xf3418d94                          // vmul.f32      d24, d17, d4
  .long  0xf3419d96                          // vmul.f32      d25, d17, d6
  .long  0xf2443da3                          // vadd.f32      d19, d20, d19
  .long  0xf2462da2                          // vadd.f32      d18, d22, d18
  .long  0xf245ada0                          // vadd.f32      d26, d21, d16
  .long  0xf247bd81                          // vadd.f32      d27, d23, d1
  .long  0xf248cd80                          // vadd.f32      d28, d24, d0
  .long  0xf249dd82                          // vadd.f32      d29, d25, d2
  .long  0xf2073c31                          // vfma.f32      d3, d7, d17
  .long  0xf2499da2                          // vadd.f32      d25, d25, d18
  .long  0xf2473da3                          // vadd.f32      d19, d23, d19
  .long  0xf3f97501                          // vceq.f32      d23, d1, #0
  .long  0xf2455d84                          // vadd.f32      d21, d21, d4
  .long  0xf2444d85                          // vadd.f32      d20, d20, d5
  .long  0xf2440e07                          // vceq.f32      d16, d4, d7
  .long  0xf2466d86                          // vadd.f32      d22, d22, d6
  .long  0xf2451e07                          // vceq.f32      d17, d5, d7
  .long  0xf2462e07                          // vceq.f32      d18, d6, d7
  .long  0xf35b71b3                          // vbsl          d23, d27, d19
  .long  0xf3f93500                          // vceq.f32      d19, d0, #0
  .long  0xf2488daa                          // vadd.f32      d24, d24, d26
  .long  0xf35c31b8                          // vbsl          d19, d28, d24
  .long  0xf3f98502                          // vceq.f32      d24, d2, #0
  .long  0xf35d81b9                          // vbsl          d24, d29, d25
  .long  0xf35501b3                          // vbsl          d16, d21, d19
  .long  0xf35411b7                          // vbsl          d17, d20, d23
  .long  0xf35621b8                          // vbsl          d18, d22, d24
  .long  0xf22001b0                          // vorr          d0, d16, d16
  .long  0xf22111b1                          // vorr          d1, d17, d17
  .long  0xf22221b2                          // vorr          d2, d18, d18
  .long  0xecbd8b08                          // vpop          {d8-d11}
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_colordodge_vfp4
.globl _sk_colordodge_vfp4
FUNCTION(_sk_colordodge_vfp4)
_sk_colordodge_vfp4:
  .long  0xed2d8b0e                          // vpush         {d8-d14}
  .long  0xf2238d02                          // vsub.f32      d8, d3, d2
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3039d16                          // vmul.f32      d9, d3, d6
  .long  0xf223ad01                          // vsub.f32      d10, d3, d1
  .long  0xf303bd15                          // vmul.f32      d11, d3, d5
  .long  0xf223cd00                          // vsub.f32      d12, d3, d0
  .long  0xf303dd14                          // vmul.f32      d13, d3, d4
  .long  0xeec9eaa8                          // vdiv.f32      s29, s19, s17
  .long  0xee89ea08                          // vdiv.f32      s28, s18, s16
  .long  0xeecb8aaa                          // vdiv.f32      s17, s23, s21
  .long  0xeecd9aac                          // vdiv.f32      s19, s27, s25
  .long  0xee8b8a0a                          // vdiv.f32      s16, s22, s20
  .long  0xee8d9a0c                          // vdiv.f32      s18, s26, s24
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xf2672f0e                          // vmin.f32      d18, d7, d14
  .long  0xf2601d87                          // vsub.f32      d17, d16, d7
  .long  0xf2673f08                          // vmin.f32      d19, d7, d8
  .long  0xf2674f09                          // vmin.f32      d20, d7, d9
  .long  0xf2600d83                          // vsub.f32      d16, d16, d3
  .long  0xf3415d92                          // vmul.f32      d21, d17, d2
  .long  0xf3422d93                          // vmul.f32      d18, d18, d3
  .long  0xf3416d91                          // vmul.f32      d22, d17, d1
  .long  0xf3433d93                          // vmul.f32      d19, d19, d3
  .long  0xf3411d90                          // vmul.f32      d17, d17, d0
  .long  0xf3444d93                          // vmul.f32      d20, d20, d3
  .long  0xf3407d95                          // vmul.f32      d23, d16, d5
  .long  0xf3408d94                          // vmul.f32      d24, d16, d4
  .long  0xf3409d96                          // vmul.f32      d25, d16, d6
  .long  0xf2452da2                          // vadd.f32      d18, d21, d18
  .long  0xf2463da3                          // vadd.f32      d19, d22, d19
  .long  0xf2414da4                          // vadd.f32      d20, d17, d20
  .long  0xf241ae03                          // vceq.f32      d26, d1, d3
  .long  0xf247bd81                          // vadd.f32      d27, d23, d1
  .long  0xf3b91505                          // vceq.f32      d1, d5, #0
  .long  0xf240ce03                          // vceq.f32      d28, d0, d3
  .long  0xf248dd80                          // vadd.f32      d29, d24, d0
  .long  0xf3b90504                          // vceq.f32      d0, d4, #0
  .long  0xf242ee03                          // vceq.f32      d30, d2, d3
  .long  0xf249fd82                          // vadd.f32      d31, d25, d2
  .long  0xf3b92506                          // vceq.f32      d2, d6, #0
  .long  0xf2073c30                          // vfma.f32      d3, d7, d16
  .long  0xf2410d84                          // vadd.f32      d16, d17, d4
  .long  0xf2491da2                          // vadd.f32      d17, d25, d18
  .long  0xf2462d85                          // vadd.f32      d18, d22, d5
  .long  0xf2455d86                          // vadd.f32      d21, d21, d6
  .long  0xf2473da3                          // vadd.f32      d19, d23, d19
  .long  0xf2484da4                          // vadd.f32      d20, d24, d20
  .long  0xf35fe1b1                          // vbsl          d30, d31, d17
  .long  0xf35ba1b3                          // vbsl          d26, d27, d19
  .long  0xf35dc1b4                          // vbsl          d28, d29, d20
  .long  0xf31001bc                          // vbsl          d0, d16, d28
  .long  0xf31211ba                          // vbsl          d1, d18, d26
  .long  0xf31521be                          // vbsl          d2, d21, d30
  .long  0xecbd8b0e                          // vpop          {d8-d14}
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_hardlight_vfp4
.globl _sk_hardlight_vfp4
FUNCTION(_sk_hardlight_vfp4)
_sk_hardlight_vfp4:
  .long  0xf2c71f10                          // vmov.f32      d17, #1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2670d04                          // vsub.f32      d16, d7, d4
  .long  0xf2617d87                          // vsub.f32      d23, d17, d7
  .long  0xf2611d83                          // vsub.f32      d17, d17, d3
  .long  0xf2672d05                          // vsub.f32      d18, d7, d5
  .long  0xf2674d06                          // vsub.f32      d20, d7, d6
  .long  0xf2633d00                          // vsub.f32      d19, d3, d0
  .long  0xf2635d01                          // vsub.f32      d21, d3, d1
  .long  0xf2636d02                          // vsub.f32      d22, d3, d2
  .long  0xf347bd90                          // vmul.f32      d27, d23, d0
  .long  0xf341cd94                          // vmul.f32      d28, d17, d4
  .long  0xf3430db0                          // vmul.f32      d16, d19, d16
  .long  0xf3463db4                          // vmul.f32      d19, d22, d20
  .long  0xf3452db2                          // vmul.f32      d18, d21, d18
  .long  0xf2404d00                          // vadd.f32      d20, d0, d0
  .long  0xf3405d14                          // vmul.f32      d21, d0, d4
  .long  0xf2416d01                          // vadd.f32      d22, d1, d1
  .long  0xf3418d15                          // vmul.f32      d24, d1, d5
  .long  0xf2429d02                          // vadd.f32      d25, d2, d2
  .long  0xf342ad16                          // vmul.f32      d26, d2, d6
  .long  0xf347dd91                          // vmul.f32      d29, d23, d1
  .long  0xf341fd95                          // vmul.f32      d31, d17, d5
  .long  0xf24cbdab                          // vadd.f32      d27, d28, d27
  .long  0xf3477d92                          // vmul.f32      d23, d23, d2
  .long  0xf341cd96                          // vmul.f32      d28, d17, d6
  .long  0xf2400da0                          // vadd.f32      d16, d16, d16
  .long  0xf343ed17                          // vmul.f32      d30, d3, d7
  .long  0xf2422da2                          // vadd.f32      d18, d18, d18
  .long  0xf2433da3                          // vadd.f32      d19, d19, d19
  .long  0xf3434e24                          // vcge.f32      d20, d3, d20
  .long  0xf2455da5                          // vadd.f32      d21, d21, d21
  .long  0xf3436e26                          // vcge.f32      d22, d3, d22
  .long  0xf3439e29                          // vcge.f32      d25, d3, d25
  .long  0xf2488da8                          // vadd.f32      d24, d24, d24
  .long  0xf24aadaa                          // vadd.f32      d26, d26, d26
  .long  0xf2073c31                          // vfma.f32      d3, d7, d17
  .long  0xf24fddad                          // vadd.f32      d29, d31, d29
  .long  0xf24c1da7                          // vadd.f32      d17, d28, d23
  .long  0xf26e0da0                          // vsub.f32      d16, d30, d16
  .long  0xf26e2da2                          // vsub.f32      d18, d30, d18
  .long  0xf26e3da3                          // vsub.f32      d19, d30, d19
  .long  0xf35541b0                          // vbsl          d20, d21, d16
  .long  0xf35861b2                          // vbsl          d22, d24, d18
  .long  0xf35a91b3                          // vbsl          d25, d26, d19
  .long  0xf20b0da4                          // vadd.f32      d0, d27, d20
  .long  0xf20d1da6                          // vadd.f32      d1, d29, d22
  .long  0xf2012da9                          // vadd.f32      d2, d17, d25
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_overlay_vfp4
.globl _sk_overlay_vfp4
FUNCTION(_sk_overlay_vfp4)
_sk_overlay_vfp4:
  .long  0xf2c71f10                          // vmov.f32      d17, #1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2670d04                          // vsub.f32      d16, d7, d4
  .long  0xf2617d87                          // vsub.f32      d23, d17, d7
  .long  0xf2611d83                          // vsub.f32      d17, d17, d3
  .long  0xf2672d05                          // vsub.f32      d18, d7, d5
  .long  0xf2674d06                          // vsub.f32      d20, d7, d6
  .long  0xf2633d00                          // vsub.f32      d19, d3, d0
  .long  0xf2635d01                          // vsub.f32      d21, d3, d1
  .long  0xf2636d02                          // vsub.f32      d22, d3, d2
  .long  0xf347bd90                          // vmul.f32      d27, d23, d0
  .long  0xf341cd94                          // vmul.f32      d28, d17, d4
  .long  0xf3430db0                          // vmul.f32      d16, d19, d16
  .long  0xf3463db4                          // vmul.f32      d19, d22, d20
  .long  0xf3452db2                          // vmul.f32      d18, d21, d18
  .long  0xf2444d04                          // vadd.f32      d20, d4, d4
  .long  0xf3405d14                          // vmul.f32      d21, d0, d4
  .long  0xf2456d05                          // vadd.f32      d22, d5, d5
  .long  0xf3418d15                          // vmul.f32      d24, d1, d5
  .long  0xf2469d06                          // vadd.f32      d25, d6, d6
  .long  0xf342ad16                          // vmul.f32      d26, d2, d6
  .long  0xf347dd91                          // vmul.f32      d29, d23, d1
  .long  0xf341fd95                          // vmul.f32      d31, d17, d5
  .long  0xf24cbdab                          // vadd.f32      d27, d28, d27
  .long  0xf3477d92                          // vmul.f32      d23, d23, d2
  .long  0xf341cd96                          // vmul.f32      d28, d17, d6
  .long  0xf343ed17                          // vmul.f32      d30, d3, d7
  .long  0xf2400da0                          // vadd.f32      d16, d16, d16
  .long  0xf2422da2                          // vadd.f32      d18, d18, d18
  .long  0xf2433da3                          // vadd.f32      d19, d19, d19
  .long  0xf3474e24                          // vcge.f32      d20, d7, d20
  .long  0xf2455da5                          // vadd.f32      d21, d21, d21
  .long  0xf3476e26                          // vcge.f32      d22, d7, d22
  .long  0xf2488da8                          // vadd.f32      d24, d24, d24
  .long  0xf3479e29                          // vcge.f32      d25, d7, d25
  .long  0xf24aadaa                          // vadd.f32      d26, d26, d26
  .long  0xf2073c31                          // vfma.f32      d3, d7, d17
  .long  0xf24fddad                          // vadd.f32      d29, d31, d29
  .long  0xf24c1da7                          // vadd.f32      d17, d28, d23
  .long  0xf26e0da0                          // vsub.f32      d16, d30, d16
  .long  0xf26e2da2                          // vsub.f32      d18, d30, d18
  .long  0xf26e3da3                          // vsub.f32      d19, d30, d19
  .long  0xf35541b0                          // vbsl          d20, d21, d16
  .long  0xf35861b2                          // vbsl          d22, d24, d18
  .long  0xf35a91b3                          // vbsl          d25, d26, d19
  .long  0xf20b0da4                          // vadd.f32      d0, d27, d20
  .long  0xf20d1da6                          // vadd.f32      d1, d29, d22
  .long  0xf2012da9                          // vadd.f32      d2, d17, d25
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_softlight_vfp4
.globl _sk_softlight_vfp4
FUNCTION(_sk_softlight_vfp4)
_sk_softlight_vfp4:
  .long  0xed2d8b06                          // vpush         {d8-d10}
  .long  0xeec58aa7                          // vdiv.f32      s17, s11, s15
  .long  0xf3f90407                          // vcgt.f32      d16, d7, #0
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xeec49aa7                          // vdiv.f32      s19, s9, s15
  .long  0xeec6aaa7                          // vdiv.f32      s21, s13, s15
  .long  0xee858a07                          // vdiv.f32      s16, s10, s14
  .long  0xee849a07                          // vdiv.f32      s18, s8, s14
  .long  0xee86aa07                          // vdiv.f32      s20, s12, s14
  .long  0xf26021b0                          // vorr          d18, d16, d16
  .long  0xf2c01010                          // vmov.i32      d17, #0
  .long  0xf3582131                          // vbsl          d18, d8, d17
  .long  0xf26031b0                          // vorr          d19, d16, d16
  .long  0xf3fb45a2                          // vrsqrte.f32   d20, d18
  .long  0xf3593131                          // vbsl          d19, d9, d17
  .long  0xf35a0131                          // vbsl          d16, d10, d17
  .long  0xf3fb15a3                          // vrsqrte.f32   d17, d19
  .long  0xf3fb55a0                          // vrsqrte.f32   d21, d16
  .long  0xf3446db4                          // vmul.f32      d22, d20, d20
  .long  0xf243ada3                          // vadd.f32      d26, d19, d19
  .long  0xf240bda0                          // vadd.f32      d27, d16, d16
  .long  0xf3417db1                          // vmul.f32      d23, d17, d17
  .long  0xf3458db5                          // vmul.f32      d24, d21, d21
  .long  0xf2626fb6                          // vrsqrts.f32   d22, d18, d22
  .long  0xf2429da2                          // vadd.f32      d25, d18, d18
  .long  0xf2637fb7                          // vrsqrts.f32   d23, d19, d23
  .long  0xf2608fb8                          // vrsqrts.f32   d24, d16, d24
  .long  0xf2818f1c                          // vmov.f32      d8, #7
  .long  0xf2499da9                          // vadd.f32      d25, d25, d25
  .long  0xf3444db6                          // vmul.f32      d20, d20, d22
  .long  0xf24a6daa                          // vadd.f32      d22, d26, d26
  .long  0xf24badab                          // vadd.f32      d26, d27, d27
  .long  0xf3411db7                          // vmul.f32      d17, d17, d23
  .long  0xf3455db8                          // vmul.f32      d21, d21, d24
  .long  0xf3fb7524                          // vrecpe.f32    d23, d20
  .long  0xf3498db9                          // vmul.f32      d24, d25, d25
  .long  0xf3fbd521                          // vrecpe.f32    d29, d17
  .long  0xf34aedba                          // vmul.f32      d30, d26, d26
  .long  0xf3fbf525                          // vrecpe.f32    d31, d21
  .long  0xf2444fb7                          // vrecps.f32    d20, d20, d23
  .long  0xf346cdb6                          // vmul.f32      d28, d22, d22
  .long  0xf2411fbd                          // vrecps.f32    d17, d17, d29
  .long  0xf3c7bf10                          // vmov.f32      d27, #-1
  .long  0xf2455fbf                          // vrecps.f32    d21, d21, d31
  .long  0xf24aadae                          // vadd.f32      d26, d26, d30
  .long  0xf2498da8                          // vadd.f32      d24, d25, d24
  .long  0xf2429dab                          // vadd.f32      d25, d18, d27
  .long  0xf2466dac                          // vadd.f32      d22, d22, d28
  .long  0xf243cdab                          // vadd.f32      d28, d19, d27
  .long  0xf240bdab                          // vadd.f32      d27, d16, d27
  .long  0xf3474db4                          // vmul.f32      d20, d23, d20
  .long  0xf2c7ef10                          // vmov.f32      d30, #1
  .long  0xf34d1db1                          // vmul.f32      d17, d29, d17
  .long  0xf34badba                          // vmul.f32      d26, d27, d26
  .long  0xf242bd02                          // vadd.f32      d27, d2, d2
  .long  0xf26edda0                          // vsub.f32      d29, d30, d16
  .long  0xf3498db8                          // vmul.f32      d24, d25, d24
  .long  0xf3429d98                          // vmul.f32      d25, d18, d8
  .long  0xf34f5db5                          // vmul.f32      d21, d31, d21
  .long  0xf26efda2                          // vsub.f32      d31, d30, d18
  .long  0xf2642da2                          // vsub.f32      d18, d20, d18
  .long  0xf26b4d83                          // vsub.f32      d20, d27, d3
  .long  0xf2498da8                          // vadd.f32      d24, d25, d24
  .long  0xf34c6db6                          // vmul.f32      d22, d28, d22
  .long  0xf3437d98                          // vmul.f32      d23, d19, d8
  .long  0xf3449dbd                          // vmul.f32      d25, d20, d29
  .long  0xf245dd05                          // vadd.f32      d29, d5, d5
  .long  0xf340cd98                          // vmul.f32      d28, d16, d8
  .long  0xf2476da6                          // vadd.f32      d22, d23, d22
  .long  0xf2611da3                          // vsub.f32      d17, d17, d19
  .long  0xf24dddad                          // vadd.f32      d29, d29, d29
  .long  0xf24c7daa                          // vadd.f32      d23, d28, d26
  .long  0xf2650da0                          // vsub.f32      d16, d21, d16
  .long  0xf26e3da3                          // vsub.f32      d19, d30, d19
  .long  0xf347de2d                          // vcge.f32      d29, d7, d29
  .long  0xf241ad01                          // vadd.f32      d26, d1, d1
  .long  0xf3444d97                          // vmul.f32      d20, d20, d7
  .long  0xf358d1b2                          // vbsl          d29, d24, d18
  .long  0xf2448d04                          // vadd.f32      d24, d4, d4
  .long  0xf2462d06                          // vadd.f32      d18, d6, d6
  .long  0xf26a5d83                          // vsub.f32      d21, d26, d3
  .long  0xf2488da8                          // vadd.f32      d24, d24, d24
  .long  0xf2422da2                          // vadd.f32      d18, d18, d18
  .long  0xf345cdbf                          // vmul.f32      d28, d21, d31
  .long  0xf3455d97                          // vmul.f32      d21, d21, d7
  .long  0xf3478e28                          // vcge.f32      d24, d7, d24
  .long  0xf3472e22                          // vcge.f32      d18, d7, d18
  .long  0xf343fd14                          // vmul.f32      d31, d3, d4
  .long  0xf3455dbd                          // vmul.f32      d21, d21, d29
  .long  0xf35681b1                          // vbsl          d24, d22, d17
  .long  0xf2401d00                          // vadd.f32      d17, d0, d0
  .long  0xf35721b0                          // vbsl          d18, d23, d16
  .long  0xf24c0d83                          // vadd.f32      d16, d28, d3
  .long  0xf2496d83                          // vadd.f32      d22, d25, d3
  .long  0xf2617d83                          // vsub.f32      d23, d17, d3
  .long  0xf3442db2                          // vmul.f32      d18, d20, d18
  .long  0xf3434e2a                          // vcge.f32      d20, d3, d26
  .long  0xf343ae2b                          // vcge.f32      d26, d3, d27
  .long  0xf3473db3                          // vmul.f32      d19, d23, d19
  .long  0xf3477d97                          // vmul.f32      d23, d23, d7
  .long  0xf3431e21                          // vcge.f32      d17, d3, d17
  .long  0xf3400d95                          // vmul.f32      d16, d16, d5
  .long  0xf2433d83                          // vadd.f32      d19, d19, d3
  .long  0xf3477db8                          // vmul.f32      d23, d23, d24
  .long  0xf26e8d87                          // vsub.f32      d24, d30, d7
  .long  0xf26eed83                          // vsub.f32      d30, d30, d3
  .long  0xf3433d94                          // vmul.f32      d19, d19, d4
  .long  0xf24f7da7                          // vadd.f32      d23, d31, d23
  .long  0xf3489d91                          // vmul.f32      d25, d24, d1
  .long  0xf348cd90                          // vmul.f32      d28, d24, d0
  .long  0xf34edd94                          // vmul.f32      d29, d30, d4
  .long  0xf34ebd95                          // vmul.f32      d27, d30, d5
  .long  0xf3488d92                          // vmul.f32      d24, d24, d2
  .long  0xf34efd96                          // vmul.f32      d31, d30, d6
  .long  0xf24dcdac                          // vadd.f32      d28, d29, d28
  .long  0xf343dd15                          // vmul.f32      d29, d3, d5
  .long  0xf24b9da9                          // vadd.f32      d25, d27, d25
  .long  0xf343bd16                          // vmul.f32      d27, d3, d6
  .long  0xf3466d96                          // vmul.f32      d22, d22, d6
  .long  0xf24f8da8                          // vadd.f32      d24, d31, d24
  .long  0xf24d5da5                          // vadd.f32      d21, d29, d21
  .long  0xf24b2da2                          // vadd.f32      d18, d27, d18
  .long  0xf35311b7                          // vbsl          d17, d19, d23
  .long  0xf35041b5                          // vbsl          d20, d16, d21
  .long  0xf356a1b2                          // vbsl          d26, d22, d18
  .long  0xf2073c3e                          // vfma.f32      d3, d7, d30
  .long  0xf20c0da1                          // vadd.f32      d0, d28, d17
  .long  0xf2091da4                          // vadd.f32      d1, d25, d20
  .long  0xf2082daa                          // vadd.f32      d2, d24, d26
  .long  0xecbd8b06                          // vpop          {d8-d10}
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_clamp_0_vfp4
.globl _sk_clamp_0_vfp4
FUNCTION(_sk_clamp_0_vfp4)
_sk_clamp_0_vfp4:
  .long  0xf2c00010                          // vmov.i32      d16, #0
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2000f20                          // vmax.f32      d0, d0, d16
  .long  0xf2011f20                          // vmax.f32      d1, d1, d16
  .long  0xf2022f20                          // vmax.f32      d2, d2, d16
  .long  0xf2033f20                          // vmax.f32      d3, d3, d16
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_clamp_1_vfp4
.globl _sk_clamp_1_vfp4
FUNCTION(_sk_clamp_1_vfp4)
_sk_clamp_1_vfp4:
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2200f20                          // vmin.f32      d0, d0, d16
  .long  0xf2211f20                          // vmin.f32      d1, d1, d16
  .long  0xf2222f20                          // vmin.f32      d2, d2, d16
  .long  0xf2233f20                          // vmin.f32      d3, d3, d16
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_clamp_a_vfp4
.globl _sk_clamp_a_vfp4
FUNCTION(_sk_clamp_a_vfp4)
_sk_clamp_a_vfp4:
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2233f20                          // vmin.f32      d3, d3, d16
  .long  0xf2200f03                          // vmin.f32      d0, d0, d3
  .long  0xf2211f03                          // vmin.f32      d1, d1, d3
  .long  0xf2222f03                          // vmin.f32      d2, d2, d3
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_set_rgb_vfp4
.globl _sk_set_rgb_vfp4
FUNCTION(_sk_set_rgb_vfp4)
_sk_set_rgb_vfp4:
  .long  0xe92d4800                          // push          {fp, lr}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe283e008                          // add           lr, r3, #8
  .long  0xf4a30c9d                          // vld1.32       {d0[]}, [r3 :32]!
  .long  0xf4ae2c9f                          // vld1.32       {d2[]}, [lr :32]
  .long  0xf4a31c9f                          // vld1.32       {d1[]}, [r3 :32]
  .long  0xe8bd4800                          // pop           {fp, lr}
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_swap_rb_vfp4
.globl _sk_swap_rb_vfp4
FUNCTION(_sk_swap_rb_vfp4)
_sk_swap_rb_vfp4:
  .long  0xeef00b40                          // vmov.f64      d16, d0
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xeeb00b42                          // vmov.f64      d0, d2
  .long  0xeeb02b60                          // vmov.f64      d2, d16
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_swap_vfp4
.globl _sk_swap_vfp4
FUNCTION(_sk_swap_vfp4)
_sk_swap_vfp4:
  .long  0xeef00b43                          // vmov.f64      d16, d3
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xeef01b42                          // vmov.f64      d17, d2
  .long  0xeef02b41                          // vmov.f64      d18, d1
  .long  0xeef03b40                          // vmov.f64      d19, d0
  .long  0xeeb00b44                          // vmov.f64      d0, d4
  .long  0xeeb01b45                          // vmov.f64      d1, d5
  .long  0xeeb02b46                          // vmov.f64      d2, d6
  .long  0xeeb03b47                          // vmov.f64      d3, d7
  .long  0xeeb04b63                          // vmov.f64      d4, d19
  .long  0xeeb05b62                          // vmov.f64      d5, d18
  .long  0xeeb06b61                          // vmov.f64      d6, d17
  .long  0xeeb07b60                          // vmov.f64      d7, d16
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_move_src_dst_vfp4
.globl _sk_move_src_dst_vfp4
FUNCTION(_sk_move_src_dst_vfp4)
_sk_move_src_dst_vfp4:
  .long  0xeeb04b40                          // vmov.f64      d4, d0
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xeeb05b41                          // vmov.f64      d5, d1
  .long  0xeeb06b42                          // vmov.f64      d6, d2
  .long  0xeeb07b43                          // vmov.f64      d7, d3
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_move_dst_src_vfp4
.globl _sk_move_dst_src_vfp4
FUNCTION(_sk_move_dst_src_vfp4)
_sk_move_dst_src_vfp4:
  .long  0xeeb00b44                          // vmov.f64      d0, d4
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xeeb01b45                          // vmov.f64      d1, d5
  .long  0xeeb02b46                          // vmov.f64      d2, d6
  .long  0xeeb03b47                          // vmov.f64      d3, d7
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_premul_vfp4
.globl _sk_premul_vfp4
FUNCTION(_sk_premul_vfp4)
_sk_premul_vfp4:
  .long  0xf3000d13                          // vmul.f32      d0, d0, d3
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3011d13                          // vmul.f32      d1, d1, d3
  .long  0xf3022d13                          // vmul.f32      d2, d2, d3
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_unpremul_vfp4
.globl _sk_unpremul_vfp4
FUNCTION(_sk_unpremul_vfp4)
_sk_unpremul_vfp4:
  .long  0xed2d8b04                          // vpush         {d8-d9}
  .long  0xeeb78a00                          // vmov.f32      s16, #112
  .long  0xf3f91503                          // vceq.f32      d17, d3, #0
  .long  0xf2c00010                          // vmov.i32      d16, #0
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xeec89a23                          // vdiv.f32      s19, s16, s7
  .long  0xee889a03                          // vdiv.f32      s18, s16, s6
  .long  0xf3501199                          // vbsl          d17, d16, d9
  .long  0xf3010d90                          // vmul.f32      d0, d17, d0
  .long  0xf3011d91                          // vmul.f32      d1, d17, d1
  .long  0xf3012d92                          // vmul.f32      d2, d17, d2
  .long  0xecbd8b04                          // vpop          {d8-d9}
  .long  0xe12fff13                          // bx            r3
  .long  0xe320f000                          // nop           {0}

HIDDEN _sk_from_srgb_vfp4
.globl _sk_from_srgb_vfp4
FUNCTION(_sk_from_srgb_vfp4)
_sk_from_srgb_vfp4:
  .long  0xeddf3b20                          // vldr          d19, [pc, #128]
  .long  0xf3408d10                          // vmul.f32      d24, d0, d0
  .long  0xeddf0b1c                          // vldr          d16, [pc, #112]
  .long  0xf26341b3                          // vorr          d20, d19, d19
  .long  0xf26351b3                          // vorr          d21, d19, d19
  .long  0xeddf9b1f                          // vldr          d25, [pc, #124]
  .long  0xf2404c30                          // vfma.f32      d20, d0, d16
  .long  0xeddf2b1b                          // vldr          d18, [pc, #108]
  .long  0xf2415c30                          // vfma.f32      d21, d1, d16
  .long  0xeddfcb1d                          // vldr          d28, [pc, #116]
  .long  0xf2423c30                          // vfma.f32      d19, d2, d16
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3426d12                          // vmul.f32      d22, d2, d2
  .long  0xf3417d11                          // vmul.f32      d23, d1, d1
  .long  0xf3620e80                          // vcgt.f32      d16, d18, d0
  .long  0xf3621e81                          // vcgt.f32      d17, d18, d1
  .long  0xf341ad39                          // vmul.f32      d26, d1, d25
  .long  0xf342bd39                          // vmul.f32      d27, d2, d25
  .long  0xf3622e82                          // vcgt.f32      d18, d18, d2
  .long  0xf3409d39                          // vmul.f32      d25, d0, d25
  .long  0xf26cd1bc                          // vorr          d29, d28, d28
  .long  0xf248dcb4                          // vfma.f32      d29, d24, d20
  .long  0xf26c41bc                          // vorr          d20, d28, d28
  .long  0xf2474cb5                          // vfma.f32      d20, d23, d21
  .long  0xf246ccb3                          // vfma.f32      d28, d22, d19
  .long  0xf35901bd                          // vbsl          d16, d25, d29
  .long  0xf35a11b4                          // vbsl          d17, d26, d20
  .long  0xf35b21bc                          // vbsl          d18, d27, d28
  .long  0xf22001b0                          // vorr          d0, d16, d16
  .long  0xf22111b1                          // vorr          d1, d17, d17
  .long  0xf22221b2                          // vorr          d2, d18, d18
  .long  0xe12fff13                          // bx            r3
  .long  0x3e99999a                          // .word         0x3e99999a
  .long  0x3e99999a                          // .word         0x3e99999a
  .long  0x3f328f5c                          // .word         0x3f328f5c
  .long  0x3f328f5c                          // .word         0x3f328f5c
  .long  0x3d6147ae                          // .word         0x3d6147ae
  .long  0x3d6147ae                          // .word         0x3d6147ae
  .long  0x3d9e8391                          // .word         0x3d9e8391
  .long  0x3d9e8391                          // .word         0x3d9e8391
  .long  0x3b23d70a                          // .word         0x3b23d70a
  .long  0x3b23d70a                          // .word         0x3b23d70a

HIDDEN _sk_to_srgb_vfp4
.globl _sk_to_srgb_vfp4
FUNCTION(_sk_to_srgb_vfp4)
_sk_to_srgb_vfp4:
  .long  0xf3fb0582                          // vrsqrte.f32   d16, d2
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3fb1581                          // vrsqrte.f32   d17, d1
  .long  0xf3fb2580                          // vrsqrte.f32   d18, d0
  .long  0xf3403db0                          // vmul.f32      d19, d16, d16
  .long  0xf3414db1                          // vmul.f32      d20, d17, d17
  .long  0xf3425db2                          // vmul.f32      d21, d18, d18
  .long  0xf2623f33                          // vrsqrts.f32   d19, d2, d19
  .long  0xf2614f34                          // vrsqrts.f32   d20, d1, d20
  .long  0xf2605f35                          // vrsqrts.f32   d21, d0, d21
  .long  0xf3400db3                          // vmul.f32      d16, d16, d19
  .long  0xf3411db4                          // vmul.f32      d17, d17, d20
  .long  0xf3422db5                          // vmul.f32      d18, d18, d21
  .long  0xf3fb3520                          // vrecpe.f32    d19, d16
  .long  0xf3fb4521                          // vrecpe.f32    d20, d17
  .long  0xf3fb6522                          // vrecpe.f32    d22, d18
  .long  0xf3fb55a0                          // vrsqrte.f32   d21, d16
  .long  0xf3fb75a1                          // vrsqrte.f32   d23, d17
  .long  0xf3fb85a2                          // vrsqrte.f32   d24, d18
  .long  0xf2409fb3                          // vrecps.f32    d25, d16, d19
  .long  0xf241afb4                          // vrecps.f32    d26, d17, d20
  .long  0xf242bfb6                          // vrecps.f32    d27, d18, d22
  .long  0xf345cdb5                          // vmul.f32      d28, d21, d21
  .long  0xf347ddb7                          // vmul.f32      d29, d23, d23
  .long  0xf348edb8                          // vmul.f32      d30, d24, d24
  .long  0xf2600fbc                          // vrsqrts.f32   d16, d16, d28
  .long  0xf2611fbd                          // vrsqrts.f32   d17, d17, d29
  .long  0xf2622fbe                          // vrsqrts.f32   d18, d18, d30
  .long  0xf3433db9                          // vmul.f32      d19, d19, d25
  .long  0xeddf9b21                          // vldr          d25, [pc, #132]
  .long  0xf3444dba                          // vmul.f32      d20, d20, d26
  .long  0xeddfab21                          // vldr          d26, [pc, #132]
  .long  0xf3466dbb                          // vmul.f32      d22, d22, d27
  .long  0xf26ab1ba                          // vorr          d27, d26, d26
  .long  0xf243bcb9                          // vfma.f32      d27, d19, d25
  .long  0xf26a31ba                          // vorr          d19, d26, d26
  .long  0xf2443cb9                          // vfma.f32      d19, d20, d25
  .long  0xeddf4b1d                          // vldr          d20, [pc, #116]
  .long  0xf246acb9                          // vfma.f32      d26, d22, d25
  .long  0xf3450db0                          // vmul.f32      d16, d21, d16
  .long  0xeddf5b1c                          // vldr          d21, [pc, #112]
  .long  0xf3471db1                          // vmul.f32      d17, d23, d17
  .long  0xf3482db2                          // vmul.f32      d18, d24, d18
  .long  0xf3406d35                          // vmul.f32      d22, d0, d21
  .long  0xf240bcb4                          // vfma.f32      d27, d16, d20
  .long  0xf2413cb4                          // vfma.f32      d19, d17, d20
  .long  0xf242acb4                          // vfma.f32      d26, d18, d20
  .long  0xeddf2b17                          // vldr          d18, [pc, #92]
  .long  0xf3417d35                          // vmul.f32      d23, d1, d21
  .long  0xf3620e80                          // vcgt.f32      d16, d18, d0
  .long  0xf3621e81                          // vcgt.f32      d17, d18, d1
  .long  0xf3622e82                          // vcgt.f32      d18, d18, d2
  .long  0xf3425d35                          // vmul.f32      d21, d2, d21
  .long  0xf2c74f10                          // vmov.f32      d20, #1
  .long  0xf2648faa                          // vmin.f32      d24, d20, d26
  .long  0xf2643fa3                          // vmin.f32      d19, d20, d19
  .long  0xf2644fab                          // vmin.f32      d20, d20, d27
  .long  0xf35601b8                          // vbsl          d16, d22, d24
  .long  0xf35711b3                          // vbsl          d17, d23, d19
  .long  0xf35521b4                          // vbsl          d18, d21, d20
  .long  0xf22001b0                          // vorr          d0, d16, d16
  .long  0xf22111b1                          // vorr          d1, d17, d17
  .long  0xf22221b2                          // vorr          d2, d18, d18
  .long  0xe12fff13                          // bx            r3
  .long  0x3f306fce                          // .word         0x3f306fce
  .long  0x3f306fce                          // .word         0x3f306fce
  .long  0xbdca57a8                          // .word         0xbdca57a8
  .long  0xbdca57a8                          // .word         0xbdca57a8
  .long  0x3ed287c2                          // .word         0x3ed287c2
  .long  0x3ed287c2                          // .word         0x3ed287c2
  .long  0x41475c29                          // .word         0x41475c29
  .long  0x41475c29                          // .word         0x41475c29
  .long  0x3b8ce704                          // .word         0x3b8ce704
  .long  0x3b8ce704                          // .word         0x3b8ce704

HIDDEN _sk_rgb_to_hsl_vfp4
.globl _sk_rgb_to_hsl_vfp4
FUNCTION(_sk_rgb_to_hsl_vfp4)
_sk_rgb_to_hsl_vfp4:
  .long  0xed2d8b08                          // vpush         {d8-d11}
  .long  0xf2401f01                          // vmax.f32      d17, d0, d1
  .long  0xeddf9b2c                          // vldr          d25, [pc, #176]
  .long  0xf2600f01                          // vmin.f32      d16, d0, d1
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xeeb78a00                          // vmov.f32      s16, #112
  .long  0xf2c3461f                          // vmov.i32      d20, #1056964608
  .long  0xf2411f82                          // vmax.f32      d17, d17, d2
  .long  0xf2602f82                          // vmin.f32      d18, d16, d2
  .long  0xf2c45610                          // vmov.i32      d21, #1073741824
  .long  0xf2607d01                          // vsub.f32      d23, d0, d1
  .long  0xf2656da1                          // vsub.f32      d22, d21, d17
  .long  0xf221ada2                          // vsub.f32      d10, d17, d18
  .long  0xf2413da2                          // vadd.f32      d19, d17, d18
  .long  0xf2c08010                          // vmov.i32      d24, #0
  .long  0xf2666da2                          // vsub.f32      d22, d22, d18
  .long  0xf241ae80                          // vceq.f32      d26, d17, d0
  .long  0xeec8ba2a                          // vdiv.f32      s23, s16, s21
  .long  0xf3430db4                          // vmul.f32      d16, d19, d20
  .long  0xee88ba0a                          // vdiv.f32      s22, s16, s20
  .long  0xf3209ea4                          // vcgt.f32      d9, d16, d20
  .long  0xf2614d02                          // vsub.f32      d20, d1, d2
  .long  0xf3477d9b                          // vmul.f32      d23, d23, d11
  .long  0xf31691b3                          // vbsl          d9, d22, d19
  .long  0xf2623d00                          // vsub.f32      d19, d2, d0
  .long  0xf3626e01                          // vcgt.f32      d22, d2, d1
  .long  0xeeca8aa9                          // vdiv.f32      s17, s21, s19
  .long  0xee8a8a09                          // vdiv.f32      s16, s20, s18
  .long  0xf3433d9b                          // vmul.f32      d19, d19, d11
  .long  0xf3444d9b                          // vmul.f32      d20, d20, d11
  .long  0xf35961b8                          // vbsl          d22, d25, d24
  .long  0xf2419e81                          // vceq.f32      d25, d17, d1
  .long  0xf2011ea2                          // vceq.f32      d1, d17, d18
  .long  0xf2433da5                          // vadd.f32      d19, d19, d21
  .long  0xf2c15f10                          // vmov.f32      d21, #4
  .long  0xf2464da4                          // vadd.f32      d20, d22, d20
  .long  0xf2471da5                          // vadd.f32      d17, d23, d21
  .long  0xf35391b1                          // vbsl          d25, d19, d17
  .long  0xeddf1b0a                          // vldr          d17, [pc, #40]
  .long  0xf2612111                          // vorr          d18, d1, d1
  .long  0xf354a1b9                          // vbsl          d26, d20, d25
  .long  0xf35821ba                          // vbsl          d18, d24, d26
  .long  0xf3181198                          // vbsl          d1, d24, d8
  .long  0xf3020db1                          // vmul.f32      d0, d18, d17
  .long  0xf22021b0                          // vorr          d2, d16, d16
  .long  0xecbd8b08                          // vpop          {d8-d11}
  .long  0xe12fff13                          // bx            r3
  .long  0xe320f000                          // nop           {0}
  .long  0x40c00000                          // .word         0x40c00000
  .long  0x40c00000                          // .word         0x40c00000
  .long  0x3e2aaaab                          // .word         0x3e2aaaab
  .long  0x3e2aaaab                          // .word         0x3e2aaaab

HIDDEN _sk_hsl_to_rgb_vfp4
.globl _sk_hsl_to_rgb_vfp4
FUNCTION(_sk_hsl_to_rgb_vfp4)
_sk_hsl_to_rgb_vfp4:
  .long  0xf2c72f10                          // vmov.f32      d18, #1
  .long  0xeddf0b4f                          // vldr          d16, [pc, #316]
  .long  0xf2c3161f                          // vmov.i32      d17, #1056964608
  .long  0xeddf9b4f                          // vldr          d25, [pc, #316]
  .long  0xf2415d22                          // vadd.f32      d21, d1, d18
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3414d12                          // vmul.f32      d20, d1, d2
  .long  0xf2416d02                          // vadd.f32      d22, d1, d2
  .long  0xf2407d20                          // vadd.f32      d23, d0, d16
  .long  0xf3610e82                          // vcgt.f32      d16, d17, d2
  .long  0xf3455d92                          // vmul.f32      d21, d21, d2
  .long  0xf2664da4                          // vsub.f32      d20, d22, d20
  .long  0xf2426d02                          // vadd.f32      d22, d2, d2
  .long  0xf3c73f10                          // vmov.f32      d19, #-1
  .long  0xf35501b4                          // vbsl          d16, d21, d20
  .long  0xf2409d29                          // vadd.f32      d25, d0, d25
  .long  0xf2408d23                          // vadd.f32      d24, d0, d19
  .long  0xf3f9e629                          // vclt.f32      d30, d25, #0
  .long  0xf360ae22                          // vcgt.f32      d26, d0, d18
  .long  0xf247cda3                          // vadd.f32      d28, d23, d19
  .long  0xf367dea2                          // vcgt.f32      d29, d23, d18
  .long  0xf240bd22                          // vadd.f32      d27, d0, d18
  .long  0xf2666da0                          // vsub.f32      d22, d22, d16
  .long  0xf2474da2                          // vadd.f32      d20, d23, d18
  .long  0xf358a190                          // vbsl          d26, d24, d0
  .long  0xf3f98600                          // vclt.f32      d24, d0, #0
  .long  0xf3695ea2                          // vcgt.f32      d21, d25, d18
  .long  0xf2493da3                          // vadd.f32      d19, d25, d19
  .long  0xf35b81ba                          // vbsl          d24, d27, d26
  .long  0xf3f9a627                          // vclt.f32      d26, d23, #0
  .long  0xf35cd1b7                          // vbsl          d29, d28, d23
  .long  0xeddfcb35                          // vldr          d28, [pc, #212]
  .long  0xf2492da2                          // vadd.f32      d18, d25, d18
  .long  0xf260bda6                          // vsub.f32      d27, d16, d22
  .long  0xf354a1bd                          // vbsl          d26, d20, d29
  .long  0xf2c14f18                          // vmov.f32      d20, #6
  .long  0xf35351b9                          // vbsl          d21, d19, d25
  .long  0xf26cddaa                          // vsub.f32      d29, d28, d26
  .long  0xf352e1b5                          // vbsl          d30, d18, d21
  .long  0xf34b2db4                          // vmul.f32      d18, d27, d20
  .long  0xf26c3da8                          // vsub.f32      d19, d28, d24
  .long  0xf26c4dae                          // vsub.f32      d20, d28, d30
  .long  0xf36cbeaa                          // vcgt.f32      d27, d28, d26
  .long  0xf3425dbd                          // vmul.f32      d21, d18, d29
  .long  0xf3477db2                          // vmul.f32      d23, d23, d18
  .long  0xf3423db3                          // vmul.f32      d19, d18, d19
  .long  0xf3444db2                          // vmul.f32      d20, d20, d18
  .long  0xf2465da5                          // vadd.f32      d21, d22, d21
  .long  0xf342dd90                          // vmul.f32      d29, d18, d0
  .long  0xf3210eaa                          // vcgt.f32      d0, d17, d26
  .long  0xf3492db2                          // vmul.f32      d18, d25, d18
  .long  0xf355b1b6                          // vbsl          d27, d21, d22
  .long  0xeddf5b22                          // vldr          d21, [pc, #136]
  .long  0xf36cfea8                          // vcgt.f32      d31, d28, d24
  .long  0xf2463da3                          // vadd.f32      d19, d22, d19
  .long  0xf36cceae                          // vcgt.f32      d28, d28, d30
  .long  0xf2464da4                          // vadd.f32      d20, d22, d20
  .long  0xf365aeaa                          // vcgt.f32      d26, d21, d26
  .long  0xf2467da7                          // vadd.f32      d23, d22, d23
  .long  0xf3619ea8                          // vcgt.f32      d25, d17, d24
  .long  0xf3611eae                          // vcgt.f32      d17, d17, d30
  .long  0xf31001bb                          // vbsl          d0, d16, d27
  .long  0xf353f1b6                          // vbsl          d31, d19, d22
  .long  0xf354c1b6                          // vbsl          d28, d20, d22
  .long  0xf357a190                          // vbsl          d26, d23, d0
  .long  0xf3b90501                          // vceq.f32      d0, d1, #0
  .long  0xf3658ea8                          // vcgt.f32      d24, d21, d24
  .long  0xf246ddad                          // vadd.f32      d29, d22, d29
  .long  0xf3653eae                          // vcgt.f32      d19, d21, d30
  .long  0xf2462da2                          // vadd.f32      d18, d22, d18
  .long  0xf35091bf                          // vbsl          d25, d16, d31
  .long  0xf35011bc                          // vbsl          d17, d16, d28
  .long  0xf2600110                          // vorr          d16, d0, d0
  .long  0xf2201110                          // vorr          d1, d0, d0
  .long  0xf352013a                          // vbsl          d16, d2, d26
  .long  0xf35d81b9                          // vbsl          d24, d29, d25
  .long  0xf35231b1                          // vbsl          d19, d18, d17
  .long  0xf3121138                          // vbsl          d1, d2, d24
  .long  0xf3120133                          // vbsl          d0, d2, d19
  .long  0xf22021b0                          // vorr          d2, d16, d16
  .long  0xe12fff13                          // bx            r3
  .long  0xe320f000                          // nop           {0}
  .long  0xbeaaaaab                          // .word         0xbeaaaaab
  .long  0xbeaaaaab                          // .word         0xbeaaaaab
  .long  0x3eaaaaab                          // .word         0x3eaaaaab
  .long  0x3eaaaaab                          // .word         0x3eaaaaab
  .long  0x3f2aaaab                          // .word         0x3f2aaaab
  .long  0x3f2aaaab                          // .word         0x3f2aaaab
  .long  0x3e2aaaab                          // .word         0x3e2aaaab
  .long  0x3e2aaaab                          // .word         0x3e2aaaab

HIDDEN _sk_scale_1_float_vfp4
.globl _sk_scale_1_float_vfp4
FUNCTION(_sk_scale_1_float_vfp4)
_sk_scale_1_float_vfp4:
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf4e30c9f                          // vld1.32       {d16[]}, [r3 :32]
  .long  0xf3000d90                          // vmul.f32      d0, d16, d0
  .long  0xf3001d91                          // vmul.f32      d1, d16, d1
  .long  0xf3002d92                          // vmul.f32      d2, d16, d2
  .long  0xf3003d93                          // vmul.f32      d3, d16, d3
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_scale_u8_vfp4
.globl _sk_scale_u8_vfp4
FUNCTION(_sk_scale_u8_vfp4)
_sk_scale_u8_vfp4:
  .long  0xe24dd004                          // sub           sp, sp, #4
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xe0833000                          // add           r3, r3, r0
  .long  0xe1d330b0                          // ldrh          r3, [r3]
  .long  0xe1cd30b0                          // strh          r3, [sp]
  .long  0xe1a0300d                          // mov           r3, sp
  .long  0xf4e3041f                          // vld1.16       {d16[0]}, [r3 :16]
  .long  0xf3c80a30                          // vmovl.u8      q8, d16
  .long  0xf3d00a30                          // vmovl.u16     q8, d16
  .long  0xf3fb06a0                          // vcvt.f32.u32  d16, d16
  .long  0xeddf1b06                          // vldr          d17, [pc, #24]
  .long  0xf3400db1                          // vmul.f32      d16, d16, d17
  .long  0xf3000d90                          // vmul.f32      d0, d16, d0
  .long  0xf3001d91                          // vmul.f32      d1, d16, d1
  .long  0xf3002d92                          // vmul.f32      d2, d16, d2
  .long  0xf3003d93                          // vmul.f32      d3, d16, d3
  .long  0xe28dd004                          // add           sp, sp, #4
  .long  0xe12fff1c                          // bx            ip
  .long  0x3b808081                          // .word         0x3b808081
  .long  0x3b808081                          // .word         0x3b808081

HIDDEN _sk_lerp_1_float_vfp4
.globl _sk_lerp_1_float_vfp4
FUNCTION(_sk_lerp_1_float_vfp4)
_sk_lerp_1_float_vfp4:
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf2600d04                          // vsub.f32      d16, d0, d4
  .long  0xf2611d05                          // vsub.f32      d17, d1, d5
  .long  0xf2622d06                          // vsub.f32      d18, d2, d6
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf2633d07                          // vsub.f32      d19, d3, d7
  .long  0xf4e34c9f                          // vld1.32       {d20[]}, [r3 :32]
  .long  0xf2240114                          // vorr          d0, d4, d4
  .long  0xf2251115                          // vorr          d1, d5, d5
  .long  0xf2262116                          // vorr          d2, d6, d6
  .long  0xf2273117                          // vorr          d3, d7, d7
  .long  0xf2000cb4                          // vfma.f32      d0, d16, d20
  .long  0xf2011cb4                          // vfma.f32      d1, d17, d20
  .long  0xf2022cb4                          // vfma.f32      d2, d18, d20
  .long  0xf2033cb4                          // vfma.f32      d3, d19, d20
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_lerp_u8_vfp4
.globl _sk_lerp_u8_vfp4
FUNCTION(_sk_lerp_u8_vfp4)
_sk_lerp_u8_vfp4:
  .long  0xe24dd004                          // sub           sp, sp, #4
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf2602d04                          // vsub.f32      d18, d0, d4
  .long  0xf2623d06                          // vsub.f32      d19, d2, d6
  .long  0xf2634d07                          // vsub.f32      d20, d3, d7
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xf2240114                          // vorr          d0, d4, d4
  .long  0xf2262116                          // vorr          d2, d6, d6
  .long  0xe0833000                          // add           r3, r3, r0
  .long  0xf2273117                          // vorr          d3, d7, d7
  .long  0xe1d330b0                          // ldrh          r3, [r3]
  .long  0xe1cd30b0                          // strh          r3, [sp]
  .long  0xe1a0300d                          // mov           r3, sp
  .long  0xf4e3041f                          // vld1.16       {d16[0]}, [r3 :16]
  .long  0xf3c80a30                          // vmovl.u8      q8, d16
  .long  0xf3d00a30                          // vmovl.u16     q8, d16
  .long  0xf3fb06a0                          // vcvt.f32.u32  d16, d16
  .long  0xeddf1b08                          // vldr          d17, [pc, #32]
  .long  0xf3400db1                          // vmul.f32      d16, d16, d17
  .long  0xf2611d05                          // vsub.f32      d17, d1, d5
  .long  0xf2251115                          // vorr          d1, d5, d5
  .long  0xf2020cb0                          // vfma.f32      d0, d18, d16
  .long  0xf2011cb0                          // vfma.f32      d1, d17, d16
  .long  0xf2032cb0                          // vfma.f32      d2, d19, d16
  .long  0xf2043cb0                          // vfma.f32      d3, d20, d16
  .long  0xe28dd004                          // add           sp, sp, #4
  .long  0xe12fff1c                          // bx            ip
  .long  0x3b808081                          // .word         0x3b808081
  .long  0x3b808081                          // .word         0x3b808081

HIDDEN _sk_lerp_565_vfp4
.globl _sk_lerp_565_vfp4
FUNCTION(_sk_lerp_565_vfp4)
_sk_lerp_565_vfp4:
  .long  0xe24dd004                          // sub           sp, sp, #4
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf3c72218                          // vmov.i32      d18, #63488
  .long  0xf2c1101f                          // vmov.i32      d17, #31
  .long  0xf2603d04                          // vsub.f32      d19, d0, d4
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xf2616d05                          // vsub.f32      d22, d1, d5
  .long  0xf2240114                          // vorr          d0, d4, d4
  .long  0xf2251115                          // vorr          d1, d5, d5
  .long  0xe7933080                          // ldr           r3, [r3, r0, lsl #1]
  .long  0xf2873f10                          // vmov.f32      d3, #1
  .long  0xe58d3000                          // str           r3, [sp]
  .long  0xe1a0300d                          // mov           r3, sp
  .long  0xf4e3083f                          // vld1.32       {d16[0]}, [r3 :32]
  .long  0xe3a03e7e                          // mov           r3, #2016
  .long  0xf3d04a30                          // vmovl.u16     q10, d16
  .long  0xee803b90                          // vdup.32       d16, r3
  .long  0xf24421b2                          // vand          d18, d20, d18
  .long  0xf24411b1                          // vand          d17, d20, d17
  .long  0xeddf5b12                          // vldr          d21, [pc, #72]
  .long  0xf24401b0                          // vand          d16, d20, d16
  .long  0xeddf4b0e                          // vldr          d20, [pc, #56]
  .long  0xf3fb2622                          // vcvt.f32.s32  d18, d18
  .long  0xf3fb0620                          // vcvt.f32.s32  d16, d16
  .long  0xf3fb1621                          // vcvt.f32.s32  d17, d17
  .long  0xf3422db4                          // vmul.f32      d18, d18, d20
  .long  0xeddf4b0d                          // vldr          d20, [pc, #52]
  .long  0xf3400db5                          // vmul.f32      d16, d16, d21
  .long  0xf2625d06                          // vsub.f32      d21, d2, d6
  .long  0xf3411db4                          // vmul.f32      d17, d17, d20
  .long  0xf2262116                          // vorr          d2, d6, d6
  .long  0xf2030cb2                          // vfma.f32      d0, d19, d18
  .long  0xf2061cb0                          // vfma.f32      d1, d22, d16
  .long  0xf2052cb1                          // vfma.f32      d2, d21, d17
  .long  0xe28dd004                          // add           sp, sp, #4
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x37842108                          // .word         0x37842108
  .long  0x37842108                          // .word         0x37842108
  .long  0x3a020821                          // .word         0x3a020821
  .long  0x3a020821                          // .word         0x3a020821
  .long  0x3d042108                          // .word         0x3d042108
  .long  0x3d042108                          // .word         0x3d042108

HIDDEN _sk_load_tables_vfp4
.globl _sk_load_tables_vfp4
FUNCTION(_sk_load_tables_vfp4)
_sk_load_tables_vfp4:
  .long  0xe92d48f0                          // push          {r4, r5, r6, r7, fp, lr}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf3c7001f                          // vmov.i32      d16, #255
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe593e000                          // ldr           lr, [r3]
  .long  0xe99300b0                          // ldmib         r3, {r4, r5, r7}
  .long  0xe08e3100                          // add           r3, lr, r0, lsl #2
  .long  0xedd31b00                          // vldr          d17, [r3]
  .long  0xf24121b0                          // vand          d18, d17, d16
  .long  0xf3f83031                          // vshr.u32      d19, d17, #8
  .long  0xee323b90                          // vmov.32       r3, d18[1]
  .long  0xee126b90                          // vmov.32       r6, d18[0]
  .long  0xf3f02031                          // vshr.u32      d18, d17, #16
  .long  0xf24221b0                          // vand          d18, d18, d16
  .long  0xf24301b0                          // vand          d16, d19, d16
  .long  0xe0843103                          // add           r3, r4, r3, lsl #2
  .long  0xedd30a00                          // vldr          s1, [r3]
  .long  0xe0843106                          // add           r3, r4, r6, lsl #2
  .long  0xee326b90                          // vmov.32       r6, d18[1]
  .long  0xed930a00                          // vldr          s0, [r3]
  .long  0xee303b90                          // vmov.32       r3, d16[1]
  .long  0xee104b90                          // vmov.32       r4, d16[0]
  .long  0xf3e80031                          // vshr.u32      d16, d17, #24
  .long  0xeddf1b0d                          // vldr          d17, [pc, #52]
  .long  0xf3fb0620                          // vcvt.f32.s32  d16, d16
  .long  0xf3003db1                          // vmul.f32      d3, d16, d17
  .long  0xe087e106                          // add           lr, r7, r6, lsl #2
  .long  0xee126b90                          // vmov.32       r6, d18[0]
  .long  0xe0853103                          // add           r3, r5, r3, lsl #2
  .long  0xedde2a00                          // vldr          s5, [lr]
  .long  0xedd31a00                          // vldr          s3, [r3]
  .long  0xe0853104                          // add           r3, r5, r4, lsl #2
  .long  0xed931a00                          // vldr          s2, [r3]
  .long  0xe0873106                          // add           r3, r7, r6, lsl #2
  .long  0xed932a00                          // vldr          s4, [r3]
  .long  0xe8bd48f0                          // pop           {r4, r5, r6, r7, fp, lr}
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x3b808081                          // .word         0x3b808081
  .long  0x3b808081                          // .word         0x3b808081

HIDDEN _sk_load_tables_u16_be_vfp4
.globl _sk_load_tables_u16_be_vfp4
FUNCTION(_sk_load_tables_u16_be_vfp4)
_sk_load_tables_u16_be_vfp4:
  .long  0xe92d48f0                          // push          {r4, r5, r6, r7, fp, lr}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf3c7801f                          // vmov.i32      d24, #255
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe5936000                          // ldr           r6, [r3]
  .long  0xe9934030                          // ldmib         r3, {r4, r5, lr}
  .long  0xe0863180                          // add           r3, r6, r0, lsl #3
  .long  0xf4e3070d                          // vld4.16       {d16[0],d17[0],d18[0],d19[0]}, [r3]!
  .long  0xf4e3074f                          // vld4.16       {d16[1],d17[1],d18[1],d19[1]}, [r3]
  .long  0xee903bb0                          // vmov.u16      r3, d16[0]
  .long  0xee926bb0                          // vmov.u16      r6, d18[0]
  .long  0xee043b90                          // vmov.32       d20[0], r3
  .long  0xee913bb0                          // vmov.u16      r3, d17[0]
  .long  0xee056b90                          // vmov.32       d21[0], r6
  .long  0xee906bf0                          // vmov.u16      r6, d16[1]
  .long  0xee063b90                          // vmov.32       d22[0], r3
  .long  0xee933bb0                          // vmov.u16      r3, d19[0]
  .long  0xee246b90                          // vmov.32       d20[1], r6
  .long  0xee926bf0                          // vmov.u16      r6, d18[1]
  .long  0xf24441b8                          // vand          d20, d20, d24
  .long  0xee073b90                          // vmov.32       d23[0], r3
  .long  0xee913bf0                          // vmov.u16      r3, d17[1]
  .long  0xee256b90                          // vmov.32       d21[1], r6
  .long  0xee936bf0                          // vmov.u16      r6, d19[1]
  .long  0xf24501b8                          // vand          d16, d21, d24
  .long  0xee107b90                          // vmov.32       r7, d16[0]
  .long  0xee263b90                          // vmov.32       d22[1], r3
  .long  0xee343b90                          // vmov.32       r3, d20[1]
  .long  0xf24611b8                          // vand          d17, d22, d24
  .long  0xee276b90                          // vmov.32       d23[1], r6
  .long  0xee146b90                          // vmov.32       r6, d20[0]
  .long  0xf2e82537                          // vshl.s32      d18, d23, #8
  .long  0xe0843103                          // add           r3, r4, r3, lsl #2
  .long  0xedd30a00                          // vldr          s1, [r3]
  .long  0xe0843106                          // add           r3, r4, r6, lsl #2
  .long  0xee304b90                          // vmov.32       r4, d16[1]
  .long  0xee116b90                          // vmov.32       r6, d17[0]
  .long  0xf3c70c1f                          // vmov.i32      d16, #65535
  .long  0xed930a00                          // vldr          s0, [r3]
  .long  0xee313b90                          // vmov.32       r3, d17[1]
  .long  0xf24711b0                          // vand          d17, d23, d16
  .long  0xf3f81031                          // vshr.u32      d17, d17, #8
  .long  0xf26211b1                          // vorr          d17, d18, d17
  .long  0xf24101b0                          // vand          d16, d17, d16
  .long  0xeddf1b0c                          // vldr          d17, [pc, #48]
  .long  0xf3fb06a0                          // vcvt.f32.u32  d16, d16
  .long  0xf3003db1                          // vmul.f32      d3, d16, d17
  .long  0xe08e4104                          // add           r4, lr, r4, lsl #2
  .long  0xedd42a00                          // vldr          s5, [r4]
  .long  0xe0853103                          // add           r3, r5, r3, lsl #2
  .long  0xedd31a00                          // vldr          s3, [r3]
  .long  0xe0853106                          // add           r3, r5, r6, lsl #2
  .long  0xed931a00                          // vldr          s2, [r3]
  .long  0xe08e3107                          // add           r3, lr, r7, lsl #2
  .long  0xed932a00                          // vldr          s4, [r3]
  .long  0xe8bd48f0                          // pop           {r4, r5, r6, r7, fp, lr}
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x37800080                          // .word         0x37800080
  .long  0x37800080                          // .word         0x37800080

HIDDEN _sk_load_tables_rgb_u16_be_vfp4
.globl _sk_load_tables_rgb_u16_be_vfp4
FUNCTION(_sk_load_tables_rgb_u16_be_vfp4)
_sk_load_tables_rgb_u16_be_vfp4:
  .long  0xe92d48f0                          // push          {r4, r5, r6, r7, fp, lr}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf3c7601f                          // vmov.i32      d22, #255
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf2873f10                          // vmov.f32      d3, #1
  .long  0xe5936000                          // ldr           r6, [r3]
  .long  0xe9934030                          // ldmib         r3, {r4, r5, lr}
  .long  0xe0803080                          // add           r3, r0, r0, lsl #1
  .long  0xe0863083                          // add           r3, r6, r3, lsl #1
  .long  0xf4e3060d                          // vld3.16       {d16[0],d17[0],d18[0]}, [r3]!
  .long  0xf4e3064f                          // vld3.16       {d16[1],d17[1],d18[1]}, [r3]
  .long  0xee903bb0                          // vmov.u16      r3, d16[0]
  .long  0xee926bb0                          // vmov.u16      r6, d18[0]
  .long  0xee043b90                          // vmov.32       d20[0], r3
  .long  0xee903bf0                          // vmov.u16      r3, d16[1]
  .long  0xee056b90                          // vmov.32       d21[0], r6
  .long  0xee916bb0                          // vmov.u16      r6, d17[0]
  .long  0xee243b90                          // vmov.32       d20[1], r3
  .long  0xee923bf0                          // vmov.u16      r3, d18[1]
  .long  0xf24441b6                          // vand          d20, d20, d22
  .long  0xee076b90                          // vmov.32       d23[0], r6
  .long  0xee916bf0                          // vmov.u16      r6, d17[1]
  .long  0xee253b90                          // vmov.32       d21[1], r3
  .long  0xee343b90                          // vmov.32       r3, d20[1]
  .long  0xf24501b6                          // vand          d16, d21, d22
  .long  0xee276b90                          // vmov.32       d23[1], r6
  .long  0xee146b90                          // vmov.32       r6, d20[0]
  .long  0xf24711b6                          // vand          d17, d23, d22
  .long  0xee107b90                          // vmov.32       r7, d16[0]
  .long  0xe0843103                          // add           r3, r4, r3, lsl #2
  .long  0xedd30a00                          // vldr          s1, [r3]
  .long  0xe0843106                          // add           r3, r4, r6, lsl #2
  .long  0xee304b90                          // vmov.32       r4, d16[1]
  .long  0xee116b90                          // vmov.32       r6, d17[0]
  .long  0xed930a00                          // vldr          s0, [r3]
  .long  0xee313b90                          // vmov.32       r3, d17[1]
  .long  0xe08e4104                          // add           r4, lr, r4, lsl #2
  .long  0xedd42a00                          // vldr          s5, [r4]
  .long  0xe0853103                          // add           r3, r5, r3, lsl #2
  .long  0xedd31a00                          // vldr          s3, [r3]
  .long  0xe0853106                          // add           r3, r5, r6, lsl #2
  .long  0xed931a00                          // vldr          s2, [r3]
  .long  0xe08e3107                          // add           r3, lr, r7, lsl #2
  .long  0xed932a00                          // vldr          s4, [r3]
  .long  0xe8bd48f0                          // pop           {r4, r5, r6, r7, fp, lr}
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_byte_tables_vfp4
.globl _sk_byte_tables_vfp4
FUNCTION(_sk_byte_tables_vfp4)
_sk_byte_tables_vfp4:
  .long  0xe92d4bf0                          // push          {r4, r5, r6, r7, r8, r9, fp, lr}
  .long  0xeddf0b37                          // vldr          d16, [pc, #220]
  .long  0xf2c3261f                          // vmov.i32      d18, #1056964608
  .long  0xf2c3361f                          // vmov.i32      d19, #1056964608
  .long  0xe8911010                          // ldm           r1, {r4, ip}
  .long  0xf2422c30                          // vfma.f32      d18, d2, d16
  .long  0xf2413c30                          // vfma.f32      d19, d1, d16
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf2c3461f                          // vmov.i32      d20, #1056964608
  .long  0xe89402e0                          // ldm           r4, {r5, r6, r7, r9}
  .long  0xf2404c30                          // vfma.f32      d20, d0, d16
  .long  0xf2c3161f                          // vmov.i32      d17, #1056964608
  .long  0xf2431c30                          // vfma.f32      d17, d3, d16
  .long  0xf3fb27a2                          // vcvt.u32.f32  d18, d18
  .long  0xf3fb37a3                          // vcvt.u32.f32  d19, d19
  .long  0xf3fb47a4                          // vcvt.u32.f32  d20, d20
  .long  0xee123b90                          // vmov.32       r3, d18[0]
  .long  0xf3fb07a1                          // vcvt.u32.f32  d16, d17
  .long  0xee13eb90                          // vmov.32       lr, d19[0]
  .long  0xee144b90                          // vmov.32       r4, d20[0]
  .long  0xe7d78003                          // ldrb          r8, [r7, r3]
  .long  0xe7d6300e                          // ldrb          r3, [r6, lr]
  .long  0xee053b90                          // vmov.32       d21[0], r3
  .long  0xe7d53004                          // ldrb          r3, [r5, r4]
  .long  0xee344b90                          // vmov.32       r4, d20[1]
  .long  0xee013b90                          // vmov.32       d17[0], r3
  .long  0xee103b90                          // vmov.32       r3, d16[0]
  .long  0xee048b90                          // vmov.32       d20[0], r8
  .long  0xe7d5e004                          // ldrb          lr, [r5, r4]
  .long  0xee334b90                          // vmov.32       r4, d19[1]
  .long  0xee325b90                          // vmov.32       r5, d18[1]
  .long  0xf3c7201f                          // vmov.i32      d18, #255
  .long  0xe7d93003                          // ldrb          r3, [r9, r3]
  .long  0xee21eb90                          // vmov.32       d17[1], lr
  .long  0xf24111b2                          // vand          d17, d17, d18
  .long  0xf3fb16a1                          // vcvt.f32.u32  d17, d17
  .long  0xe7d64004                          // ldrb          r4, [r6, r4]
  .long  0xee306b90                          // vmov.32       r6, d16[1]
  .long  0xee003b90                          // vmov.32       d16[0], r3
  .long  0xee254b90                          // vmov.32       d21[1], r4
  .long  0xe7d74005                          // ldrb          r4, [r7, r5]
  .long  0xf24531b2                          // vand          d19, d21, d18
  .long  0xee244b90                          // vmov.32       d20[1], r4
  .long  0xf24441b2                          // vand          d20, d20, d18
  .long  0xf3fb46a4                          // vcvt.f32.u32  d20, d20
  .long  0xe7d93006                          // ldrb          r3, [r9, r6]
  .long  0xee203b90                          // vmov.32       d16[1], r3
  .long  0xf24001b2                          // vand          d16, d16, d18
  .long  0xf3fb26a3                          // vcvt.f32.u32  d18, d19
  .long  0xeddf3b09                          // vldr          d19, [pc, #36]
  .long  0xf3fb06a0                          // vcvt.f32.u32  d16, d16
  .long  0xf3010db3                          // vmul.f32      d0, d17, d19
  .long  0xf3042db3                          // vmul.f32      d2, d20, d19
  .long  0xf3021db3                          // vmul.f32      d1, d18, d19
  .long  0xf3003db3                          // vmul.f32      d3, d16, d19
  .long  0xe8bd4bf0                          // pop           {r4, r5, r6, r7, r8, r9, fp, lr}
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x437f0000                          // .word         0x437f0000
  .long  0x437f0000                          // .word         0x437f0000
  .long  0x3b808081                          // .word         0x3b808081
  .long  0x3b808081                          // .word         0x3b808081

HIDDEN _sk_byte_tables_rgb_vfp4
.globl _sk_byte_tables_rgb_vfp4
FUNCTION(_sk_byte_tables_rgb_vfp4)
_sk_byte_tables_rgb_vfp4:
  .long  0xe92d41f0                          // push          {r4, r5, r6, r7, r8, lr}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf2c3261f                          // vmov.i32      d18, #1056964608
  .long  0xf2c3161f                          // vmov.i32      d17, #1056964608
  .long  0xf3c7301f                          // vmov.i32      d19, #255
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe593e000                          // ldr           lr, [r3]
  .long  0xe9930110                          // ldmib         r3, {r4, r8}
  .long  0xe593300c                          // ldr           r3, [r3, #12]
  .long  0xe2433001                          // sub           r3, r3, #1
  .long  0xee803b90                          // vdup.32       d16, r3
  .long  0xf3fb0620                          // vcvt.f32.s32  d16, d16
  .long  0xf2402c30                          // vfma.f32      d18, d0, d16
  .long  0xf2411c30                          // vfma.f32      d17, d1, d16
  .long  0xf3fb27a2                          // vcvt.u32.f32  d18, d18
  .long  0xf3fb17a1                          // vcvt.u32.f32  d17, d17
  .long  0xee123b90                          // vmov.32       r3, d18[0]
  .long  0xee326b90                          // vmov.32       r6, d18[1]
  .long  0xf2c3261f                          // vmov.i32      d18, #1056964608
  .long  0xf2422c30                          // vfma.f32      d18, d2, d16
  .long  0xf3fb07a2                          // vcvt.u32.f32  d16, d18
  .long  0xee107b90                          // vmov.32       r7, d16[0]
  .long  0xee305b90                          // vmov.32       r5, d16[1]
  .long  0xe7de3003                          // ldrb          r3, [lr, r3]
  .long  0xe7dee006                          // ldrb          lr, [lr, r6]
  .long  0xee116b90                          // vmov.32       r6, d17[0]
  .long  0xee023b90                          // vmov.32       d18[0], r3
  .long  0xee313b90                          // vmov.32       r3, d17[1]
  .long  0xee22eb90                          // vmov.32       d18[1], lr
  .long  0xf24221b3                          // vand          d18, d18, d19
  .long  0xf3fb26a2                          // vcvt.f32.u32  d18, d18
  .long  0xe7d87007                          // ldrb          r7, [r8, r7]
  .long  0xee017b90                          // vmov.32       d17[0], r7
  .long  0xe7d46006                          // ldrb          r6, [r4, r6]
  .long  0xe7d43003                          // ldrb          r3, [r4, r3]
  .long  0xee006b90                          // vmov.32       d16[0], r6
  .long  0xe7d84005                          // ldrb          r4, [r8, r5]
  .long  0xee203b90                          // vmov.32       d16[1], r3
  .long  0xee214b90                          // vmov.32       d17[1], r4
  .long  0xf24001b3                          // vand          d16, d16, d19
  .long  0xf24111b3                          // vand          d17, d17, d19
  .long  0xeddf3b07                          // vldr          d19, [pc, #28]
  .long  0xf3fb06a0                          // vcvt.f32.u32  d16, d16
  .long  0xf3fb16a1                          // vcvt.f32.u32  d17, d17
  .long  0xf3020db3                          // vmul.f32      d0, d18, d19
  .long  0xf3001db3                          // vmul.f32      d1, d16, d19
  .long  0xf3012db3                          // vmul.f32      d2, d17, d19
  .long  0xe8bd41f0                          // pop           {r4, r5, r6, r7, r8, lr}
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x3b808081                          // .word         0x3b808081
  .long  0x3b808081                          // .word         0x3b808081

HIDDEN _sk_table_r_vfp4
.globl _sk_table_r_vfp4
FUNCTION(_sk_table_r_vfp4)
_sk_table_r_vfp4:
  .long  0xe92d4010                          // push          {r4, lr}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf2c3161f                          // vmov.i32      d17, #1056964608
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe593e000                          // ldr           lr, [r3]
  .long  0xe5933004                          // ldr           r3, [r3, #4]
  .long  0xe2433001                          // sub           r3, r3, #1
  .long  0xee803b90                          // vdup.32       d16, r3
  .long  0xf3fb0620                          // vcvt.f32.s32  d16, d16
  .long  0xf2401c30                          // vfma.f32      d17, d0, d16
  .long  0xf3fb07a1                          // vcvt.u32.f32  d16, d17
  .long  0xee303b90                          // vmov.32       r3, d16[1]
  .long  0xee104b90                          // vmov.32       r4, d16[0]
  .long  0xe08e3103                          // add           r3, lr, r3, lsl #2
  .long  0xedd30a00                          // vldr          s1, [r3]
  .long  0xe08e3104                          // add           r3, lr, r4, lsl #2
  .long  0xed930a00                          // vldr          s0, [r3]
  .long  0xe8bd4010                          // pop           {r4, lr}
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_table_g_vfp4
.globl _sk_table_g_vfp4
FUNCTION(_sk_table_g_vfp4)
_sk_table_g_vfp4:
  .long  0xe92d4010                          // push          {r4, lr}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf2c3161f                          // vmov.i32      d17, #1056964608
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe593e000                          // ldr           lr, [r3]
  .long  0xe5933004                          // ldr           r3, [r3, #4]
  .long  0xe2433001                          // sub           r3, r3, #1
  .long  0xee803b90                          // vdup.32       d16, r3
  .long  0xf3fb0620                          // vcvt.f32.s32  d16, d16
  .long  0xf2411c30                          // vfma.f32      d17, d1, d16
  .long  0xf3fb07a1                          // vcvt.u32.f32  d16, d17
  .long  0xee303b90                          // vmov.32       r3, d16[1]
  .long  0xee104b90                          // vmov.32       r4, d16[0]
  .long  0xe08e3103                          // add           r3, lr, r3, lsl #2
  .long  0xedd31a00                          // vldr          s3, [r3]
  .long  0xe08e3104                          // add           r3, lr, r4, lsl #2
  .long  0xed931a00                          // vldr          s2, [r3]
  .long  0xe8bd4010                          // pop           {r4, lr}
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_table_b_vfp4
.globl _sk_table_b_vfp4
FUNCTION(_sk_table_b_vfp4)
_sk_table_b_vfp4:
  .long  0xe92d4010                          // push          {r4, lr}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf2c3161f                          // vmov.i32      d17, #1056964608
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe593e000                          // ldr           lr, [r3]
  .long  0xe5933004                          // ldr           r3, [r3, #4]
  .long  0xe2433001                          // sub           r3, r3, #1
  .long  0xee803b90                          // vdup.32       d16, r3
  .long  0xf3fb0620                          // vcvt.f32.s32  d16, d16
  .long  0xf2421c30                          // vfma.f32      d17, d2, d16
  .long  0xf3fb07a1                          // vcvt.u32.f32  d16, d17
  .long  0xee303b90                          // vmov.32       r3, d16[1]
  .long  0xee104b90                          // vmov.32       r4, d16[0]
  .long  0xe08e3103                          // add           r3, lr, r3, lsl #2
  .long  0xedd32a00                          // vldr          s5, [r3]
  .long  0xe08e3104                          // add           r3, lr, r4, lsl #2
  .long  0xed932a00                          // vldr          s4, [r3]
  .long  0xe8bd4010                          // pop           {r4, lr}
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_table_a_vfp4
.globl _sk_table_a_vfp4
FUNCTION(_sk_table_a_vfp4)
_sk_table_a_vfp4:
  .long  0xe92d4010                          // push          {r4, lr}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf2c3161f                          // vmov.i32      d17, #1056964608
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe593e000                          // ldr           lr, [r3]
  .long  0xe5933004                          // ldr           r3, [r3, #4]
  .long  0xe2433001                          // sub           r3, r3, #1
  .long  0xee803b90                          // vdup.32       d16, r3
  .long  0xf3fb0620                          // vcvt.f32.s32  d16, d16
  .long  0xf2431c30                          // vfma.f32      d17, d3, d16
  .long  0xf3fb07a1                          // vcvt.u32.f32  d16, d17
  .long  0xee303b90                          // vmov.32       r3, d16[1]
  .long  0xee104b90                          // vmov.32       r4, d16[0]
  .long  0xe08e3103                          // add           r3, lr, r3, lsl #2
  .long  0xedd33a00                          // vldr          s7, [r3]
  .long  0xe08e3104                          // add           r3, lr, r4, lsl #2
  .long  0xed933a00                          // vldr          s6, [r3]
  .long  0xe8bd4010                          // pop           {r4, lr}
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_parametric_r_vfp4
.globl _sk_parametric_r_vfp4
FUNCTION(_sk_parametric_r_vfp4)
_sk_parametric_r_vfp4:
  .long  0xe92d4800                          // push          {fp, lr}
  .long  0xed2d8b06                          // vpush         {d8-d10}
  .long  0xe591e000                          // ldr           lr, [r1]
  .long  0xeddf3b41                          // vldr          d19, [pc, #260]
  .long  0xed9f8a4e                          // vldr          s16, [pc, #312]
  .long  0xe1a0300e                          // mov           r3, lr
  .long  0xeddf4b42                          // vldr          d20, [pc, #264]
  .long  0xf4e30c9d                          // vld1.32       {d16[]}, [r3 :32]!
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf4e31c9f                          // vld1.32       {d17[]}, [r3 :32]
  .long  0xe28e3008                          // add           r3, lr, #8
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xe28e300c                          // add           r3, lr, #12
  .long  0xf2412c90                          // vfma.f32      d18, d17, d0
  .long  0xf2c71d1f                          // vmov.i32      d17, #8388607
  .long  0xf24211b1                          // vand          d17, d18, d17
  .long  0xf2c3171f                          // vorr.i32      d17, #1056964608
  .long  0xf3fb2622                          // vcvt.f32.s32  d18, d18
  .long  0xf2019da3                          // vadd.f32      d9, d17, d19
  .long  0xf2c33614                          // vmov.i32      d19, #872415232
  .long  0xf3422db3                          // vmul.f32      d18, d18, d19
  .long  0xeddf3b30                          // vldr          d19, [pc, #192]
  .long  0xeec8aa29                          // vdiv.f32      s21, s16, s19
  .long  0xee88aa09                          // vdiv.f32      s20, s16, s18
  .long  0xf3411db3                          // vmul.f32      d17, d17, d19
  .long  0xed9f8a39                          // vldr          s16, [pc, #228]
  .long  0xf2422da4                          // vadd.f32      d18, d18, d20
  .long  0xeddf4b2e                          // vldr          d20, [pc, #184]
  .long  0xf2c03010                          // vmov.i32      d19, #0
  .long  0xf2621da1                          // vsub.f32      d17, d18, d17
  .long  0xf2611d8a                          // vsub.f32      d17, d17, d10
  .long  0xf3400db1                          // vmul.f32      d16, d16, d17
  .long  0xf3fb1720                          // vcvt.s32.f32  d17, d16
  .long  0xf3fb1621                          // vcvt.f32.s32  d17, d17
  .long  0xf3612ea0                          // vcgt.f32      d18, d17, d16
  .long  0xf35421b3                          // vbsl          d18, d20, d19
  .long  0xeddf4b2b                          // vldr          d20, [pc, #172]
  .long  0xf2611da2                          // vsub.f32      d17, d17, d18
  .long  0xeddf2b25                          // vldr          d18, [pc, #148]
  .long  0xf2601da1                          // vsub.f32      d17, d16, d17
  .long  0xf2400da4                          // vadd.f32      d16, d16, d20
  .long  0xf2229da1                          // vsub.f32      d9, d18, d17
  .long  0xeddf2b23                          // vldr          d18, [pc, #140]
  .long  0xf3411db2                          // vmul.f32      d17, d17, d18
  .long  0xf2c3261f                          // vmov.i32      d18, #1056964608
  .long  0xeec8aa29                          // vdiv.f32      s21, s16, s19
  .long  0xee88aa09                          // vdiv.f32      s20, s16, s18
  .long  0xf2600da1                          // vsub.f32      d16, d16, d17
  .long  0xf2c4161b                          // vmov.i32      d17, #1258291200
  .long  0xf2400d8a                          // vadd.f32      d16, d16, d10
  .long  0xf2402cb1                          // vfma.f32      d18, d16, d17
  .long  0xf4e30c9f                          // vld1.32       {d16[]}, [r3 :32]
  .long  0xe28e3018                          // add           r3, lr, #24
  .long  0xf4e31c9f                          // vld1.32       {d17[]}, [r3 :32]
  .long  0xe28e3010                          // add           r3, lr, #16
  .long  0xf2401c90                          // vfma.f32      d17, d16, d0
  .long  0xf4e30c9f                          // vld1.32       {d16[]}, [r3 :32]
  .long  0xe28e3014                          // add           r3, lr, #20
  .long  0xf3400e80                          // vcge.f32      d16, d16, d0
  .long  0xf4e34c9f                          // vld1.32       {d20[]}, [r3 :32]
  .long  0xf3fb27a2                          // vcvt.u32.f32  d18, d18
  .long  0xf2442da2                          // vadd.f32      d18, d20, d18
  .long  0xf35101b2                          // vbsl          d16, d17, d18
  .long  0xf2c71f10                          // vmov.f32      d17, #1
  .long  0xf2400fa3                          // vmax.f32      d16, d16, d19
  .long  0xf2200fa1                          // vmin.f32      d0, d16, d17
  .long  0xecbd8b06                          // vpop          {d8-d10}
  .long  0xe8bd4800                          // pop           {fp, lr}
  .long  0xe12fff1c                          // bx            ip
  .long  0x3eb444f9                          // .word         0x3eb444f9
  .long  0x3eb444f9                          // .word         0x3eb444f9
  .long  0x3fbfbf75                          // .word         0x3fbfbf75
  .long  0x3fbfbf75                          // .word         0x3fbfbf75
  .long  0xc2f87377                          // .word         0xc2f87377
  .long  0xc2f87377                          // .word         0xc2f87377
  .long  0x3f800000                          // .word         0x3f800000
  .long  0x3f800000                          // .word         0x3f800000
  .long  0x409af5f8                          // .word         0x409af5f8
  .long  0x409af5f8                          // .word         0x409af5f8
  .long  0x3fbebc8d                          // .word         0x3fbebc8d
  .long  0x3fbebc8d                          // .word         0x3fbebc8d
  .long  0x42f28c51                          // .word         0x42f28c51
  .long  0x42f28c51                          // .word         0x42f28c51
  .long  0x3fdce9a3                          // .word         0x3fdce9a3
  .long  0x41ddd2fe                          // .word         0x41ddd2fe

HIDDEN _sk_parametric_g_vfp4
.globl _sk_parametric_g_vfp4
FUNCTION(_sk_parametric_g_vfp4)
_sk_parametric_g_vfp4:
  .long  0xe92d4800                          // push          {fp, lr}
  .long  0xed2d8b06                          // vpush         {d8-d10}
  .long  0xe591e000                          // ldr           lr, [r1]
  .long  0xeddf3b41                          // vldr          d19, [pc, #260]
  .long  0xed9f8a4e                          // vldr          s16, [pc, #312]
  .long  0xe1a0300e                          // mov           r3, lr
  .long  0xeddf4b42                          // vldr          d20, [pc, #264]
  .long  0xf4e30c9d                          // vld1.32       {d16[]}, [r3 :32]!
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf4e31c9f                          // vld1.32       {d17[]}, [r3 :32]
  .long  0xe28e3008                          // add           r3, lr, #8
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xe28e300c                          // add           r3, lr, #12
  .long  0xf2412c91                          // vfma.f32      d18, d17, d1
  .long  0xf2c71d1f                          // vmov.i32      d17, #8388607
  .long  0xf24211b1                          // vand          d17, d18, d17
  .long  0xf2c3171f                          // vorr.i32      d17, #1056964608
  .long  0xf3fb2622                          // vcvt.f32.s32  d18, d18
  .long  0xf2019da3                          // vadd.f32      d9, d17, d19
  .long  0xf2c33614                          // vmov.i32      d19, #872415232
  .long  0xf3422db3                          // vmul.f32      d18, d18, d19
  .long  0xeddf3b30                          // vldr          d19, [pc, #192]
  .long  0xeec8aa29                          // vdiv.f32      s21, s16, s19
  .long  0xee88aa09                          // vdiv.f32      s20, s16, s18
  .long  0xf3411db3                          // vmul.f32      d17, d17, d19
  .long  0xed9f8a39                          // vldr          s16, [pc, #228]
  .long  0xf2422da4                          // vadd.f32      d18, d18, d20
  .long  0xeddf4b2e                          // vldr          d20, [pc, #184]
  .long  0xf2c03010                          // vmov.i32      d19, #0
  .long  0xf2621da1                          // vsub.f32      d17, d18, d17
  .long  0xf2611d8a                          // vsub.f32      d17, d17, d10
  .long  0xf3400db1                          // vmul.f32      d16, d16, d17
  .long  0xf3fb1720                          // vcvt.s32.f32  d17, d16
  .long  0xf3fb1621                          // vcvt.f32.s32  d17, d17
  .long  0xf3612ea0                          // vcgt.f32      d18, d17, d16
  .long  0xf35421b3                          // vbsl          d18, d20, d19
  .long  0xeddf4b2b                          // vldr          d20, [pc, #172]
  .long  0xf2611da2                          // vsub.f32      d17, d17, d18
  .long  0xeddf2b25                          // vldr          d18, [pc, #148]
  .long  0xf2601da1                          // vsub.f32      d17, d16, d17
  .long  0xf2400da4                          // vadd.f32      d16, d16, d20
  .long  0xf2229da1                          // vsub.f32      d9, d18, d17
  .long  0xeddf2b23                          // vldr          d18, [pc, #140]
  .long  0xf3411db2                          // vmul.f32      d17, d17, d18
  .long  0xf2c3261f                          // vmov.i32      d18, #1056964608
  .long  0xeec8aa29                          // vdiv.f32      s21, s16, s19
  .long  0xee88aa09                          // vdiv.f32      s20, s16, s18
  .long  0xf2600da1                          // vsub.f32      d16, d16, d17
  .long  0xf2c4161b                          // vmov.i32      d17, #1258291200
  .long  0xf2400d8a                          // vadd.f32      d16, d16, d10
  .long  0xf2402cb1                          // vfma.f32      d18, d16, d17
  .long  0xf4e30c9f                          // vld1.32       {d16[]}, [r3 :32]
  .long  0xe28e3018                          // add           r3, lr, #24
  .long  0xf4e31c9f                          // vld1.32       {d17[]}, [r3 :32]
  .long  0xe28e3010                          // add           r3, lr, #16
  .long  0xf2401c91                          // vfma.f32      d17, d16, d1
  .long  0xf4e30c9f                          // vld1.32       {d16[]}, [r3 :32]
  .long  0xe28e3014                          // add           r3, lr, #20
  .long  0xf3400e81                          // vcge.f32      d16, d16, d1
  .long  0xf4e34c9f                          // vld1.32       {d20[]}, [r3 :32]
  .long  0xf3fb27a2                          // vcvt.u32.f32  d18, d18
  .long  0xf2442da2                          // vadd.f32      d18, d20, d18
  .long  0xf35101b2                          // vbsl          d16, d17, d18
  .long  0xf2c71f10                          // vmov.f32      d17, #1
  .long  0xf2400fa3                          // vmax.f32      d16, d16, d19
  .long  0xf2201fa1                          // vmin.f32      d1, d16, d17
  .long  0xecbd8b06                          // vpop          {d8-d10}
  .long  0xe8bd4800                          // pop           {fp, lr}
  .long  0xe12fff1c                          // bx            ip
  .long  0x3eb444f9                          // .word         0x3eb444f9
  .long  0x3eb444f9                          // .word         0x3eb444f9
  .long  0x3fbfbf75                          // .word         0x3fbfbf75
  .long  0x3fbfbf75                          // .word         0x3fbfbf75
  .long  0xc2f87377                          // .word         0xc2f87377
  .long  0xc2f87377                          // .word         0xc2f87377
  .long  0x3f800000                          // .word         0x3f800000
  .long  0x3f800000                          // .word         0x3f800000
  .long  0x409af5f8                          // .word         0x409af5f8
  .long  0x409af5f8                          // .word         0x409af5f8
  .long  0x3fbebc8d                          // .word         0x3fbebc8d
  .long  0x3fbebc8d                          // .word         0x3fbebc8d
  .long  0x42f28c51                          // .word         0x42f28c51
  .long  0x42f28c51                          // .word         0x42f28c51
  .long  0x3fdce9a3                          // .word         0x3fdce9a3
  .long  0x41ddd2fe                          // .word         0x41ddd2fe

HIDDEN _sk_parametric_b_vfp4
.globl _sk_parametric_b_vfp4
FUNCTION(_sk_parametric_b_vfp4)
_sk_parametric_b_vfp4:
  .long  0xe92d4800                          // push          {fp, lr}
  .long  0xed2d8b06                          // vpush         {d8-d10}
  .long  0xe591e000                          // ldr           lr, [r1]
  .long  0xeddf3b41                          // vldr          d19, [pc, #260]
  .long  0xed9f8a4e                          // vldr          s16, [pc, #312]
  .long  0xe1a0300e                          // mov           r3, lr
  .long  0xeddf4b42                          // vldr          d20, [pc, #264]
  .long  0xf4e30c9d                          // vld1.32       {d16[]}, [r3 :32]!
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf4e31c9f                          // vld1.32       {d17[]}, [r3 :32]
  .long  0xe28e3008                          // add           r3, lr, #8
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xe28e300c                          // add           r3, lr, #12
  .long  0xf2412c92                          // vfma.f32      d18, d17, d2
  .long  0xf2c71d1f                          // vmov.i32      d17, #8388607
  .long  0xf24211b1                          // vand          d17, d18, d17
  .long  0xf2c3171f                          // vorr.i32      d17, #1056964608
  .long  0xf3fb2622                          // vcvt.f32.s32  d18, d18
  .long  0xf2019da3                          // vadd.f32      d9, d17, d19
  .long  0xf2c33614                          // vmov.i32      d19, #872415232
  .long  0xf3422db3                          // vmul.f32      d18, d18, d19
  .long  0xeddf3b30                          // vldr          d19, [pc, #192]
  .long  0xeec8aa29                          // vdiv.f32      s21, s16, s19
  .long  0xee88aa09                          // vdiv.f32      s20, s16, s18
  .long  0xf3411db3                          // vmul.f32      d17, d17, d19
  .long  0xed9f8a39                          // vldr          s16, [pc, #228]
  .long  0xf2422da4                          // vadd.f32      d18, d18, d20
  .long  0xeddf4b2e                          // vldr          d20, [pc, #184]
  .long  0xf2c03010                          // vmov.i32      d19, #0
  .long  0xf2621da1                          // vsub.f32      d17, d18, d17
  .long  0xf2611d8a                          // vsub.f32      d17, d17, d10
  .long  0xf3400db1                          // vmul.f32      d16, d16, d17
  .long  0xf3fb1720                          // vcvt.s32.f32  d17, d16
  .long  0xf3fb1621                          // vcvt.f32.s32  d17, d17
  .long  0xf3612ea0                          // vcgt.f32      d18, d17, d16
  .long  0xf35421b3                          // vbsl          d18, d20, d19
  .long  0xeddf4b2b                          // vldr          d20, [pc, #172]
  .long  0xf2611da2                          // vsub.f32      d17, d17, d18
  .long  0xeddf2b25                          // vldr          d18, [pc, #148]
  .long  0xf2601da1                          // vsub.f32      d17, d16, d17
  .long  0xf2400da4                          // vadd.f32      d16, d16, d20
  .long  0xf2229da1                          // vsub.f32      d9, d18, d17
  .long  0xeddf2b23                          // vldr          d18, [pc, #140]
  .long  0xf3411db2                          // vmul.f32      d17, d17, d18
  .long  0xf2c3261f                          // vmov.i32      d18, #1056964608
  .long  0xeec8aa29                          // vdiv.f32      s21, s16, s19
  .long  0xee88aa09                          // vdiv.f32      s20, s16, s18
  .long  0xf2600da1                          // vsub.f32      d16, d16, d17
  .long  0xf2c4161b                          // vmov.i32      d17, #1258291200
  .long  0xf2400d8a                          // vadd.f32      d16, d16, d10
  .long  0xf2402cb1                          // vfma.f32      d18, d16, d17
  .long  0xf4e30c9f                          // vld1.32       {d16[]}, [r3 :32]
  .long  0xe28e3018                          // add           r3, lr, #24
  .long  0xf4e31c9f                          // vld1.32       {d17[]}, [r3 :32]
  .long  0xe28e3010                          // add           r3, lr, #16
  .long  0xf2401c92                          // vfma.f32      d17, d16, d2
  .long  0xf4e30c9f                          // vld1.32       {d16[]}, [r3 :32]
  .long  0xe28e3014                          // add           r3, lr, #20
  .long  0xf3400e82                          // vcge.f32      d16, d16, d2
  .long  0xf4e34c9f                          // vld1.32       {d20[]}, [r3 :32]
  .long  0xf3fb27a2                          // vcvt.u32.f32  d18, d18
  .long  0xf2442da2                          // vadd.f32      d18, d20, d18
  .long  0xf35101b2                          // vbsl          d16, d17, d18
  .long  0xf2c71f10                          // vmov.f32      d17, #1
  .long  0xf2400fa3                          // vmax.f32      d16, d16, d19
  .long  0xf2202fa1                          // vmin.f32      d2, d16, d17
  .long  0xecbd8b06                          // vpop          {d8-d10}
  .long  0xe8bd4800                          // pop           {fp, lr}
  .long  0xe12fff1c                          // bx            ip
  .long  0x3eb444f9                          // .word         0x3eb444f9
  .long  0x3eb444f9                          // .word         0x3eb444f9
  .long  0x3fbfbf75                          // .word         0x3fbfbf75
  .long  0x3fbfbf75                          // .word         0x3fbfbf75
  .long  0xc2f87377                          // .word         0xc2f87377
  .long  0xc2f87377                          // .word         0xc2f87377
  .long  0x3f800000                          // .word         0x3f800000
  .long  0x3f800000                          // .word         0x3f800000
  .long  0x409af5f8                          // .word         0x409af5f8
  .long  0x409af5f8                          // .word         0x409af5f8
  .long  0x3fbebc8d                          // .word         0x3fbebc8d
  .long  0x3fbebc8d                          // .word         0x3fbebc8d
  .long  0x42f28c51                          // .word         0x42f28c51
  .long  0x42f28c51                          // .word         0x42f28c51
  .long  0x3fdce9a3                          // .word         0x3fdce9a3
  .long  0x41ddd2fe                          // .word         0x41ddd2fe

HIDDEN _sk_parametric_a_vfp4
.globl _sk_parametric_a_vfp4
FUNCTION(_sk_parametric_a_vfp4)
_sk_parametric_a_vfp4:
  .long  0xe92d4800                          // push          {fp, lr}
  .long  0xed2d8b06                          // vpush         {d8-d10}
  .long  0xe591e000                          // ldr           lr, [r1]
  .long  0xeddf3b41                          // vldr          d19, [pc, #260]
  .long  0xed9f8a4e                          // vldr          s16, [pc, #312]
  .long  0xe1a0300e                          // mov           r3, lr
  .long  0xeddf4b42                          // vldr          d20, [pc, #264]
  .long  0xf4e30c9d                          // vld1.32       {d16[]}, [r3 :32]!
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf4e31c9f                          // vld1.32       {d17[]}, [r3 :32]
  .long  0xe28e3008                          // add           r3, lr, #8
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xe28e300c                          // add           r3, lr, #12
  .long  0xf2412c93                          // vfma.f32      d18, d17, d3
  .long  0xf2c71d1f                          // vmov.i32      d17, #8388607
  .long  0xf24211b1                          // vand          d17, d18, d17
  .long  0xf2c3171f                          // vorr.i32      d17, #1056964608
  .long  0xf3fb2622                          // vcvt.f32.s32  d18, d18
  .long  0xf2019da3                          // vadd.f32      d9, d17, d19
  .long  0xf2c33614                          // vmov.i32      d19, #872415232
  .long  0xf3422db3                          // vmul.f32      d18, d18, d19
  .long  0xeddf3b30                          // vldr          d19, [pc, #192]
  .long  0xeec8aa29                          // vdiv.f32      s21, s16, s19
  .long  0xee88aa09                          // vdiv.f32      s20, s16, s18
  .long  0xf3411db3                          // vmul.f32      d17, d17, d19
  .long  0xed9f8a39                          // vldr          s16, [pc, #228]
  .long  0xf2422da4                          // vadd.f32      d18, d18, d20
  .long  0xeddf4b2e                          // vldr          d20, [pc, #184]
  .long  0xf2c03010                          // vmov.i32      d19, #0
  .long  0xf2621da1                          // vsub.f32      d17, d18, d17
  .long  0xf2611d8a                          // vsub.f32      d17, d17, d10
  .long  0xf3400db1                          // vmul.f32      d16, d16, d17
  .long  0xf3fb1720                          // vcvt.s32.f32  d17, d16
  .long  0xf3fb1621                          // vcvt.f32.s32  d17, d17
  .long  0xf3612ea0                          // vcgt.f32      d18, d17, d16
  .long  0xf35421b3                          // vbsl          d18, d20, d19
  .long  0xeddf4b2b                          // vldr          d20, [pc, #172]
  .long  0xf2611da2                          // vsub.f32      d17, d17, d18
  .long  0xeddf2b25                          // vldr          d18, [pc, #148]
  .long  0xf2601da1                          // vsub.f32      d17, d16, d17
  .long  0xf2400da4                          // vadd.f32      d16, d16, d20
  .long  0xf2229da1                          // vsub.f32      d9, d18, d17
  .long  0xeddf2b23                          // vldr          d18, [pc, #140]
  .long  0xf3411db2                          // vmul.f32      d17, d17, d18
  .long  0xf2c3261f                          // vmov.i32      d18, #1056964608
  .long  0xeec8aa29                          // vdiv.f32      s21, s16, s19
  .long  0xee88aa09                          // vdiv.f32      s20, s16, s18
  .long  0xf2600da1                          // vsub.f32      d16, d16, d17
  .long  0xf2c4161b                          // vmov.i32      d17, #1258291200
  .long  0xf2400d8a                          // vadd.f32      d16, d16, d10
  .long  0xf2402cb1                          // vfma.f32      d18, d16, d17
  .long  0xf4e30c9f                          // vld1.32       {d16[]}, [r3 :32]
  .long  0xe28e3018                          // add           r3, lr, #24
  .long  0xf4e31c9f                          // vld1.32       {d17[]}, [r3 :32]
  .long  0xe28e3010                          // add           r3, lr, #16
  .long  0xf2401c93                          // vfma.f32      d17, d16, d3
  .long  0xf4e30c9f                          // vld1.32       {d16[]}, [r3 :32]
  .long  0xe28e3014                          // add           r3, lr, #20
  .long  0xf3400e83                          // vcge.f32      d16, d16, d3
  .long  0xf4e34c9f                          // vld1.32       {d20[]}, [r3 :32]
  .long  0xf3fb27a2                          // vcvt.u32.f32  d18, d18
  .long  0xf2442da2                          // vadd.f32      d18, d20, d18
  .long  0xf35101b2                          // vbsl          d16, d17, d18
  .long  0xf2c71f10                          // vmov.f32      d17, #1
  .long  0xf2400fa3                          // vmax.f32      d16, d16, d19
  .long  0xf2203fa1                          // vmin.f32      d3, d16, d17
  .long  0xecbd8b06                          // vpop          {d8-d10}
  .long  0xe8bd4800                          // pop           {fp, lr}
  .long  0xe12fff1c                          // bx            ip
  .long  0x3eb444f9                          // .word         0x3eb444f9
  .long  0x3eb444f9                          // .word         0x3eb444f9
  .long  0x3fbfbf75                          // .word         0x3fbfbf75
  .long  0x3fbfbf75                          // .word         0x3fbfbf75
  .long  0xc2f87377                          // .word         0xc2f87377
  .long  0xc2f87377                          // .word         0xc2f87377
  .long  0x3f800000                          // .word         0x3f800000
  .long  0x3f800000                          // .word         0x3f800000
  .long  0x409af5f8                          // .word         0x409af5f8
  .long  0x409af5f8                          // .word         0x409af5f8
  .long  0x3fbebc8d                          // .word         0x3fbebc8d
  .long  0x3fbebc8d                          // .word         0x3fbebc8d
  .long  0x42f28c51                          // .word         0x42f28c51
  .long  0x42f28c51                          // .word         0x42f28c51
  .long  0x3fdce9a3                          // .word         0x3fdce9a3
  .long  0x41ddd2fe                          // .word         0x41ddd2fe

HIDDEN _sk_lab_to_xyz_vfp4
.globl _sk_lab_to_xyz_vfp4
FUNCTION(_sk_lab_to_xyz_vfp4)
_sk_lab_to_xyz_vfp4:
  .long  0xeddf1b2e                          // vldr          d17, [pc, #184]
  .long  0xf3c43613                          // vmov.i32      d19, #-1023410176
  .long  0xeddf0b2a                          // vldr          d16, [pc, #168]
  .long  0xf2c34f10                          // vmov.f32      d20, #16
  .long  0xf3401d31                          // vmul.f32      d17, d0, d17
  .long  0xeddf5b2f                          // vldr          d21, [pc, #188]
  .long  0xf3412d30                          // vmul.f32      d18, d1, d16
  .long  0xeddf6b2f                          // vldr          d22, [pc, #188]
  .long  0xf3420d30                          // vmul.f32      d16, d2, d16
  .long  0xeddf7b2f                          // vldr          d23, [pc, #188]
  .long  0xeddf8b30                          // vldr          d24, [pc, #192]
  .long  0xf2411da4                          // vadd.f32      d17, d17, d20
  .long  0xeddf4b24                          // vldr          d20, [pc, #144]
  .long  0xf2422da3                          // vadd.f32      d18, d18, d19
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf2400da3                          // vadd.f32      d16, d16, d19
  .long  0xeddf3b22                          // vldr          d19, [pc, #136]
  .long  0xf3411db3                          // vmul.f32      d17, d17, d19
  .long  0xf3422db4                          // vmul.f32      d18, d18, d20
  .long  0xf3400db5                          // vmul.f32      d16, d16, d21
  .long  0xf2412da2                          // vadd.f32      d18, d17, d18
  .long  0xf2610da0                          // vsub.f32      d16, d17, d16
  .long  0xf3415db1                          // vmul.f32      d21, d17, d17
  .long  0xf3423db2                          // vmul.f32      d19, d18, d18
  .long  0xf3404db0                          // vmul.f32      d20, d16, d16
  .long  0xf3415db5                          // vmul.f32      d21, d17, d21
  .long  0xf2411da6                          // vadd.f32      d17, d17, d22
  .long  0xf3423db3                          // vmul.f32      d19, d18, d19
  .long  0xf3404db4                          // vmul.f32      d20, d16, d20
  .long  0xf2400da6                          // vadd.f32      d16, d16, d22
  .long  0xf2422da6                          // vadd.f32      d18, d18, d22
  .long  0xeddf6b1d                          // vldr          d22, [pc, #116]
  .long  0xf3639ea7                          // vcgt.f32      d25, d19, d23
  .long  0xf364aea7                          // vcgt.f32      d26, d20, d23
  .long  0xf3400db8                          // vmul.f32      d16, d16, d24
  .long  0xf3422db8                          // vmul.f32      d18, d18, d24
  .long  0xf35391b2                          // vbsl          d25, d19, d18
  .long  0xeddf2b19                          // vldr          d18, [pc, #100]
  .long  0xf354a1b0                          // vbsl          d26, d20, d16
  .long  0xf3251ea7                          // vcgt.f32      d1, d21, d23
  .long  0xf3090db6                          // vmul.f32      d0, d25, d22
  .long  0xf30a2db2                          // vmul.f32      d2, d26, d18
  .long  0xf3410db8                          // vmul.f32      d16, d17, d24
  .long  0xf31511b0                          // vbsl          d1, d21, d16
  .long  0xe12fff13                          // bx            r3
  .long  0xe320f000                          // nop           {0}
  .long  0x437f0000                          // .word         0x437f0000
  .long  0x437f0000                          // .word         0x437f0000
  .long  0x42c80000                          // .word         0x42c80000
  .long  0x42c80000                          // .word         0x42c80000
  .long  0x3b03126f                          // .word         0x3b03126f
  .long  0x3b03126f                          // .word         0x3b03126f
  .long  0x3c0d3dcb                          // .word         0x3c0d3dcb
  .long  0x3c0d3dcb                          // .word         0x3c0d3dcb
  .long  0x3ba3d70a                          // .word         0x3ba3d70a
  .long  0x3ba3d70a                          // .word         0x3ba3d70a
  .long  0xbe0d3dcb                          // .word         0xbe0d3dcb
  .long  0xbe0d3dcb                          // .word         0xbe0d3dcb
  .long  0x3c1118c2                          // .word         0x3c1118c2
  .long  0x3c1118c2                          // .word         0x3c1118c2
  .long  0x3e038050                          // .word         0x3e038050
  .long  0x3e038050                          // .word         0x3e038050
  .long  0x3f76d71f                          // .word         0x3f76d71f
  .long  0x3f76d71f                          // .word         0x3f76d71f
  .long  0x3f5340f6                          // .word         0x3f5340f6
  .long  0x3f5340f6                          // .word         0x3f5340f6

HIDDEN _sk_load_a8_vfp4
.globl _sk_load_a8_vfp4
FUNCTION(_sk_load_a8_vfp4)
_sk_load_a8_vfp4:
  .long  0xe24dd004                          // sub           sp, sp, #4
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf2800010                          // vmov.i32      d0, #0
  .long  0xf2801010                          // vmov.i32      d1, #0
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xf2802010                          // vmov.i32      d2, #0
  .long  0xe0833000                          // add           r3, r3, r0
  .long  0xe1d330b0                          // ldrh          r3, [r3]
  .long  0xe1cd30b0                          // strh          r3, [sp]
  .long  0xe1a0300d                          // mov           r3, sp
  .long  0xf4e3041f                          // vld1.16       {d16[0]}, [r3 :16]
  .long  0xf3c80a30                          // vmovl.u8      q8, d16
  .long  0xf3d00a30                          // vmovl.u16     q8, d16
  .long  0xf3fb06a0                          // vcvt.f32.u32  d16, d16
  .long  0xeddf1b03                          // vldr          d17, [pc, #12]
  .long  0xf3003db1                          // vmul.f32      d3, d16, d17
  .long  0xe28dd004                          // add           sp, sp, #4
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x3b808081                          // .word         0x3b808081
  .long  0x3b808081                          // .word         0x3b808081

HIDDEN _sk_gather_a8_vfp4
.globl _sk_gather_a8_vfp4
FUNCTION(_sk_gather_a8_vfp4)
_sk_gather_a8_vfp4:
  .long  0xe92d4010                          // push          {r4, lr}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf3fb0701                          // vcvt.s32.f32  d16, d1
  .long  0xf3fb1700                          // vcvt.s32.f32  d17, d0
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf2800010                          // vmov.i32      d0, #0
  .long  0xe493e008                          // ldr           lr, [r3], #8
  .long  0xf2801010                          // vmov.i32      d1, #0
  .long  0xf2802010                          // vmov.i32      d2, #0
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xf26219a0                          // vmla.i32      d17, d18, d16
  .long  0xee113b90                          // vmov.32       r3, d17[0]
  .long  0xee314b90                          // vmov.32       r4, d17[1]
  .long  0xf3c7101f                          // vmov.i32      d17, #255
  .long  0xe7de3003                          // ldrb          r3, [lr, r3]
  .long  0xe7de4004                          // ldrb          r4, [lr, r4]
  .long  0xee003b90                          // vmov.32       d16[0], r3
  .long  0xee204b90                          // vmov.32       d16[1], r4
  .long  0xf24001b1                          // vand          d16, d16, d17
  .long  0xeddf1b03                          // vldr          d17, [pc, #12]
  .long  0xf3fb06a0                          // vcvt.f32.u32  d16, d16
  .long  0xf3003db1                          // vmul.f32      d3, d16, d17
  .long  0xe8bd4010                          // pop           {r4, lr}
  .long  0xe12fff1c                          // bx            ip
  .long  0x3b808081                          // .word         0x3b808081
  .long  0x3b808081                          // .word         0x3b808081

HIDDEN _sk_store_a8_vfp4
.globl _sk_store_a8_vfp4
FUNCTION(_sk_store_a8_vfp4)
_sk_store_a8_vfp4:
  .long  0xe92d4800                          // push          {fp, lr}
  .long  0xeddf0b0d                          // vldr          d16, [pc, #52]
  .long  0xf2c3161f                          // vmov.i32      d17, #1056964608
  .long  0xf2431c30                          // vfma.f32      d17, d3, d16
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xf3fb07a1                          // vcvt.u32.f32  d16, d17
  .long  0xee10eb90                          // vmov.32       lr, d16[0]
  .long  0xee30cb90                          // vmov.32       ip, d16[1]
  .long  0xe7e3e000                          // strb          lr, [r3, r0]!
  .long  0xe5c3c001                          // strb          ip, [r3, #1]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe8bd4800                          // pop           {fp, lr}
  .long  0xe12fff1c                          // bx            ip
  .long  0x437f0000                          // .word         0x437f0000
  .long  0x437f0000                          // .word         0x437f0000

HIDDEN _sk_load_g8_vfp4
.globl _sk_load_g8_vfp4
FUNCTION(_sk_load_g8_vfp4)
_sk_load_g8_vfp4:
  .long  0xe24dd004                          // sub           sp, sp, #4
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf2873f10                          // vmov.f32      d3, #1
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xe0833000                          // add           r3, r3, r0
  .long  0xe1d330b0                          // ldrh          r3, [r3]
  .long  0xe1cd30b0                          // strh          r3, [sp]
  .long  0xe1a0300d                          // mov           r3, sp
  .long  0xf4e3041f                          // vld1.16       {d16[0]}, [r3 :16]
  .long  0xf3c80a30                          // vmovl.u8      q8, d16
  .long  0xf3d00a30                          // vmovl.u16     q8, d16
  .long  0xf3fb06a0                          // vcvt.f32.u32  d16, d16
  .long  0xeddf1b05                          // vldr          d17, [pc, #20]
  .long  0xf3000db1                          // vmul.f32      d0, d16, d17
  .long  0xf2201110                          // vorr          d1, d0, d0
  .long  0xf2202110                          // vorr          d2, d0, d0
  .long  0xe28dd004                          // add           sp, sp, #4
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x3b808081                          // .word         0x3b808081
  .long  0x3b808081                          // .word         0x3b808081

HIDDEN _sk_gather_g8_vfp4
.globl _sk_gather_g8_vfp4
FUNCTION(_sk_gather_g8_vfp4)
_sk_gather_g8_vfp4:
  .long  0xe92d4010                          // push          {r4, lr}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf3fb0701                          // vcvt.s32.f32  d16, d1
  .long  0xf3fb1700                          // vcvt.s32.f32  d17, d0
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf2873f10                          // vmov.f32      d3, #1
  .long  0xe493e008                          // ldr           lr, [r3], #8
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xf26219a0                          // vmla.i32      d17, d18, d16
  .long  0xee113b90                          // vmov.32       r3, d17[0]
  .long  0xee314b90                          // vmov.32       r4, d17[1]
  .long  0xf3c7101f                          // vmov.i32      d17, #255
  .long  0xe7de3003                          // ldrb          r3, [lr, r3]
  .long  0xe7de4004                          // ldrb          r4, [lr, r4]
  .long  0xee003b90                          // vmov.32       d16[0], r3
  .long  0xee204b90                          // vmov.32       d16[1], r4
  .long  0xf24001b1                          // vand          d16, d16, d17
  .long  0xeddf1b05                          // vldr          d17, [pc, #20]
  .long  0xf3fb06a0                          // vcvt.f32.u32  d16, d16
  .long  0xf3000db1                          // vmul.f32      d0, d16, d17
  .long  0xf2201110                          // vorr          d1, d0, d0
  .long  0xf2202110                          // vorr          d2, d0, d0
  .long  0xe8bd4010                          // pop           {r4, lr}
  .long  0xe12fff1c                          // bx            ip
  .long  0x3b808081                          // .word         0x3b808081
  .long  0x3b808081                          // .word         0x3b808081

HIDDEN _sk_gather_i8_vfp4
.globl _sk_gather_i8_vfp4
FUNCTION(_sk_gather_i8_vfp4)
_sk_gather_i8_vfp4:
  .long  0xe92d4010                          // push          {r4, lr}
  .long  0xe1a0e001                          // mov           lr, r1
  .long  0xe491c004                          // ldr           ip, [r1], #4
  .long  0xf3fb0701                          // vcvt.s32.f32  d16, d1
  .long  0xe35c0000                          // cmp           ip, #0
  .long  0xf3fb1700                          // vcvt.s32.f32  d17, d0
  .long  0xe1a0300c                          // mov           r3, ip
  .long  0x028e1008                          // addeq         r1, lr, #8
  .long  0x059e3004                          // ldreq         r3, [lr, #4]
  .long  0xe493e008                          // ldr           lr, [r3], #8
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xf26219a0                          // vmla.i32      d17, d18, d16
  .long  0xee113b90                          // vmov.32       r3, d17[0]
  .long  0xee314b90                          // vmov.32       r4, d17[1]
  .long  0xf3c7101f                          // vmov.i32      d17, #255
  .long  0xe7de3003                          // ldrb          r3, [lr, r3]
  .long  0xe7de4004                          // ldrb          r4, [lr, r4]
  .long  0xee003b90                          // vmov.32       d16[0], r3
  .long  0xee204b90                          // vmov.32       d16[1], r4
  .long  0xe59c4004                          // ldr           r4, [ip, #4]
  .long  0xf24001b1                          // vand          d16, d16, d17
  .long  0xee103b90                          // vmov.32       r3, d16[0]
  .long  0xee30eb90                          // vmov.32       lr, d16[1]
  .long  0xe0843103                          // add           r3, r4, r3, lsl #2
  .long  0xf4e3083f                          // vld1.32       {d16[0]}, [r3 :32]
  .long  0xe084310e                          // add           r3, r4, lr, lsl #2
  .long  0xf4e308bf                          // vld1.32       {d16[1]}, [r3 :32]
  .long  0xf24021b1                          // vand          d18, d16, d17
  .long  0xf3f83030                          // vshr.u32      d19, d16, #8
  .long  0xf3e84030                          // vshr.u32      d20, d16, #24
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3f00030                          // vshr.u32      d16, d16, #16
  .long  0xf24331b1                          // vand          d19, d19, d17
  .long  0xf24001b1                          // vand          d16, d16, d17
  .long  0xeddf1b0a                          // vldr          d17, [pc, #40]
  .long  0xf3fb2622                          // vcvt.f32.s32  d18, d18
  .long  0xf3fb4624                          // vcvt.f32.s32  d20, d20
  .long  0xf3fb3623                          // vcvt.f32.s32  d19, d19
  .long  0xf3fb0620                          // vcvt.f32.s32  d16, d16
  .long  0xf3020db1                          // vmul.f32      d0, d18, d17
  .long  0xf3043db1                          // vmul.f32      d3, d20, d17
  .long  0xf3031db1                          // vmul.f32      d1, d19, d17
  .long  0xf3002db1                          // vmul.f32      d2, d16, d17
  .long  0xe8bd4010                          // pop           {r4, lr}
  .long  0xe12fff13                          // bx            r3
  .long  0xe320f000                          // nop           {0}
  .long  0x3b808081                          // .word         0x3b808081
  .long  0x3b808081                          // .word         0x3b808081

HIDDEN _sk_load_565_vfp4
.globl _sk_load_565_vfp4
FUNCTION(_sk_load_565_vfp4)
_sk_load_565_vfp4:
  .long  0xe24dd004                          // sub           sp, sp, #4
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf2c1101f                          // vmov.i32      d17, #31
  .long  0xf3c72218                          // vmov.i32      d18, #63488
  .long  0xeddf3b16                          // vldr          d19, [pc, #88]
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xf2873f10                          // vmov.f32      d3, #1
  .long  0xe7933080                          // ldr           r3, [r3, r0, lsl #1]
  .long  0xe58d3000                          // str           r3, [sp]
  .long  0xe1a0300d                          // mov           r3, sp
  .long  0xf4e3083f                          // vld1.32       {d16[0]}, [r3 :32]
  .long  0xe3a03e7e                          // mov           r3, #2016
  .long  0xf3d04a30                          // vmovl.u16     q10, d16
  .long  0xee803b90                          // vdup.32       d16, r3
  .long  0xf24411b1                          // vand          d17, d20, d17
  .long  0xeddf5b0e                          // vldr          d21, [pc, #56]
  .long  0xf24421b2                          // vand          d18, d20, d18
  .long  0xf24401b0                          // vand          d16, d20, d16
  .long  0xeddf4b09                          // vldr          d20, [pc, #36]
  .long  0xf3fb2622                          // vcvt.f32.s32  d18, d18
  .long  0xf3fb0620                          // vcvt.f32.s32  d16, d16
  .long  0xf3fb1621                          // vcvt.f32.s32  d17, d17
  .long  0xf3020db3                          // vmul.f32      d0, d18, d19
  .long  0xf3001db4                          // vmul.f32      d1, d16, d20
  .long  0xf3012db5                          // vmul.f32      d2, d17, d21
  .long  0xe28dd004                          // add           sp, sp, #4
  .long  0xe12fff1c                          // bx            ip
  .long  0x37842108                          // .word         0x37842108
  .long  0x37842108                          // .word         0x37842108
  .long  0x3a020821                          // .word         0x3a020821
  .long  0x3a020821                          // .word         0x3a020821
  .long  0x3d042108                          // .word         0x3d042108
  .long  0x3d042108                          // .word         0x3d042108

HIDDEN _sk_gather_565_vfp4
.globl _sk_gather_565_vfp4
FUNCTION(_sk_gather_565_vfp4)
_sk_gather_565_vfp4:
  .long  0xe92d4010                          // push          {r4, lr}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf3fb0701                          // vcvt.s32.f32  d16, d1
  .long  0xf3fb1700                          // vcvt.s32.f32  d17, d0
  .long  0xeddf4b20                          // vldr          d20, [pc, #128]
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe493e008                          // ldr           lr, [r3], #8
  .long  0xf2873f10                          // vmov.f32      d3, #1
  .long  0xeddf5b1e                          // vldr          d21, [pc, #120]
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xf26219a0                          // vmla.i32      d17, d18, d16
  .long  0xf2c1201f                          // vmov.i32      d18, #31
  .long  0xee113b90                          // vmov.32       r3, d17[0]
  .long  0xee314b90                          // vmov.32       r4, d17[1]
  .long  0xf3c71218                          // vmov.i32      d17, #63488
  .long  0xe08e3083                          // add           r3, lr, r3, lsl #1
  .long  0xe08e4084                          // add           r4, lr, r4, lsl #1
  .long  0xe1d330b0                          // ldrh          r3, [r3]
  .long  0xe1d440b0                          // ldrh          r4, [r4]
  .long  0xee003b90                          // vmov.32       d16[0], r3
  .long  0xe3a03e7e                          // mov           r3, #2016
  .long  0xee833b90                          // vdup.32       d19, r3
  .long  0xee204b90                          // vmov.32       d16[1], r4
  .long  0xf24011b1                          // vand          d17, d16, d17
  .long  0xf24031b3                          // vand          d19, d16, d19
  .long  0xf24001b2                          // vand          d16, d16, d18
  .long  0xf3fb2623                          // vcvt.f32.s32  d18, d19
  .long  0xeddf3b07                          // vldr          d19, [pc, #28]
  .long  0xf3fb1621                          // vcvt.f32.s32  d17, d17
  .long  0xf3fb0620                          // vcvt.f32.s32  d16, d16
  .long  0xf3021db4                          // vmul.f32      d1, d18, d20
  .long  0xf3010db3                          // vmul.f32      d0, d17, d19
  .long  0xf3002db5                          // vmul.f32      d2, d16, d21
  .long  0xe8bd4010                          // pop           {r4, lr}
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x37842108                          // .word         0x37842108
  .long  0x37842108                          // .word         0x37842108
  .long  0x3a020821                          // .word         0x3a020821
  .long  0x3a020821                          // .word         0x3a020821
  .long  0x3d042108                          // .word         0x3d042108
  .long  0x3d042108                          // .word         0x3d042108

HIDDEN _sk_store_565_vfp4
.globl _sk_store_565_vfp4
FUNCTION(_sk_store_565_vfp4)
_sk_store_565_vfp4:
  .long  0xf2c30f1f                          // vmov.f32      d16, #31
  .long  0xeddf1b15                          // vldr          d17, [pc, #84]
  .long  0xf2c3361f                          // vmov.i32      d19, #1056964608
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2413c31                          // vfma.f32      d19, d1, d17
  .long  0xf2c3161f                          // vmov.i32      d17, #1056964608
  .long  0xf2401c30                          // vfma.f32      d17, d0, d16
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xf2c3261f                          // vmov.i32      d18, #1056964608
  .long  0xf2422c30                          // vfma.f32      d18, d2, d16
  .long  0xe0833080                          // add           r3, r3, r0, lsl #1
  .long  0xf3fb07a3                          // vcvt.u32.f32  d16, d19
  .long  0xf3fb17a1                          // vcvt.u32.f32  d17, d17
  .long  0xf3fb27a2                          // vcvt.u32.f32  d18, d18
  .long  0xf2e50530                          // vshl.s32      d16, d16, #5
  .long  0xf2eb1531                          // vshl.s32      d17, d17, #11
  .long  0xf26001b1                          // vorr          d16, d16, d17
  .long  0xf26001b2                          // vorr          d16, d16, d18
  .long  0xf3f60121                          // vuzp.16       d16, d17
  .long  0xf4c3080f                          // vst1.32       {d16[0]}, [r3]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip
  .long  0x427c0000                          // .word         0x427c0000
  .long  0x427c0000                          // .word         0x427c0000

HIDDEN _sk_load_4444_vfp4
.globl _sk_load_4444_vfp4
FUNCTION(_sk_load_4444_vfp4)
_sk_load_4444_vfp4:
  .long  0xe24dd004                          // sub           sp, sp, #4
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf3c71210                          // vmov.i32      d17, #61440
  .long  0xf3c74010                          // vmov.i32      d20, #240
  .long  0xf2c0501f                          // vmov.i32      d21, #15
  .long  0xeddf6b1d                          // vldr          d22, [pc, #116]
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe7933080                          // ldr           r3, [r3, r0, lsl #1]
  .long  0xe58d3000                          // str           r3, [sp]
  .long  0xe1a0300d                          // mov           r3, sp
  .long  0xf4e3083f                          // vld1.32       {d16[0]}, [r3 :32]
  .long  0xf3d02a30                          // vmovl.u16     q9, d16
  .long  0xf2c0021f                          // vmov.i32      d16, #3840
  .long  0xf24211b1                          // vand          d17, d18, d17
  .long  0xf24201b0                          // vand          d16, d18, d16
  .long  0xf24241b4                          // vand          d20, d18, d20
  .long  0xf24221b5                          // vand          d18, d18, d21
  .long  0xeddf3b0c                          // vldr          d19, [pc, #48]
  .long  0xf3fb1621                          // vcvt.f32.s32  d17, d17
  .long  0xeddf5b0c                          // vldr          d21, [pc, #48]
  .long  0xf3fb0620                          // vcvt.f32.s32  d16, d16
  .long  0xf3fb4624                          // vcvt.f32.s32  d20, d20
  .long  0xf3fb2622                          // vcvt.f32.s32  d18, d18
  .long  0xf3010db3                          // vmul.f32      d0, d17, d19
  .long  0xeddf1b0b                          // vldr          d17, [pc, #44]
  .long  0xf3001db5                          // vmul.f32      d1, d16, d21
  .long  0xf3042db6                          // vmul.f32      d2, d20, d22
  .long  0xf3023db1                          // vmul.f32      d3, d18, d17
  .long  0xe28dd004                          // add           sp, sp, #4
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x37888889                          // .word         0x37888889
  .long  0x37888889                          // .word         0x37888889
  .long  0x39888889                          // .word         0x39888889
  .long  0x39888889                          // .word         0x39888889
  .long  0x3b888889                          // .word         0x3b888889
  .long  0x3b888889                          // .word         0x3b888889
  .long  0x3d888889                          // .word         0x3d888889
  .long  0x3d888889                          // .word         0x3d888889

HIDDEN _sk_gather_4444_vfp4
.globl _sk_gather_4444_vfp4
FUNCTION(_sk_gather_4444_vfp4)
_sk_gather_4444_vfp4:
  .long  0xe92d4010                          // push          {r4, lr}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf3fb0701                          // vcvt.s32.f32  d16, d1
  .long  0xf3fb1700                          // vcvt.s32.f32  d17, d0
  .long  0xf3c73010                          // vmov.i32      d19, #240
  .long  0xeddf5b21                          // vldr          d21, [pc, #132]
  .long  0xe493e008                          // ldr           lr, [r3], #8
  .long  0xf2c0401f                          // vmov.i32      d20, #15
  .long  0xeddf6b20                          // vldr          d22, [pc, #128]
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xf26219a0                          // vmla.i32      d17, d18, d16
  .long  0xf2c0221f                          // vmov.i32      d18, #3840
  .long  0xee113b90                          // vmov.32       r3, d17[0]
  .long  0xee314b90                          // vmov.32       r4, d17[1]
  .long  0xf3c71210                          // vmov.i32      d17, #61440
  .long  0xe08e3083                          // add           r3, lr, r3, lsl #1
  .long  0xe08e4084                          // add           r4, lr, r4, lsl #1
  .long  0xe1d330b0                          // ldrh          r3, [r3]
  .long  0xe1d440b0                          // ldrh          r4, [r4]
  .long  0xee003b90                          // vmov.32       d16[0], r3
  .long  0xee204b90                          // vmov.32       d16[1], r4
  .long  0xf24011b1                          // vand          d17, d16, d17
  .long  0xf24021b2                          // vand          d18, d16, d18
  .long  0xf24031b3                          // vand          d19, d16, d19
  .long  0xf24001b4                          // vand          d16, d16, d20
  .long  0xeddf4b0a                          // vldr          d20, [pc, #40]
  .long  0xf3fb1621                          // vcvt.f32.s32  d17, d17
  .long  0xf3fb2622                          // vcvt.f32.s32  d18, d18
  .long  0xf3fb3623                          // vcvt.f32.s32  d19, d19
  .long  0xf3fb0620                          // vcvt.f32.s32  d16, d16
  .long  0xf3010db4                          // vmul.f32      d0, d17, d20
  .long  0xeddf1b0a                          // vldr          d17, [pc, #40]
  .long  0xf3021db5                          // vmul.f32      d1, d18, d21
  .long  0xf3032db6                          // vmul.f32      d2, d19, d22
  .long  0xf3003db1                          // vmul.f32      d3, d16, d17
  .long  0xe8bd4010                          // pop           {r4, lr}
  .long  0xe12fff1c                          // bx            ip
  .long  0x37888889                          // .word         0x37888889
  .long  0x37888889                          // .word         0x37888889
  .long  0x39888889                          // .word         0x39888889
  .long  0x39888889                          // .word         0x39888889
  .long  0x3b888889                          // .word         0x3b888889
  .long  0x3b888889                          // .word         0x3b888889
  .long  0x3d888889                          // .word         0x3d888889
  .long  0x3d888889                          // .word         0x3d888889

HIDDEN _sk_store_4444_vfp4
.globl _sk_store_4444_vfp4
FUNCTION(_sk_store_4444_vfp4)
_sk_store_4444_vfp4:
  .long  0xf2c20f1e                          // vmov.f32      d16, #15
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2c3261f                          // vmov.i32      d18, #1056964608
  .long  0xf2c3361f                          // vmov.i32      d19, #1056964608
  .long  0xf2402c30                          // vfma.f32      d18, d0, d16
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xf2413c30                          // vfma.f32      d19, d1, d16
  .long  0xf2c3461f                          // vmov.i32      d20, #1056964608
  .long  0xe0833080                          // add           r3, r3, r0, lsl #1
  .long  0xf2424c30                          // vfma.f32      d20, d2, d16
  .long  0xf2c3161f                          // vmov.i32      d17, #1056964608
  .long  0xf2431c30                          // vfma.f32      d17, d3, d16
  .long  0xf3fb07a2                          // vcvt.u32.f32  d16, d18
  .long  0xf3fb27a3                          // vcvt.u32.f32  d18, d19
  .long  0xf3fb37a4                          // vcvt.u32.f32  d19, d20
  .long  0xf2ec0530                          // vshl.s32      d16, d16, #12
  .long  0xf2e82532                          // vshl.s32      d18, d18, #8
  .long  0xf3fb17a1                          // vcvt.u32.f32  d17, d17
  .long  0xf2e43533                          // vshl.s32      d19, d19, #4
  .long  0xf26201b0                          // vorr          d16, d18, d16
  .long  0xf26001b3                          // vorr          d16, d16, d19
  .long  0xf26001b1                          // vorr          d16, d16, d17
  .long  0xf3f60121                          // vuzp.16       d16, d17
  .long  0xf4c3080f                          // vst1.32       {d16[0]}, [r3]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_load_8888_vfp4
.globl _sk_load_8888_vfp4
FUNCTION(_sk_load_8888_vfp4)
_sk_load_8888_vfp4:
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf3c7001f                          // vmov.i32      d16, #255
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xe0833100                          // add           r3, r3, r0, lsl #2
  .long  0xedd31b00                          // vldr          d17, [r3]
  .long  0xf24121b0                          // vand          d18, d17, d16
  .long  0xf3f83031                          // vshr.u32      d19, d17, #8
  .long  0xf3e84031                          // vshr.u32      d20, d17, #24
  .long  0xf3f01031                          // vshr.u32      d17, d17, #16
  .long  0xf24331b0                          // vand          d19, d19, d16
  .long  0xf24101b0                          // vand          d16, d17, d16
  .long  0xeddf1b08                          // vldr          d17, [pc, #32]
  .long  0xf3fb2622                          // vcvt.f32.s32  d18, d18
  .long  0xf3fb4624                          // vcvt.f32.s32  d20, d20
  .long  0xf3fb3623                          // vcvt.f32.s32  d19, d19
  .long  0xf3fb0620                          // vcvt.f32.s32  d16, d16
  .long  0xf3020db1                          // vmul.f32      d0, d18, d17
  .long  0xf3043db1                          // vmul.f32      d3, d20, d17
  .long  0xf3031db1                          // vmul.f32      d1, d19, d17
  .long  0xf3002db1                          // vmul.f32      d2, d16, d17
  .long  0xe12fff1c                          // bx            ip
  .long  0x3b808081                          // .word         0x3b808081
  .long  0x3b808081                          // .word         0x3b808081

HIDDEN _sk_gather_8888_vfp4
.globl _sk_gather_8888_vfp4
FUNCTION(_sk_gather_8888_vfp4)
_sk_gather_8888_vfp4:
  .long  0xe92d4010                          // push          {r4, lr}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf3fb0701                          // vcvt.s32.f32  d16, d1
  .long  0xf3fb1700                          // vcvt.s32.f32  d17, d0
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe493e008                          // ldr           lr, [r3], #8
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xf26219a0                          // vmla.i32      d17, d18, d16
  .long  0xee113b90                          // vmov.32       r3, d17[0]
  .long  0xee314b90                          // vmov.32       r4, d17[1]
  .long  0xf3c7101f                          // vmov.i32      d17, #255
  .long  0xe08e3103                          // add           r3, lr, r3, lsl #2
  .long  0xf4e3083f                          // vld1.32       {d16[0]}, [r3 :32]
  .long  0xe08e3104                          // add           r3, lr, r4, lsl #2
  .long  0xf4e308bf                          // vld1.32       {d16[1]}, [r3 :32]
  .long  0xf24021b1                          // vand          d18, d16, d17
  .long  0xf3f83030                          // vshr.u32      d19, d16, #8
  .long  0xf3e84030                          // vshr.u32      d20, d16, #24
  .long  0xf3f00030                          // vshr.u32      d16, d16, #16
  .long  0xf24331b1                          // vand          d19, d19, d17
  .long  0xf24001b1                          // vand          d16, d16, d17
  .long  0xeddf1b09                          // vldr          d17, [pc, #36]
  .long  0xf3fb2622                          // vcvt.f32.s32  d18, d18
  .long  0xf3fb4624                          // vcvt.f32.s32  d20, d20
  .long  0xf3fb3623                          // vcvt.f32.s32  d19, d19
  .long  0xf3fb0620                          // vcvt.f32.s32  d16, d16
  .long  0xf3020db1                          // vmul.f32      d0, d18, d17
  .long  0xf3043db1                          // vmul.f32      d3, d20, d17
  .long  0xf3031db1                          // vmul.f32      d1, d19, d17
  .long  0xf3002db1                          // vmul.f32      d2, d16, d17
  .long  0xe8bd4010                          // pop           {r4, lr}
  .long  0xe12fff1c                          // bx            ip
  .long  0x3b808081                          // .word         0x3b808081
  .long  0x3b808081                          // .word         0x3b808081

HIDDEN _sk_store_8888_vfp4
.globl _sk_store_8888_vfp4
FUNCTION(_sk_store_8888_vfp4)
_sk_store_8888_vfp4:
  .long  0xeddf0b1a                          // vldr          d16, [pc, #104]
  .long  0xf2c3261f                          // vmov.i32      d18, #1056964608
  .long  0xf2412c30                          // vfma.f32      d18, d1, d16
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2c3361f                          // vmov.i32      d19, #1056964608
  .long  0xf2c3161f                          // vmov.i32      d17, #1056964608
  .long  0xf2423c30                          // vfma.f32      d19, d2, d16
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xf2c3461f                          // vmov.i32      d20, #1056964608
  .long  0xf2401c30                          // vfma.f32      d17, d0, d16
  .long  0xe0833100                          // add           r3, r3, r0, lsl #2
  .long  0xf2434c30                          // vfma.f32      d20, d3, d16
  .long  0xf3fb07a2                          // vcvt.u32.f32  d16, d18
  .long  0xf3fb27a3                          // vcvt.u32.f32  d18, d19
  .long  0xf3fb17a1                          // vcvt.u32.f32  d17, d17
  .long  0xf3fb37a4                          // vcvt.u32.f32  d19, d20
  .long  0xf2e80530                          // vshl.s32      d16, d16, #8
  .long  0xf2f02532                          // vshl.s32      d18, d18, #16
  .long  0xf26001b1                          // vorr          d16, d16, d17
  .long  0xf2f81533                          // vshl.s32      d17, d19, #24
  .long  0xf26001b2                          // vorr          d16, d16, d18
  .long  0xf26001b1                          // vorr          d16, d16, d17
  .long  0xedc30b00                          // vstr          d16, [r3]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x437f0000                          // .word         0x437f0000
  .long  0x437f0000                          // .word         0x437f0000

HIDDEN _sk_load_f16_vfp4
.globl _sk_load_f16_vfp4
FUNCTION(_sk_load_f16_vfp4)
_sk_load_f16_vfp4:
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xe0833180                          // add           r3, r3, r0, lsl #3
  .long  0xf4e3070d                          // vld4.16       {d16[0],d17[0],d18[0],d19[0]}, [r3]!
  .long  0xf4e3074f                          // vld4.16       {d16[1],d17[1],d18[1],d19[1]}, [r3]
  .long  0xf3b60720                          // vcvt.f32.f16  q0, d16
  .long  0xf3b62722                          // vcvt.f32.f16  q1, d18
  .long  0xf3f64721                          // vcvt.f32.f16  q10, d17
  .long  0xf3f60723                          // vcvt.f32.f16  q8, d19
  .long  0xf22411b4                          // vorr          d1, d20, d20
  .long  0xf22031b0                          // vorr          d3, d16, d16
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_gather_f16_vfp4
.globl _sk_gather_f16_vfp4
FUNCTION(_sk_gather_f16_vfp4)
_sk_gather_f16_vfp4:
  .long  0xe92d4c10                          // push          {r4, sl, fp, lr}
  .long  0xe28db008                          // add           fp, sp, #8
  .long  0xe24dd010                          // sub           sp, sp, #16
  .long  0xe7c3d01f                          // bfc           sp, #0, #4
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf3fb0701                          // vcvt.s32.f32  d16, d1
  .long  0xf3fb1700                          // vcvt.s32.f32  d17, d0
  .long  0xe493c008                          // ldr           ip, [r3], #8
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xf26219a0                          // vmla.i32      d17, d18, d16
  .long  0xee113b90                          // vmov.32       r3, d17[0]
  .long  0xee31eb90                          // vmov.32       lr, d17[1]
  .long  0xe08c4183                          // add           r4, ip, r3, lsl #3
  .long  0xe08c318e                          // add           r3, ip, lr, lsl #3
  .long  0xedd31b00                          // vldr          d17, [r3]
  .long  0xe1a0300d                          // mov           r3, sp
  .long  0xedd40b00                          // vldr          d16, [r4]
  .long  0xf4430aef                          // vst1.64       {d16-d17}, [r3 :128]
  .long  0xf4e3071f                          // vld4.16       {d16[0],d17[0],d18[0],d19[0]}, [r3 :64]
  .long  0xe3833008                          // orr           r3, r3, #8
  .long  0xf4e3075f                          // vld4.16       {d16[1],d17[1],d18[1],d19[1]}, [r3 :64]
  .long  0xf3b60720                          // vcvt.f32.f16  q0, d16
  .long  0xf3b62722                          // vcvt.f32.f16  q1, d18
  .long  0xe5913004                          // ldr           r3, [r1, #4]
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf3f64721                          // vcvt.f32.f16  q10, d17
  .long  0xf3f60723                          // vcvt.f32.f16  q8, d19
  .long  0xf22411b4                          // vorr          d1, d20, d20
  .long  0xf22031b0                          // vorr          d3, d16, d16
  .long  0xe12fff33                          // blx           r3
  .long  0xe24bd008                          // sub           sp, fp, #8
  .long  0xe8bd8c10                          // pop           {r4, sl, fp, pc}

HIDDEN _sk_store_f16_vfp4
.globl _sk_store_f16_vfp4
FUNCTION(_sk_store_f16_vfp4)
_sk_store_f16_vfp4:
  .long  0xf2630113                          // vorr          d16, d3, d3
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2612111                          // vorr          d18, d1, d1
  .long  0xf3f67620                          // vcvt.f16.f32  d23, q8
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xf3f66602                          // vcvt.f16.f32  d22, q1
  .long  0xe0833180                          // add           r3, r3, r0, lsl #3
  .long  0xf3f65622                          // vcvt.f16.f32  d21, q9
  .long  0xf3f64600                          // vcvt.f16.f32  d20, q0
  .long  0xf22211b2                          // vorr          d1, d18, d18
  .long  0xf22031b0                          // vorr          d3, d16, d16
  .long  0xf4c3470d                          // vst4.16       {d20[0],d21[0],d22[0],d23[0]}, [r3]!
  .long  0xf4c3474f                          // vst4.16       {d20[1],d21[1],d22[1],d23[1]}, [r3]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_load_u16_be_vfp4
.globl _sk_load_u16_be_vfp4
FUNCTION(_sk_load_u16_be_vfp4)
_sk_load_u16_be_vfp4:
  .long  0xe92d48f0                          // push          {r4, r5, r6, r7, fp, lr}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xe0833180                          // add           r3, r3, r0, lsl #3
  .long  0xf4e3070d                          // vld4.16       {d16[0],d17[0],d18[0],d19[0]}, [r3]!
  .long  0xf4e3074f                          // vld4.16       {d16[1],d17[1],d18[1],d19[1]}, [r3]
  .long  0xee903bb0                          // vmov.u16      r3, d16[0]
  .long  0xee92ebb0                          // vmov.u16      lr, d18[0]
  .long  0xee914bb0                          // vmov.u16      r4, d17[0]
  .long  0xee937bb0                          // vmov.u16      r7, d19[0]
  .long  0xee905bf0                          // vmov.u16      r5, d16[1]
  .long  0xee926bf0                          // vmov.u16      r6, d18[1]
  .long  0xee043b90                          // vmov.32       d20[0], r3
  .long  0xee05eb90                          // vmov.32       d21[0], lr
  .long  0xee93ebf0                          // vmov.u16      lr, d19[1]
  .long  0xee913bf0                          // vmov.u16      r3, d17[1]
  .long  0xf3c71c1f                          // vmov.i32      d17, #65535
  .long  0xee004b90                          // vmov.32       d16[0], r4
  .long  0xee027b90                          // vmov.32       d18[0], r7
  .long  0xee245b90                          // vmov.32       d20[1], r5
  .long  0xf24431b1                          // vand          d19, d20, d17
  .long  0xee256b90                          // vmov.32       d21[1], r6
  .long  0xf2e84534                          // vshl.s32      d20, d20, #8
  .long  0xf24561b1                          // vand          d22, d21, d17
  .long  0xf3f83033                          // vshr.u32      d19, d19, #8
  .long  0xf2e85535                          // vshl.s32      d21, d21, #8
  .long  0xf26431b3                          // vorr          d19, d20, d19
  .long  0xf3f86036                          // vshr.u32      d22, d22, #8
  .long  0xf24331b1                          // vand          d19, d19, d17
  .long  0xf26551b6                          // vorr          d21, d21, d22
  .long  0xf3fb36a3                          // vcvt.f32.u32  d19, d19
  .long  0xee22eb90                          // vmov.32       d18[1], lr
  .long  0xee203b90                          // vmov.32       d16[1], r3
  .long  0xf24281b1                          // vand          d24, d18, d17
  .long  0xf2e82532                          // vshl.s32      d18, d18, #8
  .long  0xf24071b1                          // vand          d23, d16, d17
  .long  0xf3f84038                          // vshr.u32      d20, d24, #8
  .long  0xf2e80530                          // vshl.s32      d16, d16, #8
  .long  0xf3f87037                          // vshr.u32      d23, d23, #8
  .long  0xf26221b4                          // vorr          d18, d18, d20
  .long  0xf26001b7                          // vorr          d16, d16, d23
  .long  0xf24541b1                          // vand          d20, d21, d17
  .long  0xf24001b1                          // vand          d16, d16, d17
  .long  0xf24211b1                          // vand          d17, d18, d17
  .long  0xeddf2b09                          // vldr          d18, [pc, #36]
  .long  0xf3fb06a0                          // vcvt.f32.u32  d16, d16
  .long  0xf3fb46a4                          // vcvt.f32.u32  d20, d20
  .long  0xf3fb16a1                          // vcvt.f32.u32  d17, d17
  .long  0xf3030db2                          // vmul.f32      d0, d19, d18
  .long  0xf3001db2                          // vmul.f32      d1, d16, d18
  .long  0xf3042db2                          // vmul.f32      d2, d20, d18
  .long  0xf3013db2                          // vmul.f32      d3, d17, d18
  .long  0xe8bd48f0                          // pop           {r4, r5, r6, r7, fp, lr}
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x37800080                          // .word         0x37800080
  .long  0x37800080                          // .word         0x37800080

HIDDEN _sk_load_rgb_u16_be_vfp4
.globl _sk_load_rgb_u16_be_vfp4
FUNCTION(_sk_load_rgb_u16_be_vfp4)
_sk_load_rgb_u16_be_vfp4:
  .long  0xe92d48f0                          // push          {r4, r5, r6, r7, fp, lr}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf2873f10                          // vmov.f32      d3, #1
  .long  0xe593e000                          // ldr           lr, [r3]
  .long  0xe0803080                          // add           r3, r0, r0, lsl #1
  .long  0xe08e3083                          // add           r3, lr, r3, lsl #1
  .long  0xf4e3060d                          // vld3.16       {d16[0],d17[0],d18[0]}, [r3]!
  .long  0xf4e3064f                          // vld3.16       {d16[1],d17[1],d18[1]}, [r3]
  .long  0xee90ebb0                          // vmov.u16      lr, d16[0]
  .long  0xee913bb0                          // vmov.u16      r3, d17[0]
  .long  0xee924bb0                          // vmov.u16      r4, d18[0]
  .long  0xee927bf0                          // vmov.u16      r7, d18[1]
  .long  0xf3c73c1f                          // vmov.i32      d19, #65535
  .long  0xee905bf0                          // vmov.u16      r5, d16[1]
  .long  0xee916bf0                          // vmov.u16      r6, d17[1]
  .long  0xee00eb90                          // vmov.32       d16[0], lr
  .long  0xee013b90                          // vmov.32       d17[0], r3
  .long  0xee024b90                          // vmov.32       d18[0], r4
  .long  0xee205b90                          // vmov.32       d16[1], r5
  .long  0xee216b90                          // vmov.32       d17[1], r6
  .long  0xf24041b3                          // vand          d20, d16, d19
  .long  0xf2e80530                          // vshl.s32      d16, d16, #8
  .long  0xee227b90                          // vmov.32       d18[1], r7
  .long  0xf24151b3                          // vand          d21, d17, d19
  .long  0xf3f84034                          // vshr.u32      d20, d20, #8
  .long  0xf24261b3                          // vand          d22, d18, d19
  .long  0xf2e81531                          // vshl.s32      d17, d17, #8
  .long  0xf3f85035                          // vshr.u32      d21, d21, #8
  .long  0xf2e82532                          // vshl.s32      d18, d18, #8
  .long  0xf3f86036                          // vshr.u32      d22, d22, #8
  .long  0xf26001b4                          // vorr          d16, d16, d20
  .long  0xf26111b5                          // vorr          d17, d17, d21
  .long  0xf26221b6                          // vorr          d18, d18, d22
  .long  0xf24001b3                          // vand          d16, d16, d19
  .long  0xf24111b3                          // vand          d17, d17, d19
  .long  0xf24221b3                          // vand          d18, d18, d19
  .long  0xeddf3b07                          // vldr          d19, [pc, #28]
  .long  0xf3fb06a0                          // vcvt.f32.u32  d16, d16
  .long  0xf3fb16a1                          // vcvt.f32.u32  d17, d17
  .long  0xf3fb26a2                          // vcvt.f32.u32  d18, d18
  .long  0xf3000db3                          // vmul.f32      d0, d16, d19
  .long  0xf3011db3                          // vmul.f32      d1, d17, d19
  .long  0xf3022db3                          // vmul.f32      d2, d18, d19
  .long  0xe8bd48f0                          // pop           {r4, r5, r6, r7, fp, lr}
  .long  0xe12fff1c                          // bx            ip
  .long  0x37800080                          // .word         0x37800080
  .long  0x37800080                          // .word         0x37800080

HIDDEN _sk_store_u16_be_vfp4
.globl _sk_store_u16_be_vfp4
FUNCTION(_sk_store_u16_be_vfp4)
_sk_store_u16_be_vfp4:
  .long  0xeddf0b2a                          // vldr          d16, [pc, #168]
  .long  0xf2c3261f                          // vmov.i32      d18, #1056964608
  .long  0xf2c3361f                          // vmov.i32      d19, #1056964608
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2432c30                          // vfma.f32      d18, d3, d16
  .long  0xf2c3461f                          // vmov.i32      d20, #1056964608
  .long  0xf2423c30                          // vfma.f32      d19, d2, d16
  .long  0xf2c3161f                          // vmov.i32      d17, #1056964608
  .long  0xf2414c30                          // vfma.f32      d20, d1, d16
  .long  0xf2401c30                          // vfma.f32      d17, d0, d16
  .long  0xf3fb07a2                          // vcvt.u32.f32  d16, d18
  .long  0xf3fb27a3                          // vcvt.u32.f32  d18, d19
  .long  0xf3c73c1f                          // vmov.i32      d19, #65535
  .long  0xf3fb47a4                          // vcvt.u32.f32  d20, d20
  .long  0xf3fb17a1                          // vcvt.u32.f32  d17, d17
  .long  0xf24051b3                          // vand          d21, d16, d19
  .long  0xf24261b3                          // vand          d22, d18, d19
  .long  0xf24471b3                          // vand          d23, d20, d19
  .long  0xf24131b3                          // vand          d19, d17, d19
  .long  0xf2e80530                          // vshl.s32      d16, d16, #8
  .long  0xf3f85035                          // vshr.u32      d21, d21, #8
  .long  0xf2e82532                          // vshl.s32      d18, d18, #8
  .long  0xf3f86036                          // vshr.u32      d22, d22, #8
  .long  0xf260b1b5                          // vorr          d27, d16, d21
  .long  0xf2e84534                          // vshl.s32      d20, d20, #8
  .long  0xf3f87037                          // vshr.u32      d23, d23, #8
  .long  0xf262a1b6                          // vorr          d26, d18, d22
  .long  0xf2e81531                          // vshl.s32      d17, d17, #8
  .long  0xf3f83033                          // vshr.u32      d19, d19, #8
  .long  0xf26491b7                          // vorr          d25, d20, d23
  .long  0xf26181b3                          // vorr          d24, d17, d19
  .long  0xf3f6b120                          // vuzp.16       d27, d16
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xf3f6a120                          // vuzp.16       d26, d16
  .long  0xe0833180                          // add           r3, r3, r0, lsl #3
  .long  0xf3f69120                          // vuzp.16       d25, d16
  .long  0xf3f68120                          // vuzp.16       d24, d16
  .long  0xf4c3870d                          // vst4.16       {d24[0],d25[0],d26[0],d27[0]}, [r3]!
  .long  0xf4c3874f                          // vst4.16       {d24[1],d25[1],d26[1],d27[1]}, [r3]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x477fff00                          // .word         0x477fff00
  .long  0x477fff00                          // .word         0x477fff00

HIDDEN _sk_load_f32_vfp4
.globl _sk_load_f32_vfp4
FUNCTION(_sk_load_f32_vfp4)
_sk_load_f32_vfp4:
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xe0833200                          // add           r3, r3, r0, lsl #4
  .long  0xf423008f                          // vld4.32       {d0-d3}, [r3]
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_store_f32_vfp4
.globl _sk_store_f32_vfp4
FUNCTION(_sk_store_f32_vfp4)
_sk_store_f32_vfp4:
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xe5933000                          // ldr           r3, [r3]
  .long  0xe0833200                          // add           r3, r3, r0, lsl #4
  .long  0xf403008f                          // vst4.32       {d0-d3}, [r3]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_clamp_x_vfp4
.globl _sk_clamp_x_vfp4
FUNCTION(_sk_clamp_x_vfp4)
_sk_clamp_x_vfp4:
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf2c00010                          // vmov.i32      d16, #0
  .long  0xf3c71e1f                          // vmov.i8       d17, #255
  .long  0xf2400f80                          // vmax.f32      d16, d16, d0
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xf26218a1                          // vadd.i32      d17, d18, d17
  .long  0xf2200fa1                          // vmin.f32      d0, d16, d17
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_clamp_y_vfp4
.globl _sk_clamp_y_vfp4
FUNCTION(_sk_clamp_y_vfp4)
_sk_clamp_y_vfp4:
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf2c00010                          // vmov.i32      d16, #0
  .long  0xf3c71e1f                          // vmov.i8       d17, #255
  .long  0xf2400f81                          // vmax.f32      d16, d16, d1
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xf26218a1                          // vadd.i32      d17, d18, d17
  .long  0xf2201fa1                          // vmin.f32      d1, d16, d17
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_repeat_x_vfp4
.globl _sk_repeat_x_vfp4
FUNCTION(_sk_repeat_x_vfp4)
_sk_repeat_x_vfp4:
  .long  0xed2d8b04                          // vpush         {d8-d9}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf2c02010                          // vmov.i32      d18, #0
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xeddf3b10                          // vldr          d19, [pc, #64]
  .long  0xed938a00                          // vldr          s16, [r3]
  .long  0xeec09a88                          // vdiv.f32      s19, s1, s16
  .long  0xee809a08                          // vdiv.f32      s18, s0, s16
  .long  0xf3fb0709                          // vcvt.s32.f32  d16, d9
  .long  0xf3fb0620                          // vcvt.f32.s32  d16, d16
  .long  0xf3601e89                          // vcgt.f32      d17, d16, d9
  .long  0xf35311b2                          // vbsl          d17, d19, d18
  .long  0xf3f42c08                          // vdup.32       d18, d8[0]
  .long  0xf2600da1                          // vsub.f32      d16, d16, d17
  .long  0xf3c71e1f                          // vmov.i8       d17, #255
  .long  0xf26218a1                          // vadd.i32      d17, d18, d17
  .long  0xf2e009c8                          // vmul.f32      d16, d16, d8[0]
  .long  0xf2600d20                          // vsub.f32      d16, d0, d16
  .long  0xf2200fa1                          // vmin.f32      d0, d16, d17
  .long  0xecbd8b04                          // vpop          {d8-d9}
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x3f800000                          // .word         0x3f800000
  .long  0x3f800000                          // .word         0x3f800000

HIDDEN _sk_repeat_y_vfp4
.globl _sk_repeat_y_vfp4
FUNCTION(_sk_repeat_y_vfp4)
_sk_repeat_y_vfp4:
  .long  0xed2d8b04                          // vpush         {d8-d9}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf2c02010                          // vmov.i32      d18, #0
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xeddf3b10                          // vldr          d19, [pc, #64]
  .long  0xed938a00                          // vldr          s16, [r3]
  .long  0xeec19a88                          // vdiv.f32      s19, s3, s16
  .long  0xee819a08                          // vdiv.f32      s18, s2, s16
  .long  0xf3fb0709                          // vcvt.s32.f32  d16, d9
  .long  0xf3fb0620                          // vcvt.f32.s32  d16, d16
  .long  0xf3601e89                          // vcgt.f32      d17, d16, d9
  .long  0xf35311b2                          // vbsl          d17, d19, d18
  .long  0xf3f42c08                          // vdup.32       d18, d8[0]
  .long  0xf2600da1                          // vsub.f32      d16, d16, d17
  .long  0xf3c71e1f                          // vmov.i8       d17, #255
  .long  0xf26218a1                          // vadd.i32      d17, d18, d17
  .long  0xf2e009c8                          // vmul.f32      d16, d16, d8[0]
  .long  0xf2610d20                          // vsub.f32      d16, d1, d16
  .long  0xf2201fa1                          // vmin.f32      d1, d16, d17
  .long  0xecbd8b04                          // vpop          {d8-d9}
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x3f800000                          // .word         0x3f800000
  .long  0x3f800000                          // .word         0x3f800000

HIDDEN _sk_mirror_x_vfp4
.globl _sk_mirror_x_vfp4
FUNCTION(_sk_mirror_x_vfp4)
_sk_mirror_x_vfp4:
  .long  0xed2d8b04                          // vpush         {d8-d9}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf2c03010                          // vmov.i32      d19, #0
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xeddf4b14                          // vldr          d20, [pc, #80]
  .long  0xed938a00                          // vldr          s16, [r3]
  .long  0xee389a08                          // vadd.f32      s18, s16, s16
  .long  0xf3f40c08                          // vdup.32       d16, d8[0]
  .long  0xf2200d20                          // vsub.f32      d0, d0, d16
  .long  0xeec08a89                          // vdiv.f32      s17, s1, s18
  .long  0xee808a09                          // vdiv.f32      s16, s0, s18
  .long  0xf3fb1708                          // vcvt.s32.f32  d17, d8
  .long  0xf3fb1621                          // vcvt.f32.s32  d17, d17
  .long  0xf3612e88                          // vcgt.f32      d18, d17, d8
  .long  0xf35421b3                          // vbsl          d18, d20, d19
  .long  0xf2611da2                          // vsub.f32      d17, d17, d18
  .long  0xf3c72e1f                          // vmov.i8       d18, #255
  .long  0xf2e119c9                          // vmul.f32      d17, d17, d9[0]
  .long  0xf2601d21                          // vsub.f32      d17, d0, d17
  .long  0xf2611da0                          // vsub.f32      d17, d17, d16
  .long  0xf26008a2                          // vadd.i32      d16, d16, d18
  .long  0xf3f91721                          // vabs.f32      d17, d17
  .long  0xf2210fa0                          // vmin.f32      d0, d17, d16
  .long  0xecbd8b04                          // vpop          {d8-d9}
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x3f800000                          // .word         0x3f800000
  .long  0x3f800000                          // .word         0x3f800000

HIDDEN _sk_mirror_y_vfp4
.globl _sk_mirror_y_vfp4
FUNCTION(_sk_mirror_y_vfp4)
_sk_mirror_y_vfp4:
  .long  0xed2d8b04                          // vpush         {d8-d9}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf2c03010                          // vmov.i32      d19, #0
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xeddf4b14                          // vldr          d20, [pc, #80]
  .long  0xed938a00                          // vldr          s16, [r3]
  .long  0xee389a08                          // vadd.f32      s18, s16, s16
  .long  0xf3f40c08                          // vdup.32       d16, d8[0]
  .long  0xf2211d20                          // vsub.f32      d1, d1, d16
  .long  0xeec18a89                          // vdiv.f32      s17, s3, s18
  .long  0xee818a09                          // vdiv.f32      s16, s2, s18
  .long  0xf3fb1708                          // vcvt.s32.f32  d17, d8
  .long  0xf3fb1621                          // vcvt.f32.s32  d17, d17
  .long  0xf3612e88                          // vcgt.f32      d18, d17, d8
  .long  0xf35421b3                          // vbsl          d18, d20, d19
  .long  0xf2611da2                          // vsub.f32      d17, d17, d18
  .long  0xf3c72e1f                          // vmov.i8       d18, #255
  .long  0xf2e119c9                          // vmul.f32      d17, d17, d9[0]
  .long  0xf2611d21                          // vsub.f32      d17, d1, d17
  .long  0xf2611da0                          // vsub.f32      d17, d17, d16
  .long  0xf26008a2                          // vadd.i32      d16, d16, d18
  .long  0xf3f91721                          // vabs.f32      d17, d17
  .long  0xf2211fa0                          // vmin.f32      d1, d17, d16
  .long  0xecbd8b04                          // vpop          {d8-d9}
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x3f800000                          // .word         0x3f800000
  .long  0x3f800000                          // .word         0x3f800000

HIDDEN _sk_luminance_to_alpha_vfp4
.globl _sk_luminance_to_alpha_vfp4
FUNCTION(_sk_luminance_to_alpha_vfp4)
_sk_luminance_to_alpha_vfp4:
  .long  0xeddf0b0a                          // vldr          d16, [pc, #40]
  .long  0xeddf1b0b                          // vldr          d17, [pc, #44]
  .long  0xf3410d30                          // vmul.f32      d16, d1, d16
  .long  0xe4913004                          // ldr           r3, [r1], #4
  .long  0xf3401d31                          // vmul.f32      d17, d0, d17
  .long  0xf2800010                          // vmov.i32      d0, #0
  .long  0xf2801010                          // vmov.i32      d1, #0
  .long  0xf2013da0                          // vadd.f32      d3, d17, d16
  .long  0xeddf0b06                          // vldr          d16, [pc, #24]
  .long  0xf2023c30                          // vfma.f32      d3, d2, d16
  .long  0xf2802010                          // vmov.i32      d2, #0
  .long  0xe12fff13                          // bx            r3
  .long  0x3f371759                          // .word         0x3f371759
  .long  0x3f371759                          // .word         0x3f371759
  .long  0x3e59b3d0                          // .word         0x3e59b3d0
  .long  0x3e59b3d0                          // .word         0x3e59b3d0
  .long  0x3d93dd98                          // .word         0x3d93dd98
  .long  0x3d93dd98                          // .word         0x3d93dd98

HIDDEN _sk_matrix_2x3_vfp4
.globl _sk_matrix_2x3_vfp4
FUNCTION(_sk_matrix_2x3_vfp4)
_sk_matrix_2x3_vfp4:
  .long  0xe92d4800                          // push          {fp, lr}
  .long  0xe591e000                          // ldr           lr, [r1]
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe28e300c                          // add           r3, lr, #12
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xe28e3008                          // add           r3, lr, #8
  .long  0xf4e31c9f                          // vld1.32       {d17[]}, [r3 :32]
  .long  0xe28e3010                          // add           r3, lr, #16
  .long  0xf4e30c9f                          // vld1.32       {d16[]}, [r3 :32]
  .long  0xe28e3014                          // add           r3, lr, #20
  .long  0xf2410c31                          // vfma.f32      d16, d1, d17
  .long  0xf4e31c9f                          // vld1.32       {d17[]}, [r3 :32]
  .long  0xf2411c32                          // vfma.f32      d17, d1, d18
  .long  0xf4ee2c9d                          // vld1.32       {d18[]}, [lr :32]!
  .long  0xf4ee3c9f                          // vld1.32       {d19[]}, [lr :32]
  .long  0xf2400c32                          // vfma.f32      d16, d0, d18
  .long  0xf2401c33                          // vfma.f32      d17, d0, d19
  .long  0xf22001b0                          // vorr          d0, d16, d16
  .long  0xf22111b1                          // vorr          d1, d17, d17
  .long  0xe8bd4800                          // pop           {fp, lr}
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_matrix_3x4_vfp4
.globl _sk_matrix_3x4_vfp4
FUNCTION(_sk_matrix_3x4_vfp4)
_sk_matrix_3x4_vfp4:
  .long  0xe92d4800                          // push          {fp, lr}
  .long  0xe591e000                          // ldr           lr, [r1]
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe28e3020                          // add           r3, lr, #32
  .long  0xf4e33c9f                          // vld1.32       {d19[]}, [r3 :32]
  .long  0xe28e302c                          // add           r3, lr, #44
  .long  0xf4e30c9f                          // vld1.32       {d16[]}, [r3 :32]
  .long  0xe28e301c                          // add           r3, lr, #28
  .long  0xf2420c33                          // vfma.f32      d16, d2, d19
  .long  0xf4e34c9f                          // vld1.32       {d20[]}, [r3 :32]
  .long  0xe28e3018                          // add           r3, lr, #24
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xe28e3024                          // add           r3, lr, #36
  .long  0xf4e31c9f                          // vld1.32       {d17[]}, [r3 :32]
  .long  0xe28e3028                          // add           r3, lr, #40
  .long  0xf2421c32                          // vfma.f32      d17, d2, d18
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xe28e3010                          // add           r3, lr, #16
  .long  0xf2422c34                          // vfma.f32      d18, d2, d20
  .long  0xf4e33c9f                          // vld1.32       {d19[]}, [r3 :32]
  .long  0xe28e300c                          // add           r3, lr, #12
  .long  0xf4e34c9f                          // vld1.32       {d20[]}, [r3 :32]
  .long  0xe28e3014                          // add           r3, lr, #20
  .long  0xf2411c34                          // vfma.f32      d17, d1, d20
  .long  0xf4e34c9f                          // vld1.32       {d20[]}, [r3 :32]
  .long  0xf2410c34                          // vfma.f32      d16, d1, d20
  .long  0xe28e3008                          // add           r3, lr, #8
  .long  0xf2412c33                          // vfma.f32      d18, d1, d19
  .long  0xf4ee3c9d                          // vld1.32       {d19[]}, [lr :32]!
  .long  0xf4ee4c9f                          // vld1.32       {d20[]}, [lr :32]
  .long  0xf2401c33                          // vfma.f32      d17, d0, d19
  .long  0xf4e33c9f                          // vld1.32       {d19[]}, [r3 :32]
  .long  0xf2400c33                          // vfma.f32      d16, d0, d19
  .long  0xf2402c34                          // vfma.f32      d18, d0, d20
  .long  0xf22101b1                          // vorr          d0, d17, d17
  .long  0xf22021b0                          // vorr          d2, d16, d16
  .long  0xf22211b2                          // vorr          d1, d18, d18
  .long  0xe8bd4800                          // pop           {fp, lr}
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_matrix_4x5_vfp4
.globl _sk_matrix_4x5_vfp4
FUNCTION(_sk_matrix_4x5_vfp4)
_sk_matrix_4x5_vfp4:
  .long  0xe92d4010                          // push          {r4, lr}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xf2620112                          // vorr          d16, d2, d2
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe2834014                          // add           r4, r3, #20
  .long  0xe1a0e003                          // mov           lr, r3
  .long  0xf4e45c9f                          // vld1.32       {d21[]}, [r4 :32]
  .long  0xe2834028                          // add           r4, r3, #40
  .long  0xf4e46c9f                          // vld1.32       {d22[]}, [r4 :32]
  .long  0xe2834038                          // add           r4, r3, #56
  .long  0xf4e47c9f                          // vld1.32       {d23[]}, [r4 :32]
  .long  0xe2834048                          // add           r4, r3, #72
  .long  0xf4a42c9f                          // vld1.32       {d2[]}, [r4 :32]
  .long  0xe2834034                          // add           r4, r3, #52
  .long  0xf2032c37                          // vfma.f32      d2, d3, d23
  .long  0xf4e48c9f                          // vld1.32       {d24[]}, [r4 :32]
  .long  0xe2834044                          // add           r4, r3, #68
  .long  0xf4e41c9f                          // vld1.32       {d17[]}, [r4 :32]
  .long  0xe2834030                          // add           r4, r3, #48
  .long  0xf2431c38                          // vfma.f32      d17, d3, d24
  .long  0xf4e49c9f                          // vld1.32       {d25[]}, [r4 :32]
  .long  0xe283403c                          // add           r4, r3, #60
  .long  0xf4e43c9f                          // vld1.32       {d19[]}, [r4 :32]
  .long  0xe283404c                          // add           r4, r3, #76
  .long  0xf2002cb6                          // vfma.f32      d2, d16, d22
  .long  0xf4e42c9f                          // vld1.32       {d18[]}, [r4 :32]
  .long  0xe2834040                          // add           r4, r3, #64
  .long  0xf2432c33                          // vfma.f32      d18, d3, d19
  .long  0xf4e43c9f                          // vld1.32       {d19[]}, [r4 :32]
  .long  0xe2834020                          // add           r4, r3, #32
  .long  0xf2433c39                          // vfma.f32      d19, d3, d25
  .long  0xf4e47c9f                          // vld1.32       {d23[]}, [r4 :32]
  .long  0xe283402c                          // add           r4, r3, #44
  .long  0xf4e48c9f                          // vld1.32       {d24[]}, [r4 :32]
  .long  0xe2834024                          // add           r4, r3, #36
  .long  0xf2402cb8                          // vfma.f32      d18, d16, d24
  .long  0xf4e48c9f                          // vld1.32       {d24[]}, [r4 :32]
  .long  0xf2401cb8                          // vfma.f32      d17, d16, d24
  .long  0xe2834010                          // add           r4, r3, #16
  .long  0xf2403cb7                          // vfma.f32      d19, d16, d23
  .long  0xf4ee4c9d                          // vld1.32       {d20[]}, [lr :32]!
  .long  0xf4e40c9f                          // vld1.32       {d16[]}, [r4 :32]
  .long  0xe283401c                          // add           r4, r3, #28
  .long  0xf4e46c9f                          // vld1.32       {d22[]}, [r4 :32]
  .long  0xe2834018                          // add           r4, r3, #24
  .long  0xf2412c36                          // vfma.f32      d18, d1, d22
  .long  0xf2411c35                          // vfma.f32      d17, d1, d21
  .long  0xf4ee5c9f                          // vld1.32       {d21[]}, [lr :32]
  .long  0xf2413c30                          // vfma.f32      d19, d1, d16
  .long  0xf4e40c9f                          // vld1.32       {d16[]}, [r4 :32]
  .long  0xe2834008                          // add           r4, r3, #8
  .long  0xe283300c                          // add           r3, r3, #12
  .long  0xf2012c30                          // vfma.f32      d2, d1, d16
  .long  0xf4e40c9f                          // vld1.32       {d16[]}, [r4 :32]
  .long  0xf2401c35                          // vfma.f32      d17, d0, d21
  .long  0xf2403c34                          // vfma.f32      d19, d0, d20
  .long  0xf4e34c9f                          // vld1.32       {d20[]}, [r3 :32]
  .long  0xf2402c34                          // vfma.f32      d18, d0, d20
  .long  0xf2002c30                          // vfma.f32      d2, d0, d16
  .long  0xf22111b1                          // vorr          d1, d17, d17
  .long  0xf22301b3                          // vorr          d0, d19, d19
  .long  0xf22231b2                          // vorr          d3, d18, d18
  .long  0xe8bd4010                          // pop           {r4, lr}
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_matrix_perspective_vfp4
.globl _sk_matrix_perspective_vfp4
FUNCTION(_sk_matrix_perspective_vfp4)
_sk_matrix_perspective_vfp4:
  .long  0xe92d4010                          // push          {r4, lr}
  .long  0xe591e000                          // ldr           lr, [r1]
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe28e301c                          // add           r3, lr, #28
  .long  0xe28e4010                          // add           r4, lr, #16
  .long  0xf4e30c9f                          // vld1.32       {d16[]}, [r3 :32]
  .long  0xe28e3020                          // add           r3, lr, #32
  .long  0xf4e31c9f                          // vld1.32       {d17[]}, [r3 :32]
  .long  0xe28e3018                          // add           r3, lr, #24
  .long  0xf2411c30                          // vfma.f32      d17, d1, d16
  .long  0xf4e30c9f                          // vld1.32       {d16[]}, [r3 :32]
  .long  0xe1a0300e                          // mov           r3, lr
  .long  0xf4e42c9f                          // vld1.32       {d18[]}, [r4 :32]
  .long  0xe28e4008                          // add           r4, lr, #8
  .long  0xf4e43c9f                          // vld1.32       {d19[]}, [r4 :32]
  .long  0xf2401c30                          // vfma.f32      d17, d0, d16
  .long  0xf4e30c9d                          // vld1.32       {d16[]}, [r3 :32]!
  .long  0xf4e35c9f                          // vld1.32       {d21[]}, [r3 :32]
  .long  0xe28e3014                          // add           r3, lr, #20
  .long  0xf2413c35                          // vfma.f32      d19, d1, d21
  .long  0xf4e35c9f                          // vld1.32       {d21[]}, [r3 :32]
  .long  0xe28e300c                          // add           r3, lr, #12
  .long  0xf2415c32                          // vfma.f32      d21, d1, d18
  .long  0xf4e32c9f                          // vld1.32       {d18[]}, [r3 :32]
  .long  0xf3fb4521                          // vrecpe.f32    d20, d17
  .long  0xf2403c30                          // vfma.f32      d19, d0, d16
  .long  0xf2411fb4                          // vrecps.f32    d17, d17, d20
  .long  0xf2405c32                          // vfma.f32      d21, d0, d18
  .long  0xf3440db1                          // vmul.f32      d16, d20, d17
  .long  0xf3030db0                          // vmul.f32      d0, d19, d16
  .long  0xf3051db0                          // vmul.f32      d1, d21, d16
  .long  0xe8bd4010                          // pop           {r4, lr}
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_linear_gradient_vfp4
.globl _sk_linear_gradient_vfp4
FUNCTION(_sk_linear_gradient_vfp4)
_sk_linear_gradient_vfp4:
  .long  0xe92d4010                          // push          {r4, lr}
  .long  0xe591e000                          // ldr           lr, [r1]
  .long  0xe28e3014                          // add           r3, lr, #20
  .long  0xe1a0400e                          // mov           r4, lr
  .long  0xf4a33c9f                          // vld1.32       {d3[]}, [r3 :32]
  .long  0xe28e3010                          // add           r3, lr, #16
  .long  0xf4a32c9f                          // vld1.32       {d2[]}, [r3 :32]
  .long  0xe28e3008                          // add           r3, lr, #8
  .long  0xf4e30c9f                          // vld1.32       {d16[]}, [r3 :32]
  .long  0xe494c00c                          // ldr           ip, [r4], #12
  .long  0xf4a41c9f                          // vld1.32       {d1[]}, [r4 :32]
  .long  0xe35c0000                          // cmp           ip, #0
  .long  0x0a000036                          // beq           2d70 <sk_linear_gradient_vfp4+0x110>
  .long  0xe59e3004                          // ldr           r3, [lr, #4]
  .long  0xf2c01010                          // vmov.i32      d17, #0
  .long  0xf2c07010                          // vmov.i32      d23, #0
  .long  0xf2c08010                          // vmov.i32      d24, #0
  .long  0xe2833020                          // add           r3, r3, #32
  .long  0xf2c06010                          // vmov.i32      d22, #0
  .long  0xe2434018                          // sub           r4, r3, #24
  .long  0xf4e33c9f                          // vld1.32       {d19[]}, [r3 :32]
  .long  0xe25cc001                          // subs          ip, ip, #1
  .long  0xf4e4dc9f                          // vld1.32       {d29[]}, [r4 :32]
  .long  0xe2434014                          // sub           r4, r3, #20
  .long  0xf4e45c9f                          // vld1.32       {d21[]}, [r4 :32]
  .long  0xe243400c                          // sub           r4, r3, #12
  .long  0xf4e44c9f                          // vld1.32       {d20[]}, [r4 :32]
  .long  0xe2434020                          // sub           r4, r3, #32
  .long  0xf4e42c9f                          // vld1.32       {d18[]}, [r4 :32]
  .long  0xe2434004                          // sub           r4, r3, #4
  .long  0xf3622e80                          // vcgt.f32      d18, d18, d0
  .long  0xf4e4bc9f                          // vld1.32       {d27[]}, [r4 :32]
  .long  0xe2434008                          // sub           r4, r3, #8
  .long  0xf4e4cc9f                          // vld1.32       {d28[]}, [r4 :32]
  .long  0xe2434010                          // sub           r4, r3, #16
  .long  0xf262a1b2                          // vorr          d26, d18, d18
  .long  0xf4e4ec9f                          // vld1.32       {d30[]}, [r4 :32]
  .long  0xe243401c                          // sub           r4, r3, #28
  .long  0xf352a13b                          // vbsl          d26, d2, d27
  .long  0xe2833024                          // add           r3, r3, #36
  .long  0xf262b1b2                          // vorr          d27, d18, d18
  .long  0xf26291b2                          // vorr          d25, d18, d18
  .long  0xf351b13c                          // vbsl          d27, d1, d28
  .long  0xf262c1b2                          // vorr          d28, d18, d18
  .long  0xf3539133                          // vbsl          d25, d3, d19
  .long  0xf350c1b4                          // vbsl          d28, d16, d20
  .long  0xf4e40c9f                          // vld1.32       {d16[]}, [r4 :32]
  .long  0xf26241b2                          // vorr          d20, d18, d18
  .long  0xf26231b2                          // vorr          d19, d18, d18
  .long  0xf35841b5                          // vbsl          d20, d24, d21
  .long  0xf26251b2                          // vorr          d21, d18, d18
  .long  0xf35121b0                          // vbsl          d18, d17, d16
  .long  0xf35731be                          // vbsl          d19, d23, d30
  .long  0xf35651bd                          // vbsl          d21, d22, d29
  .long  0xf26211b2                          // vorr          d17, d18, d18
  .long  0xf22931b9                          // vorr          d3, d25, d25
  .long  0xf22a21ba                          // vorr          d2, d26, d26
  .long  0xf22b11bb                          // vorr          d1, d27, d27
  .long  0xf26c01bc                          // vorr          d16, d28, d28
  .long  0xf26371b3                          // vorr          d23, d19, d19
  .long  0xf26481b4                          // vorr          d24, d20, d20
  .long  0xf26561b5                          // vorr          d22, d21, d21
  .long  0x1affffd3                          // bne           2cac <sk_linear_gradient_vfp4+0x4c>
  .long  0xf26c01bc                          // vorr          d16, d28, d28
  .long  0xf22b11bb                          // vorr          d1, d27, d27
  .long  0xf22a21ba                          // vorr          d2, d26, d26
  .long  0xf22931b9                          // vorr          d3, d25, d25
  .long  0xea000003                          // b             2d80 <sk_linear_gradient_vfp4+0x120>
  .long  0xf2c05010                          // vmov.i32      d21, #0
  .long  0xf2c04010                          // vmov.i32      d20, #0
  .long  0xf2c03010                          // vmov.i32      d19, #0
  .long  0xf2c02010                          // vmov.i32      d18, #0
  .long  0xf2400c32                          // vfma.f32      d16, d0, d18
  .long  0xe5913004                          // ldr           r3, [r1, #4]
  .long  0xf2001c35                          // vfma.f32      d1, d0, d21
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xf2002c34                          // vfma.f32      d2, d0, d20
  .long  0xf2003c33                          // vfma.f32      d3, d0, d19
  .long  0xf22001b0                          // vorr          d0, d16, d16
  .long  0xe8bd4010                          // pop           {r4, lr}
  .long  0xe12fff13                          // bx            r3

HIDDEN _sk_linear_gradient_2stops_vfp4
.globl _sk_linear_gradient_2stops_vfp4
FUNCTION(_sk_linear_gradient_2stops_vfp4)
_sk_linear_gradient_2stops_vfp4:
  .long  0xe92d4010                          // push          {r4, lr}
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xe283400c                          // add           r4, r3, #12
  .long  0xe1a0e003                          // mov           lr, r3
  .long  0xf4e42c9f                          // vld1.32       {d18[]}, [r4 :32]
  .long  0xe2834008                          // add           r4, r3, #8
  .long  0xf4e43c9f                          // vld1.32       {d19[]}, [r4 :32]
  .long  0xe2834018                          // add           r4, r3, #24
  .long  0xf4a42c9f                          // vld1.32       {d2[]}, [r4 :32]
  .long  0xe2834010                          // add           r4, r3, #16
  .long  0xf2002c33                          // vfma.f32      d2, d0, d19
  .long  0xf4e40c9f                          // vld1.32       {d16[]}, [r4 :32]
  .long  0xe283401c                          // add           r4, r3, #28
  .long  0xe2833014                          // add           r3, r3, #20
  .long  0xf4ee1c9d                          // vld1.32       {d17[]}, [lr :32]!
  .long  0xf2400c31                          // vfma.f32      d16, d0, d17
  .long  0xf4a43c9f                          // vld1.32       {d3[]}, [r4 :32]
  .long  0xf2003c32                          // vfma.f32      d3, d0, d18
  .long  0xf4ee1c9f                          // vld1.32       {d17[]}, [lr :32]
  .long  0xf4a31c9f                          // vld1.32       {d1[]}, [r3 :32]
  .long  0xf2001c31                          // vfma.f32      d1, d0, d17
  .long  0xf22001b0                          // vorr          d0, d16, d16
  .long  0xe8bd4010                          // pop           {r4, lr}
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_save_xy_vfp4
.globl _sk_save_xy_vfp4
FUNCTION(_sk_save_xy_vfp4)
_sk_save_xy_vfp4:
  .long  0xf2c3061f                          // vmov.i32      d16, #1056964608
  .long  0xeddf7b17                          // vldr          d23, [pc, #92]
  .long  0xf2c06010                          // vmov.i32      d22, #0
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2401d20                          // vadd.f32      d17, d0, d16
  .long  0xf2410d20                          // vadd.f32      d16, d1, d16
  .long  0xed830b00                          // vstr          d0, [r3]
  .long  0xed831b08                          // vstr          d1, [r3, #32]
  .long  0xf3fb2721                          // vcvt.s32.f32  d18, d17
  .long  0xf3fb3720                          // vcvt.s32.f32  d19, d16
  .long  0xf3fb2622                          // vcvt.f32.s32  d18, d18
  .long  0xf3fb3623                          // vcvt.f32.s32  d19, d19
  .long  0xf3624ea1                          // vcgt.f32      d20, d18, d17
  .long  0xf3635ea0                          // vcgt.f32      d21, d19, d16
  .long  0xf35741b6                          // vbsl          d20, d23, d22
  .long  0xf35751b6                          // vbsl          d21, d23, d22
  .long  0xf2622da4                          // vsub.f32      d18, d18, d20
  .long  0xf2633da5                          // vsub.f32      d19, d19, d21
  .long  0xf2611da2                          // vsub.f32      d17, d17, d18
  .long  0xf2600da3                          // vsub.f32      d16, d16, d19
  .long  0xedc31b10                          // vstr          d17, [r3, #64]
  .long  0xedc30b18                          // vstr          d16, [r3, #96]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip
  .long  0x3f800000                          // .word         0x3f800000
  .long  0x3f800000                          // .word         0x3f800000

HIDDEN _sk_accumulate_vfp4
.globl _sk_accumulate_vfp4
FUNCTION(_sk_accumulate_vfp4)
_sk_accumulate_vfp4:
  .long  0xe8911008                          // ldm           r1, {r3, ip}
  .long  0xe2811008                          // add           r1, r1, #8
  .long  0xedd31b28                          // vldr          d17, [r3, #160]
  .long  0xedd30b20                          // vldr          d16, [r3, #128]
  .long  0xf3400db1                          // vmul.f32      d16, d16, d17
  .long  0xf2004c90                          // vfma.f32      d4, d16, d0
  .long  0xf2005c91                          // vfma.f32      d5, d16, d1
  .long  0xf2006c92                          // vfma.f32      d6, d16, d2
  .long  0xf2007c93                          // vfma.f32      d7, d16, d3
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_bilinear_nx_vfp4
.globl _sk_bilinear_nx_vfp4
FUNCTION(_sk_bilinear_nx_vfp4)
_sk_bilinear_nx_vfp4:
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xedd32b10                          // vldr          d18, [r3, #64]
  .long  0xf2600da2                          // vsub.f32      d16, d16, d18
  .long  0xedd31b00                          // vldr          d17, [r3]
  .long  0xf3c3261f                          // vmov.i32      d18, #-1090519040
  .long  0xf2010da2                          // vadd.f32      d0, d17, d18
  .long  0xedc30b20                          // vstr          d16, [r3, #128]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_bilinear_px_vfp4
.globl _sk_bilinear_px_vfp4
FUNCTION(_sk_bilinear_px_vfp4)
_sk_bilinear_px_vfp4:
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2c3061f                          // vmov.i32      d16, #1056964608
  .long  0xedd31b00                          // vldr          d17, [r3]
  .long  0xedd32b10                          // vldr          d18, [r3, #64]
  .long  0xf2010da0                          // vadd.f32      d0, d17, d16
  .long  0xedc32b20                          // vstr          d18, [r3, #128]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_bilinear_ny_vfp4
.globl _sk_bilinear_ny_vfp4
FUNCTION(_sk_bilinear_ny_vfp4)
_sk_bilinear_ny_vfp4:
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xedd32b18                          // vldr          d18, [r3, #96]
  .long  0xf2600da2                          // vsub.f32      d16, d16, d18
  .long  0xedd31b08                          // vldr          d17, [r3, #32]
  .long  0xf3c3261f                          // vmov.i32      d18, #-1090519040
  .long  0xf2011da2                          // vadd.f32      d1, d17, d18
  .long  0xedc30b28                          // vstr          d16, [r3, #160]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_bilinear_py_vfp4
.globl _sk_bilinear_py_vfp4
FUNCTION(_sk_bilinear_py_vfp4)
_sk_bilinear_py_vfp4:
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2c3061f                          // vmov.i32      d16, #1056964608
  .long  0xedd31b08                          // vldr          d17, [r3, #32]
  .long  0xedd32b18                          // vldr          d18, [r3, #96]
  .long  0xf2011da0                          // vadd.f32      d1, d17, d16
  .long  0xedc32b28                          // vstr          d18, [r3, #160]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip

HIDDEN _sk_bicubic_n3x_vfp4
.globl _sk_bicubic_n3x_vfp4
FUNCTION(_sk_bicubic_n3x_vfp4)
_sk_bicubic_n3x_vfp4:
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xeddf3b10                          // vldr          d19, [pc, #64]
  .long  0xedd32b10                          // vldr          d18, [r3, #64]
  .long  0xf2600da2                          // vsub.f32      d16, d16, d18
  .long  0xeddf2b0b                          // vldr          d18, [pc, #44]
  .long  0xedd31b00                          // vldr          d17, [r3]
  .long  0xf2403cb2                          // vfma.f32      d19, d16, d18
  .long  0xf3400db0                          // vmul.f32      d16, d16, d16
  .long  0xf3c72f18                          // vmov.f32      d18, #-1.5
  .long  0xf2010da2                          // vadd.f32      d0, d17, d18
  .long  0xf3400db3                          // vmul.f32      d16, d16, d19
  .long  0xedc30b20                          // vstr          d16, [r3, #128]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x3ec71c72                          // .word         0x3ec71c72
  .long  0x3ec71c72                          // .word         0x3ec71c72
  .long  0xbeaaaaab                          // .word         0xbeaaaaab
  .long  0xbeaaaaab                          // .word         0xbeaaaaab

HIDDEN _sk_bicubic_n1x_vfp4
.globl _sk_bicubic_n1x_vfp4
FUNCTION(_sk_bicubic_n1x_vfp4)
_sk_bicubic_n1x_vfp4:
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xf2c73f18                          // vmov.f32      d19, #1.5
  .long  0xedd32b10                          // vldr          d18, [r3, #64]
  .long  0xf2600da2                          // vsub.f32      d16, d16, d18
  .long  0xeddf2b0d                          // vldr          d18, [pc, #52]
  .long  0xedd31b00                          // vldr          d17, [r3]
  .long  0xf2403cb2                          // vfma.f32      d19, d16, d18
  .long  0xf2c3261f                          // vmov.i32      d18, #1056964608
  .long  0xf2402cb3                          // vfma.f32      d18, d16, d19
  .long  0xeddf3b0a                          // vldr          d19, [pc, #40]
  .long  0xf2403cb2                          // vfma.f32      d19, d16, d18
  .long  0xf3c3061f                          // vmov.i32      d16, #-1090519040
  .long  0xf2010da0                          // vadd.f32      d0, d17, d16
  .long  0xedc33b20                          // vstr          d19, [r3, #128]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0xbf955555                          // .word         0xbf955555
  .long  0xbf955555                          // .word         0xbf955555
  .long  0x3d638e39                          // .word         0x3d638e39
  .long  0x3d638e39                          // .word         0x3d638e39

HIDDEN _sk_bicubic_p1x_vfp4
.globl _sk_bicubic_p1x_vfp4
FUNCTION(_sk_bicubic_p1x_vfp4)
_sk_bicubic_p1x_vfp4:
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2c71f18                          // vmov.f32      d17, #1.5
  .long  0xeddf0b0c                          // vldr          d16, [pc, #48]
  .long  0xedd33b10                          // vldr          d19, [r3, #64]
  .long  0xf2431cb0                          // vfma.f32      d17, d19, d16
  .long  0xedd32b00                          // vldr          d18, [r3]
  .long  0xf2c3061f                          // vmov.i32      d16, #1056964608
  .long  0xf2020da0                          // vadd.f32      d0, d18, d16
  .long  0xf2430cb1                          // vfma.f32      d16, d19, d17
  .long  0xeddf1b07                          // vldr          d17, [pc, #28]
  .long  0xf2431cb0                          // vfma.f32      d17, d19, d16
  .long  0xedc31b20                          // vstr          d17, [r3, #128]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip
  .long  0xbf955555                          // .word         0xbf955555
  .long  0xbf955555                          // .word         0xbf955555
  .long  0x3d638e39                          // .word         0x3d638e39
  .long  0x3d638e39                          // .word         0x3d638e39

HIDDEN _sk_bicubic_p3x_vfp4
.globl _sk_bicubic_p3x_vfp4
FUNCTION(_sk_bicubic_p3x_vfp4)
_sk_bicubic_p3x_vfp4:
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xeddf0b0d                          // vldr          d16, [pc, #52]
  .long  0xeddf3b0e                          // vldr          d19, [pc, #56]
  .long  0xedd32b10                          // vldr          d18, [r3, #64]
  .long  0xf2423cb0                          // vfma.f32      d19, d18, d16
  .long  0xedd31b00                          // vldr          d17, [r3]
  .long  0xf3420db2                          // vmul.f32      d16, d18, d18
  .long  0xf2c72f18                          // vmov.f32      d18, #1.5
  .long  0xf2010da2                          // vadd.f32      d0, d17, d18
  .long  0xf3400db3                          // vmul.f32      d16, d16, d19
  .long  0xedc30b20                          // vstr          d16, [r3, #128]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x3ec71c72                          // .word         0x3ec71c72
  .long  0x3ec71c72                          // .word         0x3ec71c72
  .long  0xbeaaaaab                          // .word         0xbeaaaaab
  .long  0xbeaaaaab                          // .word         0xbeaaaaab

HIDDEN _sk_bicubic_n3y_vfp4
.globl _sk_bicubic_n3y_vfp4
FUNCTION(_sk_bicubic_n3y_vfp4)
_sk_bicubic_n3y_vfp4:
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xeddf3b10                          // vldr          d19, [pc, #64]
  .long  0xedd32b18                          // vldr          d18, [r3, #96]
  .long  0xf2600da2                          // vsub.f32      d16, d16, d18
  .long  0xeddf2b0b                          // vldr          d18, [pc, #44]
  .long  0xedd31b08                          // vldr          d17, [r3, #32]
  .long  0xf2403cb2                          // vfma.f32      d19, d16, d18
  .long  0xf3400db0                          // vmul.f32      d16, d16, d16
  .long  0xf3c72f18                          // vmov.f32      d18, #-1.5
  .long  0xf2011da2                          // vadd.f32      d1, d17, d18
  .long  0xf3400db3                          // vmul.f32      d16, d16, d19
  .long  0xedc30b28                          // vstr          d16, [r3, #160]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x3ec71c72                          // .word         0x3ec71c72
  .long  0x3ec71c72                          // .word         0x3ec71c72
  .long  0xbeaaaaab                          // .word         0xbeaaaaab
  .long  0xbeaaaaab                          // .word         0xbeaaaaab

HIDDEN _sk_bicubic_n1y_vfp4
.globl _sk_bicubic_n1y_vfp4
FUNCTION(_sk_bicubic_n1y_vfp4)
_sk_bicubic_n1y_vfp4:
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2c70f10                          // vmov.f32      d16, #1
  .long  0xf2c73f18                          // vmov.f32      d19, #1.5
  .long  0xedd32b18                          // vldr          d18, [r3, #96]
  .long  0xf2600da2                          // vsub.f32      d16, d16, d18
  .long  0xeddf2b0d                          // vldr          d18, [pc, #52]
  .long  0xedd31b08                          // vldr          d17, [r3, #32]
  .long  0xf2403cb2                          // vfma.f32      d19, d16, d18
  .long  0xf2c3261f                          // vmov.i32      d18, #1056964608
  .long  0xf2402cb3                          // vfma.f32      d18, d16, d19
  .long  0xeddf3b0a                          // vldr          d19, [pc, #40]
  .long  0xf2403cb2                          // vfma.f32      d19, d16, d18
  .long  0xf3c3061f                          // vmov.i32      d16, #-1090519040
  .long  0xf2011da0                          // vadd.f32      d1, d17, d16
  .long  0xedc33b28                          // vstr          d19, [r3, #160]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0xbf955555                          // .word         0xbf955555
  .long  0xbf955555                          // .word         0xbf955555
  .long  0x3d638e39                          // .word         0x3d638e39
  .long  0x3d638e39                          // .word         0x3d638e39

HIDDEN _sk_bicubic_p1y_vfp4
.globl _sk_bicubic_p1y_vfp4
FUNCTION(_sk_bicubic_p1y_vfp4)
_sk_bicubic_p1y_vfp4:
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xf2c71f18                          // vmov.f32      d17, #1.5
  .long  0xeddf0b0c                          // vldr          d16, [pc, #48]
  .long  0xedd33b18                          // vldr          d19, [r3, #96]
  .long  0xf2431cb0                          // vfma.f32      d17, d19, d16
  .long  0xedd32b08                          // vldr          d18, [r3, #32]
  .long  0xf2c3061f                          // vmov.i32      d16, #1056964608
  .long  0xf2021da0                          // vadd.f32      d1, d18, d16
  .long  0xf2430cb1                          // vfma.f32      d16, d19, d17
  .long  0xeddf1b07                          // vldr          d17, [pc, #28]
  .long  0xf2431cb0                          // vfma.f32      d17, d19, d16
  .long  0xedc31b28                          // vstr          d17, [r3, #160]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip
  .long  0xbf955555                          // .word         0xbf955555
  .long  0xbf955555                          // .word         0xbf955555
  .long  0x3d638e39                          // .word         0x3d638e39
  .long  0x3d638e39                          // .word         0x3d638e39

HIDDEN _sk_bicubic_p3y_vfp4
.globl _sk_bicubic_p3y_vfp4
FUNCTION(_sk_bicubic_p3y_vfp4)
_sk_bicubic_p3y_vfp4:
  .long  0xe5913000                          // ldr           r3, [r1]
  .long  0xeddf0b0d                          // vldr          d16, [pc, #52]
  .long  0xeddf3b0e                          // vldr          d19, [pc, #56]
  .long  0xedd32b18                          // vldr          d18, [r3, #96]
  .long  0xf2423cb0                          // vfma.f32      d19, d18, d16
  .long  0xedd31b08                          // vldr          d17, [r3, #32]
  .long  0xf3420db2                          // vmul.f32      d16, d18, d18
  .long  0xf2c72f18                          // vmov.f32      d18, #1.5
  .long  0xf2011da2                          // vadd.f32      d1, d17, d18
  .long  0xf3400db3                          // vmul.f32      d16, d16, d19
  .long  0xedc30b28                          // vstr          d16, [r3, #160]
  .long  0xe2813008                          // add           r3, r1, #8
  .long  0xe591c004                          // ldr           ip, [r1, #4]
  .long  0xe1a01003                          // mov           r1, r3
  .long  0xe12fff1c                          // bx            ip
  .long  0xe320f000                          // nop           {0}
  .long  0x3ec71c72                          // .word         0x3ec71c72
  .long  0x3ec71c72                          // .word         0x3ec71c72
  .long  0xbeaaaaab                          // .word         0xbeaaaaab
  .long  0xbeaaaaab                          // .word         0xbeaaaaab

HIDDEN _sk_callback_vfp4
.globl _sk_callback_vfp4
FUNCTION(_sk_callback_vfp4)
_sk_callback_vfp4:
  .long  0xe92d48f0                          // push          {r4, r5, r6, r7, fp, lr}
  .long  0xed2d8b08                          // vpush         {d8-d11}
  .long  0xe1a05001                          // mov           r5, r1
  .long  0xe1a06000                          // mov           r6, r0
  .long  0xe5957000                          // ldr           r7, [r5]
  .long  0xe1a04002                          // mov           r4, r2
  .long  0xe3a01002                          // mov           r1, #2
  .long  0xeeb08b47                          // vmov.f64      d8, d7
  .long  0xe2870004                          // add           r0, r7, #4
  .long  0xf400008f                          // vst4.32       {d0-d3}, [r0]
  .long  0xe1a00007                          // mov           r0, r7
  .long  0xe5972000                          // ldr           r2, [r7]
  .long  0xeeb09b46                          // vmov.f64      d9, d6
  .long  0xeeb0ab45                          // vmov.f64      d10, d5
  .long  0xeeb0bb44                          // vmov.f64      d11, d4
  .long  0xe12fff32                          // blx           r2
  .long  0xe5970084                          // ldr           r0, [r7, #132]
  .long  0xe2851008                          // add           r1, r5, #8
  .long  0xe5953004                          // ldr           r3, [r5, #4]
  .long  0xe1a02004                          // mov           r2, r4
  .long  0xeeb04b4b                          // vmov.f64      d4, d11
  .long  0xf420008f                          // vld4.32       {d0-d3}, [r0]
  .long  0xe1a00006                          // mov           r0, r6
  .long  0xeeb05b4a                          // vmov.f64      d5, d10
  .long  0xeeb06b49                          // vmov.f64      d6, d9
  .long  0xeeb07b48                          // vmov.f64      d7, d8
  .long  0xecbd8b08                          // vpop          {d8-d11}
  .long  0xe8bd48f0                          // pop           {r4, r5, r6, r7, fp, lr}
  .long  0xe12fff13                          // bx            r3
#elif defined(__x86_64__)
BALIGN32

HIDDEN _sk_start_pipeline_hsw
.globl _sk_start_pipeline_hsw
FUNCTION(_sk_start_pipeline_hsw)
_sk_start_pipeline_hsw:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,85                               // push          %r13
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  73,137,205                          // mov           %rcx,%r13
  .byte  73,137,214                          // mov           %rdx,%r14
  .byte  72,137,251                          // mov           %rdi,%rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  73,137,199                          // mov           %rax,%r15
  .byte  73,137,244                          // mov           %rsi,%r12
  .byte  72,141,67,8                         // lea           0x8(%rbx),%rax
  .byte  76,57,232                           // cmp           %r13,%rax
  .byte  118,5                               // jbe           28 <_sk_start_pipeline_hsw+0x28>
  .byte  72,137,223                          // mov           %rbx,%rdi
  .byte  235,65                              // jmp           69 <_sk_start_pipeline_hsw+0x69>
  .byte  185,0,0,0,0                         // mov           $0x0,%ecx
  .byte  197,252,87,192                      // vxorps        %ymm0,%ymm0,%ymm0
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  197,236,87,210                      // vxorps        %ymm2,%ymm2,%ymm2
  .byte  197,228,87,219                      // vxorps        %ymm3,%ymm3,%ymm3
  .byte  197,220,87,228                      // vxorps        %ymm4,%ymm4,%ymm4
  .byte  197,212,87,237                      // vxorps        %ymm5,%ymm5,%ymm5
  .byte  197,204,87,246                      // vxorps        %ymm6,%ymm6,%ymm6
  .byte  197,196,87,255                      // vxorps        %ymm7,%ymm7,%ymm7
  .byte  72,137,223                          // mov           %rbx,%rdi
  .byte  76,137,230                          // mov           %r12,%rsi
  .byte  76,137,242                          // mov           %r14,%rdx
  .byte  65,255,215                          // callq         *%r15
  .byte  72,141,123,8                        // lea           0x8(%rbx),%rdi
  .byte  72,131,195,16                       // add           $0x10,%rbx
  .byte  76,57,235                           // cmp           %r13,%rbx
  .byte  72,137,251                          // mov           %rdi,%rbx
  .byte  118,191                             // jbe           28 <_sk_start_pipeline_hsw+0x28>
  .byte  76,137,233                          // mov           %r13,%rcx
  .byte  72,41,249                           // sub           %rdi,%rcx
  .byte  116,41                              // je            9a <_sk_start_pipeline_hsw+0x9a>
  .byte  197,252,87,192                      // vxorps        %ymm0,%ymm0,%ymm0
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  197,236,87,210                      // vxorps        %ymm2,%ymm2,%ymm2
  .byte  197,228,87,219                      // vxorps        %ymm3,%ymm3,%ymm3
  .byte  197,220,87,228                      // vxorps        %ymm4,%ymm4,%ymm4
  .byte  197,212,87,237                      // vxorps        %ymm5,%ymm5,%ymm5
  .byte  197,204,87,246                      // vxorps        %ymm6,%ymm6,%ymm6
  .byte  197,196,87,255                      // vxorps        %ymm7,%ymm7,%ymm7
  .byte  76,137,230                          // mov           %r12,%rsi
  .byte  76,137,242                          // mov           %r14,%rdx
  .byte  65,255,215                          // callq         *%r15
  .byte  76,137,232                          // mov           %r13,%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,93                               // pop           %r13
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  197,248,119                         // vzeroupper
  .byte  195                                 // retq

HIDDEN _sk_just_return_hsw
.globl _sk_just_return_hsw
FUNCTION(_sk_just_return_hsw)
_sk_just_return_hsw:
  .byte  195                                 // retq

HIDDEN _sk_seed_shader_hsw
.globl _sk_seed_shader_hsw
FUNCTION(_sk_seed_shader_hsw)
_sk_seed_shader_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,249,110,199                     // vmovd         %edi,%xmm0
  .byte  196,226,125,88,192                  // vpbroadcastd  %xmm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  196,226,125,24,13,253,63,0,0        // vbroadcastss  0x3ffd(%rip),%ymm1        # 40c0 <_sk_callback_hsw+0x126>
  .byte  197,252,88,193                      // vaddps        %ymm1,%ymm0,%ymm0
  .byte  197,252,88,2                        // vaddps        (%rdx),%ymm0,%ymm0
  .byte  196,226,125,24,16                   // vbroadcastss  (%rax),%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  197,236,88,201                      // vaddps        %ymm1,%ymm2,%ymm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,226,125,24,21,225,63,0,0        // vbroadcastss  0x3fe1(%rip),%ymm2        # 40c4 <_sk_callback_hsw+0x12a>
  .byte  197,228,87,219                      // vxorps        %ymm3,%ymm3,%ymm3
  .byte  197,220,87,228                      // vxorps        %ymm4,%ymm4,%ymm4
  .byte  197,212,87,237                      // vxorps        %ymm5,%ymm5,%ymm5
  .byte  197,204,87,246                      // vxorps        %ymm6,%ymm6,%ymm6
  .byte  197,196,87,255                      // vxorps        %ymm7,%ymm7,%ymm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_constant_color_hsw
.globl _sk_constant_color_hsw
FUNCTION(_sk_constant_color_hsw)
_sk_constant_color_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,226,125,24,0                    // vbroadcastss  (%rax),%ymm0
  .byte  196,226,125,24,72,4                 // vbroadcastss  0x4(%rax),%ymm1
  .byte  196,226,125,24,80,8                 // vbroadcastss  0x8(%rax),%ymm2
  .byte  196,226,125,24,88,12                // vbroadcastss  0xc(%rax),%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clear_hsw
.globl _sk_clear_hsw
FUNCTION(_sk_clear_hsw)
_sk_clear_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,87,192                      // vxorps        %ymm0,%ymm0,%ymm0
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  197,236,87,210                      // vxorps        %ymm2,%ymm2,%ymm2
  .byte  197,228,87,219                      // vxorps        %ymm3,%ymm3,%ymm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcatop_hsw
.globl _sk_srcatop_hsw
FUNCTION(_sk_srcatop_hsw)
_sk_srcatop_hsw:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,204                       // vmulps        %ymm4,%ymm8,%ymm9
  .byte  196,194,69,168,193                  // vfmadd213ps   %ymm9,%ymm7,%ymm0
  .byte  197,60,89,205                       // vmulps        %ymm5,%ymm8,%ymm9
  .byte  196,194,69,168,201                  // vfmadd213ps   %ymm9,%ymm7,%ymm1
  .byte  197,60,89,206                       // vmulps        %ymm6,%ymm8,%ymm9
  .byte  196,194,69,168,209                  // vfmadd213ps   %ymm9,%ymm7,%ymm2
  .byte  197,60,89,199                       // vmulps        %ymm7,%ymm8,%ymm8
  .byte  196,194,69,168,216                  // vfmadd213ps   %ymm8,%ymm7,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstatop_hsw
.globl _sk_dstatop_hsw
FUNCTION(_sk_dstatop_hsw)
_sk_dstatop_hsw:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,199                       // vsubps        %ymm7,%ymm8,%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  196,226,101,184,196                 // vfmadd231ps   %ymm4,%ymm3,%ymm0
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  196,226,101,184,205                 // vfmadd231ps   %ymm5,%ymm3,%ymm1
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  196,226,101,184,214                 // vfmadd231ps   %ymm6,%ymm3,%ymm2
  .byte  197,60,89,195                       // vmulps        %ymm3,%ymm8,%ymm8
  .byte  196,194,69,168,216                  // vfmadd213ps   %ymm8,%ymm7,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcin_hsw
.globl _sk_srcin_hsw
FUNCTION(_sk_srcin_hsw)
_sk_srcin_hsw:
  .byte  197,252,89,199                      // vmulps        %ymm7,%ymm0,%ymm0
  .byte  197,244,89,207                      // vmulps        %ymm7,%ymm1,%ymm1
  .byte  197,236,89,215                      // vmulps        %ymm7,%ymm2,%ymm2
  .byte  197,228,89,223                      // vmulps        %ymm7,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstin_hsw
.globl _sk_dstin_hsw
FUNCTION(_sk_dstin_hsw)
_sk_dstin_hsw:
  .byte  197,228,89,196                      // vmulps        %ymm4,%ymm3,%ymm0
  .byte  197,228,89,205                      // vmulps        %ymm5,%ymm3,%ymm1
  .byte  197,228,89,214                      // vmulps        %ymm6,%ymm3,%ymm2
  .byte  197,228,89,223                      // vmulps        %ymm7,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcout_hsw
.globl _sk_srcout_hsw
FUNCTION(_sk_srcout_hsw)
_sk_srcout_hsw:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,199                       // vsubps        %ymm7,%ymm8,%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstout_hsw
.globl _sk_dstout_hsw
FUNCTION(_sk_dstout_hsw)
_sk_dstout_hsw:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,226,125,88,192                  // vpbroadcastd  %xmm0,%ymm0
  .byte  197,252,92,219                      // vsubps        %ymm3,%ymm0,%ymm3
  .byte  197,228,89,196                      // vmulps        %ymm4,%ymm3,%ymm0
  .byte  197,228,89,205                      // vmulps        %ymm5,%ymm3,%ymm1
  .byte  197,228,89,214                      // vmulps        %ymm6,%ymm3,%ymm2
  .byte  197,228,89,223                      // vmulps        %ymm7,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcover_hsw
.globl _sk_srcover_hsw
FUNCTION(_sk_srcover_hsw)
_sk_srcover_hsw:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  196,194,93,184,192                  // vfmadd231ps   %ymm8,%ymm4,%ymm0
  .byte  196,194,85,184,200                  // vfmadd231ps   %ymm8,%ymm5,%ymm1
  .byte  196,194,77,184,208                  // vfmadd231ps   %ymm8,%ymm6,%ymm2
  .byte  196,194,69,184,216                  // vfmadd231ps   %ymm8,%ymm7,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstover_hsw
.globl _sk_dstover_hsw
FUNCTION(_sk_dstover_hsw)
_sk_dstover_hsw:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,199                       // vsubps        %ymm7,%ymm8,%ymm8
  .byte  196,226,61,168,196                  // vfmadd213ps   %ymm4,%ymm8,%ymm0
  .byte  196,226,61,168,205                  // vfmadd213ps   %ymm5,%ymm8,%ymm1
  .byte  196,226,61,168,214                  // vfmadd213ps   %ymm6,%ymm8,%ymm2
  .byte  196,226,61,168,223                  // vfmadd213ps   %ymm7,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_modulate_hsw
.globl _sk_modulate_hsw
FUNCTION(_sk_modulate_hsw)
_sk_modulate_hsw:
  .byte  197,252,89,196                      // vmulps        %ymm4,%ymm0,%ymm0
  .byte  197,244,89,205                      // vmulps        %ymm5,%ymm1,%ymm1
  .byte  197,236,89,214                      // vmulps        %ymm6,%ymm2,%ymm2
  .byte  197,228,89,223                      // vmulps        %ymm7,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_multiply_hsw
.globl _sk_multiply_hsw
FUNCTION(_sk_multiply_hsw)
_sk_multiply_hsw:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,207                       // vsubps        %ymm7,%ymm8,%ymm9
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,212                       // vmulps        %ymm4,%ymm8,%ymm10
  .byte  196,98,53,184,208                   // vfmadd231ps   %ymm0,%ymm9,%ymm10
  .byte  196,194,93,168,194                  // vfmadd213ps   %ymm10,%ymm4,%ymm0
  .byte  197,52,89,209                       // vmulps        %ymm1,%ymm9,%ymm10
  .byte  196,98,61,184,213                   // vfmadd231ps   %ymm5,%ymm8,%ymm10
  .byte  196,194,85,168,202                  // vfmadd213ps   %ymm10,%ymm5,%ymm1
  .byte  197,52,89,210                       // vmulps        %ymm2,%ymm9,%ymm10
  .byte  196,98,61,184,214                   // vfmadd231ps   %ymm6,%ymm8,%ymm10
  .byte  196,194,77,168,210                  // vfmadd213ps   %ymm10,%ymm6,%ymm2
  .byte  197,52,89,203                       // vmulps        %ymm3,%ymm9,%ymm9
  .byte  196,66,69,168,193                   // vfmadd213ps   %ymm9,%ymm7,%ymm8
  .byte  196,194,69,168,216                  // vfmadd213ps   %ymm8,%ymm7,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_plus__hsw
.globl _sk_plus__hsw
FUNCTION(_sk_plus__hsw)
_sk_plus__hsw:
  .byte  197,252,88,196                      // vaddps        %ymm4,%ymm0,%ymm0
  .byte  197,244,88,205                      // vaddps        %ymm5,%ymm1,%ymm1
  .byte  197,236,88,214                      // vaddps        %ymm6,%ymm2,%ymm2
  .byte  197,228,88,223                      // vaddps        %ymm7,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_screen_hsw
.globl _sk_screen_hsw
FUNCTION(_sk_screen_hsw)
_sk_screen_hsw:
  .byte  197,124,88,196                      // vaddps        %ymm4,%ymm0,%ymm8
  .byte  196,194,93,172,192                  // vfnmadd213ps  %ymm8,%ymm4,%ymm0
  .byte  197,116,88,197                      // vaddps        %ymm5,%ymm1,%ymm8
  .byte  196,194,85,172,200                  // vfnmadd213ps  %ymm8,%ymm5,%ymm1
  .byte  197,108,88,198                      // vaddps        %ymm6,%ymm2,%ymm8
  .byte  196,194,77,172,208                  // vfnmadd213ps  %ymm8,%ymm6,%ymm2
  .byte  197,100,88,199                      // vaddps        %ymm7,%ymm3,%ymm8
  .byte  196,194,69,172,216                  // vfnmadd213ps  %ymm8,%ymm7,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_xor__hsw
.globl _sk_xor__hsw
FUNCTION(_sk_xor__hsw)
_sk_xor__hsw:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,207                       // vsubps        %ymm7,%ymm8,%ymm9
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,212                       // vmulps        %ymm4,%ymm8,%ymm10
  .byte  196,194,53,168,194                  // vfmadd213ps   %ymm10,%ymm9,%ymm0
  .byte  197,180,89,201                      // vmulps        %ymm1,%ymm9,%ymm1
  .byte  196,226,61,184,205                  // vfmadd231ps   %ymm5,%ymm8,%ymm1
  .byte  197,180,89,210                      // vmulps        %ymm2,%ymm9,%ymm2
  .byte  196,226,61,184,214                  // vfmadd231ps   %ymm6,%ymm8,%ymm2
  .byte  197,180,89,219                      // vmulps        %ymm3,%ymm9,%ymm3
  .byte  196,98,69,168,195                   // vfmadd213ps   %ymm3,%ymm7,%ymm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,124,41,195                      // vmovaps       %ymm8,%ymm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_darken_hsw
.globl _sk_darken_hsw
FUNCTION(_sk_darken_hsw)
_sk_darken_hsw:
  .byte  197,124,88,196                      // vaddps        %ymm4,%ymm0,%ymm8
  .byte  197,252,89,199                      // vmulps        %ymm7,%ymm0,%ymm0
  .byte  197,100,89,204                      // vmulps        %ymm4,%ymm3,%ymm9
  .byte  196,193,124,95,193                  // vmaxps        %ymm9,%ymm0,%ymm0
  .byte  197,188,92,192                      // vsubps        %ymm0,%ymm8,%ymm0
  .byte  197,116,88,197                      // vaddps        %ymm5,%ymm1,%ymm8
  .byte  197,244,89,207                      // vmulps        %ymm7,%ymm1,%ymm1
  .byte  197,100,89,205                      // vmulps        %ymm5,%ymm3,%ymm9
  .byte  196,193,116,95,201                  // vmaxps        %ymm9,%ymm1,%ymm1
  .byte  197,188,92,201                      // vsubps        %ymm1,%ymm8,%ymm1
  .byte  197,108,88,198                      // vaddps        %ymm6,%ymm2,%ymm8
  .byte  197,236,89,215                      // vmulps        %ymm7,%ymm2,%ymm2
  .byte  197,100,89,206                      // vmulps        %ymm6,%ymm3,%ymm9
  .byte  196,193,108,95,209                  // vmaxps        %ymm9,%ymm2,%ymm2
  .byte  197,188,92,210                      // vsubps        %ymm2,%ymm8,%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  196,194,69,184,216                  // vfmadd231ps   %ymm8,%ymm7,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_lighten_hsw
.globl _sk_lighten_hsw
FUNCTION(_sk_lighten_hsw)
_sk_lighten_hsw:
  .byte  197,124,88,196                      // vaddps        %ymm4,%ymm0,%ymm8
  .byte  197,252,89,199                      // vmulps        %ymm7,%ymm0,%ymm0
  .byte  197,100,89,204                      // vmulps        %ymm4,%ymm3,%ymm9
  .byte  196,193,124,93,193                  // vminps        %ymm9,%ymm0,%ymm0
  .byte  197,188,92,192                      // vsubps        %ymm0,%ymm8,%ymm0
  .byte  197,116,88,197                      // vaddps        %ymm5,%ymm1,%ymm8
  .byte  197,244,89,207                      // vmulps        %ymm7,%ymm1,%ymm1
  .byte  197,100,89,205                      // vmulps        %ymm5,%ymm3,%ymm9
  .byte  196,193,116,93,201                  // vminps        %ymm9,%ymm1,%ymm1
  .byte  197,188,92,201                      // vsubps        %ymm1,%ymm8,%ymm1
  .byte  197,108,88,198                      // vaddps        %ymm6,%ymm2,%ymm8
  .byte  197,236,89,215                      // vmulps        %ymm7,%ymm2,%ymm2
  .byte  197,100,89,206                      // vmulps        %ymm6,%ymm3,%ymm9
  .byte  196,193,108,93,209                  // vminps        %ymm9,%ymm2,%ymm2
  .byte  197,188,92,210                      // vsubps        %ymm2,%ymm8,%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  196,194,69,184,216                  // vfmadd231ps   %ymm8,%ymm7,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_difference_hsw
.globl _sk_difference_hsw
FUNCTION(_sk_difference_hsw)
_sk_difference_hsw:
  .byte  197,124,88,196                      // vaddps        %ymm4,%ymm0,%ymm8
  .byte  197,252,89,199                      // vmulps        %ymm7,%ymm0,%ymm0
  .byte  197,100,89,204                      // vmulps        %ymm4,%ymm3,%ymm9
  .byte  196,193,124,93,193                  // vminps        %ymm9,%ymm0,%ymm0
  .byte  197,252,88,192                      // vaddps        %ymm0,%ymm0,%ymm0
  .byte  197,188,92,192                      // vsubps        %ymm0,%ymm8,%ymm0
  .byte  197,116,88,197                      // vaddps        %ymm5,%ymm1,%ymm8
  .byte  197,244,89,207                      // vmulps        %ymm7,%ymm1,%ymm1
  .byte  197,100,89,205                      // vmulps        %ymm5,%ymm3,%ymm9
  .byte  196,193,116,93,201                  // vminps        %ymm9,%ymm1,%ymm1
  .byte  197,244,88,201                      // vaddps        %ymm1,%ymm1,%ymm1
  .byte  197,188,92,201                      // vsubps        %ymm1,%ymm8,%ymm1
  .byte  197,108,88,198                      // vaddps        %ymm6,%ymm2,%ymm8
  .byte  197,236,89,215                      // vmulps        %ymm7,%ymm2,%ymm2
  .byte  197,100,89,206                      // vmulps        %ymm6,%ymm3,%ymm9
  .byte  196,193,108,93,209                  // vminps        %ymm9,%ymm2,%ymm2
  .byte  197,236,88,210                      // vaddps        %ymm2,%ymm2,%ymm2
  .byte  197,188,92,210                      // vsubps        %ymm2,%ymm8,%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  196,194,69,184,216                  // vfmadd231ps   %ymm8,%ymm7,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_exclusion_hsw
.globl _sk_exclusion_hsw
FUNCTION(_sk_exclusion_hsw)
_sk_exclusion_hsw:
  .byte  197,124,88,196                      // vaddps        %ymm4,%ymm0,%ymm8
  .byte  197,252,89,196                      // vmulps        %ymm4,%ymm0,%ymm0
  .byte  197,252,88,192                      // vaddps        %ymm0,%ymm0,%ymm0
  .byte  197,188,92,192                      // vsubps        %ymm0,%ymm8,%ymm0
  .byte  197,116,88,197                      // vaddps        %ymm5,%ymm1,%ymm8
  .byte  197,244,89,205                      // vmulps        %ymm5,%ymm1,%ymm1
  .byte  197,244,88,201                      // vaddps        %ymm1,%ymm1,%ymm1
  .byte  197,188,92,201                      // vsubps        %ymm1,%ymm8,%ymm1
  .byte  197,108,88,198                      // vaddps        %ymm6,%ymm2,%ymm8
  .byte  197,236,89,214                      // vmulps        %ymm6,%ymm2,%ymm2
  .byte  197,236,88,210                      // vaddps        %ymm2,%ymm2,%ymm2
  .byte  197,188,92,210                      // vsubps        %ymm2,%ymm8,%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  196,194,69,184,216                  // vfmadd231ps   %ymm8,%ymm7,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_colorburn_hsw
.globl _sk_colorburn_hsw
FUNCTION(_sk_colorburn_hsw)
_sk_colorburn_hsw:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,207                       // vsubps        %ymm7,%ymm8,%ymm9
  .byte  197,52,89,216                       // vmulps        %ymm0,%ymm9,%ymm11
  .byte  196,65,44,87,210                    // vxorps        %ymm10,%ymm10,%ymm10
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,228                       // vmulps        %ymm4,%ymm8,%ymm12
  .byte  197,68,92,236                       // vsubps        %ymm4,%ymm7,%ymm13
  .byte  197,20,89,235                       // vmulps        %ymm3,%ymm13,%ymm13
  .byte  197,20,94,232                       // vdivps        %ymm0,%ymm13,%ymm13
  .byte  196,65,68,93,237                    // vminps        %ymm13,%ymm7,%ymm13
  .byte  196,65,68,92,237                    // vsubps        %ymm13,%ymm7,%ymm13
  .byte  196,66,101,168,235                  // vfmadd213ps   %ymm11,%ymm3,%ymm13
  .byte  196,65,28,88,237                    // vaddps        %ymm13,%ymm12,%ymm13
  .byte  197,28,88,224                       // vaddps        %ymm0,%ymm12,%ymm12
  .byte  196,193,124,194,194,0               // vcmpeqps      %ymm10,%ymm0,%ymm0
  .byte  196,195,21,74,196,0                 // vblendvps     %ymm0,%ymm12,%ymm13,%ymm0
  .byte  197,92,194,231,0                    // vcmpeqps      %ymm7,%ymm4,%ymm12
  .byte  197,36,88,220                       // vaddps        %ymm4,%ymm11,%ymm11
  .byte  196,195,125,74,195,192              // vblendvps     %ymm12,%ymm11,%ymm0,%ymm0
  .byte  197,52,89,217                       // vmulps        %ymm1,%ymm9,%ymm11
  .byte  197,60,89,229                       // vmulps        %ymm5,%ymm8,%ymm12
  .byte  197,68,92,237                       // vsubps        %ymm5,%ymm7,%ymm13
  .byte  197,20,89,235                       // vmulps        %ymm3,%ymm13,%ymm13
  .byte  197,20,94,233                       // vdivps        %ymm1,%ymm13,%ymm13
  .byte  196,65,68,93,237                    // vminps        %ymm13,%ymm7,%ymm13
  .byte  196,65,68,92,237                    // vsubps        %ymm13,%ymm7,%ymm13
  .byte  196,66,101,168,235                  // vfmadd213ps   %ymm11,%ymm3,%ymm13
  .byte  196,65,28,88,237                    // vaddps        %ymm13,%ymm12,%ymm13
  .byte  197,28,88,225                       // vaddps        %ymm1,%ymm12,%ymm12
  .byte  196,193,116,194,202,0               // vcmpeqps      %ymm10,%ymm1,%ymm1
  .byte  196,195,21,74,204,16                // vblendvps     %ymm1,%ymm12,%ymm13,%ymm1
  .byte  197,84,194,231,0                    // vcmpeqps      %ymm7,%ymm5,%ymm12
  .byte  197,36,88,221                       // vaddps        %ymm5,%ymm11,%ymm11
  .byte  196,195,117,74,203,192              // vblendvps     %ymm12,%ymm11,%ymm1,%ymm1
  .byte  197,52,89,202                       // vmulps        %ymm2,%ymm9,%ymm9
  .byte  196,65,108,194,210,0                // vcmpeqps      %ymm10,%ymm2,%ymm10
  .byte  197,60,89,222                       // vmulps        %ymm6,%ymm8,%ymm11
  .byte  197,68,92,230                       // vsubps        %ymm6,%ymm7,%ymm12
  .byte  197,28,89,227                       // vmulps        %ymm3,%ymm12,%ymm12
  .byte  197,28,94,226                       // vdivps        %ymm2,%ymm12,%ymm12
  .byte  197,164,88,210                      // vaddps        %ymm2,%ymm11,%ymm2
  .byte  196,65,68,93,228                    // vminps        %ymm12,%ymm7,%ymm12
  .byte  196,65,68,92,228                    // vsubps        %ymm12,%ymm7,%ymm12
  .byte  196,66,101,168,225                  // vfmadd213ps   %ymm9,%ymm3,%ymm12
  .byte  196,65,36,88,220                    // vaddps        %ymm12,%ymm11,%ymm11
  .byte  196,227,37,74,210,160               // vblendvps     %ymm10,%ymm2,%ymm11,%ymm2
  .byte  197,76,194,215,0                    // vcmpeqps      %ymm7,%ymm6,%ymm10
  .byte  197,52,88,206                       // vaddps        %ymm6,%ymm9,%ymm9
  .byte  196,195,109,74,209,160              // vblendvps     %ymm10,%ymm9,%ymm2,%ymm2
  .byte  196,194,69,184,216                  // vfmadd231ps   %ymm8,%ymm7,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_colordodge_hsw
.globl _sk_colordodge_hsw
FUNCTION(_sk_colordodge_hsw)
_sk_colordodge_hsw:
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,200                     // vmovd         %eax,%xmm9
  .byte  196,66,125,88,201                   // vpbroadcastd  %xmm9,%ymm9
  .byte  197,52,92,215                       // vsubps        %ymm7,%ymm9,%ymm10
  .byte  197,44,89,216                       // vmulps        %ymm0,%ymm10,%ymm11
  .byte  197,52,92,203                       // vsubps        %ymm3,%ymm9,%ymm9
  .byte  197,100,89,228                      // vmulps        %ymm4,%ymm3,%ymm12
  .byte  197,100,92,232                      // vsubps        %ymm0,%ymm3,%ymm13
  .byte  196,65,28,94,229                    // vdivps        %ymm13,%ymm12,%ymm12
  .byte  197,52,89,236                       // vmulps        %ymm4,%ymm9,%ymm13
  .byte  196,65,68,93,228                    // vminps        %ymm12,%ymm7,%ymm12
  .byte  196,66,101,168,227                  // vfmadd213ps   %ymm11,%ymm3,%ymm12
  .byte  196,65,20,88,228                    // vaddps        %ymm12,%ymm13,%ymm12
  .byte  197,20,88,232                       // vaddps        %ymm0,%ymm13,%ymm13
  .byte  197,252,194,195,0                   // vcmpeqps      %ymm3,%ymm0,%ymm0
  .byte  196,195,29,74,197,0                 // vblendvps     %ymm0,%ymm13,%ymm12,%ymm0
  .byte  196,65,92,194,224,0                 // vcmpeqps      %ymm8,%ymm4,%ymm12
  .byte  197,36,88,220                       // vaddps        %ymm4,%ymm11,%ymm11
  .byte  196,195,125,74,195,192              // vblendvps     %ymm12,%ymm11,%ymm0,%ymm0
  .byte  197,44,89,217                       // vmulps        %ymm1,%ymm10,%ymm11
  .byte  197,100,89,229                      // vmulps        %ymm5,%ymm3,%ymm12
  .byte  197,100,92,233                      // vsubps        %ymm1,%ymm3,%ymm13
  .byte  196,65,28,94,229                    // vdivps        %ymm13,%ymm12,%ymm12
  .byte  197,52,89,237                       // vmulps        %ymm5,%ymm9,%ymm13
  .byte  196,65,68,93,228                    // vminps        %ymm12,%ymm7,%ymm12
  .byte  196,66,101,168,227                  // vfmadd213ps   %ymm11,%ymm3,%ymm12
  .byte  196,65,20,88,228                    // vaddps        %ymm12,%ymm13,%ymm12
  .byte  197,20,88,233                       // vaddps        %ymm1,%ymm13,%ymm13
  .byte  197,244,194,203,0                   // vcmpeqps      %ymm3,%ymm1,%ymm1
  .byte  196,195,29,74,205,16                // vblendvps     %ymm1,%ymm13,%ymm12,%ymm1
  .byte  196,65,84,194,224,0                 // vcmpeqps      %ymm8,%ymm5,%ymm12
  .byte  197,36,88,221                       // vaddps        %ymm5,%ymm11,%ymm11
  .byte  196,195,117,74,203,192              // vblendvps     %ymm12,%ymm11,%ymm1,%ymm1
  .byte  197,44,89,210                       // vmulps        %ymm2,%ymm10,%ymm10
  .byte  197,100,89,222                      // vmulps        %ymm6,%ymm3,%ymm11
  .byte  197,100,92,226                      // vsubps        %ymm2,%ymm3,%ymm12
  .byte  196,65,36,94,220                    // vdivps        %ymm12,%ymm11,%ymm11
  .byte  197,52,89,230                       // vmulps        %ymm6,%ymm9,%ymm12
  .byte  196,65,68,93,219                    // vminps        %ymm11,%ymm7,%ymm11
  .byte  196,66,101,168,218                  // vfmadd213ps   %ymm10,%ymm3,%ymm11
  .byte  196,65,28,88,219                    // vaddps        %ymm11,%ymm12,%ymm11
  .byte  197,28,88,226                       // vaddps        %ymm2,%ymm12,%ymm12
  .byte  197,236,194,211,0                   // vcmpeqps      %ymm3,%ymm2,%ymm2
  .byte  196,195,37,74,212,32                // vblendvps     %ymm2,%ymm12,%ymm11,%ymm2
  .byte  196,65,76,194,192,0                 // vcmpeqps      %ymm8,%ymm6,%ymm8
  .byte  197,44,88,214                       // vaddps        %ymm6,%ymm10,%ymm10
  .byte  196,195,109,74,210,128              // vblendvps     %ymm8,%ymm10,%ymm2,%ymm2
  .byte  196,194,69,184,217                  // vfmadd231ps   %ymm9,%ymm7,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_hardlight_hsw
.globl _sk_hardlight_hsw
FUNCTION(_sk_hardlight_hsw)
_sk_hardlight_hsw:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,215                       // vsubps        %ymm7,%ymm8,%ymm10
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,220                       // vmulps        %ymm4,%ymm8,%ymm11
  .byte  196,98,45,184,216                   // vfmadd231ps   %ymm0,%ymm10,%ymm11
  .byte  197,124,88,200                      // vaddps        %ymm0,%ymm0,%ymm9
  .byte  197,52,194,227,2                    // vcmpleps      %ymm3,%ymm9,%ymm12
  .byte  197,124,89,204                      // vmulps        %ymm4,%ymm0,%ymm9
  .byte  196,65,52,88,233                    // vaddps        %ymm9,%ymm9,%ymm13
  .byte  197,100,89,207                      // vmulps        %ymm7,%ymm3,%ymm9
  .byte  197,68,92,244                       // vsubps        %ymm4,%ymm7,%ymm14
  .byte  197,228,92,192                      // vsubps        %ymm0,%ymm3,%ymm0
  .byte  196,193,124,89,198                  // vmulps        %ymm14,%ymm0,%ymm0
  .byte  197,252,88,192                      // vaddps        %ymm0,%ymm0,%ymm0
  .byte  197,180,92,192                      // vsubps        %ymm0,%ymm9,%ymm0
  .byte  196,195,125,74,197,192              // vblendvps     %ymm12,%ymm13,%ymm0,%ymm0
  .byte  196,193,124,88,195                  // vaddps        %ymm11,%ymm0,%ymm0
  .byte  197,44,89,217                       // vmulps        %ymm1,%ymm10,%ymm11
  .byte  196,98,61,184,221                   // vfmadd231ps   %ymm5,%ymm8,%ymm11
  .byte  197,116,88,225                      // vaddps        %ymm1,%ymm1,%ymm12
  .byte  197,28,194,227,2                    // vcmpleps      %ymm3,%ymm12,%ymm12
  .byte  197,116,89,237                      // vmulps        %ymm5,%ymm1,%ymm13
  .byte  196,65,20,88,237                    // vaddps        %ymm13,%ymm13,%ymm13
  .byte  197,68,92,245                       // vsubps        %ymm5,%ymm7,%ymm14
  .byte  197,228,92,201                      // vsubps        %ymm1,%ymm3,%ymm1
  .byte  196,193,116,89,206                  // vmulps        %ymm14,%ymm1,%ymm1
  .byte  197,244,88,201                      // vaddps        %ymm1,%ymm1,%ymm1
  .byte  197,180,92,201                      // vsubps        %ymm1,%ymm9,%ymm1
  .byte  196,195,117,74,205,192              // vblendvps     %ymm12,%ymm13,%ymm1,%ymm1
  .byte  196,193,116,88,203                  // vaddps        %ymm11,%ymm1,%ymm1
  .byte  197,44,89,210                       // vmulps        %ymm2,%ymm10,%ymm10
  .byte  196,98,61,184,214                   // vfmadd231ps   %ymm6,%ymm8,%ymm10
  .byte  197,108,88,218                      // vaddps        %ymm2,%ymm2,%ymm11
  .byte  197,36,194,219,2                    // vcmpleps      %ymm3,%ymm11,%ymm11
  .byte  197,108,89,230                      // vmulps        %ymm6,%ymm2,%ymm12
  .byte  196,65,28,88,228                    // vaddps        %ymm12,%ymm12,%ymm12
  .byte  197,68,92,238                       // vsubps        %ymm6,%ymm7,%ymm13
  .byte  197,228,92,210                      // vsubps        %ymm2,%ymm3,%ymm2
  .byte  196,193,108,89,213                  // vmulps        %ymm13,%ymm2,%ymm2
  .byte  197,236,88,210                      // vaddps        %ymm2,%ymm2,%ymm2
  .byte  197,180,92,210                      // vsubps        %ymm2,%ymm9,%ymm2
  .byte  196,195,109,74,212,176              // vblendvps     %ymm11,%ymm12,%ymm2,%ymm2
  .byte  196,193,108,88,210                  // vaddps        %ymm10,%ymm2,%ymm2
  .byte  196,194,69,184,216                  // vfmadd231ps   %ymm8,%ymm7,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_overlay_hsw
.globl _sk_overlay_hsw
FUNCTION(_sk_overlay_hsw)
_sk_overlay_hsw:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,215                       // vsubps        %ymm7,%ymm8,%ymm10
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,220                       // vmulps        %ymm4,%ymm8,%ymm11
  .byte  196,98,45,184,216                   // vfmadd231ps   %ymm0,%ymm10,%ymm11
  .byte  197,92,88,204                       // vaddps        %ymm4,%ymm4,%ymm9
  .byte  197,52,194,231,2                    // vcmpleps      %ymm7,%ymm9,%ymm12
  .byte  197,124,89,204                      // vmulps        %ymm4,%ymm0,%ymm9
  .byte  196,65,52,88,233                    // vaddps        %ymm9,%ymm9,%ymm13
  .byte  197,100,89,207                      // vmulps        %ymm7,%ymm3,%ymm9
  .byte  197,68,92,244                       // vsubps        %ymm4,%ymm7,%ymm14
  .byte  197,228,92,192                      // vsubps        %ymm0,%ymm3,%ymm0
  .byte  196,193,124,89,198                  // vmulps        %ymm14,%ymm0,%ymm0
  .byte  197,252,88,192                      // vaddps        %ymm0,%ymm0,%ymm0
  .byte  197,180,92,192                      // vsubps        %ymm0,%ymm9,%ymm0
  .byte  196,195,125,74,197,192              // vblendvps     %ymm12,%ymm13,%ymm0,%ymm0
  .byte  196,193,124,88,195                  // vaddps        %ymm11,%ymm0,%ymm0
  .byte  197,44,89,217                       // vmulps        %ymm1,%ymm10,%ymm11
  .byte  196,98,61,184,221                   // vfmadd231ps   %ymm5,%ymm8,%ymm11
  .byte  197,84,88,229                       // vaddps        %ymm5,%ymm5,%ymm12
  .byte  197,28,194,231,2                    // vcmpleps      %ymm7,%ymm12,%ymm12
  .byte  197,116,89,237                      // vmulps        %ymm5,%ymm1,%ymm13
  .byte  196,65,20,88,237                    // vaddps        %ymm13,%ymm13,%ymm13
  .byte  197,68,92,245                       // vsubps        %ymm5,%ymm7,%ymm14
  .byte  197,228,92,201                      // vsubps        %ymm1,%ymm3,%ymm1
  .byte  196,193,116,89,206                  // vmulps        %ymm14,%ymm1,%ymm1
  .byte  197,244,88,201                      // vaddps        %ymm1,%ymm1,%ymm1
  .byte  197,180,92,201                      // vsubps        %ymm1,%ymm9,%ymm1
  .byte  196,195,117,74,205,192              // vblendvps     %ymm12,%ymm13,%ymm1,%ymm1
  .byte  196,193,116,88,203                  // vaddps        %ymm11,%ymm1,%ymm1
  .byte  197,44,89,210                       // vmulps        %ymm2,%ymm10,%ymm10
  .byte  196,98,61,184,214                   // vfmadd231ps   %ymm6,%ymm8,%ymm10
  .byte  197,76,88,222                       // vaddps        %ymm6,%ymm6,%ymm11
  .byte  197,36,194,223,2                    // vcmpleps      %ymm7,%ymm11,%ymm11
  .byte  197,108,89,230                      // vmulps        %ymm6,%ymm2,%ymm12
  .byte  196,65,28,88,228                    // vaddps        %ymm12,%ymm12,%ymm12
  .byte  197,68,92,238                       // vsubps        %ymm6,%ymm7,%ymm13
  .byte  197,228,92,210                      // vsubps        %ymm2,%ymm3,%ymm2
  .byte  196,193,108,89,213                  // vmulps        %ymm13,%ymm2,%ymm2
  .byte  197,236,88,210                      // vaddps        %ymm2,%ymm2,%ymm2
  .byte  197,180,92,210                      // vsubps        %ymm2,%ymm9,%ymm2
  .byte  196,195,109,74,212,176              // vblendvps     %ymm11,%ymm12,%ymm2,%ymm2
  .byte  196,193,108,88,210                  // vaddps        %ymm10,%ymm2,%ymm2
  .byte  196,194,69,184,216                  // vfmadd231ps   %ymm8,%ymm7,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_softlight_hsw
.globl _sk_softlight_hsw
FUNCTION(_sk_softlight_hsw)
_sk_softlight_hsw:
  .byte  197,252,17,84,36,200                // vmovups       %ymm2,-0x38(%rsp)
  .byte  196,65,44,87,210                    // vxorps        %ymm10,%ymm10,%ymm10
  .byte  197,44,194,223,1                    // vcmpltps      %ymm7,%ymm10,%ymm11
  .byte  197,92,94,199                       // vdivps        %ymm7,%ymm4,%ymm8
  .byte  196,67,45,74,224,176                // vblendvps     %ymm11,%ymm8,%ymm10,%ymm12
  .byte  196,65,28,88,196                    // vaddps        %ymm12,%ymm12,%ymm8
  .byte  196,65,60,88,232                    // vaddps        %ymm8,%ymm8,%ymm13
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  196,66,21,168,237                   // vfmadd213ps   %ymm13,%ymm13,%ymm13
  .byte  196,65,28,92,240                    // vsubps        %ymm8,%ymm12,%ymm14
  .byte  184,0,0,224,64                      // mov           $0x40e00000,%eax
  .byte  197,121,110,200                     // vmovd         %eax,%xmm9
  .byte  196,66,125,88,201                   // vpbroadcastd  %xmm9,%ymm9
  .byte  196,65,28,89,249                    // vmulps        %ymm9,%ymm12,%ymm15
  .byte  196,66,21,184,254                   // vfmadd231ps   %ymm14,%ymm13,%ymm15
  .byte  196,65,124,82,236                   // vrsqrtps      %ymm12,%ymm13
  .byte  196,65,124,83,237                   // vrcpps        %ymm13,%ymm13
  .byte  196,65,20,92,236                    // vsubps        %ymm12,%ymm13,%ymm13
  .byte  197,92,88,244                       // vaddps        %ymm4,%ymm4,%ymm14
  .byte  196,65,12,88,246                    // vaddps        %ymm14,%ymm14,%ymm14
  .byte  197,12,194,247,2                    // vcmpleps      %ymm7,%ymm14,%ymm14
  .byte  196,67,21,74,239,224                // vblendvps     %ymm14,%ymm15,%ymm13,%ymm13
  .byte  197,124,88,240                      // vaddps        %ymm0,%ymm0,%ymm14
  .byte  197,12,92,251                       // vsubps        %ymm3,%ymm14,%ymm15
  .byte  196,65,60,92,228                    // vsubps        %ymm12,%ymm8,%ymm12
  .byte  196,98,5,168,227                    // vfmadd213ps   %ymm3,%ymm15,%ymm12
  .byte  197,28,89,228                       // vmulps        %ymm4,%ymm12,%ymm12
  .byte  197,4,89,255                        // vmulps        %ymm7,%ymm15,%ymm15
  .byte  196,65,4,89,237                     // vmulps        %ymm13,%ymm15,%ymm13
  .byte  196,98,101,184,236                  // vfmadd231ps   %ymm4,%ymm3,%ymm13
  .byte  197,12,194,243,2                    // vcmpleps      %ymm3,%ymm14,%ymm14
  .byte  196,195,21,74,212,224               // vblendvps     %ymm14,%ymm12,%ymm13,%ymm2
  .byte  197,84,94,239                       // vdivps        %ymm7,%ymm5,%ymm13
  .byte  196,67,45,74,237,176                // vblendvps     %ymm11,%ymm13,%ymm10,%ymm13
  .byte  196,65,20,88,245                    // vaddps        %ymm13,%ymm13,%ymm14
  .byte  196,65,12,88,246                    // vaddps        %ymm14,%ymm14,%ymm14
  .byte  196,66,13,168,246                   // vfmadd213ps   %ymm14,%ymm14,%ymm14
  .byte  196,65,20,92,248                    // vsubps        %ymm8,%ymm13,%ymm15
  .byte  196,65,4,89,246                     // vmulps        %ymm14,%ymm15,%ymm14
  .byte  196,66,53,184,245                   // vfmadd231ps   %ymm13,%ymm9,%ymm14
  .byte  196,65,124,82,253                   // vrsqrtps      %ymm13,%ymm15
  .byte  196,65,124,83,255                   // vrcpps        %ymm15,%ymm15
  .byte  196,65,4,92,253                     // vsubps        %ymm13,%ymm15,%ymm15
  .byte  197,84,88,229                       // vaddps        %ymm5,%ymm5,%ymm12
  .byte  196,65,28,88,228                    // vaddps        %ymm12,%ymm12,%ymm12
  .byte  197,28,194,231,2                    // vcmpleps      %ymm7,%ymm12,%ymm12
  .byte  196,67,5,74,230,192                 // vblendvps     %ymm12,%ymm14,%ymm15,%ymm12
  .byte  197,116,88,241                      // vaddps        %ymm1,%ymm1,%ymm14
  .byte  196,65,60,92,237                    // vsubps        %ymm13,%ymm8,%ymm13
  .byte  197,12,92,251                       // vsubps        %ymm3,%ymm14,%ymm15
  .byte  196,98,5,168,235                    // vfmadd213ps   %ymm3,%ymm15,%ymm13
  .byte  197,4,89,255                        // vmulps        %ymm7,%ymm15,%ymm15
  .byte  196,65,4,89,228                     // vmulps        %ymm12,%ymm15,%ymm12
  .byte  197,20,89,237                       // vmulps        %ymm5,%ymm13,%ymm13
  .byte  196,98,101,184,229                  // vfmadd231ps   %ymm5,%ymm3,%ymm12
  .byte  197,12,194,243,2                    // vcmpleps      %ymm3,%ymm14,%ymm14
  .byte  196,67,29,74,237,224                // vblendvps     %ymm14,%ymm13,%ymm12,%ymm13
  .byte  197,76,94,231                       // vdivps        %ymm7,%ymm6,%ymm12
  .byte  196,67,45,74,212,176                // vblendvps     %ymm11,%ymm12,%ymm10,%ymm10
  .byte  196,65,44,88,218                    // vaddps        %ymm10,%ymm10,%ymm11
  .byte  196,65,36,88,219                    // vaddps        %ymm11,%ymm11,%ymm11
  .byte  196,66,37,168,219                   // vfmadd213ps   %ymm11,%ymm11,%ymm11
  .byte  196,65,44,92,224                    // vsubps        %ymm8,%ymm10,%ymm12
  .byte  196,65,28,89,219                    // vmulps        %ymm11,%ymm12,%ymm11
  .byte  196,66,45,168,203                   // vfmadd213ps   %ymm11,%ymm10,%ymm9
  .byte  196,65,124,82,218                   // vrsqrtps      %ymm10,%ymm11
  .byte  196,65,124,83,219                   // vrcpps        %ymm11,%ymm11
  .byte  196,65,36,92,218                    // vsubps        %ymm10,%ymm11,%ymm11
  .byte  197,76,88,230                       // vaddps        %ymm6,%ymm6,%ymm12
  .byte  196,65,28,88,228                    // vaddps        %ymm12,%ymm12,%ymm12
  .byte  197,28,194,231,2                    // vcmpleps      %ymm7,%ymm12,%ymm12
  .byte  196,67,37,74,201,192                // vblendvps     %ymm12,%ymm9,%ymm11,%ymm9
  .byte  197,124,16,116,36,200               // vmovups       -0x38(%rsp),%ymm14
  .byte  196,65,12,88,222                    // vaddps        %ymm14,%ymm14,%ymm11
  .byte  197,36,92,227                       // vsubps        %ymm3,%ymm11,%ymm12
  .byte  196,65,60,92,210                    // vsubps        %ymm10,%ymm8,%ymm10
  .byte  196,98,29,168,211                   // vfmadd213ps   %ymm3,%ymm12,%ymm10
  .byte  197,28,89,231                       // vmulps        %ymm7,%ymm12,%ymm12
  .byte  196,65,28,89,201                    // vmulps        %ymm9,%ymm12,%ymm9
  .byte  197,44,89,214                       // vmulps        %ymm6,%ymm10,%ymm10
  .byte  196,98,101,184,206                  // vfmadd231ps   %ymm6,%ymm3,%ymm9
  .byte  197,36,194,219,2                    // vcmpleps      %ymm3,%ymm11,%ymm11
  .byte  196,67,53,74,202,176                // vblendvps     %ymm11,%ymm10,%ymm9,%ymm9
  .byte  197,60,92,215                       // vsubps        %ymm7,%ymm8,%ymm10
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,220                       // vmulps        %ymm4,%ymm8,%ymm11
  .byte  196,98,45,184,216                   // vfmadd231ps   %ymm0,%ymm10,%ymm11
  .byte  196,193,108,88,195                  // vaddps        %ymm11,%ymm2,%ymm0
  .byte  197,172,89,201                      // vmulps        %ymm1,%ymm10,%ymm1
  .byte  196,226,61,184,205                  // vfmadd231ps   %ymm5,%ymm8,%ymm1
  .byte  196,193,116,88,205                  // vaddps        %ymm13,%ymm1,%ymm1
  .byte  196,193,44,89,214                   // vmulps        %ymm14,%ymm10,%ymm2
  .byte  196,226,61,184,214                  // vfmadd231ps   %ymm6,%ymm8,%ymm2
  .byte  196,193,108,88,209                  // vaddps        %ymm9,%ymm2,%ymm2
  .byte  196,194,69,184,216                  // vfmadd231ps   %ymm8,%ymm7,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_0_hsw
.globl _sk_clamp_0_hsw
FUNCTION(_sk_clamp_0_hsw)
_sk_clamp_0_hsw:
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  196,193,124,95,192                  // vmaxps        %ymm8,%ymm0,%ymm0
  .byte  196,193,116,95,200                  // vmaxps        %ymm8,%ymm1,%ymm1
  .byte  196,193,108,95,208                  // vmaxps        %ymm8,%ymm2,%ymm2
  .byte  196,193,100,95,216                  // vmaxps        %ymm8,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_1_hsw
.globl _sk_clamp_1_hsw
FUNCTION(_sk_clamp_1_hsw)
_sk_clamp_1_hsw:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  196,193,124,93,192                  // vminps        %ymm8,%ymm0,%ymm0
  .byte  196,193,116,93,200                  // vminps        %ymm8,%ymm1,%ymm1
  .byte  196,193,108,93,208                  // vminps        %ymm8,%ymm2,%ymm2
  .byte  196,193,100,93,216                  // vminps        %ymm8,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_a_hsw
.globl _sk_clamp_a_hsw
FUNCTION(_sk_clamp_a_hsw)
_sk_clamp_a_hsw:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  196,193,100,93,216                  // vminps        %ymm8,%ymm3,%ymm3
  .byte  197,252,93,195                      // vminps        %ymm3,%ymm0,%ymm0
  .byte  197,244,93,203                      // vminps        %ymm3,%ymm1,%ymm1
  .byte  197,236,93,211                      // vminps        %ymm3,%ymm2,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_set_rgb_hsw
.globl _sk_set_rgb_hsw
FUNCTION(_sk_set_rgb_hsw)
_sk_set_rgb_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,226,125,24,0                    // vbroadcastss  (%rax),%ymm0
  .byte  196,226,125,24,72,4                 // vbroadcastss  0x4(%rax),%ymm1
  .byte  196,226,125,24,80,8                 // vbroadcastss  0x8(%rax),%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_swap_rb_hsw
.globl _sk_swap_rb_hsw
FUNCTION(_sk_swap_rb_hsw)
_sk_swap_rb_hsw:
  .byte  197,124,40,192                      // vmovaps       %ymm0,%ymm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,40,194                      // vmovaps       %ymm2,%ymm0
  .byte  197,124,41,194                      // vmovaps       %ymm8,%ymm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_swap_hsw
.globl _sk_swap_hsw
FUNCTION(_sk_swap_hsw)
_sk_swap_hsw:
  .byte  197,124,40,195                      // vmovaps       %ymm3,%ymm8
  .byte  197,124,40,202                      // vmovaps       %ymm2,%ymm9
  .byte  197,124,40,209                      // vmovaps       %ymm1,%ymm10
  .byte  197,124,40,216                      // vmovaps       %ymm0,%ymm11
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,40,196                      // vmovaps       %ymm4,%ymm0
  .byte  197,252,40,205                      // vmovaps       %ymm5,%ymm1
  .byte  197,252,40,214                      // vmovaps       %ymm6,%ymm2
  .byte  197,252,40,223                      // vmovaps       %ymm7,%ymm3
  .byte  197,124,41,220                      // vmovaps       %ymm11,%ymm4
  .byte  197,124,41,213                      // vmovaps       %ymm10,%ymm5
  .byte  197,124,41,206                      // vmovaps       %ymm9,%ymm6
  .byte  197,124,41,199                      // vmovaps       %ymm8,%ymm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_move_src_dst_hsw
.globl _sk_move_src_dst_hsw
FUNCTION(_sk_move_src_dst_hsw)
_sk_move_src_dst_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,40,224                      // vmovaps       %ymm0,%ymm4
  .byte  197,252,40,233                      // vmovaps       %ymm1,%ymm5
  .byte  197,252,40,242                      // vmovaps       %ymm2,%ymm6
  .byte  197,252,40,251                      // vmovaps       %ymm3,%ymm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_move_dst_src_hsw
.globl _sk_move_dst_src_hsw
FUNCTION(_sk_move_dst_src_hsw)
_sk_move_dst_src_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,40,196                      // vmovaps       %ymm4,%ymm0
  .byte  197,252,40,205                      // vmovaps       %ymm5,%ymm1
  .byte  197,252,40,214                      // vmovaps       %ymm6,%ymm2
  .byte  197,252,40,223                      // vmovaps       %ymm7,%ymm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_premul_hsw
.globl _sk_premul_hsw
FUNCTION(_sk_premul_hsw)
_sk_premul_hsw:
  .byte  197,252,89,195                      // vmulps        %ymm3,%ymm0,%ymm0
  .byte  197,244,89,203                      // vmulps        %ymm3,%ymm1,%ymm1
  .byte  197,236,89,211                      // vmulps        %ymm3,%ymm2,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_unpremul_hsw
.globl _sk_unpremul_hsw
FUNCTION(_sk_unpremul_hsw)
_sk_unpremul_hsw:
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  196,65,100,194,200,0                // vcmpeqps      %ymm8,%ymm3,%ymm9
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,208                     // vmovd         %eax,%xmm10
  .byte  196,66,125,88,210                   // vpbroadcastd  %xmm10,%ymm10
  .byte  197,44,94,211                       // vdivps        %ymm3,%ymm10,%ymm10
  .byte  196,67,45,74,192,144                // vblendvps     %ymm9,%ymm8,%ymm10,%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_from_srgb_hsw
.globl _sk_from_srgb_hsw
FUNCTION(_sk_from_srgb_hsw)
_sk_from_srgb_hsw:
  .byte  184,145,131,158,61                  // mov           $0x3d9e8391,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,89,200                       // vmulps        %ymm0,%ymm8,%ymm9
  .byte  197,124,89,208                      // vmulps        %ymm0,%ymm0,%ymm10
  .byte  184,154,153,153,62                  // mov           $0x3e99999a,%eax
  .byte  197,121,110,216                     // vmovd         %eax,%xmm11
  .byte  196,66,125,88,219                   // vpbroadcastd  %xmm11,%ymm11
  .byte  184,92,143,50,63                    // mov           $0x3f328f5c,%eax
  .byte  197,121,110,224                     // vmovd         %eax,%xmm12
  .byte  196,66,125,88,228                   // vpbroadcastd  %xmm12,%ymm12
  .byte  196,65,125,111,235                  // vmovdqa       %ymm11,%ymm13
  .byte  196,66,125,168,236                  // vfmadd213ps   %ymm12,%ymm0,%ymm13
  .byte  184,10,215,35,59                    // mov           $0x3b23d70a,%eax
  .byte  197,121,110,240                     // vmovd         %eax,%xmm14
  .byte  196,66,125,88,246                   // vpbroadcastd  %xmm14,%ymm14
  .byte  196,66,45,168,238                   // vfmadd213ps   %ymm14,%ymm10,%ymm13
  .byte  184,174,71,97,61                    // mov           $0x3d6147ae,%eax
  .byte  197,121,110,208                     // vmovd         %eax,%xmm10
  .byte  196,66,125,88,210                   // vpbroadcastd  %xmm10,%ymm10
  .byte  196,193,124,194,194,1               // vcmpltps      %ymm10,%ymm0,%ymm0
  .byte  196,195,21,74,193,0                 // vblendvps     %ymm0,%ymm9,%ymm13,%ymm0
  .byte  197,60,89,201                       // vmulps        %ymm1,%ymm8,%ymm9
  .byte  197,116,89,233                      // vmulps        %ymm1,%ymm1,%ymm13
  .byte  196,65,125,111,251                  // vmovdqa       %ymm11,%ymm15
  .byte  196,66,117,168,252                  // vfmadd213ps   %ymm12,%ymm1,%ymm15
  .byte  196,66,21,168,254                   // vfmadd213ps   %ymm14,%ymm13,%ymm15
  .byte  196,193,116,194,202,1               // vcmpltps      %ymm10,%ymm1,%ymm1
  .byte  196,195,5,74,201,16                 // vblendvps     %ymm1,%ymm9,%ymm15,%ymm1
  .byte  197,60,89,194                       // vmulps        %ymm2,%ymm8,%ymm8
  .byte  197,108,89,202                      // vmulps        %ymm2,%ymm2,%ymm9
  .byte  196,66,109,168,220                  // vfmadd213ps   %ymm12,%ymm2,%ymm11
  .byte  196,66,53,168,222                   // vfmadd213ps   %ymm14,%ymm9,%ymm11
  .byte  196,193,108,194,210,1               // vcmpltps      %ymm10,%ymm2,%ymm2
  .byte  196,195,37,74,208,32                // vblendvps     %ymm2,%ymm8,%ymm11,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_to_srgb_hsw
.globl _sk_to_srgb_hsw
FUNCTION(_sk_to_srgb_hsw)
_sk_to_srgb_hsw:
  .byte  197,124,82,192                      // vrsqrtps      %ymm0,%ymm8
  .byte  196,65,124,83,216                   // vrcpps        %ymm8,%ymm11
  .byte  196,65,124,82,224                   // vrsqrtps      %ymm8,%ymm12
  .byte  184,41,92,71,65                     // mov           $0x41475c29,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,89,232                       // vmulps        %ymm0,%ymm8,%ymm13
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,200                     // vmovd         %eax,%xmm9
  .byte  196,66,125,88,201                   // vpbroadcastd  %xmm9,%ymm9
  .byte  184,194,135,210,62                  // mov           $0x3ed287c2,%eax
  .byte  197,121,110,208                     // vmovd         %eax,%xmm10
  .byte  196,66,125,88,210                   // vpbroadcastd  %xmm10,%ymm10
  .byte  184,206,111,48,63                   // mov           $0x3f306fce,%eax
  .byte  197,121,110,240                     // vmovd         %eax,%xmm14
  .byte  196,66,125,88,246                   // vpbroadcastd  %xmm14,%ymm14
  .byte  184,168,87,202,61                   // mov           $0x3dca57a8,%eax
  .byte  53,0,0,0,128                        // xor           $0x80000000,%eax
  .byte  197,121,110,248                     // vmovd         %eax,%xmm15
  .byte  196,66,125,88,255                   // vpbroadcastd  %xmm15,%ymm15
  .byte  196,66,13,168,223                   // vfmadd213ps   %ymm15,%ymm14,%ymm11
  .byte  196,66,45,184,220                   // vfmadd231ps   %ymm12,%ymm10,%ymm11
  .byte  196,65,52,93,219                    // vminps        %ymm11,%ymm9,%ymm11
  .byte  184,4,231,140,59                    // mov           $0x3b8ce704,%eax
  .byte  197,121,110,224                     // vmovd         %eax,%xmm12
  .byte  196,66,125,88,228                   // vpbroadcastd  %xmm12,%ymm12
  .byte  196,193,124,194,196,1               // vcmpltps      %ymm12,%ymm0,%ymm0
  .byte  196,195,37,74,197,0                 // vblendvps     %ymm0,%ymm13,%ymm11,%ymm0
  .byte  197,124,82,217                      // vrsqrtps      %ymm1,%ymm11
  .byte  196,65,124,83,235                   // vrcpps        %ymm11,%ymm13
  .byte  196,65,124,82,219                   // vrsqrtps      %ymm11,%ymm11
  .byte  196,66,13,168,239                   // vfmadd213ps   %ymm15,%ymm14,%ymm13
  .byte  196,66,45,184,235                   // vfmadd231ps   %ymm11,%ymm10,%ymm13
  .byte  197,60,89,217                       // vmulps        %ymm1,%ymm8,%ymm11
  .byte  196,65,52,93,237                    // vminps        %ymm13,%ymm9,%ymm13
  .byte  196,193,116,194,204,1               // vcmpltps      %ymm12,%ymm1,%ymm1
  .byte  196,195,21,74,203,16                // vblendvps     %ymm1,%ymm11,%ymm13,%ymm1
  .byte  197,124,82,218                      // vrsqrtps      %ymm2,%ymm11
  .byte  196,65,124,83,235                   // vrcpps        %ymm11,%ymm13
  .byte  196,66,13,168,239                   // vfmadd213ps   %ymm15,%ymm14,%ymm13
  .byte  196,65,124,82,219                   // vrsqrtps      %ymm11,%ymm11
  .byte  196,66,45,184,235                   // vfmadd231ps   %ymm11,%ymm10,%ymm13
  .byte  196,65,52,93,205                    // vminps        %ymm13,%ymm9,%ymm9
  .byte  197,60,89,194                       // vmulps        %ymm2,%ymm8,%ymm8
  .byte  196,193,108,194,212,1               // vcmpltps      %ymm12,%ymm2,%ymm2
  .byte  196,195,53,74,208,32                // vblendvps     %ymm2,%ymm8,%ymm9,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_rgb_to_hsl_hsw
.globl _sk_rgb_to_hsl_hsw
FUNCTION(_sk_rgb_to_hsl_hsw)
_sk_rgb_to_hsl_hsw:
  .byte  197,252,17,124,36,200               // vmovups       %ymm7,-0x38(%rsp)
  .byte  197,252,40,254                      // vmovaps       %ymm6,%ymm7
  .byte  197,252,40,245                      // vmovaps       %ymm5,%ymm6
  .byte  197,252,40,236                      // vmovaps       %ymm4,%ymm5
  .byte  197,252,40,227                      // vmovaps       %ymm3,%ymm4
  .byte  197,252,40,216                      // vmovaps       %ymm0,%ymm3
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  65,184,171,170,42,62                // mov           $0x3e2aaaab,%r8d
  .byte  184,0,0,192,64                      // mov           $0x40c00000,%eax
  .byte  197,121,110,200                     // vmovd         %eax,%xmm9
  .byte  65,185,0,0,0,64                     // mov           $0x40000000,%r9d
  .byte  184,0,0,128,64                      // mov           $0x40800000,%eax
  .byte  197,121,110,208                     // vmovd         %eax,%xmm10
  .byte  197,100,95,217                      // vmaxps        %ymm1,%ymm3,%ymm11
  .byte  197,36,95,218                       // vmaxps        %ymm2,%ymm11,%ymm11
  .byte  197,100,93,225                      // vminps        %ymm1,%ymm3,%ymm12
  .byte  197,28,93,226                       // vminps        %ymm2,%ymm12,%ymm12
  .byte  196,65,36,92,236                    // vsubps        %ymm12,%ymm11,%ymm13
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  196,65,60,94,197                    // vdivps        %ymm13,%ymm8,%ymm8
  .byte  197,116,194,242,1                   // vcmpltps      %ymm2,%ymm1,%ymm14
  .byte  196,66,125,88,201                   // vpbroadcastd  %xmm9,%ymm9
  .byte  196,65,4,87,255                     // vxorps        %ymm15,%ymm15,%ymm15
  .byte  196,67,5,74,201,224                 // vblendvps     %ymm14,%ymm9,%ymm15,%ymm9
  .byte  197,116,92,242                      // vsubps        %ymm2,%ymm1,%ymm14
  .byte  196,66,61,168,241                   // vfmadd213ps   %ymm9,%ymm8,%ymm14
  .byte  197,236,92,195                      // vsubps        %ymm3,%ymm2,%ymm0
  .byte  197,100,92,201                      // vsubps        %ymm1,%ymm3,%ymm9
  .byte  196,66,125,88,210                   // vpbroadcastd  %xmm10,%ymm10
  .byte  196,66,61,168,202                   // vfmadd213ps   %ymm10,%ymm8,%ymm9
  .byte  196,193,121,110,209                 // vmovd         %r9d,%xmm2
  .byte  196,98,125,88,210                   // vpbroadcastd  %xmm2,%ymm10
  .byte  196,194,61,168,194                  // vfmadd213ps   %ymm10,%ymm8,%ymm0
  .byte  197,164,194,201,0                   // vcmpeqps      %ymm1,%ymm11,%ymm1
  .byte  196,227,53,74,192,16                // vblendvps     %ymm1,%ymm0,%ymm9,%ymm0
  .byte  184,0,0,0,63                        // mov           $0x3f000000,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  197,164,194,211,0                   // vcmpeqps      %ymm3,%ymm11,%ymm2
  .byte  196,195,125,74,198,32               // vblendvps     %ymm2,%ymm14,%ymm0,%ymm0
  .byte  196,193,36,88,220                   // vaddps        %ymm12,%ymm11,%ymm3
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,228,89,209                      // vmulps        %ymm1,%ymm3,%ymm2
  .byte  197,244,194,202,1                   // vcmpltps      %ymm2,%ymm1,%ymm1
  .byte  196,65,44,92,195                    // vsubps        %ymm11,%ymm10,%ymm8
  .byte  196,65,60,92,196                    // vsubps        %ymm12,%ymm8,%ymm8
  .byte  196,195,101,74,200,16               // vblendvps     %ymm1,%ymm8,%ymm3,%ymm1
  .byte  196,193,36,194,220,0                // vcmpeqps      %ymm12,%ymm11,%ymm3
  .byte  197,148,94,201                      // vdivps        %ymm1,%ymm13,%ymm1
  .byte  196,195,125,74,199,48               // vblendvps     %ymm3,%ymm15,%ymm0,%ymm0
  .byte  196,195,117,74,207,48               // vblendvps     %ymm3,%ymm15,%ymm1,%ymm1
  .byte  196,193,121,110,216                 // vmovd         %r8d,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  197,228,89,192                      // vmulps        %ymm0,%ymm3,%ymm0
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,40,220                      // vmovaps       %ymm4,%ymm3
  .byte  197,252,40,229                      // vmovaps       %ymm5,%ymm4
  .byte  197,252,40,238                      // vmovaps       %ymm6,%ymm5
  .byte  197,252,40,247                      // vmovaps       %ymm7,%ymm6
  .byte  197,252,16,124,36,200               // vmovups       -0x38(%rsp),%ymm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_hsl_to_rgb_hsw
.globl _sk_hsl_to_rgb_hsw
FUNCTION(_sk_hsl_to_rgb_hsw)
_sk_hsl_to_rgb_hsw:
  .byte  72,131,236,56                       // sub           $0x38,%rsp
  .byte  197,252,17,60,36                    // vmovups       %ymm7,(%rsp)
  .byte  197,252,17,116,36,224               // vmovups       %ymm6,-0x20(%rsp)
  .byte  197,252,17,108,36,192               // vmovups       %ymm5,-0x40(%rsp)
  .byte  197,252,17,100,36,160               // vmovups       %ymm4,-0x60(%rsp)
  .byte  197,252,17,92,36,128                // vmovups       %ymm3,-0x80(%rsp)
  .byte  197,252,40,233                      // vmovaps       %ymm1,%ymm5
  .byte  184,0,0,0,63                        // mov           $0x3f000000,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,98,125,88,193                   // vpbroadcastd  %xmm1,%ymm8
  .byte  196,193,108,194,200,1               // vcmpltps      %ymm8,%ymm2,%ymm1
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,224                     // vmovd         %eax,%xmm4
  .byte  196,98,125,88,212                   // vpbroadcastd  %xmm4,%ymm10
  .byte  197,172,88,229                      // vaddps        %ymm5,%ymm10,%ymm4
  .byte  197,220,89,226                      // vmulps        %ymm2,%ymm4,%ymm4
  .byte  197,84,88,202                       // vaddps        %ymm2,%ymm5,%ymm9
  .byte  196,98,85,188,202                   // vfnmadd231ps  %ymm2,%ymm5,%ymm9
  .byte  196,99,53,74,204,16                 // vblendvps     %ymm1,%ymm4,%ymm9,%ymm9
  .byte  65,184,0,0,0,64                     // mov           $0x40000000,%r8d
  .byte  184,171,170,170,62                  // mov           $0x3eaaaaab,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,98,125,88,233                   // vpbroadcastd  %xmm1,%ymm13
  .byte  197,148,88,224                      // vaddps        %ymm0,%ymm13,%ymm4
  .byte  184,0,0,0,0                         // mov           $0x0,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,98,125,88,225                   // vpbroadcastd  %xmm1,%ymm12
  .byte  197,172,194,204,1                   // vcmpltps      %ymm4,%ymm10,%ymm1
  .byte  196,65,92,92,218                    // vsubps        %ymm10,%ymm4,%ymm11
  .byte  196,195,93,74,203,16                // vblendvps     %ymm1,%ymm11,%ymm4,%ymm1
  .byte  196,65,92,194,220,1                 // vcmpltps      %ymm12,%ymm4,%ymm11
  .byte  197,44,88,244                       // vaddps        %ymm4,%ymm10,%ymm14
  .byte  196,195,117,74,206,176              // vblendvps     %ymm11,%ymm14,%ymm1,%ymm1
  .byte  196,193,121,110,216                 // vmovd         %r8d,%xmm3
  .byte  196,98,125,88,219                   // vpbroadcastd  %xmm3,%ymm11
  .byte  196,66,109,170,217                  // vfmsub213ps   %ymm9,%ymm2,%ymm11
  .byte  65,184,171,170,42,62                // mov           $0x3e2aaaab,%r8d
  .byte  184,0,0,192,64                      // mov           $0x40c00000,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  196,65,52,92,243                    // vsubps        %ymm11,%ymm9,%ymm14
  .byte  197,12,89,243                       // vmulps        %ymm3,%ymm14,%ymm14
  .byte  184,171,170,42,63                   // mov           $0x3f2aaaab,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,98,125,88,251                   // vpbroadcastd  %xmm3,%ymm15
  .byte  197,132,92,217                      // vsubps        %ymm1,%ymm15,%ymm3
  .byte  196,194,13,168,219                  // vfmadd213ps   %ymm11,%ymm14,%ymm3
  .byte  196,193,116,194,255,1               // vcmpltps      %ymm15,%ymm1,%ymm7
  .byte  196,227,37,74,219,112               // vblendvps     %ymm7,%ymm3,%ymm11,%ymm3
  .byte  196,193,116,194,248,1               // vcmpltps      %ymm8,%ymm1,%ymm7
  .byte  196,195,101,74,249,112              // vblendvps     %ymm7,%ymm9,%ymm3,%ymm7
  .byte  196,193,121,110,216                 // vmovd         %r8d,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  197,244,194,203,1                   // vcmpltps      %ymm3,%ymm1,%ymm1
  .byte  196,194,13,168,227                  // vfmadd213ps   %ymm11,%ymm14,%ymm4
  .byte  196,227,69,74,228,16                // vblendvps     %ymm1,%ymm4,%ymm7,%ymm4
  .byte  197,172,194,200,1                   // vcmpltps      %ymm0,%ymm10,%ymm1
  .byte  196,193,124,92,250                  // vsubps        %ymm10,%ymm0,%ymm7
  .byte  196,227,125,74,207,16               // vblendvps     %ymm1,%ymm7,%ymm0,%ymm1
  .byte  196,193,124,194,252,1               // vcmpltps      %ymm12,%ymm0,%ymm7
  .byte  197,172,88,240                      // vaddps        %ymm0,%ymm10,%ymm6
  .byte  196,227,117,74,206,112              // vblendvps     %ymm7,%ymm6,%ymm1,%ymm1
  .byte  197,132,92,241                      // vsubps        %ymm1,%ymm15,%ymm6
  .byte  196,194,13,168,243                  // vfmadd213ps   %ymm11,%ymm14,%ymm6
  .byte  196,193,116,194,255,1               // vcmpltps      %ymm15,%ymm1,%ymm7
  .byte  196,227,37,74,246,112               // vblendvps     %ymm7,%ymm6,%ymm11,%ymm6
  .byte  196,193,116,194,248,1               // vcmpltps      %ymm8,%ymm1,%ymm7
  .byte  196,195,77,74,241,112               // vblendvps     %ymm7,%ymm9,%ymm6,%ymm6
  .byte  197,244,194,203,1                   // vcmpltps      %ymm3,%ymm1,%ymm1
  .byte  196,193,124,92,253                  // vsubps        %ymm13,%ymm0,%ymm7
  .byte  196,194,13,168,195                  // vfmadd213ps   %ymm11,%ymm14,%ymm0
  .byte  196,227,77,74,200,16                // vblendvps     %ymm1,%ymm0,%ymm6,%ymm1
  .byte  197,172,194,199,1                   // vcmpltps      %ymm7,%ymm10,%ymm0
  .byte  196,193,68,92,242                   // vsubps        %ymm10,%ymm7,%ymm6
  .byte  196,227,69,74,198,0                 // vblendvps     %ymm0,%ymm6,%ymm7,%ymm0
  .byte  196,193,68,194,244,1                // vcmpltps      %ymm12,%ymm7,%ymm6
  .byte  197,44,88,215                       // vaddps        %ymm7,%ymm10,%ymm10
  .byte  196,195,125,74,194,96               // vblendvps     %ymm6,%ymm10,%ymm0,%ymm0
  .byte  196,194,13,168,251                  // vfmadd213ps   %ymm11,%ymm14,%ymm7
  .byte  197,132,92,240                      // vsubps        %ymm0,%ymm15,%ymm6
  .byte  196,194,13,168,243                  // vfmadd213ps   %ymm11,%ymm14,%ymm6
  .byte  196,65,124,194,215,1                // vcmpltps      %ymm15,%ymm0,%ymm10
  .byte  196,227,37,74,246,160               // vblendvps     %ymm10,%ymm6,%ymm11,%ymm6
  .byte  196,65,124,194,192,1                // vcmpltps      %ymm8,%ymm0,%ymm8
  .byte  196,195,77,74,241,128               // vblendvps     %ymm8,%ymm9,%ymm6,%ymm6
  .byte  197,252,194,195,1                   // vcmpltps      %ymm3,%ymm0,%ymm0
  .byte  196,227,77,74,223,0                 // vblendvps     %ymm0,%ymm7,%ymm6,%ymm3
  .byte  197,252,87,192                      // vxorps        %ymm0,%ymm0,%ymm0
  .byte  197,212,194,232,0                   // vcmpeqps      %ymm0,%ymm5,%ymm5
  .byte  196,227,93,74,194,80                // vblendvps     %ymm5,%ymm2,%ymm4,%ymm0
  .byte  196,227,117,74,202,80               // vblendvps     %ymm5,%ymm2,%ymm1,%ymm1
  .byte  196,227,101,74,210,80               // vblendvps     %ymm5,%ymm2,%ymm3,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,16,92,36,128                // vmovups       -0x80(%rsp),%ymm3
  .byte  197,252,16,100,36,160               // vmovups       -0x60(%rsp),%ymm4
  .byte  197,252,16,108,36,192               // vmovups       -0x40(%rsp),%ymm5
  .byte  197,252,16,116,36,224               // vmovups       -0x20(%rsp),%ymm6
  .byte  197,252,16,60,36                    // vmovups       (%rsp),%ymm7
  .byte  72,131,196,56                       // add           $0x38,%rsp
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_scale_1_float_hsw
.globl _sk_scale_1_float_hsw
FUNCTION(_sk_scale_1_float_hsw)
_sk_scale_1_float_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,0                     // vbroadcastss  (%rax),%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_scale_u8_hsw
.globl _sk_scale_u8_hsw
FUNCTION(_sk_scale_u8_hsw)
_sk_scale_u8_hsw:
  .byte  73,137,200                          // mov           %rcx,%r8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,1,248                            // add           %rdi,%rax
  .byte  77,133,192                          // test          %r8,%r8
  .byte  117,56                              // jne           105a <_sk_scale_u8_hsw+0x48>
  .byte  197,122,126,0                       // vmovq         (%rax),%xmm8
  .byte  196,66,125,49,192                   // vpmovzxbd     %xmm8,%ymm8
  .byte  196,65,124,91,192                   // vcvtdq2ps     %ymm8,%ymm8
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,121,110,200                     // vmovd         %eax,%xmm9
  .byte  196,66,125,88,201                   // vpbroadcastd  %xmm9,%ymm9
  .byte  196,65,60,89,193                    // vmulps        %ymm9,%ymm8,%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,137,193                          // mov           %r8,%rcx
  .byte  255,224                             // jmpq          *%rax
  .byte  49,201                              // xor           %ecx,%ecx
  .byte  77,137,194                          // mov           %r8,%r10
  .byte  69,49,201                           // xor           %r9d,%r9d
  .byte  68,15,182,24                        // movzbl        (%rax),%r11d
  .byte  72,255,192                          // inc           %rax
  .byte  73,211,227                          // shl           %cl,%r11
  .byte  77,9,217                            // or            %r11,%r9
  .byte  72,131,193,8                        // add           $0x8,%rcx
  .byte  73,255,202                          // dec           %r10
  .byte  117,234                             // jne           1062 <_sk_scale_u8_hsw+0x50>
  .byte  196,65,249,110,193                  // vmovq         %r9,%xmm8
  .byte  235,167                             // jmp           1026 <_sk_scale_u8_hsw+0x14>

HIDDEN _sk_lerp_1_float_hsw
.globl _sk_lerp_1_float_hsw
FUNCTION(_sk_lerp_1_float_hsw)
_sk_lerp_1_float_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,0                     // vbroadcastss  (%rax),%ymm8
  .byte  197,252,92,196                      // vsubps        %ymm4,%ymm0,%ymm0
  .byte  196,226,61,168,196                  // vfmadd213ps   %ymm4,%ymm8,%ymm0
  .byte  197,244,92,205                      // vsubps        %ymm5,%ymm1,%ymm1
  .byte  196,226,61,168,205                  // vfmadd213ps   %ymm5,%ymm8,%ymm1
  .byte  197,236,92,214                      // vsubps        %ymm6,%ymm2,%ymm2
  .byte  196,226,61,168,214                  // vfmadd213ps   %ymm6,%ymm8,%ymm2
  .byte  197,228,92,223                      // vsubps        %ymm7,%ymm3,%ymm3
  .byte  196,226,61,168,223                  // vfmadd213ps   %ymm7,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_lerp_u8_hsw
.globl _sk_lerp_u8_hsw
FUNCTION(_sk_lerp_u8_hsw)
_sk_lerp_u8_hsw:
  .byte  73,137,200                          // mov           %rcx,%r8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,1,248                            // add           %rdi,%rax
  .byte  77,133,192                          // test          %r8,%r8
  .byte  117,76                              // jne           110a <_sk_lerp_u8_hsw+0x5c>
  .byte  197,122,126,0                       // vmovq         (%rax),%xmm8
  .byte  196,66,125,49,192                   // vpmovzxbd     %xmm8,%ymm8
  .byte  196,65,124,91,192                   // vcvtdq2ps     %ymm8,%ymm8
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,121,110,200                     // vmovd         %eax,%xmm9
  .byte  196,66,125,88,201                   // vpbroadcastd  %xmm9,%ymm9
  .byte  196,65,60,89,193                    // vmulps        %ymm9,%ymm8,%ymm8
  .byte  197,252,92,196                      // vsubps        %ymm4,%ymm0,%ymm0
  .byte  196,226,61,168,196                  // vfmadd213ps   %ymm4,%ymm8,%ymm0
  .byte  197,244,92,205                      // vsubps        %ymm5,%ymm1,%ymm1
  .byte  196,226,61,168,205                  // vfmadd213ps   %ymm5,%ymm8,%ymm1
  .byte  197,236,92,214                      // vsubps        %ymm6,%ymm2,%ymm2
  .byte  196,226,61,168,214                  // vfmadd213ps   %ymm6,%ymm8,%ymm2
  .byte  197,228,92,223                      // vsubps        %ymm7,%ymm3,%ymm3
  .byte  196,226,61,168,223                  // vfmadd213ps   %ymm7,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,137,193                          // mov           %r8,%rcx
  .byte  255,224                             // jmpq          *%rax
  .byte  49,201                              // xor           %ecx,%ecx
  .byte  77,137,194                          // mov           %r8,%r10
  .byte  69,49,201                           // xor           %r9d,%r9d
  .byte  68,15,182,24                        // movzbl        (%rax),%r11d
  .byte  72,255,192                          // inc           %rax
  .byte  73,211,227                          // shl           %cl,%r11
  .byte  77,9,217                            // or            %r11,%r9
  .byte  72,131,193,8                        // add           $0x8,%rcx
  .byte  73,255,202                          // dec           %r10
  .byte  117,234                             // jne           1112 <_sk_lerp_u8_hsw+0x64>
  .byte  196,65,249,110,193                  // vmovq         %r9,%xmm8
  .byte  235,147                             // jmp           10c2 <_sk_lerp_u8_hsw+0x14>

HIDDEN _sk_lerp_565_hsw
.globl _sk_lerp_565_hsw
FUNCTION(_sk_lerp_565_hsw)
_sk_lerp_565_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,16                           // mov           (%rax),%r10
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  15,133,179,0,0,0                    // jne           11f0 <_sk_lerp_565_hsw+0xc1>
  .byte  196,193,122,111,28,122              // vmovdqu       (%r10,%rdi,2),%xmm3
  .byte  196,98,125,51,195                   // vpmovzxwd     %xmm3,%ymm8
  .byte  184,0,248,0,0                       // mov           $0xf800,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  196,193,101,219,216                 // vpand         %ymm8,%ymm3,%ymm3
  .byte  197,124,91,203                      // vcvtdq2ps     %ymm3,%ymm9
  .byte  184,8,33,132,55                     // mov           $0x37842108,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  197,52,89,203                       // vmulps        %ymm3,%ymm9,%ymm9
  .byte  184,224,7,0,0                       // mov           $0x7e0,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  196,193,101,219,216                 // vpand         %ymm8,%ymm3,%ymm3
  .byte  197,124,91,211                      // vcvtdq2ps     %ymm3,%ymm10
  .byte  184,33,8,2,58                       // mov           $0x3a020821,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  197,44,89,211                       // vmulps        %ymm3,%ymm10,%ymm10
  .byte  184,31,0,0,0                        // mov           $0x1f,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  196,193,101,219,216                 // vpand         %ymm8,%ymm3,%ymm3
  .byte  197,124,91,195                      // vcvtdq2ps     %ymm3,%ymm8
  .byte  184,8,33,4,61                       // mov           $0x3d042108,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  197,252,92,196                      // vsubps        %ymm4,%ymm0,%ymm0
  .byte  196,226,53,168,196                  // vfmadd213ps   %ymm4,%ymm9,%ymm0
  .byte  197,244,92,205                      // vsubps        %ymm5,%ymm1,%ymm1
  .byte  196,226,45,168,205                  // vfmadd213ps   %ymm5,%ymm10,%ymm1
  .byte  197,236,92,214                      // vsubps        %ymm6,%ymm2,%ymm2
  .byte  196,226,101,168,214                 // vfmadd213ps   %ymm6,%ymm3,%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  65,128,224,7                        // and           $0x7,%r8b
  .byte  197,225,239,219                     // vpxor         %xmm3,%xmm3,%xmm3
  .byte  65,254,200                          // dec           %r8b
  .byte  65,128,248,6                        // cmp           $0x6,%r8b
  .byte  15,135,59,255,255,255               // ja            1143 <_sk_lerp_565_hsw+0x14>
  .byte  69,15,182,192                       // movzbl        %r8b,%r8d
  .byte  76,141,13,73,0,0,0                  // lea           0x49(%rip),%r9        # 125c <_sk_lerp_565_hsw+0x12d>
  .byte  75,99,4,129                         // movslq        (%r9,%r8,4),%rax
  .byte  76,1,200                            // add           %r9,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  197,225,239,219                     // vpxor         %xmm3,%xmm3,%xmm3
  .byte  196,193,97,196,92,122,12,6          // vpinsrw       $0x6,0xc(%r10,%rdi,2),%xmm3,%xmm3
  .byte  196,193,97,196,92,122,10,5          // vpinsrw       $0x5,0xa(%r10,%rdi,2),%xmm3,%xmm3
  .byte  196,193,97,196,92,122,8,4           // vpinsrw       $0x4,0x8(%r10,%rdi,2),%xmm3,%xmm3
  .byte  196,193,97,196,92,122,6,3           // vpinsrw       $0x3,0x6(%r10,%rdi,2),%xmm3,%xmm3
  .byte  196,193,97,196,92,122,4,2           // vpinsrw       $0x2,0x4(%r10,%rdi,2),%xmm3,%xmm3
  .byte  196,193,97,196,92,122,2,1           // vpinsrw       $0x1,0x2(%r10,%rdi,2),%xmm3,%xmm3
  .byte  196,193,97,196,28,122,0             // vpinsrw       $0x0,(%r10,%rdi,2),%xmm3,%xmm3
  .byte  233,231,254,255,255                 // jmpq          1143 <_sk_lerp_565_hsw+0x14>
  .byte  244                                 // hlt
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  236                                 // in            (%dx),%al
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,228                             // jmpq          *%rsp
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  220,255                             // fdivr         %st,%st(7)
  .byte  255                                 // (bad)
  .byte  255,212                             // callq         *%rsp
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,204                             // dec           %esp
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,192                             // inc           %eax
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_load_tables_hsw
.globl _sk_load_tables_hsw
FUNCTION(_sk_load_tables_hsw)
_sk_load_tables_hsw:
  .byte  73,137,200                          // mov           %rcx,%r8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,141,12,189,0,0,0,0               // lea           0x0(,%rdi,4),%r9
  .byte  76,3,8                              // add           (%rax),%r9
  .byte  77,133,192                          // test          %r8,%r8
  .byte  117,109                             // jne           12fa <_sk_load_tables_hsw+0x82>
  .byte  196,193,126,111,25                  // vmovdqu       (%r9),%ymm3
  .byte  197,229,219,13,6,47,0,0             // vpand         0x2f06(%rip),%ymm3,%ymm1        # 41a0 <_sk_callback_hsw+0x206>
  .byte  196,65,61,118,192                   // vpcmpeqd      %ymm8,%ymm8,%ymm8
  .byte  72,139,72,8                         // mov           0x8(%rax),%rcx
  .byte  76,139,72,16                        // mov           0x10(%rax),%r9
  .byte  197,237,118,210                     // vpcmpeqd      %ymm2,%ymm2,%ymm2
  .byte  196,226,109,146,4,137               // vgatherdps    %ymm2,(%rcx,%ymm1,4),%ymm0
  .byte  196,226,101,0,21,6,47,0,0           // vpshufb       0x2f06(%rip),%ymm3,%ymm2        # 41c0 <_sk_callback_hsw+0x226>
  .byte  196,65,53,118,201                   // vpcmpeqd      %ymm9,%ymm9,%ymm9
  .byte  196,194,53,146,12,145               // vgatherdps    %ymm9,(%r9,%ymm2,4),%ymm1
  .byte  72,139,64,24                        // mov           0x18(%rax),%rax
  .byte  196,98,101,0,13,14,47,0,0           // vpshufb       0x2f0e(%rip),%ymm3,%ymm9        # 41e0 <_sk_callback_hsw+0x246>
  .byte  196,162,61,146,20,136               // vgatherdps    %ymm8,(%rax,%ymm9,4),%ymm2
  .byte  197,229,114,211,24                  // vpsrld        $0x18,%ymm3,%ymm3
  .byte  197,124,91,195                      // vcvtdq2ps     %ymm3,%ymm8
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,137,193                          // mov           %r8,%rcx
  .byte  255,224                             // jmpq          *%rax
  .byte  185,8,0,0,0                         // mov           $0x8,%ecx
  .byte  68,41,193                           // sub           %r8d,%ecx
  .byte  192,225,3                           // shl           $0x3,%cl
  .byte  73,199,194,255,255,255,255          // mov           $0xffffffffffffffff,%r10
  .byte  73,211,234                          // shr           %cl,%r10
  .byte  196,193,249,110,194                 // vmovq         %r10,%xmm0
  .byte  196,226,125,33,192                  // vpmovsxbd     %xmm0,%ymm0
  .byte  196,194,125,140,25                  // vpmaskmovd    (%r9),%ymm0,%ymm3
  .byte  233,111,255,255,255                 // jmpq          1292 <_sk_load_tables_hsw+0x1a>

HIDDEN _sk_load_tables_u16_be_hsw
.globl _sk_load_tables_u16_be_hsw
FUNCTION(_sk_load_tables_u16_be_hsw)
_sk_load_tables_u16_be_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  76,141,12,189,0,0,0,0               // lea           0x0(,%rdi,4),%r9
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  15,133,208,0,0,0                    // jne           1409 <_sk_load_tables_u16_be_hsw+0xe6>
  .byte  196,1,121,16,4,72                   // vmovupd       (%r8,%r9,2),%xmm8
  .byte  196,129,121,16,84,72,16             // vmovupd       0x10(%r8,%r9,2),%xmm2
  .byte  196,129,121,16,92,72,32             // vmovupd       0x20(%r8,%r9,2),%xmm3
  .byte  196,1,122,111,76,72,48              // vmovdqu       0x30(%r8,%r9,2),%xmm9
  .byte  197,185,97,194                      // vpunpcklwd    %xmm2,%xmm8,%xmm0
  .byte  197,185,105,210                     // vpunpckhwd    %xmm2,%xmm8,%xmm2
  .byte  196,193,97,97,201                   // vpunpcklwd    %xmm9,%xmm3,%xmm1
  .byte  196,193,97,105,217                  // vpunpckhwd    %xmm9,%xmm3,%xmm3
  .byte  197,121,97,194                      // vpunpcklwd    %xmm2,%xmm0,%xmm8
  .byte  197,121,105,202                     // vpunpckhwd    %xmm2,%xmm0,%xmm9
  .byte  197,241,97,195                      // vpunpcklwd    %xmm3,%xmm1,%xmm0
  .byte  197,113,105,235                     // vpunpckhwd    %xmm3,%xmm1,%xmm13
  .byte  197,185,108,200                     // vpunpcklqdq   %xmm0,%xmm8,%xmm1
  .byte  197,185,109,208                     // vpunpckhqdq   %xmm0,%xmm8,%xmm2
  .byte  196,65,49,108,197                   // vpunpcklqdq   %xmm13,%xmm9,%xmm8
  .byte  197,121,111,21,149,47,0,0           // vmovdqa       0x2f95(%rip),%xmm10        # 4320 <_sk_callback_hsw+0x386>
  .byte  196,193,113,219,194                 // vpand         %xmm10,%xmm1,%xmm0
  .byte  196,226,125,51,200                  // vpmovzxwd     %xmm0,%ymm1
  .byte  196,65,37,118,219                   // vpcmpeqd      %ymm11,%ymm11,%ymm11
  .byte  76,139,64,8                         // mov           0x8(%rax),%r8
  .byte  76,139,72,16                        // mov           0x10(%rax),%r9
  .byte  196,65,29,118,228                   // vpcmpeqd      %ymm12,%ymm12,%ymm12
  .byte  196,194,29,146,4,136                // vgatherdps    %ymm12,(%r8,%ymm1,4),%ymm0
  .byte  196,193,105,219,202                 // vpand         %xmm10,%xmm2,%xmm1
  .byte  196,226,125,51,209                  // vpmovzxwd     %xmm1,%ymm2
  .byte  196,65,29,118,228                   // vpcmpeqd      %ymm12,%ymm12,%ymm12
  .byte  196,194,29,146,12,145               // vgatherdps    %ymm12,(%r9,%ymm2,4),%ymm1
  .byte  72,139,64,24                        // mov           0x18(%rax),%rax
  .byte  196,193,57,219,210                  // vpand         %xmm10,%xmm8,%xmm2
  .byte  196,98,125,51,194                   // vpmovzxwd     %xmm2,%ymm8
  .byte  196,162,37,146,20,128               // vgatherdps    %ymm11,(%rax,%ymm8,4),%ymm2
  .byte  184,128,0,128,55                    // mov           $0x37800080,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,98,125,88,195                   // vpbroadcastd  %xmm3,%ymm8
  .byte  196,193,49,109,221                  // vpunpckhqdq   %xmm13,%xmm9,%xmm3
  .byte  197,177,113,243,8                   // vpsllw        $0x8,%xmm3,%xmm9
  .byte  197,225,113,211,8                   // vpsrlw        $0x8,%xmm3,%xmm3
  .byte  197,177,235,219                     // vpor          %xmm3,%xmm9,%xmm3
  .byte  196,226,125,51,219                  // vpmovzxwd     %xmm3,%ymm3
  .byte  197,252,91,219                      // vcvtdq2ps     %ymm3,%ymm3
  .byte  196,193,100,89,216                  // vmulps        %ymm8,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,1,123,16,4,72                   // vmovsd        (%r8,%r9,2),%xmm8
  .byte  196,65,49,239,201                   // vpxor         %xmm9,%xmm9,%xmm9
  .byte  72,131,249,1                        // cmp           $0x1,%rcx
  .byte  116,85                              // je            146f <_sk_load_tables_u16_be_hsw+0x14c>
  .byte  196,1,57,22,68,72,8                 // vmovhpd       0x8(%r8,%r9,2),%xmm8,%xmm8
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  114,72                              // jb            146f <_sk_load_tables_u16_be_hsw+0x14c>
  .byte  196,129,123,16,84,72,16             // vmovsd        0x10(%r8,%r9,2),%xmm2
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  116,72                              // je            147c <_sk_load_tables_u16_be_hsw+0x159>
  .byte  196,129,105,22,84,72,24             // vmovhpd       0x18(%r8,%r9,2),%xmm2,%xmm2
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  114,59                              // jb            147c <_sk_load_tables_u16_be_hsw+0x159>
  .byte  196,129,123,16,92,72,32             // vmovsd        0x20(%r8,%r9,2),%xmm3
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  15,132,2,255,255,255                // je            1354 <_sk_load_tables_u16_be_hsw+0x31>
  .byte  196,129,97,22,92,72,40              // vmovhpd       0x28(%r8,%r9,2),%xmm3,%xmm3
  .byte  72,131,249,7                        // cmp           $0x7,%rcx
  .byte  15,130,241,254,255,255              // jb            1354 <_sk_load_tables_u16_be_hsw+0x31>
  .byte  196,1,122,126,76,72,48              // vmovq         0x30(%r8,%r9,2),%xmm9
  .byte  233,229,254,255,255                 // jmpq          1354 <_sk_load_tables_u16_be_hsw+0x31>
  .byte  197,225,87,219                      // vxorpd        %xmm3,%xmm3,%xmm3
  .byte  197,233,87,210                      // vxorpd        %xmm2,%xmm2,%xmm2
  .byte  233,216,254,255,255                 // jmpq          1354 <_sk_load_tables_u16_be_hsw+0x31>
  .byte  197,225,87,219                      // vxorpd        %xmm3,%xmm3,%xmm3
  .byte  233,207,254,255,255                 // jmpq          1354 <_sk_load_tables_u16_be_hsw+0x31>

HIDDEN _sk_load_tables_rgb_u16_be_hsw
.globl _sk_load_tables_rgb_u16_be_hsw
FUNCTION(_sk_load_tables_rgb_u16_be_hsw)
_sk_load_tables_rgb_u16_be_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  76,141,12,127                       // lea           (%rdi,%rdi,2),%r9
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  15,133,198,0,0,0                    // jne           155d <_sk_load_tables_rgb_u16_be_hsw+0xd8>
  .byte  196,129,122,111,4,72                // vmovdqu       (%r8,%r9,2),%xmm0
  .byte  196,129,122,111,84,72,12            // vmovdqu       0xc(%r8,%r9,2),%xmm2
  .byte  196,129,122,111,76,72,24            // vmovdqu       0x18(%r8,%r9,2),%xmm1
  .byte  196,129,122,111,92,72,32            // vmovdqu       0x20(%r8,%r9,2),%xmm3
  .byte  197,225,115,219,4                   // vpsrldq       $0x4,%xmm3,%xmm3
  .byte  197,185,115,216,6                   // vpsrldq       $0x6,%xmm0,%xmm8
  .byte  197,177,115,218,6                   // vpsrldq       $0x6,%xmm2,%xmm9
  .byte  197,161,115,217,6                   // vpsrldq       $0x6,%xmm1,%xmm11
  .byte  197,169,115,219,6                   // vpsrldq       $0x6,%xmm3,%xmm10
  .byte  197,249,97,194                      // vpunpcklwd    %xmm2,%xmm0,%xmm0
  .byte  196,193,57,97,209                   // vpunpcklwd    %xmm9,%xmm8,%xmm2
  .byte  197,241,97,203                      // vpunpcklwd    %xmm3,%xmm1,%xmm1
  .byte  196,193,33,97,218                   // vpunpcklwd    %xmm10,%xmm11,%xmm3
  .byte  197,121,97,194                      // vpunpcklwd    %xmm2,%xmm0,%xmm8
  .byte  197,249,105,194                     // vpunpckhwd    %xmm2,%xmm0,%xmm0
  .byte  197,241,97,211                      // vpunpcklwd    %xmm3,%xmm1,%xmm2
  .byte  197,241,105,203                     // vpunpckhwd    %xmm3,%xmm1,%xmm1
  .byte  197,185,108,218                     // vpunpcklqdq   %xmm2,%xmm8,%xmm3
  .byte  197,185,109,210                     // vpunpckhqdq   %xmm2,%xmm8,%xmm2
  .byte  197,121,108,193                     // vpunpcklqdq   %xmm1,%xmm0,%xmm8
  .byte  197,121,111,13,47,46,0,0            // vmovdqa       0x2e2f(%rip),%xmm9        # 4330 <_sk_callback_hsw+0x396>
  .byte  196,193,97,219,193                  // vpand         %xmm9,%xmm3,%xmm0
  .byte  196,226,125,51,200                  // vpmovzxwd     %xmm0,%ymm1
  .byte  197,229,118,219                     // vpcmpeqd      %ymm3,%ymm3,%ymm3
  .byte  76,139,64,8                         // mov           0x8(%rax),%r8
  .byte  76,139,72,16                        // mov           0x10(%rax),%r9
  .byte  196,65,45,118,210                   // vpcmpeqd      %ymm10,%ymm10,%ymm10
  .byte  196,194,45,146,4,136                // vgatherdps    %ymm10,(%r8,%ymm1,4),%ymm0
  .byte  196,193,105,219,201                 // vpand         %xmm9,%xmm2,%xmm1
  .byte  196,226,125,51,209                  // vpmovzxwd     %xmm1,%ymm2
  .byte  196,65,45,118,210                   // vpcmpeqd      %ymm10,%ymm10,%ymm10
  .byte  196,194,45,146,12,145               // vgatherdps    %ymm10,(%r9,%ymm2,4),%ymm1
  .byte  72,139,64,24                        // mov           0x18(%rax),%rax
  .byte  196,193,57,219,209                  // vpand         %xmm9,%xmm8,%xmm2
  .byte  196,98,125,51,194                   // vpmovzxwd     %xmm2,%ymm8
  .byte  196,162,101,146,20,128              // vgatherdps    %ymm3,(%rax,%ymm8,4),%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,129,121,110,4,72                // vmovd         (%r8,%r9,2),%xmm0
  .byte  196,129,121,196,68,72,4,2           // vpinsrw       $0x2,0x4(%r8,%r9,2),%xmm0,%xmm0
  .byte  72,131,249,1                        // cmp           $0x1,%rcx
  .byte  117,5                               // jne           1576 <_sk_load_tables_rgb_u16_be_hsw+0xf1>
  .byte  233,85,255,255,255                  // jmpq          14cb <_sk_load_tables_rgb_u16_be_hsw+0x46>
  .byte  196,129,121,110,76,72,6             // vmovd         0x6(%r8,%r9,2),%xmm1
  .byte  196,1,113,196,68,72,10,2            // vpinsrw       $0x2,0xa(%r8,%r9,2),%xmm1,%xmm8
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  114,26                              // jb            15a5 <_sk_load_tables_rgb_u16_be_hsw+0x120>
  .byte  196,129,121,110,76,72,12            // vmovd         0xc(%r8,%r9,2),%xmm1
  .byte  196,129,113,196,84,72,16,2          // vpinsrw       $0x2,0x10(%r8,%r9,2),%xmm1,%xmm2
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  117,10                              // jne           15aa <_sk_load_tables_rgb_u16_be_hsw+0x125>
  .byte  233,38,255,255,255                  // jmpq          14cb <_sk_load_tables_rgb_u16_be_hsw+0x46>
  .byte  233,33,255,255,255                  // jmpq          14cb <_sk_load_tables_rgb_u16_be_hsw+0x46>
  .byte  196,129,121,110,76,72,18            // vmovd         0x12(%r8,%r9,2),%xmm1
  .byte  196,1,113,196,76,72,22,2            // vpinsrw       $0x2,0x16(%r8,%r9,2),%xmm1,%xmm9
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  114,26                              // jb            15d9 <_sk_load_tables_rgb_u16_be_hsw+0x154>
  .byte  196,129,121,110,76,72,24            // vmovd         0x18(%r8,%r9,2),%xmm1
  .byte  196,129,113,196,76,72,28,2          // vpinsrw       $0x2,0x1c(%r8,%r9,2),%xmm1,%xmm1
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  117,10                              // jne           15de <_sk_load_tables_rgb_u16_be_hsw+0x159>
  .byte  233,242,254,255,255                 // jmpq          14cb <_sk_load_tables_rgb_u16_be_hsw+0x46>
  .byte  233,237,254,255,255                 // jmpq          14cb <_sk_load_tables_rgb_u16_be_hsw+0x46>
  .byte  196,129,121,110,92,72,30            // vmovd         0x1e(%r8,%r9,2),%xmm3
  .byte  196,1,97,196,92,72,34,2             // vpinsrw       $0x2,0x22(%r8,%r9,2),%xmm3,%xmm11
  .byte  72,131,249,7                        // cmp           $0x7,%rcx
  .byte  114,20                              // jb            1607 <_sk_load_tables_rgb_u16_be_hsw+0x182>
  .byte  196,129,121,110,92,72,36            // vmovd         0x24(%r8,%r9,2),%xmm3
  .byte  196,129,97,196,92,72,40,2           // vpinsrw       $0x2,0x28(%r8,%r9,2),%xmm3,%xmm3
  .byte  233,196,254,255,255                 // jmpq          14cb <_sk_load_tables_rgb_u16_be_hsw+0x46>
  .byte  233,191,254,255,255                 // jmpq          14cb <_sk_load_tables_rgb_u16_be_hsw+0x46>

HIDDEN _sk_byte_tables_hsw
.globl _sk_byte_tables_hsw
FUNCTION(_sk_byte_tables_hsw)
_sk_byte_tables_hsw:
  .byte  85                                  // push          %rbp
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,85                               // push          %r13
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,127,67                   // mov           $0x437f0000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  197,253,91,192                      // vcvtps2dq     %ymm0,%ymm0
  .byte  196,195,249,22,192,1                // vpextrq       $0x1,%xmm0,%r8
  .byte  68,137,197                          // mov           %r8d,%ebp
  .byte  77,137,194                          // mov           %r8,%r10
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  196,193,249,126,192                 // vmovq         %xmm0,%r8
  .byte  69,137,195                          // mov           %r8d,%r11d
  .byte  77,137,199                          // mov           %r8,%r15
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  196,227,125,57,192,1                // vextracti128  $0x1,%ymm0,%xmm0
  .byte  196,195,249,22,192,1                // vpextrq       $0x1,%xmm0,%r8
  .byte  69,137,198                          // mov           %r8d,%r14d
  .byte  77,137,196                          // mov           %r8,%r12
  .byte  73,193,236,32                       // shr           $0x20,%r12
  .byte  196,225,249,126,195                 // vmovq         %xmm0,%rbx
  .byte  65,137,221                          // mov           %ebx,%r13d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  76,139,64,8                         // mov           0x8(%rax),%r8
  .byte  196,131,121,32,4,25,0               // vpinsrb       $0x0,(%r9,%r11,1),%xmm0,%xmm0
  .byte  196,131,121,32,4,57,1               // vpinsrb       $0x1,(%r9,%r15,1),%xmm0,%xmm0
  .byte  65,15,182,44,41                     // movzbl        (%r9,%rbp,1),%ebp
  .byte  196,227,121,32,197,2                // vpinsrb       $0x2,%ebp,%xmm0,%xmm0
  .byte  67,15,182,44,17                     // movzbl        (%r9,%r10,1),%ebp
  .byte  196,227,121,32,197,3                // vpinsrb       $0x3,%ebp,%xmm0,%xmm0
  .byte  67,15,182,44,41                     // movzbl        (%r9,%r13,1),%ebp
  .byte  196,227,121,32,197,4                // vpinsrb       $0x4,%ebp,%xmm0,%xmm0
  .byte  65,15,182,44,25                     // movzbl        (%r9,%rbx,1),%ebp
  .byte  196,227,121,32,197,5                // vpinsrb       $0x5,%ebp,%xmm0,%xmm0
  .byte  67,15,182,44,49                     // movzbl        (%r9,%r14,1),%ebp
  .byte  196,227,121,32,197,6                // vpinsrb       $0x6,%ebp,%xmm0,%xmm0
  .byte  67,15,182,44,33                     // movzbl        (%r9,%r12,1),%ebp
  .byte  196,227,121,32,197,7                // vpinsrb       $0x7,%ebp,%xmm0,%xmm0
  .byte  196,226,125,49,192                  // vpmovzxbd     %xmm0,%ymm0
  .byte  197,124,91,208                      // vcvtdq2ps     %ymm0,%ymm10
  .byte  189,129,128,128,59                  // mov           $0x3b808081,%ebp
  .byte  197,249,110,197                     // vmovd         %ebp,%xmm0
  .byte  196,98,125,88,200                   // vpbroadcastd  %xmm0,%ymm9
  .byte  196,193,44,89,193                   // vmulps        %ymm9,%ymm10,%ymm0
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  197,253,91,201                      // vcvtps2dq     %ymm1,%ymm1
  .byte  196,227,249,22,205,1                // vpextrq       $0x1,%xmm1,%rbp
  .byte  65,137,233                          // mov           %ebp,%r9d
  .byte  72,193,237,32                       // shr           $0x20,%rbp
  .byte  196,225,249,126,203                 // vmovq         %xmm1,%rbx
  .byte  65,137,218                          // mov           %ebx,%r10d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,227,125,57,201,1                // vextracti128  $0x1,%ymm1,%xmm1
  .byte  196,195,249,22,203,1                // vpextrq       $0x1,%xmm1,%r11
  .byte  69,137,222                          // mov           %r11d,%r14d
  .byte  73,193,235,32                       // shr           $0x20,%r11
  .byte  196,193,249,126,207                 // vmovq         %xmm1,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  196,131,121,32,12,16,0              // vpinsrb       $0x0,(%r8,%r10,1),%xmm0,%xmm1
  .byte  196,195,113,32,12,24,1              // vpinsrb       $0x1,(%r8,%rbx,1),%xmm1,%xmm1
  .byte  67,15,182,28,8                      // movzbl        (%r8,%r9,1),%ebx
  .byte  196,227,113,32,203,2                // vpinsrb       $0x2,%ebx,%xmm1,%xmm1
  .byte  65,15,182,44,40                     // movzbl        (%r8,%rbp,1),%ebp
  .byte  196,227,113,32,205,3                // vpinsrb       $0x3,%ebp,%xmm1,%xmm1
  .byte  67,15,182,44,32                     // movzbl        (%r8,%r12,1),%ebp
  .byte  196,227,113,32,205,4                // vpinsrb       $0x4,%ebp,%xmm1,%xmm1
  .byte  67,15,182,44,56                     // movzbl        (%r8,%r15,1),%ebp
  .byte  196,227,113,32,205,5                // vpinsrb       $0x5,%ebp,%xmm1,%xmm1
  .byte  67,15,182,44,48                     // movzbl        (%r8,%r14,1),%ebp
  .byte  196,227,113,32,205,6                // vpinsrb       $0x6,%ebp,%xmm1,%xmm1
  .byte  67,15,182,44,24                     // movzbl        (%r8,%r11,1),%ebp
  .byte  196,227,113,32,205,7                // vpinsrb       $0x7,%ebp,%xmm1,%xmm1
  .byte  196,226,125,49,201                  // vpmovzxbd     %xmm1,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  197,180,89,201                      // vmulps        %ymm1,%ymm9,%ymm1
  .byte  76,139,64,16                        // mov           0x10(%rax),%r8
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  197,253,91,210                      // vcvtps2dq     %ymm2,%ymm2
  .byte  196,227,249,22,213,1                // vpextrq       $0x1,%xmm2,%rbp
  .byte  65,137,233                          // mov           %ebp,%r9d
  .byte  72,193,237,32                       // shr           $0x20,%rbp
  .byte  196,225,249,126,211                 // vmovq         %xmm2,%rbx
  .byte  65,137,218                          // mov           %ebx,%r10d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,227,125,57,210,1                // vextracti128  $0x1,%ymm2,%xmm2
  .byte  196,195,249,22,211,1                // vpextrq       $0x1,%xmm2,%r11
  .byte  69,137,222                          // mov           %r11d,%r14d
  .byte  73,193,235,32                       // shr           $0x20,%r11
  .byte  196,193,249,126,215                 // vmovq         %xmm2,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  196,131,121,32,20,16,0              // vpinsrb       $0x0,(%r8,%r10,1),%xmm0,%xmm2
  .byte  196,195,105,32,20,24,1              // vpinsrb       $0x1,(%r8,%rbx,1),%xmm2,%xmm2
  .byte  67,15,182,28,8                      // movzbl        (%r8,%r9,1),%ebx
  .byte  196,227,105,32,211,2                // vpinsrb       $0x2,%ebx,%xmm2,%xmm2
  .byte  65,15,182,44,40                     // movzbl        (%r8,%rbp,1),%ebp
  .byte  196,227,105,32,213,3                // vpinsrb       $0x3,%ebp,%xmm2,%xmm2
  .byte  67,15,182,44,32                     // movzbl        (%r8,%r12,1),%ebp
  .byte  196,227,105,32,213,4                // vpinsrb       $0x4,%ebp,%xmm2,%xmm2
  .byte  67,15,182,44,56                     // movzbl        (%r8,%r15,1),%ebp
  .byte  196,227,105,32,213,5                // vpinsrb       $0x5,%ebp,%xmm2,%xmm2
  .byte  67,15,182,44,48                     // movzbl        (%r8,%r14,1),%ebp
  .byte  196,227,105,32,213,6                // vpinsrb       $0x6,%ebp,%xmm2,%xmm2
  .byte  67,15,182,44,24                     // movzbl        (%r8,%r11,1),%ebp
  .byte  196,227,105,32,213,7                // vpinsrb       $0x7,%ebp,%xmm2,%xmm2
  .byte  196,226,125,49,210                  // vpmovzxbd     %xmm2,%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  197,180,89,210                      // vmulps        %ymm2,%ymm9,%ymm2
  .byte  72,139,64,24                        // mov           0x18(%rax),%rax
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  197,253,91,219                      // vcvtps2dq     %ymm3,%ymm3
  .byte  196,227,249,22,221,1                // vpextrq       $0x1,%xmm3,%rbp
  .byte  65,137,232                          // mov           %ebp,%r8d
  .byte  72,193,237,32                       // shr           $0x20,%rbp
  .byte  196,225,249,126,219                 // vmovq         %xmm3,%rbx
  .byte  65,137,217                          // mov           %ebx,%r9d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,227,125,57,219,1                // vextracti128  $0x1,%ymm3,%xmm3
  .byte  196,195,249,22,218,1                // vpextrq       $0x1,%xmm3,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  196,193,249,126,222                 // vmovq         %xmm3,%r14
  .byte  69,137,247                          // mov           %r14d,%r15d
  .byte  73,193,238,32                       // shr           $0x20,%r14
  .byte  196,163,121,32,28,8,0               // vpinsrb       $0x0,(%rax,%r9,1),%xmm0,%xmm3
  .byte  196,227,97,32,28,24,1               // vpinsrb       $0x1,(%rax,%rbx,1),%xmm3,%xmm3
  .byte  66,15,182,28,0                      // movzbl        (%rax,%r8,1),%ebx
  .byte  196,227,97,32,219,2                 // vpinsrb       $0x2,%ebx,%xmm3,%xmm3
  .byte  15,182,44,40                        // movzbl        (%rax,%rbp,1),%ebp
  .byte  196,227,97,32,221,3                 // vpinsrb       $0x3,%ebp,%xmm3,%xmm3
  .byte  66,15,182,44,56                     // movzbl        (%rax,%r15,1),%ebp
  .byte  196,227,97,32,221,4                 // vpinsrb       $0x4,%ebp,%xmm3,%xmm3
  .byte  66,15,182,44,48                     // movzbl        (%rax,%r14,1),%ebp
  .byte  196,227,97,32,221,5                 // vpinsrb       $0x5,%ebp,%xmm3,%xmm3
  .byte  66,15,182,44,24                     // movzbl        (%rax,%r11,1),%ebp
  .byte  196,227,97,32,221,6                 // vpinsrb       $0x6,%ebp,%xmm3,%xmm3
  .byte  66,15,182,4,16                      // movzbl        (%rax,%r10,1),%eax
  .byte  196,227,97,32,216,7                 // vpinsrb       $0x7,%eax,%xmm3,%xmm3
  .byte  196,226,125,49,219                  // vpmovzxbd     %xmm3,%ymm3
  .byte  197,252,91,219                      // vcvtdq2ps     %ymm3,%ymm3
  .byte  197,180,89,219                      // vmulps        %ymm3,%ymm9,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,93                               // pop           %r13
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  93                                  // pop           %rbp
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_byte_tables_rgb_hsw
.globl _sk_byte_tables_rgb_hsw
FUNCTION(_sk_byte_tables_rgb_hsw)
_sk_byte_tables_rgb_hsw:
  .byte  85                                  // push          %rbp
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,85                               // push          %r13
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  68,139,64,24                        // mov           0x18(%rax),%r8d
  .byte  65,255,200                          // dec           %r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  196,65,124,91,192                   // vcvtdq2ps     %ymm8,%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  197,253,91,192                      // vcvtps2dq     %ymm0,%ymm0
  .byte  196,195,249,22,192,1                // vpextrq       $0x1,%xmm0,%r8
  .byte  68,137,197                          // mov           %r8d,%ebp
  .byte  77,137,194                          // mov           %r8,%r10
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  196,193,249,126,192                 // vmovq         %xmm0,%r8
  .byte  69,137,195                          // mov           %r8d,%r11d
  .byte  77,137,199                          // mov           %r8,%r15
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  196,227,125,57,192,1                // vextracti128  $0x1,%ymm0,%xmm0
  .byte  196,195,249,22,192,1                // vpextrq       $0x1,%xmm0,%r8
  .byte  69,137,198                          // mov           %r8d,%r14d
  .byte  77,137,196                          // mov           %r8,%r12
  .byte  73,193,236,32                       // shr           $0x20,%r12
  .byte  196,225,249,126,195                 // vmovq         %xmm0,%rbx
  .byte  65,137,221                          // mov           %ebx,%r13d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  76,139,64,8                         // mov           0x8(%rax),%r8
  .byte  196,131,121,32,4,25,0               // vpinsrb       $0x0,(%r9,%r11,1),%xmm0,%xmm0
  .byte  196,131,121,32,4,57,1               // vpinsrb       $0x1,(%r9,%r15,1),%xmm0,%xmm0
  .byte  65,15,182,44,41                     // movzbl        (%r9,%rbp,1),%ebp
  .byte  196,227,121,32,197,2                // vpinsrb       $0x2,%ebp,%xmm0,%xmm0
  .byte  67,15,182,44,17                     // movzbl        (%r9,%r10,1),%ebp
  .byte  196,227,121,32,197,3                // vpinsrb       $0x3,%ebp,%xmm0,%xmm0
  .byte  67,15,182,44,41                     // movzbl        (%r9,%r13,1),%ebp
  .byte  196,227,121,32,197,4                // vpinsrb       $0x4,%ebp,%xmm0,%xmm0
  .byte  65,15,182,44,25                     // movzbl        (%r9,%rbx,1),%ebp
  .byte  196,227,121,32,197,5                // vpinsrb       $0x5,%ebp,%xmm0,%xmm0
  .byte  67,15,182,44,49                     // movzbl        (%r9,%r14,1),%ebp
  .byte  196,227,121,32,197,6                // vpinsrb       $0x6,%ebp,%xmm0,%xmm0
  .byte  67,15,182,44,33                     // movzbl        (%r9,%r12,1),%ebp
  .byte  196,227,121,32,197,7                // vpinsrb       $0x7,%ebp,%xmm0,%xmm0
  .byte  196,226,125,49,192                  // vpmovzxbd     %xmm0,%ymm0
  .byte  197,124,91,208                      // vcvtdq2ps     %ymm0,%ymm10
  .byte  189,129,128,128,59                  // mov           $0x3b808081,%ebp
  .byte  197,249,110,197                     // vmovd         %ebp,%xmm0
  .byte  196,98,125,88,200                   // vpbroadcastd  %xmm0,%ymm9
  .byte  196,193,44,89,193                   // vmulps        %ymm9,%ymm10,%ymm0
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  197,253,91,201                      // vcvtps2dq     %ymm1,%ymm1
  .byte  196,227,249,22,205,1                // vpextrq       $0x1,%xmm1,%rbp
  .byte  65,137,233                          // mov           %ebp,%r9d
  .byte  72,193,237,32                       // shr           $0x20,%rbp
  .byte  196,225,249,126,203                 // vmovq         %xmm1,%rbx
  .byte  65,137,218                          // mov           %ebx,%r10d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,227,125,57,201,1                // vextracti128  $0x1,%ymm1,%xmm1
  .byte  196,195,249,22,203,1                // vpextrq       $0x1,%xmm1,%r11
  .byte  69,137,222                          // mov           %r11d,%r14d
  .byte  73,193,235,32                       // shr           $0x20,%r11
  .byte  196,193,249,126,207                 // vmovq         %xmm1,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  196,131,121,32,12,16,0              // vpinsrb       $0x0,(%r8,%r10,1),%xmm0,%xmm1
  .byte  196,195,113,32,12,24,1              // vpinsrb       $0x1,(%r8,%rbx,1),%xmm1,%xmm1
  .byte  67,15,182,28,8                      // movzbl        (%r8,%r9,1),%ebx
  .byte  196,227,113,32,203,2                // vpinsrb       $0x2,%ebx,%xmm1,%xmm1
  .byte  65,15,182,44,40                     // movzbl        (%r8,%rbp,1),%ebp
  .byte  196,227,113,32,205,3                // vpinsrb       $0x3,%ebp,%xmm1,%xmm1
  .byte  67,15,182,44,32                     // movzbl        (%r8,%r12,1),%ebp
  .byte  196,227,113,32,205,4                // vpinsrb       $0x4,%ebp,%xmm1,%xmm1
  .byte  67,15,182,44,56                     // movzbl        (%r8,%r15,1),%ebp
  .byte  196,227,113,32,205,5                // vpinsrb       $0x5,%ebp,%xmm1,%xmm1
  .byte  67,15,182,44,48                     // movzbl        (%r8,%r14,1),%ebp
  .byte  196,227,113,32,205,6                // vpinsrb       $0x6,%ebp,%xmm1,%xmm1
  .byte  67,15,182,44,24                     // movzbl        (%r8,%r11,1),%ebp
  .byte  196,227,113,32,205,7                // vpinsrb       $0x7,%ebp,%xmm1,%xmm1
  .byte  196,226,125,49,201                  // vpmovzxbd     %xmm1,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  197,180,89,201                      // vmulps        %ymm1,%ymm9,%ymm1
  .byte  72,139,64,16                        // mov           0x10(%rax),%rax
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  197,253,91,210                      // vcvtps2dq     %ymm2,%ymm2
  .byte  196,227,249,22,213,1                // vpextrq       $0x1,%xmm2,%rbp
  .byte  65,137,232                          // mov           %ebp,%r8d
  .byte  72,193,237,32                       // shr           $0x20,%rbp
  .byte  196,225,249,126,211                 // vmovq         %xmm2,%rbx
  .byte  65,137,217                          // mov           %ebx,%r9d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,227,125,57,210,1                // vextracti128  $0x1,%ymm2,%xmm2
  .byte  196,195,249,22,210,1                // vpextrq       $0x1,%xmm2,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  196,193,249,126,214                 // vmovq         %xmm2,%r14
  .byte  69,137,247                          // mov           %r14d,%r15d
  .byte  73,193,238,32                       // shr           $0x20,%r14
  .byte  196,163,121,32,20,8,0               // vpinsrb       $0x0,(%rax,%r9,1),%xmm0,%xmm2
  .byte  196,227,105,32,20,24,1              // vpinsrb       $0x1,(%rax,%rbx,1),%xmm2,%xmm2
  .byte  66,15,182,28,0                      // movzbl        (%rax,%r8,1),%ebx
  .byte  196,227,105,32,211,2                // vpinsrb       $0x2,%ebx,%xmm2,%xmm2
  .byte  15,182,44,40                        // movzbl        (%rax,%rbp,1),%ebp
  .byte  196,227,105,32,213,3                // vpinsrb       $0x3,%ebp,%xmm2,%xmm2
  .byte  66,15,182,44,56                     // movzbl        (%rax,%r15,1),%ebp
  .byte  196,227,105,32,213,4                // vpinsrb       $0x4,%ebp,%xmm2,%xmm2
  .byte  66,15,182,44,48                     // movzbl        (%rax,%r14,1),%ebp
  .byte  196,227,105,32,213,5                // vpinsrb       $0x5,%ebp,%xmm2,%xmm2
  .byte  66,15,182,44,24                     // movzbl        (%rax,%r11,1),%ebp
  .byte  196,227,105,32,213,6                // vpinsrb       $0x6,%ebp,%xmm2,%xmm2
  .byte  66,15,182,4,16                      // movzbl        (%rax,%r10,1),%eax
  .byte  196,227,105,32,208,7                // vpinsrb       $0x7,%eax,%xmm2,%xmm2
  .byte  196,226,125,49,210                  // vpmovzxbd     %xmm2,%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  197,180,89,210                      // vmulps        %ymm2,%ymm9,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,93                               // pop           %r13
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  93                                  // pop           %rbp
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_table_r_hsw
.globl _sk_table_r_hsw
FUNCTION(_sk_table_r_hsw)
_sk_table_r_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  139,64,8                            // mov           0x8(%rax),%eax
  .byte  255,200                             // dec           %eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  196,65,124,91,192                   // vcvtdq2ps     %ymm8,%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  197,125,91,192                      // vcvtps2dq     %ymm0,%ymm8
  .byte  196,65,53,118,201                   // vpcmpeqd      %ymm9,%ymm9,%ymm9
  .byte  196,130,53,146,4,128                // vgatherdps    %ymm9,(%r8,%ymm8,4),%ymm0
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_table_g_hsw
.globl _sk_table_g_hsw
FUNCTION(_sk_table_g_hsw)
_sk_table_g_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  139,64,8                            // mov           0x8(%rax),%eax
  .byte  255,200                             // dec           %eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  196,65,124,91,192                   // vcvtdq2ps     %ymm8,%ymm8
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  197,125,91,193                      // vcvtps2dq     %ymm1,%ymm8
  .byte  196,65,53,118,201                   // vpcmpeqd      %ymm9,%ymm9,%ymm9
  .byte  196,130,53,146,12,128               // vgatherdps    %ymm9,(%r8,%ymm8,4),%ymm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_table_b_hsw
.globl _sk_table_b_hsw
FUNCTION(_sk_table_b_hsw)
_sk_table_b_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  139,64,8                            // mov           0x8(%rax),%eax
  .byte  255,200                             // dec           %eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  196,65,124,91,192                   // vcvtdq2ps     %ymm8,%ymm8
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  197,125,91,194                      // vcvtps2dq     %ymm2,%ymm8
  .byte  196,65,53,118,201                   // vpcmpeqd      %ymm9,%ymm9,%ymm9
  .byte  196,130,53,146,20,128               // vgatherdps    %ymm9,(%r8,%ymm8,4),%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_table_a_hsw
.globl _sk_table_a_hsw
FUNCTION(_sk_table_a_hsw)
_sk_table_a_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  139,64,8                            // mov           0x8(%rax),%eax
  .byte  255,200                             // dec           %eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  196,65,124,91,192                   // vcvtdq2ps     %ymm8,%ymm8
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  197,125,91,195                      // vcvtps2dq     %ymm3,%ymm8
  .byte  196,65,53,118,201                   // vpcmpeqd      %ymm9,%ymm9,%ymm9
  .byte  196,130,53,146,28,128               // vgatherdps    %ymm9,(%r8,%ymm8,4),%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_parametric_r_hsw
.globl _sk_parametric_r_hsw
FUNCTION(_sk_parametric_r_hsw)
_sk_parametric_r_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,64,16                 // vbroadcastss  0x10(%rax),%ymm8
  .byte  196,65,124,194,192,2                // vcmpleps      %ymm8,%ymm0,%ymm8
  .byte  196,98,125,24,72,12                 // vbroadcastss  0xc(%rax),%ymm9
  .byte  196,98,125,24,80,24                 // vbroadcastss  0x18(%rax),%ymm10
  .byte  196,66,125,168,202                  // vfmadd213ps   %ymm10,%ymm0,%ymm9
  .byte  196,98,125,24,80,4                  // vbroadcastss  0x4(%rax),%ymm10
  .byte  196,98,125,24,88,8                  // vbroadcastss  0x8(%rax),%ymm11
  .byte  196,66,125,168,211                  // vfmadd213ps   %ymm11,%ymm0,%ymm10
  .byte  196,226,125,24,0                    // vbroadcastss  (%rax),%ymm0
  .byte  196,65,124,91,218                   // vcvtdq2ps     %ymm10,%ymm11
  .byte  196,98,125,24,37,208,36,0,0         // vbroadcastss  0x24d0(%rip),%ymm12        # 40c8 <_sk_callback_hsw+0x12e>
  .byte  196,98,125,24,45,203,36,0,0         // vbroadcastss  0x24cb(%rip),%ymm13        # 40cc <_sk_callback_hsw+0x132>
  .byte  196,65,44,84,213                    // vandps        %ymm13,%ymm10,%ymm10
  .byte  196,98,125,24,45,193,36,0,0         // vbroadcastss  0x24c1(%rip),%ymm13        # 40d0 <_sk_callback_hsw+0x136>
  .byte  196,65,44,86,213                    // vorps         %ymm13,%ymm10,%ymm10
  .byte  196,98,125,24,45,183,36,0,0         // vbroadcastss  0x24b7(%rip),%ymm13        # 40d4 <_sk_callback_hsw+0x13a>
  .byte  196,66,37,184,236                   // vfmadd231ps   %ymm12,%ymm11,%ymm13
  .byte  196,98,125,24,29,173,36,0,0         // vbroadcastss  0x24ad(%rip),%ymm11        # 40d8 <_sk_callback_hsw+0x13e>
  .byte  196,66,45,172,221                   // vfnmadd213ps  %ymm13,%ymm10,%ymm11
  .byte  196,98,125,24,37,163,36,0,0         // vbroadcastss  0x24a3(%rip),%ymm12        # 40dc <_sk_callback_hsw+0x142>
  .byte  196,65,44,88,212                    // vaddps        %ymm12,%ymm10,%ymm10
  .byte  196,98,125,24,37,153,36,0,0         // vbroadcastss  0x2499(%rip),%ymm12        # 40e0 <_sk_callback_hsw+0x146>
  .byte  196,65,28,94,210                    // vdivps        %ymm10,%ymm12,%ymm10
  .byte  196,65,36,92,210                    // vsubps        %ymm10,%ymm11,%ymm10
  .byte  196,193,124,89,194                  // vmulps        %ymm10,%ymm0,%ymm0
  .byte  196,99,125,8,208,1                  // vroundps      $0x1,%ymm0,%ymm10
  .byte  196,65,124,92,210                   // vsubps        %ymm10,%ymm0,%ymm10
  .byte  196,98,125,24,29,122,36,0,0         // vbroadcastss  0x247a(%rip),%ymm11        # 40e4 <_sk_callback_hsw+0x14a>
  .byte  196,193,124,88,195                  // vaddps        %ymm11,%ymm0,%ymm0
  .byte  196,98,125,24,29,112,36,0,0         // vbroadcastss  0x2470(%rip),%ymm11        # 40e8 <_sk_callback_hsw+0x14e>
  .byte  196,98,45,172,216                   // vfnmadd213ps  %ymm0,%ymm10,%ymm11
  .byte  196,226,125,24,5,102,36,0,0         // vbroadcastss  0x2466(%rip),%ymm0        # 40ec <_sk_callback_hsw+0x152>
  .byte  196,193,124,92,194                  // vsubps        %ymm10,%ymm0,%ymm0
  .byte  196,98,125,24,21,92,36,0,0          // vbroadcastss  0x245c(%rip),%ymm10        # 40f0 <_sk_callback_hsw+0x156>
  .byte  197,172,94,192                      // vdivps        %ymm0,%ymm10,%ymm0
  .byte  197,164,88,192                      // vaddps        %ymm0,%ymm11,%ymm0
  .byte  196,98,125,24,21,79,36,0,0          // vbroadcastss  0x244f(%rip),%ymm10        # 40f4 <_sk_callback_hsw+0x15a>
  .byte  196,193,124,89,194                  // vmulps        %ymm10,%ymm0,%ymm0
  .byte  197,253,91,192                      // vcvtps2dq     %ymm0,%ymm0
  .byte  196,98,125,24,80,20                 // vbroadcastss  0x14(%rax),%ymm10
  .byte  196,193,124,88,194                  // vaddps        %ymm10,%ymm0,%ymm0
  .byte  196,195,125,74,193,128              // vblendvps     %ymm8,%ymm9,%ymm0,%ymm0
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  196,65,124,95,192                   // vmaxps        %ymm8,%ymm0,%ymm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,226,125,88,192                  // vpbroadcastd  %xmm0,%ymm0
  .byte  197,188,93,192                      // vminps        %ymm0,%ymm8,%ymm0
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_parametric_g_hsw
.globl _sk_parametric_g_hsw
FUNCTION(_sk_parametric_g_hsw)
_sk_parametric_g_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,64,16                 // vbroadcastss  0x10(%rax),%ymm8
  .byte  196,65,116,194,192,2                // vcmpleps      %ymm8,%ymm1,%ymm8
  .byte  196,98,125,24,72,12                 // vbroadcastss  0xc(%rax),%ymm9
  .byte  196,98,125,24,80,24                 // vbroadcastss  0x18(%rax),%ymm10
  .byte  196,66,117,168,202                  // vfmadd213ps   %ymm10,%ymm1,%ymm9
  .byte  196,98,125,24,80,4                  // vbroadcastss  0x4(%rax),%ymm10
  .byte  196,98,125,24,88,8                  // vbroadcastss  0x8(%rax),%ymm11
  .byte  196,66,117,168,211                  // vfmadd213ps   %ymm11,%ymm1,%ymm10
  .byte  196,226,125,24,8                    // vbroadcastss  (%rax),%ymm1
  .byte  196,65,124,91,218                   // vcvtdq2ps     %ymm10,%ymm11
  .byte  196,98,125,24,37,214,35,0,0         // vbroadcastss  0x23d6(%rip),%ymm12        # 40f8 <_sk_callback_hsw+0x15e>
  .byte  196,98,125,24,45,209,35,0,0         // vbroadcastss  0x23d1(%rip),%ymm13        # 40fc <_sk_callback_hsw+0x162>
  .byte  196,65,44,84,213                    // vandps        %ymm13,%ymm10,%ymm10
  .byte  196,98,125,24,45,199,35,0,0         // vbroadcastss  0x23c7(%rip),%ymm13        # 4100 <_sk_callback_hsw+0x166>
  .byte  196,65,44,86,213                    // vorps         %ymm13,%ymm10,%ymm10
  .byte  196,98,125,24,45,189,35,0,0         // vbroadcastss  0x23bd(%rip),%ymm13        # 4104 <_sk_callback_hsw+0x16a>
  .byte  196,66,37,184,236                   // vfmadd231ps   %ymm12,%ymm11,%ymm13
  .byte  196,98,125,24,29,179,35,0,0         // vbroadcastss  0x23b3(%rip),%ymm11        # 4108 <_sk_callback_hsw+0x16e>
  .byte  196,66,45,172,221                   // vfnmadd213ps  %ymm13,%ymm10,%ymm11
  .byte  196,98,125,24,37,169,35,0,0         // vbroadcastss  0x23a9(%rip),%ymm12        # 410c <_sk_callback_hsw+0x172>
  .byte  196,65,44,88,212                    // vaddps        %ymm12,%ymm10,%ymm10
  .byte  196,98,125,24,37,159,35,0,0         // vbroadcastss  0x239f(%rip),%ymm12        # 4110 <_sk_callback_hsw+0x176>
  .byte  196,65,28,94,210                    // vdivps        %ymm10,%ymm12,%ymm10
  .byte  196,65,36,92,210                    // vsubps        %ymm10,%ymm11,%ymm10
  .byte  196,193,116,89,202                  // vmulps        %ymm10,%ymm1,%ymm1
  .byte  196,99,125,8,209,1                  // vroundps      $0x1,%ymm1,%ymm10
  .byte  196,65,116,92,210                   // vsubps        %ymm10,%ymm1,%ymm10
  .byte  196,98,125,24,29,128,35,0,0         // vbroadcastss  0x2380(%rip),%ymm11        # 4114 <_sk_callback_hsw+0x17a>
  .byte  196,193,116,88,203                  // vaddps        %ymm11,%ymm1,%ymm1
  .byte  196,98,125,24,29,118,35,0,0         // vbroadcastss  0x2376(%rip),%ymm11        # 4118 <_sk_callback_hsw+0x17e>
  .byte  196,98,45,172,217                   // vfnmadd213ps  %ymm1,%ymm10,%ymm11
  .byte  196,226,125,24,13,108,35,0,0        // vbroadcastss  0x236c(%rip),%ymm1        # 411c <_sk_callback_hsw+0x182>
  .byte  196,193,116,92,202                  // vsubps        %ymm10,%ymm1,%ymm1
  .byte  196,98,125,24,21,98,35,0,0          // vbroadcastss  0x2362(%rip),%ymm10        # 4120 <_sk_callback_hsw+0x186>
  .byte  197,172,94,201                      // vdivps        %ymm1,%ymm10,%ymm1
  .byte  197,164,88,201                      // vaddps        %ymm1,%ymm11,%ymm1
  .byte  196,98,125,24,21,85,35,0,0          // vbroadcastss  0x2355(%rip),%ymm10        # 4124 <_sk_callback_hsw+0x18a>
  .byte  196,193,116,89,202                  // vmulps        %ymm10,%ymm1,%ymm1
  .byte  197,253,91,201                      // vcvtps2dq     %ymm1,%ymm1
  .byte  196,98,125,24,80,20                 // vbroadcastss  0x14(%rax),%ymm10
  .byte  196,193,116,88,202                  // vaddps        %ymm10,%ymm1,%ymm1
  .byte  196,195,117,74,201,128              // vblendvps     %ymm8,%ymm9,%ymm1,%ymm1
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  196,65,116,95,192                   // vmaxps        %ymm8,%ymm1,%ymm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,188,93,201                      // vminps        %ymm1,%ymm8,%ymm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_parametric_b_hsw
.globl _sk_parametric_b_hsw
FUNCTION(_sk_parametric_b_hsw)
_sk_parametric_b_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,64,16                 // vbroadcastss  0x10(%rax),%ymm8
  .byte  196,65,108,194,192,2                // vcmpleps      %ymm8,%ymm2,%ymm8
  .byte  196,98,125,24,72,12                 // vbroadcastss  0xc(%rax),%ymm9
  .byte  196,98,125,24,80,24                 // vbroadcastss  0x18(%rax),%ymm10
  .byte  196,66,109,168,202                  // vfmadd213ps   %ymm10,%ymm2,%ymm9
  .byte  196,98,125,24,80,4                  // vbroadcastss  0x4(%rax),%ymm10
  .byte  196,98,125,24,88,8                  // vbroadcastss  0x8(%rax),%ymm11
  .byte  196,66,109,168,211                  // vfmadd213ps   %ymm11,%ymm2,%ymm10
  .byte  196,226,125,24,16                   // vbroadcastss  (%rax),%ymm2
  .byte  196,65,124,91,218                   // vcvtdq2ps     %ymm10,%ymm11
  .byte  196,98,125,24,37,220,34,0,0         // vbroadcastss  0x22dc(%rip),%ymm12        # 4128 <_sk_callback_hsw+0x18e>
  .byte  196,98,125,24,45,215,34,0,0         // vbroadcastss  0x22d7(%rip),%ymm13        # 412c <_sk_callback_hsw+0x192>
  .byte  196,65,44,84,213                    // vandps        %ymm13,%ymm10,%ymm10
  .byte  196,98,125,24,45,205,34,0,0         // vbroadcastss  0x22cd(%rip),%ymm13        # 4130 <_sk_callback_hsw+0x196>
  .byte  196,65,44,86,213                    // vorps         %ymm13,%ymm10,%ymm10
  .byte  196,98,125,24,45,195,34,0,0         // vbroadcastss  0x22c3(%rip),%ymm13        # 4134 <_sk_callback_hsw+0x19a>
  .byte  196,66,37,184,236                   // vfmadd231ps   %ymm12,%ymm11,%ymm13
  .byte  196,98,125,24,29,185,34,0,0         // vbroadcastss  0x22b9(%rip),%ymm11        # 4138 <_sk_callback_hsw+0x19e>
  .byte  196,66,45,172,221                   // vfnmadd213ps  %ymm13,%ymm10,%ymm11
  .byte  196,98,125,24,37,175,34,0,0         // vbroadcastss  0x22af(%rip),%ymm12        # 413c <_sk_callback_hsw+0x1a2>
  .byte  196,65,44,88,212                    // vaddps        %ymm12,%ymm10,%ymm10
  .byte  196,98,125,24,37,165,34,0,0         // vbroadcastss  0x22a5(%rip),%ymm12        # 4140 <_sk_callback_hsw+0x1a6>
  .byte  196,65,28,94,210                    // vdivps        %ymm10,%ymm12,%ymm10
  .byte  196,65,36,92,210                    // vsubps        %ymm10,%ymm11,%ymm10
  .byte  196,193,108,89,210                  // vmulps        %ymm10,%ymm2,%ymm2
  .byte  196,99,125,8,210,1                  // vroundps      $0x1,%ymm2,%ymm10
  .byte  196,65,108,92,210                   // vsubps        %ymm10,%ymm2,%ymm10
  .byte  196,98,125,24,29,134,34,0,0         // vbroadcastss  0x2286(%rip),%ymm11        # 4144 <_sk_callback_hsw+0x1aa>
  .byte  196,193,108,88,211                  // vaddps        %ymm11,%ymm2,%ymm2
  .byte  196,98,125,24,29,124,34,0,0         // vbroadcastss  0x227c(%rip),%ymm11        # 4148 <_sk_callback_hsw+0x1ae>
  .byte  196,98,45,172,218                   // vfnmadd213ps  %ymm2,%ymm10,%ymm11
  .byte  196,226,125,24,21,114,34,0,0        // vbroadcastss  0x2272(%rip),%ymm2        # 414c <_sk_callback_hsw+0x1b2>
  .byte  196,193,108,92,210                  // vsubps        %ymm10,%ymm2,%ymm2
  .byte  196,98,125,24,21,104,34,0,0         // vbroadcastss  0x2268(%rip),%ymm10        # 4150 <_sk_callback_hsw+0x1b6>
  .byte  197,172,94,210                      // vdivps        %ymm2,%ymm10,%ymm2
  .byte  197,164,88,210                      // vaddps        %ymm2,%ymm11,%ymm2
  .byte  196,98,125,24,21,91,34,0,0          // vbroadcastss  0x225b(%rip),%ymm10        # 4154 <_sk_callback_hsw+0x1ba>
  .byte  196,193,108,89,210                  // vmulps        %ymm10,%ymm2,%ymm2
  .byte  197,253,91,210                      // vcvtps2dq     %ymm2,%ymm2
  .byte  196,98,125,24,80,20                 // vbroadcastss  0x14(%rax),%ymm10
  .byte  196,193,108,88,210                  // vaddps        %ymm10,%ymm2,%ymm2
  .byte  196,195,109,74,209,128              // vblendvps     %ymm8,%ymm9,%ymm2,%ymm2
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  196,65,108,95,192                   // vmaxps        %ymm8,%ymm2,%ymm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,226,125,88,210                  // vpbroadcastd  %xmm2,%ymm2
  .byte  197,188,93,210                      // vminps        %ymm2,%ymm8,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_parametric_a_hsw
.globl _sk_parametric_a_hsw
FUNCTION(_sk_parametric_a_hsw)
_sk_parametric_a_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,64,16                 // vbroadcastss  0x10(%rax),%ymm8
  .byte  196,65,100,194,192,2                // vcmpleps      %ymm8,%ymm3,%ymm8
  .byte  196,98,125,24,72,12                 // vbroadcastss  0xc(%rax),%ymm9
  .byte  196,98,125,24,80,24                 // vbroadcastss  0x18(%rax),%ymm10
  .byte  196,66,101,168,202                  // vfmadd213ps   %ymm10,%ymm3,%ymm9
  .byte  196,98,125,24,80,4                  // vbroadcastss  0x4(%rax),%ymm10
  .byte  196,98,125,24,88,8                  // vbroadcastss  0x8(%rax),%ymm11
  .byte  196,66,101,168,211                  // vfmadd213ps   %ymm11,%ymm3,%ymm10
  .byte  196,226,125,24,24                   // vbroadcastss  (%rax),%ymm3
  .byte  196,65,124,91,218                   // vcvtdq2ps     %ymm10,%ymm11
  .byte  196,98,125,24,37,226,33,0,0         // vbroadcastss  0x21e2(%rip),%ymm12        # 4158 <_sk_callback_hsw+0x1be>
  .byte  196,98,125,24,45,221,33,0,0         // vbroadcastss  0x21dd(%rip),%ymm13        # 415c <_sk_callback_hsw+0x1c2>
  .byte  196,65,44,84,213                    // vandps        %ymm13,%ymm10,%ymm10
  .byte  196,98,125,24,45,211,33,0,0         // vbroadcastss  0x21d3(%rip),%ymm13        # 4160 <_sk_callback_hsw+0x1c6>
  .byte  196,65,44,86,213                    // vorps         %ymm13,%ymm10,%ymm10
  .byte  196,98,125,24,45,201,33,0,0         // vbroadcastss  0x21c9(%rip),%ymm13        # 4164 <_sk_callback_hsw+0x1ca>
  .byte  196,66,37,184,236                   // vfmadd231ps   %ymm12,%ymm11,%ymm13
  .byte  196,98,125,24,29,191,33,0,0         // vbroadcastss  0x21bf(%rip),%ymm11        # 4168 <_sk_callback_hsw+0x1ce>
  .byte  196,66,45,172,221                   // vfnmadd213ps  %ymm13,%ymm10,%ymm11
  .byte  196,98,125,24,37,181,33,0,0         // vbroadcastss  0x21b5(%rip),%ymm12        # 416c <_sk_callback_hsw+0x1d2>
  .byte  196,65,44,88,212                    // vaddps        %ymm12,%ymm10,%ymm10
  .byte  196,98,125,24,37,171,33,0,0         // vbroadcastss  0x21ab(%rip),%ymm12        # 4170 <_sk_callback_hsw+0x1d6>
  .byte  196,65,28,94,210                    // vdivps        %ymm10,%ymm12,%ymm10
  .byte  196,65,36,92,210                    // vsubps        %ymm10,%ymm11,%ymm10
  .byte  196,193,100,89,218                  // vmulps        %ymm10,%ymm3,%ymm3
  .byte  196,99,125,8,211,1                  // vroundps      $0x1,%ymm3,%ymm10
  .byte  196,65,100,92,210                   // vsubps        %ymm10,%ymm3,%ymm10
  .byte  196,98,125,24,29,140,33,0,0         // vbroadcastss  0x218c(%rip),%ymm11        # 4174 <_sk_callback_hsw+0x1da>
  .byte  196,193,100,88,219                  // vaddps        %ymm11,%ymm3,%ymm3
  .byte  196,98,125,24,29,130,33,0,0         // vbroadcastss  0x2182(%rip),%ymm11        # 4178 <_sk_callback_hsw+0x1de>
  .byte  196,98,45,172,219                   // vfnmadd213ps  %ymm3,%ymm10,%ymm11
  .byte  196,226,125,24,29,120,33,0,0        // vbroadcastss  0x2178(%rip),%ymm3        # 417c <_sk_callback_hsw+0x1e2>
  .byte  196,193,100,92,218                  // vsubps        %ymm10,%ymm3,%ymm3
  .byte  196,98,125,24,21,110,33,0,0         // vbroadcastss  0x216e(%rip),%ymm10        # 4180 <_sk_callback_hsw+0x1e6>
  .byte  197,172,94,219                      // vdivps        %ymm3,%ymm10,%ymm3
  .byte  197,164,88,219                      // vaddps        %ymm3,%ymm11,%ymm3
  .byte  196,98,125,24,21,97,33,0,0          // vbroadcastss  0x2161(%rip),%ymm10        # 4184 <_sk_callback_hsw+0x1ea>
  .byte  196,193,100,89,218                  // vmulps        %ymm10,%ymm3,%ymm3
  .byte  197,253,91,219                      // vcvtps2dq     %ymm3,%ymm3
  .byte  196,98,125,24,80,20                 // vbroadcastss  0x14(%rax),%ymm10
  .byte  196,193,100,88,218                  // vaddps        %ymm10,%ymm3,%ymm3
  .byte  196,195,101,74,217,128              // vblendvps     %ymm8,%ymm9,%ymm3,%ymm3
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  196,65,100,95,192                   // vmaxps        %ymm8,%ymm3,%ymm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  197,188,93,219                      // vminps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_lab_to_xyz_hsw
.globl _sk_lab_to_xyz_hsw
FUNCTION(_sk_lab_to_xyz_hsw)
_sk_lab_to_xyz_hsw:
  .byte  184,0,0,200,66                      // mov           $0x42c80000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  184,0,0,127,67                      // mov           $0x437f0000,%eax
  .byte  197,121,110,200                     // vmovd         %eax,%xmm9
  .byte  196,66,125,88,201                   // vpbroadcastd  %xmm9,%ymm9
  .byte  184,0,0,0,67                        // mov           $0x43000000,%eax
  .byte  197,121,110,208                     // vmovd         %eax,%xmm10
  .byte  196,66,125,88,210                   // vpbroadcastd  %xmm10,%ymm10
  .byte  196,194,53,170,202                  // vfmsub213ps   %ymm10,%ymm9,%ymm1
  .byte  196,194,53,170,210                  // vfmsub213ps   %ymm10,%ymm9,%ymm2
  .byte  184,0,0,128,65                      // mov           $0x41800000,%eax
  .byte  197,121,110,200                     // vmovd         %eax,%xmm9
  .byte  196,66,125,88,201                   // vpbroadcastd  %xmm9,%ymm9
  .byte  196,66,125,168,193                  // vfmadd213ps   %ymm9,%ymm0,%ymm8
  .byte  184,203,61,13,60                    // mov           $0x3c0d3dcb,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,226,125,88,192                  // vpbroadcastd  %xmm0,%ymm0
  .byte  197,60,89,192                       // vmulps        %ymm0,%ymm8,%ymm8
  .byte  184,111,18,3,59                     // mov           $0x3b03126f,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,226,125,88,192                  // vpbroadcastd  %xmm0,%ymm0
  .byte  196,194,117,168,192                 // vfmadd213ps   %ymm8,%ymm1,%ymm0
  .byte  184,10,215,163,59                   // mov           $0x3ba3d70a,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,98,125,88,201                   // vpbroadcastd  %xmm1,%ymm9
  .byte  196,66,109,172,200                  // vfnmadd213ps  %ymm8,%ymm2,%ymm9
  .byte  197,252,89,200                      // vmulps        %ymm0,%ymm0,%ymm1
  .byte  197,124,89,217                      // vmulps        %ymm1,%ymm0,%ymm11
  .byte  184,194,24,17,60                    // mov           $0x3c1118c2,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,226,125,88,210                  // vpbroadcastd  %xmm2,%ymm2
  .byte  196,65,108,194,211,1                // vcmpltps      %ymm11,%ymm2,%ymm10
  .byte  184,203,61,13,62                    // mov           $0x3e0d3dcb,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,98,125,88,225                   // vpbroadcastd  %xmm1,%ymm12
  .byte  196,193,124,92,196                  // vsubps        %ymm12,%ymm0,%ymm0
  .byte  184,80,128,3,62                     // mov           $0x3e038050,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,98,125,88,233                   // vpbroadcastd  %xmm1,%ymm13
  .byte  196,193,124,89,197                  // vmulps        %ymm13,%ymm0,%ymm0
  .byte  196,67,125,74,219,160               // vblendvps     %ymm10,%ymm11,%ymm0,%ymm11
  .byte  196,193,60,89,200                   // vmulps        %ymm8,%ymm8,%ymm1
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  197,108,194,209,1                   // vcmpltps      %ymm1,%ymm2,%ymm10
  .byte  196,65,60,92,196                    // vsubps        %ymm12,%ymm8,%ymm8
  .byte  196,65,60,89,197                    // vmulps        %ymm13,%ymm8,%ymm8
  .byte  196,227,61,74,201,160               // vblendvps     %ymm10,%ymm1,%ymm8,%ymm1
  .byte  196,65,52,89,193                    // vmulps        %ymm9,%ymm9,%ymm8
  .byte  196,65,52,89,192                    // vmulps        %ymm8,%ymm9,%ymm8
  .byte  196,193,108,194,208,1               // vcmpltps      %ymm8,%ymm2,%ymm2
  .byte  196,65,52,92,204                    // vsubps        %ymm12,%ymm9,%ymm9
  .byte  196,65,52,89,205                    // vmulps        %ymm13,%ymm9,%ymm9
  .byte  196,67,53,74,192,32                 // vblendvps     %ymm2,%ymm8,%ymm9,%ymm8
  .byte  184,31,215,118,63                   // mov           $0x3f76d71f,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,226,125,88,192                  // vpbroadcastd  %xmm0,%ymm0
  .byte  197,164,89,192                      // vmulps        %ymm0,%ymm11,%ymm0
  .byte  184,246,64,83,63                    // mov           $0x3f5340f6,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,226,125,88,210                  // vpbroadcastd  %xmm2,%ymm2
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_a8_hsw
.globl _sk_load_a8_hsw
FUNCTION(_sk_load_a8_hsw)
_sk_load_a8_hsw:
  .byte  73,137,200                          // mov           %rcx,%r8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,1,248                            // add           %rdi,%rax
  .byte  77,133,192                          // test          %r8,%r8
  .byte  117,50                              // jne           21cc <_sk_load_a8_hsw+0x42>
  .byte  197,250,126,0                       // vmovq         (%rax),%xmm0
  .byte  196,226,125,49,192                  // vpmovzxbd     %xmm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,252,89,217                      // vmulps        %ymm1,%ymm0,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,87,192                      // vxorps        %ymm0,%ymm0,%ymm0
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  197,236,87,210                      // vxorps        %ymm2,%ymm2,%ymm2
  .byte  76,137,193                          // mov           %r8,%rcx
  .byte  255,224                             // jmpq          *%rax
  .byte  49,201                              // xor           %ecx,%ecx
  .byte  77,137,194                          // mov           %r8,%r10
  .byte  69,49,201                           // xor           %r9d,%r9d
  .byte  68,15,182,24                        // movzbl        (%rax),%r11d
  .byte  72,255,192                          // inc           %rax
  .byte  73,211,227                          // shl           %cl,%r11
  .byte  77,9,217                            // or            %r11,%r9
  .byte  72,131,193,8                        // add           $0x8,%rcx
  .byte  73,255,202                          // dec           %r10
  .byte  117,234                             // jne           21d4 <_sk_load_a8_hsw+0x4a>
  .byte  196,193,249,110,193                 // vmovq         %r9,%xmm0
  .byte  235,173                             // jmp           219e <_sk_load_a8_hsw+0x14>

HIDDEN _sk_gather_a8_hsw
.globl _sk_gather_a8_hsw
FUNCTION(_sk_gather_a8_hsw)
_sk_gather_a8_hsw:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  197,254,91,201                      // vcvttps2dq    %ymm1,%ymm1
  .byte  196,226,125,88,80,16                // vpbroadcastd  0x10(%rax),%ymm2
  .byte  196,226,109,64,201                  // vpmulld       %ymm1,%ymm2,%ymm1
  .byte  197,254,91,192                      // vcvttps2dq    %ymm0,%ymm0
  .byte  197,245,254,192                     // vpaddd        %ymm0,%ymm1,%ymm0
  .byte  196,227,249,22,192,1                // vpextrq       $0x1,%xmm0,%rax
  .byte  65,137,193                          // mov           %eax,%r9d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  196,193,249,126,194                 // vmovq         %xmm0,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  196,227,125,57,192,1                // vextracti128  $0x1,%ymm0,%xmm0
  .byte  196,227,249,22,195,1                // vpextrq       $0x1,%xmm0,%rbx
  .byte  65,137,222                          // mov           %ebx,%r14d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,193,249,126,199                 // vmovq         %xmm0,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  196,131,121,32,4,24,0               // vpinsrb       $0x0,(%r8,%r11,1),%xmm0,%xmm0
  .byte  196,131,121,32,4,16,1               // vpinsrb       $0x1,(%r8,%r10,1),%xmm0,%xmm0
  .byte  71,15,182,12,8                      // movzbl        (%r8,%r9,1),%r9d
  .byte  196,195,121,32,193,2                // vpinsrb       $0x2,%r9d,%xmm0,%xmm0
  .byte  65,15,182,4,0                       // movzbl        (%r8,%rax,1),%eax
  .byte  196,227,121,32,192,3                // vpinsrb       $0x3,%eax,%xmm0,%xmm0
  .byte  67,15,182,4,32                      // movzbl        (%r8,%r12,1),%eax
  .byte  196,227,121,32,192,4                // vpinsrb       $0x4,%eax,%xmm0,%xmm0
  .byte  67,15,182,4,56                      // movzbl        (%r8,%r15,1),%eax
  .byte  196,227,121,32,192,5                // vpinsrb       $0x5,%eax,%xmm0,%xmm0
  .byte  67,15,182,4,48                      // movzbl        (%r8,%r14,1),%eax
  .byte  196,227,121,32,192,6                // vpinsrb       $0x6,%eax,%xmm0,%xmm0
  .byte  65,15,182,4,24                      // movzbl        (%r8,%rbx,1),%eax
  .byte  196,227,121,32,192,7                // vpinsrb       $0x7,%eax,%xmm0,%xmm0
  .byte  196,226,125,49,192                  // vpmovzxbd     %xmm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,252,89,217                      // vmulps        %ymm1,%ymm0,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,87,192                      // vxorps        %ymm0,%ymm0,%ymm0
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  197,237,239,210                     // vpxor         %ymm2,%ymm2,%ymm2
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_a8_hsw
.globl _sk_store_a8_hsw
FUNCTION(_sk_store_a8_hsw)
_sk_store_a8_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  184,0,0,127,67                      // mov           $0x437f0000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,89,195                       // vmulps        %ymm3,%ymm8,%ymm8
  .byte  196,65,125,91,192                   // vcvtps2dq     %ymm8,%ymm8
  .byte  196,67,125,25,193,1                 // vextractf128  $0x1,%ymm8,%xmm9
  .byte  196,66,57,43,193                    // vpackusdw     %xmm9,%xmm8,%xmm8
  .byte  196,65,57,103,192                   // vpackuswb     %xmm8,%xmm8,%xmm8
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  117,10                              // jne           2309 <_sk_store_a8_hsw+0x3b>
  .byte  196,65,123,17,4,57                  // vmovsd        %xmm8,(%r9,%rdi,1)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  65,128,224,7                        // and           $0x7,%r8b
  .byte  65,254,200                          // dec           %r8b
  .byte  65,128,248,6                        // cmp           $0x6,%r8b
  .byte  119,236                             // ja            2305 <_sk_store_a8_hsw+0x37>
  .byte  196,66,121,48,192                   // vpmovzxbw     %xmm8,%xmm8
  .byte  65,15,182,192                       // movzbl        %r8b,%eax
  .byte  76,141,5,67,0,0,0                   // lea           0x43(%rip),%r8        # 236c <_sk_store_a8_hsw+0x9e>
  .byte  73,99,4,128                         // movslq        (%r8,%rax,4),%rax
  .byte  76,1,192                            // add           %r8,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,67,121,20,68,57,6,12            // vpextrb       $0xc,%xmm8,0x6(%r9,%rdi,1)
  .byte  196,67,121,20,68,57,5,10            // vpextrb       $0xa,%xmm8,0x5(%r9,%rdi,1)
  .byte  196,67,121,20,68,57,4,8             // vpextrb       $0x8,%xmm8,0x4(%r9,%rdi,1)
  .byte  196,67,121,20,68,57,3,6             // vpextrb       $0x6,%xmm8,0x3(%r9,%rdi,1)
  .byte  196,67,121,20,68,57,2,4             // vpextrb       $0x4,%xmm8,0x2(%r9,%rdi,1)
  .byte  196,67,121,20,68,57,1,2             // vpextrb       $0x2,%xmm8,0x1(%r9,%rdi,1)
  .byte  196,67,121,20,4,57,0                // vpextrb       $0x0,%xmm8,(%r9,%rdi,1)
  .byte  235,154                             // jmp           2305 <_sk_store_a8_hsw+0x37>
  .byte  144                                 // nop
  .byte  246,255                             // idiv          %bh
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  238                                 // out           %al,(%dx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,230                             // jmpq          *%rsi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  222,255                             // fdivrp        %st,%st(7)
  .byte  255                                 // (bad)
  .byte  255,214                             // callq         *%rsi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,206                             // dec           %esi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,198                             // inc           %esi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_load_g8_hsw
.globl _sk_load_g8_hsw
FUNCTION(_sk_load_g8_hsw)
_sk_load_g8_hsw:
  .byte  73,137,200                          // mov           %rcx,%r8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,1,248                            // add           %rdi,%rax
  .byte  77,133,192                          // test          %r8,%r8
  .byte  117,60                              // jne           23d4 <_sk_load_g8_hsw+0x4c>
  .byte  197,250,126,0                       // vmovq         (%rax),%xmm0
  .byte  196,226,125,49,192                  // vpmovzxbd     %xmm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,252,89,193                      // vmulps        %ymm1,%ymm0,%ymm0
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,226,125,88,217                  // vpbroadcastd  %xmm1,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,137,193                          // mov           %r8,%rcx
  .byte  197,252,40,200                      // vmovaps       %ymm0,%ymm1
  .byte  197,252,40,208                      // vmovaps       %ymm0,%ymm2
  .byte  255,224                             // jmpq          *%rax
  .byte  49,201                              // xor           %ecx,%ecx
  .byte  77,137,194                          // mov           %r8,%r10
  .byte  69,49,201                           // xor           %r9d,%r9d
  .byte  68,15,182,24                        // movzbl        (%rax),%r11d
  .byte  72,255,192                          // inc           %rax
  .byte  73,211,227                          // shl           %cl,%r11
  .byte  77,9,217                            // or            %r11,%r9
  .byte  72,131,193,8                        // add           $0x8,%rcx
  .byte  73,255,202                          // dec           %r10
  .byte  117,234                             // jne           23dc <_sk_load_g8_hsw+0x54>
  .byte  196,193,249,110,193                 // vmovq         %r9,%xmm0
  .byte  235,163                             // jmp           239c <_sk_load_g8_hsw+0x14>

HIDDEN _sk_gather_g8_hsw
.globl _sk_gather_g8_hsw
FUNCTION(_sk_gather_g8_hsw)
_sk_gather_g8_hsw:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  197,254,91,201                      // vcvttps2dq    %ymm1,%ymm1
  .byte  196,226,125,88,80,16                // vpbroadcastd  0x10(%rax),%ymm2
  .byte  196,226,109,64,201                  // vpmulld       %ymm1,%ymm2,%ymm1
  .byte  197,254,91,192                      // vcvttps2dq    %ymm0,%ymm0
  .byte  197,245,254,192                     // vpaddd        %ymm0,%ymm1,%ymm0
  .byte  196,227,249,22,192,1                // vpextrq       $0x1,%xmm0,%rax
  .byte  65,137,193                          // mov           %eax,%r9d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  196,193,249,126,194                 // vmovq         %xmm0,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  196,227,125,57,192,1                // vextracti128  $0x1,%ymm0,%xmm0
  .byte  196,227,249,22,195,1                // vpextrq       $0x1,%xmm0,%rbx
  .byte  65,137,222                          // mov           %ebx,%r14d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,193,249,126,199                 // vmovq         %xmm0,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  196,131,121,32,4,24,0               // vpinsrb       $0x0,(%r8,%r11,1),%xmm0,%xmm0
  .byte  196,131,121,32,4,16,1               // vpinsrb       $0x1,(%r8,%r10,1),%xmm0,%xmm0
  .byte  71,15,182,12,8                      // movzbl        (%r8,%r9,1),%r9d
  .byte  196,195,121,32,193,2                // vpinsrb       $0x2,%r9d,%xmm0,%xmm0
  .byte  65,15,182,4,0                       // movzbl        (%r8,%rax,1),%eax
  .byte  196,227,121,32,192,3                // vpinsrb       $0x3,%eax,%xmm0,%xmm0
  .byte  67,15,182,4,32                      // movzbl        (%r8,%r12,1),%eax
  .byte  196,227,121,32,192,4                // vpinsrb       $0x4,%eax,%xmm0,%xmm0
  .byte  67,15,182,4,56                      // movzbl        (%r8,%r15,1),%eax
  .byte  196,227,121,32,192,5                // vpinsrb       $0x5,%eax,%xmm0,%xmm0
  .byte  67,15,182,4,48                      // movzbl        (%r8,%r14,1),%eax
  .byte  196,227,121,32,192,6                // vpinsrb       $0x6,%eax,%xmm0,%xmm0
  .byte  65,15,182,4,24                      // movzbl        (%r8,%rbx,1),%eax
  .byte  196,227,121,32,192,7                // vpinsrb       $0x7,%eax,%xmm0,%xmm0
  .byte  196,226,125,49,192                  // vpmovzxbd     %xmm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,252,89,193                      // vmulps        %ymm1,%ymm0,%ymm0
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,226,125,88,217                  // vpbroadcastd  %xmm1,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,40,200                      // vmovaps       %ymm0,%ymm1
  .byte  197,252,40,208                      // vmovaps       %ymm0,%ymm2
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_i8_hsw
.globl _sk_gather_i8_hsw
FUNCTION(_sk_gather_i8_hsw)
_sk_gather_i8_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  73,137,192                          // mov           %rax,%r8
  .byte  77,133,192                          // test          %r8,%r8
  .byte  116,5                               // je            24ef <_sk_gather_i8_hsw+0xf>
  .byte  76,137,192                          // mov           %r8,%rax
  .byte  235,2                               // jmp           24f1 <_sk_gather_i8_hsw+0x11>
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,85                               // push          %r13
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  197,254,91,201                      // vcvttps2dq    %ymm1,%ymm1
  .byte  196,226,125,88,80,16                // vpbroadcastd  0x10(%rax),%ymm2
  .byte  196,226,109,64,201                  // vpmulld       %ymm1,%ymm2,%ymm1
  .byte  197,254,91,192                      // vcvttps2dq    %ymm0,%ymm0
  .byte  197,245,254,192                     // vpaddd        %ymm0,%ymm1,%ymm0
  .byte  196,227,249,22,192,1                // vpextrq       $0x1,%xmm0,%rax
  .byte  65,137,194                          // mov           %eax,%r10d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  196,193,249,126,195                 // vmovq         %xmm0,%r11
  .byte  69,137,222                          // mov           %r11d,%r14d
  .byte  73,193,235,32                       // shr           $0x20,%r11
  .byte  196,227,125,57,192,1                // vextracti128  $0x1,%ymm0,%xmm0
  .byte  196,227,249,22,195,1                // vpextrq       $0x1,%xmm0,%rbx
  .byte  65,137,223                          // mov           %ebx,%r15d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,193,249,126,196                 // vmovq         %xmm0,%r12
  .byte  69,137,229                          // mov           %r12d,%r13d
  .byte  73,193,236,32                       // shr           $0x20,%r12
  .byte  196,131,121,32,4,49,0               // vpinsrb       $0x0,(%r9,%r14,1),%xmm0,%xmm0
  .byte  196,131,121,32,4,25,1               // vpinsrb       $0x1,(%r9,%r11,1),%xmm0,%xmm0
  .byte  196,131,121,32,4,17,2               // vpinsrb       $0x2,(%r9,%r10,1),%xmm0,%xmm0
  .byte  196,195,121,32,4,1,3                // vpinsrb       $0x3,(%r9,%rax,1),%xmm0,%xmm0
  .byte  196,131,121,32,4,41,4               // vpinsrb       $0x4,(%r9,%r13,1),%xmm0,%xmm0
  .byte  196,131,121,32,4,33,5               // vpinsrb       $0x5,(%r9,%r12,1),%xmm0,%xmm0
  .byte  196,131,121,32,4,57,6               // vpinsrb       $0x6,(%r9,%r15,1),%xmm0,%xmm0
  .byte  196,195,121,32,4,25,7               // vpinsrb       $0x7,(%r9,%rbx,1),%xmm0,%xmm0
  .byte  196,226,125,49,192                  // vpmovzxbd     %xmm0,%ymm0
  .byte  73,139,64,8                         // mov           0x8(%r8),%rax
  .byte  197,245,118,201                     // vpcmpeqd      %ymm1,%ymm1,%ymm1
  .byte  196,226,117,144,28,128              // vpgatherdd    %ymm1,(%rax,%ymm0,4),%ymm3
  .byte  197,229,219,5,97,28,0,0             // vpand         0x1c61(%rip),%ymm3,%ymm0        # 4200 <_sk_callback_hsw+0x266>
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,98,125,88,193                   // vpbroadcastd  %xmm1,%ymm8
  .byte  196,193,124,89,192                  // vmulps        %ymm8,%ymm0,%ymm0
  .byte  196,226,101,0,13,97,28,0,0          // vpshufb       0x1c61(%rip),%ymm3,%ymm1        # 4220 <_sk_callback_hsw+0x286>
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  196,193,116,89,200                  // vmulps        %ymm8,%ymm1,%ymm1
  .byte  196,226,101,0,21,111,28,0,0         // vpshufb       0x1c6f(%rip),%ymm3,%ymm2        # 4240 <_sk_callback_hsw+0x2a6>
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  196,193,108,89,208                  // vmulps        %ymm8,%ymm2,%ymm2
  .byte  197,229,114,211,24                  // vpsrld        $0x18,%ymm3,%ymm3
  .byte  197,252,91,219                      // vcvtdq2ps     %ymm3,%ymm3
  .byte  196,193,100,89,216                  // vmulps        %ymm8,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,93                               // pop           %r13
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_565_hsw
.globl _sk_load_565_hsw
FUNCTION(_sk_load_565_hsw)
_sk_load_565_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,16                           // mov           (%rax),%r10
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  15,133,149,0,0,0                    // jne           2698 <_sk_load_565_hsw+0xa3>
  .byte  196,193,122,111,4,122               // vmovdqu       (%r10,%rdi,2),%xmm0
  .byte  196,226,125,51,208                  // vpmovzxwd     %xmm0,%ymm2
  .byte  184,0,248,0,0                       // mov           $0xf800,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,226,125,88,192                  // vpbroadcastd  %xmm0,%ymm0
  .byte  197,253,219,194                     // vpand         %ymm2,%ymm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,8,33,132,55                     // mov           $0x37842108,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,252,89,193                      // vmulps        %ymm1,%ymm0,%ymm0
  .byte  184,224,7,0,0                       // mov           $0x7e0,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,245,219,202                     // vpand         %ymm2,%ymm1,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  184,33,8,2,58                       // mov           $0x3a020821,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  197,244,89,203                      // vmulps        %ymm3,%ymm1,%ymm1
  .byte  184,31,0,0,0                        // mov           $0x1f,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  197,229,219,210                     // vpand         %ymm2,%ymm3,%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  184,8,33,4,61                       // mov           $0x3d042108,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  197,236,89,211                      // vmulps        %ymm3,%ymm2,%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  65,128,224,7                        // and           $0x7,%r8b
  .byte  197,249,239,192                     // vpxor         %xmm0,%xmm0,%xmm0
  .byte  65,254,200                          // dec           %r8b
  .byte  65,128,248,6                        // cmp           $0x6,%r8b
  .byte  15,135,89,255,255,255               // ja            2609 <_sk_load_565_hsw+0x14>
  .byte  69,15,182,192                       // movzbl        %r8b,%r8d
  .byte  76,141,13,73,0,0,0                  // lea           0x49(%rip),%r9        # 2704 <_sk_load_565_hsw+0x10f>
  .byte  75,99,4,129                         // movslq        (%r9,%r8,4),%rax
  .byte  76,1,200                            // add           %r9,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  197,249,239,192                     // vpxor         %xmm0,%xmm0,%xmm0
  .byte  196,193,121,196,68,122,12,6         // vpinsrw       $0x6,0xc(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,10,5         // vpinsrw       $0x5,0xa(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,8,4          // vpinsrw       $0x4,0x8(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,6,3          // vpinsrw       $0x3,0x6(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,4,2          // vpinsrw       $0x2,0x4(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,2,1          // vpinsrw       $0x1,0x2(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,4,122,0             // vpinsrw       $0x0,(%r10,%rdi,2),%xmm0,%xmm0
  .byte  233,5,255,255,255                   // jmpq          2609 <_sk_load_565_hsw+0x14>
  .byte  244                                 // hlt
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  236                                 // in            (%dx),%al
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,228                             // jmpq          *%rsp
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  220,255                             // fdivr         %st,%st(7)
  .byte  255                                 // (bad)
  .byte  255,212                             // callq         *%rsp
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,204                             // dec           %esp
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,192                             // inc           %eax
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_gather_565_hsw
.globl _sk_gather_565_hsw
FUNCTION(_sk_gather_565_hsw)
_sk_gather_565_hsw:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  197,254,91,201                      // vcvttps2dq    %ymm1,%ymm1
  .byte  196,226,125,88,80,16                // vpbroadcastd  0x10(%rax),%ymm2
  .byte  196,226,109,64,201                  // vpmulld       %ymm1,%ymm2,%ymm1
  .byte  197,254,91,192                      // vcvttps2dq    %ymm0,%ymm0
  .byte  197,245,254,192                     // vpaddd        %ymm0,%ymm1,%ymm0
  .byte  196,227,249,22,192,1                // vpextrq       $0x1,%xmm0,%rax
  .byte  65,137,193                          // mov           %eax,%r9d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  196,193,249,126,194                 // vmovq         %xmm0,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  196,227,125,57,192,1                // vextracti128  $0x1,%ymm0,%xmm0
  .byte  196,227,249,22,195,1                // vpextrq       $0x1,%xmm0,%rbx
  .byte  65,137,222                          // mov           %ebx,%r14d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,193,249,126,199                 // vmovq         %xmm0,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  71,15,183,20,80                     // movzwl        (%r8,%r10,2),%r10d
  .byte  71,15,183,28,88                     // movzwl        (%r8,%r11,2),%r11d
  .byte  196,193,121,110,195                 // vmovd         %r11d,%xmm0
  .byte  196,193,121,196,194,1               // vpinsrw       $0x1,%r10d,%xmm0,%xmm0
  .byte  71,15,183,12,72                     // movzwl        (%r8,%r9,2),%r9d
  .byte  196,193,121,196,193,2               // vpinsrw       $0x2,%r9d,%xmm0,%xmm0
  .byte  65,15,183,4,64                      // movzwl        (%r8,%rax,2),%eax
  .byte  197,249,196,192,3                   // vpinsrw       $0x3,%eax,%xmm0,%xmm0
  .byte  67,15,183,4,96                      // movzwl        (%r8,%r12,2),%eax
  .byte  197,249,196,192,4                   // vpinsrw       $0x4,%eax,%xmm0,%xmm0
  .byte  67,15,183,4,120                     // movzwl        (%r8,%r15,2),%eax
  .byte  197,249,196,192,5                   // vpinsrw       $0x5,%eax,%xmm0,%xmm0
  .byte  67,15,183,4,112                     // movzwl        (%r8,%r14,2),%eax
  .byte  197,249,196,192,6                   // vpinsrw       $0x6,%eax,%xmm0,%xmm0
  .byte  65,15,183,4,88                      // movzwl        (%r8,%rbx,2),%eax
  .byte  197,249,196,192,7                   // vpinsrw       $0x7,%eax,%xmm0,%xmm0
  .byte  196,226,125,51,208                  // vpmovzxwd     %xmm0,%ymm2
  .byte  184,0,248,0,0                       // mov           $0xf800,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,226,125,88,192                  // vpbroadcastd  %xmm0,%ymm0
  .byte  197,253,219,194                     // vpand         %ymm2,%ymm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,8,33,132,55                     // mov           $0x37842108,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,252,89,193                      // vmulps        %ymm1,%ymm0,%ymm0
  .byte  184,224,7,0,0                       // mov           $0x7e0,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,245,219,202                     // vpand         %ymm2,%ymm1,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  184,33,8,2,58                       // mov           $0x3a020821,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  197,244,89,203                      // vmulps        %ymm3,%ymm1,%ymm1
  .byte  184,31,0,0,0                        // mov           $0x1f,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  197,229,219,210                     // vpand         %ymm2,%ymm3,%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  184,8,33,4,61                       // mov           $0x3d042108,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  197,236,89,211                      // vmulps        %ymm3,%ymm2,%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_565_hsw
.globl _sk_store_565_hsw
FUNCTION(_sk_store_565_hsw)
_sk_store_565_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  184,0,0,248,65                      // mov           $0x41f80000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,89,200                       // vmulps        %ymm0,%ymm8,%ymm9
  .byte  196,65,125,91,201                   // vcvtps2dq     %ymm9,%ymm9
  .byte  196,193,53,114,241,11               // vpslld        $0xb,%ymm9,%ymm9
  .byte  184,0,0,124,66                      // mov           $0x427c0000,%eax
  .byte  197,121,110,208                     // vmovd         %eax,%xmm10
  .byte  196,66,125,88,210                   // vpbroadcastd  %xmm10,%ymm10
  .byte  197,44,89,209                       // vmulps        %ymm1,%ymm10,%ymm10
  .byte  196,65,125,91,210                   // vcvtps2dq     %ymm10,%ymm10
  .byte  196,193,45,114,242,5                // vpslld        $0x5,%ymm10,%ymm10
  .byte  196,65,45,235,201                   // vpor          %ymm9,%ymm10,%ymm9
  .byte  197,60,89,194                       // vmulps        %ymm2,%ymm8,%ymm8
  .byte  196,65,125,91,192                   // vcvtps2dq     %ymm8,%ymm8
  .byte  196,65,53,235,192                   // vpor          %ymm8,%ymm9,%ymm8
  .byte  196,67,125,57,193,1                 // vextracti128  $0x1,%ymm8,%xmm9
  .byte  196,66,57,43,193                    // vpackusdw     %xmm9,%xmm8,%xmm8
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  117,10                              // jne           28cf <_sk_store_565_hsw+0x6c>
  .byte  196,65,122,127,4,121                // vmovdqu       %xmm8,(%r9,%rdi,2)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  65,128,224,7                        // and           $0x7,%r8b
  .byte  65,254,200                          // dec           %r8b
  .byte  65,128,248,6                        // cmp           $0x6,%r8b
  .byte  119,236                             // ja            28cb <_sk_store_565_hsw+0x68>
  .byte  65,15,182,192                       // movzbl        %r8b,%eax
  .byte  76,141,5,66,0,0,0                   // lea           0x42(%rip),%r8        # 292c <_sk_store_565_hsw+0xc9>
  .byte  73,99,4,128                         // movslq        (%r8,%rax,4),%rax
  .byte  76,1,192                            // add           %r8,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,67,121,21,68,121,12,6           // vpextrw       $0x6,%xmm8,0xc(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,10,5           // vpextrw       $0x5,%xmm8,0xa(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,8,4            // vpextrw       $0x4,%xmm8,0x8(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,6,3            // vpextrw       $0x3,%xmm8,0x6(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,4,2            // vpextrw       $0x2,%xmm8,0x4(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,2,1            // vpextrw       $0x1,%xmm8,0x2(%r9,%rdi,2)
  .byte  196,67,121,21,4,121,0               // vpextrw       $0x0,%xmm8,(%r9,%rdi,2)
  .byte  235,159                             // jmp           28cb <_sk_store_565_hsw+0x68>
  .byte  247,255                             // idiv          %edi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  239                                 // out           %eax,(%dx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,231                             // jmpq          *%rdi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  223,255                             // (bad)
  .byte  255                                 // (bad)
  .byte  255,215                             // callq         *%rdi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,207                             // dec           %edi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,199                             // inc           %edi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_load_4444_hsw
.globl _sk_load_4444_hsw
FUNCTION(_sk_load_4444_hsw)
_sk_load_4444_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,16                           // mov           (%rax),%r10
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  15,133,179,0,0,0                    // jne           2a09 <_sk_load_4444_hsw+0xc1>
  .byte  196,193,122,111,4,122               // vmovdqu       (%r10,%rdi,2),%xmm0
  .byte  196,98,125,51,200                   // vpmovzxwd     %xmm0,%ymm9
  .byte  184,0,240,0,0                       // mov           $0xf000,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,226,125,88,192                  // vpbroadcastd  %xmm0,%ymm0
  .byte  196,193,125,219,193                 // vpand         %ymm9,%ymm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,137,136,136,55                  // mov           $0x37888889,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,252,89,193                      // vmulps        %ymm1,%ymm0,%ymm0
  .byte  184,0,15,0,0                        // mov           $0xf00,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  196,193,117,219,201                 // vpand         %ymm9,%ymm1,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  184,137,136,136,57                  // mov           $0x39888889,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,226,125,88,210                  // vpbroadcastd  %xmm2,%ymm2
  .byte  197,244,89,202                      // vmulps        %ymm2,%ymm1,%ymm1
  .byte  184,240,0,0,0                       // mov           $0xf0,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,226,125,88,210                  // vpbroadcastd  %xmm2,%ymm2
  .byte  196,193,109,219,209                 // vpand         %ymm9,%ymm2,%ymm2
  .byte  197,124,91,194                      // vcvtdq2ps     %ymm2,%ymm8
  .byte  184,137,136,136,59                  // mov           $0x3b888889,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,226,125,88,210                  // vpbroadcastd  %xmm2,%ymm2
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  184,15,0,0,0                        // mov           $0xf,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  196,193,101,219,217                 // vpand         %ymm9,%ymm3,%ymm3
  .byte  197,124,91,195                      // vcvtdq2ps     %ymm3,%ymm8
  .byte  184,137,136,136,61                  // mov           $0x3d888889,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  65,128,224,7                        // and           $0x7,%r8b
  .byte  197,249,239,192                     // vpxor         %xmm0,%xmm0,%xmm0
  .byte  65,254,200                          // dec           %r8b
  .byte  65,128,248,6                        // cmp           $0x6,%r8b
  .byte  15,135,59,255,255,255               // ja            295c <_sk_load_4444_hsw+0x14>
  .byte  69,15,182,192                       // movzbl        %r8b,%r8d
  .byte  76,141,13,76,0,0,0                  // lea           0x4c(%rip),%r9        # 2a78 <_sk_load_4444_hsw+0x130>
  .byte  75,99,4,129                         // movslq        (%r9,%r8,4),%rax
  .byte  76,1,200                            // add           %r9,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  197,249,239,192                     // vpxor         %xmm0,%xmm0,%xmm0
  .byte  196,193,121,196,68,122,12,6         // vpinsrw       $0x6,0xc(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,10,5         // vpinsrw       $0x5,0xa(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,8,4          // vpinsrw       $0x4,0x8(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,6,3          // vpinsrw       $0x3,0x6(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,4,2          // vpinsrw       $0x2,0x4(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,2,1          // vpinsrw       $0x1,0x2(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,4,122,0             // vpinsrw       $0x0,(%r10,%rdi,2),%xmm0,%xmm0
  .byte  233,231,254,255,255                 // jmpq          295c <_sk_load_4444_hsw+0x14>
  .byte  15,31,0                             // nopl          (%rax)
  .byte  241                                 // icebp
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  233,255,255,255,225                 // jmpq          ffffffffe2002a80 <_sk_callback_hsw+0xffffffffe1ffeae6>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  217,255                             // fcos
  .byte  255                                 // (bad)
  .byte  255,209                             // callq         *%rcx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,201                             // dec           %ecx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  189                                 // .byte         0xbd
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_gather_4444_hsw
.globl _sk_gather_4444_hsw
FUNCTION(_sk_gather_4444_hsw)
_sk_gather_4444_hsw:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  197,254,91,201                      // vcvttps2dq    %ymm1,%ymm1
  .byte  196,226,125,88,80,16                // vpbroadcastd  0x10(%rax),%ymm2
  .byte  196,226,109,64,201                  // vpmulld       %ymm1,%ymm2,%ymm1
  .byte  197,254,91,192                      // vcvttps2dq    %ymm0,%ymm0
  .byte  197,245,254,192                     // vpaddd        %ymm0,%ymm1,%ymm0
  .byte  196,227,249,22,192,1                // vpextrq       $0x1,%xmm0,%rax
  .byte  65,137,193                          // mov           %eax,%r9d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  196,193,249,126,194                 // vmovq         %xmm0,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  196,227,125,57,192,1                // vextracti128  $0x1,%ymm0,%xmm0
  .byte  196,227,249,22,195,1                // vpextrq       $0x1,%xmm0,%rbx
  .byte  65,137,222                          // mov           %ebx,%r14d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,193,249,126,199                 // vmovq         %xmm0,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  71,15,183,20,80                     // movzwl        (%r8,%r10,2),%r10d
  .byte  71,15,183,28,88                     // movzwl        (%r8,%r11,2),%r11d
  .byte  196,193,121,110,195                 // vmovd         %r11d,%xmm0
  .byte  196,193,121,196,194,1               // vpinsrw       $0x1,%r10d,%xmm0,%xmm0
  .byte  71,15,183,12,72                     // movzwl        (%r8,%r9,2),%r9d
  .byte  196,193,121,196,193,2               // vpinsrw       $0x2,%r9d,%xmm0,%xmm0
  .byte  65,15,183,4,64                      // movzwl        (%r8,%rax,2),%eax
  .byte  197,249,196,192,3                   // vpinsrw       $0x3,%eax,%xmm0,%xmm0
  .byte  67,15,183,4,96                      // movzwl        (%r8,%r12,2),%eax
  .byte  197,249,196,192,4                   // vpinsrw       $0x4,%eax,%xmm0,%xmm0
  .byte  67,15,183,4,120                     // movzwl        (%r8,%r15,2),%eax
  .byte  197,249,196,192,5                   // vpinsrw       $0x5,%eax,%xmm0,%xmm0
  .byte  67,15,183,4,112                     // movzwl        (%r8,%r14,2),%eax
  .byte  197,249,196,192,6                   // vpinsrw       $0x6,%eax,%xmm0,%xmm0
  .byte  65,15,183,4,88                      // movzwl        (%r8,%rbx,2),%eax
  .byte  197,249,196,192,7                   // vpinsrw       $0x7,%eax,%xmm0,%xmm0
  .byte  196,98,125,51,200                   // vpmovzxwd     %xmm0,%ymm9
  .byte  184,0,240,0,0                       // mov           $0xf000,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,226,125,88,192                  // vpbroadcastd  %xmm0,%ymm0
  .byte  196,193,125,219,193                 // vpand         %ymm9,%ymm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,137,136,136,55                  // mov           $0x37888889,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,252,89,193                      // vmulps        %ymm1,%ymm0,%ymm0
  .byte  184,0,15,0,0                        // mov           $0xf00,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  196,193,117,219,201                 // vpand         %ymm9,%ymm1,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  184,137,136,136,57                  // mov           $0x39888889,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,226,125,88,210                  // vpbroadcastd  %xmm2,%ymm2
  .byte  197,244,89,202                      // vmulps        %ymm2,%ymm1,%ymm1
  .byte  184,240,0,0,0                       // mov           $0xf0,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,226,125,88,210                  // vpbroadcastd  %xmm2,%ymm2
  .byte  196,193,109,219,209                 // vpand         %ymm9,%ymm2,%ymm2
  .byte  197,124,91,194                      // vcvtdq2ps     %ymm2,%ymm8
  .byte  184,137,136,136,59                  // mov           $0x3b888889,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,226,125,88,210                  // vpbroadcastd  %xmm2,%ymm2
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  184,15,0,0,0                        // mov           $0xf,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  196,193,101,219,217                 // vpand         %ymm9,%ymm3,%ymm3
  .byte  197,124,91,195                      // vcvtdq2ps     %ymm3,%ymm8
  .byte  184,137,136,136,61                  // mov           $0x3d888889,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_4444_hsw
.globl _sk_store_4444_hsw
FUNCTION(_sk_store_4444_hsw)
_sk_store_4444_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  184,0,0,112,65                      // mov           $0x41700000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,89,200                       // vmulps        %ymm0,%ymm8,%ymm9
  .byte  196,65,125,91,201                   // vcvtps2dq     %ymm9,%ymm9
  .byte  196,193,53,114,241,12               // vpslld        $0xc,%ymm9,%ymm9
  .byte  197,60,89,209                       // vmulps        %ymm1,%ymm8,%ymm10
  .byte  196,65,125,91,210                   // vcvtps2dq     %ymm10,%ymm10
  .byte  196,193,45,114,242,8                // vpslld        $0x8,%ymm10,%ymm10
  .byte  196,65,45,235,201                   // vpor          %ymm9,%ymm10,%ymm9
  .byte  197,60,89,210                       // vmulps        %ymm2,%ymm8,%ymm10
  .byte  196,65,125,91,210                   // vcvtps2dq     %ymm10,%ymm10
  .byte  196,193,45,114,242,4                // vpslld        $0x4,%ymm10,%ymm10
  .byte  197,60,89,195                       // vmulps        %ymm3,%ymm8,%ymm8
  .byte  196,65,125,91,192                   // vcvtps2dq     %ymm8,%ymm8
  .byte  196,65,45,235,192                   // vpor          %ymm8,%ymm10,%ymm8
  .byte  196,65,53,235,192                   // vpor          %ymm8,%ymm9,%ymm8
  .byte  196,67,125,57,193,1                 // vextracti128  $0x1,%ymm8,%xmm9
  .byte  196,66,57,43,193                    // vpackusdw     %xmm9,%xmm8,%xmm8
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  117,10                              // jne           2c67 <_sk_store_4444_hsw+0x72>
  .byte  196,65,122,127,4,121                // vmovdqu       %xmm8,(%r9,%rdi,2)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  65,128,224,7                        // and           $0x7,%r8b
  .byte  65,254,200                          // dec           %r8b
  .byte  65,128,248,6                        // cmp           $0x6,%r8b
  .byte  119,236                             // ja            2c63 <_sk_store_4444_hsw+0x6e>
  .byte  65,15,182,192                       // movzbl        %r8b,%eax
  .byte  76,141,5,66,0,0,0                   // lea           0x42(%rip),%r8        # 2cc4 <_sk_store_4444_hsw+0xcf>
  .byte  73,99,4,128                         // movslq        (%r8,%rax,4),%rax
  .byte  76,1,192                            // add           %r8,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,67,121,21,68,121,12,6           // vpextrw       $0x6,%xmm8,0xc(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,10,5           // vpextrw       $0x5,%xmm8,0xa(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,8,4            // vpextrw       $0x4,%xmm8,0x8(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,6,3            // vpextrw       $0x3,%xmm8,0x6(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,4,2            // vpextrw       $0x2,%xmm8,0x4(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,2,1            // vpextrw       $0x1,%xmm8,0x2(%r9,%rdi,2)
  .byte  196,67,121,21,4,121,0               // vpextrw       $0x0,%xmm8,(%r9,%rdi,2)
  .byte  235,159                             // jmp           2c63 <_sk_store_4444_hsw+0x6e>
  .byte  247,255                             // idiv          %edi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  239                                 // out           %eax,(%dx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,231                             // jmpq          *%rdi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  223,255                             // (bad)
  .byte  255                                 // (bad)
  .byte  255,215                             // callq         *%rdi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,207                             // dec           %edi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,199                             // inc           %edi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_load_8888_hsw
.globl _sk_load_8888_hsw
FUNCTION(_sk_load_8888_hsw)
_sk_load_8888_hsw:
  .byte  73,137,200                          // mov           %rcx,%r8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,141,12,189,0,0,0,0               // lea           0x0(,%rdi,4),%r9
  .byte  76,3,8                              // add           (%rax),%r9
  .byte  77,133,192                          // test          %r8,%r8
  .byte  117,93                              // jne           2d52 <_sk_load_8888_hsw+0x72>
  .byte  196,193,126,111,25                  // vmovdqu       (%r9),%ymm3
  .byte  197,229,219,5,94,21,0,0             // vpand         0x155e(%rip),%ymm3,%ymm0        # 4260 <_sk_callback_hsw+0x2c6>
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,98,125,88,193                   // vpbroadcastd  %xmm1,%ymm8
  .byte  196,193,124,89,192                  // vmulps        %ymm8,%ymm0,%ymm0
  .byte  196,226,101,0,13,94,21,0,0          // vpshufb       0x155e(%rip),%ymm3,%ymm1        # 4280 <_sk_callback_hsw+0x2e6>
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  196,193,116,89,200                  // vmulps        %ymm8,%ymm1,%ymm1
  .byte  196,226,101,0,21,108,21,0,0         // vpshufb       0x156c(%rip),%ymm3,%ymm2        # 42a0 <_sk_callback_hsw+0x306>
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  196,193,108,89,208                  // vmulps        %ymm8,%ymm2,%ymm2
  .byte  197,229,114,211,24                  // vpsrld        $0x18,%ymm3,%ymm3
  .byte  197,252,91,219                      // vcvtdq2ps     %ymm3,%ymm3
  .byte  196,193,100,89,216                  // vmulps        %ymm8,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,137,193                          // mov           %r8,%rcx
  .byte  255,224                             // jmpq          *%rax
  .byte  185,8,0,0,0                         // mov           $0x8,%ecx
  .byte  68,41,193                           // sub           %r8d,%ecx
  .byte  192,225,3                           // shl           $0x3,%cl
  .byte  72,199,192,255,255,255,255          // mov           $0xffffffffffffffff,%rax
  .byte  72,211,232                          // shr           %cl,%rax
  .byte  196,225,249,110,192                 // vmovq         %rax,%xmm0
  .byte  196,226,125,33,192                  // vpmovsxbd     %xmm0,%ymm0
  .byte  196,194,125,140,25                  // vpmaskmovd    (%r9),%ymm0,%ymm3
  .byte  235,130                             // jmp           2cfa <_sk_load_8888_hsw+0x1a>

HIDDEN _sk_gather_8888_hsw
.globl _sk_gather_8888_hsw
FUNCTION(_sk_gather_8888_hsw)
_sk_gather_8888_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  197,254,91,201                      // vcvttps2dq    %ymm1,%ymm1
  .byte  196,226,125,88,80,16                // vpbroadcastd  0x10(%rax),%ymm2
  .byte  196,226,109,64,201                  // vpmulld       %ymm1,%ymm2,%ymm1
  .byte  197,254,91,192                      // vcvttps2dq    %ymm0,%ymm0
  .byte  197,245,254,192                     // vpaddd        %ymm0,%ymm1,%ymm0
  .byte  197,245,118,201                     // vpcmpeqd      %ymm1,%ymm1,%ymm1
  .byte  196,194,117,144,28,128              // vpgatherdd    %ymm1,(%r8,%ymm0,4),%ymm3
  .byte  197,229,219,5,26,21,0,0             // vpand         0x151a(%rip),%ymm3,%ymm0        # 42c0 <_sk_callback_hsw+0x326>
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,98,125,88,193                   // vpbroadcastd  %xmm1,%ymm8
  .byte  196,193,124,89,192                  // vmulps        %ymm8,%ymm0,%ymm0
  .byte  196,226,101,0,13,26,21,0,0          // vpshufb       0x151a(%rip),%ymm3,%ymm1        # 42e0 <_sk_callback_hsw+0x346>
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  196,193,116,89,200                  // vmulps        %ymm8,%ymm1,%ymm1
  .byte  196,226,101,0,21,40,21,0,0          // vpshufb       0x1528(%rip),%ymm3,%ymm2        # 4300 <_sk_callback_hsw+0x366>
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  196,193,108,89,208                  // vmulps        %ymm8,%ymm2,%ymm2
  .byte  197,229,114,211,24                  // vpsrld        $0x18,%ymm3,%ymm3
  .byte  197,252,91,219                      // vcvtdq2ps     %ymm3,%ymm3
  .byte  196,193,100,89,216                  // vmulps        %ymm8,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_8888_hsw
.globl _sk_store_8888_hsw
FUNCTION(_sk_store_8888_hsw)
_sk_store_8888_hsw:
  .byte  73,137,200                          // mov           %rcx,%r8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,141,12,189,0,0,0,0               // lea           0x0(,%rdi,4),%r9
  .byte  76,3,8                              // add           (%rax),%r9
  .byte  184,0,0,127,67                      // mov           $0x437f0000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,89,200                       // vmulps        %ymm0,%ymm8,%ymm9
  .byte  196,65,125,91,201                   // vcvtps2dq     %ymm9,%ymm9
  .byte  197,60,89,209                       // vmulps        %ymm1,%ymm8,%ymm10
  .byte  196,65,125,91,210                   // vcvtps2dq     %ymm10,%ymm10
  .byte  196,193,45,114,242,8                // vpslld        $0x8,%ymm10,%ymm10
  .byte  196,65,45,235,201                   // vpor          %ymm9,%ymm10,%ymm9
  .byte  197,60,89,210                       // vmulps        %ymm2,%ymm8,%ymm10
  .byte  196,65,125,91,210                   // vcvtps2dq     %ymm10,%ymm10
  .byte  196,193,45,114,242,16               // vpslld        $0x10,%ymm10,%ymm10
  .byte  197,60,89,195                       // vmulps        %ymm3,%ymm8,%ymm8
  .byte  196,65,125,91,192                   // vcvtps2dq     %ymm8,%ymm8
  .byte  196,193,61,114,240,24               // vpslld        $0x18,%ymm8,%ymm8
  .byte  196,65,45,235,192                   // vpor          %ymm8,%ymm10,%ymm8
  .byte  196,65,53,235,192                   // vpor          %ymm8,%ymm9,%ymm8
  .byte  77,133,192                          // test          %r8,%r8
  .byte  117,12                              // jne           2e67 <_sk_store_8888_hsw+0x74>
  .byte  196,65,126,127,1                    // vmovdqu       %ymm8,(%r9)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,137,193                          // mov           %r8,%rcx
  .byte  255,224                             // jmpq          *%rax
  .byte  185,8,0,0,0                         // mov           $0x8,%ecx
  .byte  68,41,193                           // sub           %r8d,%ecx
  .byte  192,225,3                           // shl           $0x3,%cl
  .byte  72,199,192,255,255,255,255          // mov           $0xffffffffffffffff,%rax
  .byte  72,211,232                          // shr           %cl,%rax
  .byte  196,97,249,110,200                  // vmovq         %rax,%xmm9
  .byte  196,66,125,33,201                   // vpmovsxbd     %xmm9,%ymm9
  .byte  196,66,53,142,1                     // vpmaskmovd    %ymm8,%ymm9,(%r9)
  .byte  235,211                             // jmp           2e60 <_sk_store_8888_hsw+0x6d>

HIDDEN _sk_load_f16_hsw
.globl _sk_load_f16_hsw
FUNCTION(_sk_load_f16_hsw)
_sk_load_f16_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  117,97                              // jne           2ef8 <_sk_load_f16_hsw+0x6b>
  .byte  197,121,16,4,248                    // vmovupd       (%rax,%rdi,8),%xmm8
  .byte  197,249,16,84,248,16                // vmovupd       0x10(%rax,%rdi,8),%xmm2
  .byte  197,249,16,92,248,32                // vmovupd       0x20(%rax,%rdi,8),%xmm3
  .byte  197,122,111,76,248,48               // vmovdqu       0x30(%rax,%rdi,8),%xmm9
  .byte  197,185,97,194                      // vpunpcklwd    %xmm2,%xmm8,%xmm0
  .byte  197,185,105,210                     // vpunpckhwd    %xmm2,%xmm8,%xmm2
  .byte  196,193,97,97,201                   // vpunpcklwd    %xmm9,%xmm3,%xmm1
  .byte  196,193,97,105,217                  // vpunpckhwd    %xmm9,%xmm3,%xmm3
  .byte  197,121,97,194                      // vpunpcklwd    %xmm2,%xmm0,%xmm8
  .byte  197,121,105,202                     // vpunpckhwd    %xmm2,%xmm0,%xmm9
  .byte  197,241,97,211                      // vpunpcklwd    %xmm3,%xmm1,%xmm2
  .byte  197,241,105,219                     // vpunpckhwd    %xmm3,%xmm1,%xmm3
  .byte  197,185,108,194                     // vpunpcklqdq   %xmm2,%xmm8,%xmm0
  .byte  196,226,125,19,192                  // vcvtph2ps     %xmm0,%ymm0
  .byte  197,185,109,202                     // vpunpckhqdq   %xmm2,%xmm8,%xmm1
  .byte  196,226,125,19,201                  // vcvtph2ps     %xmm1,%ymm1
  .byte  197,177,108,211                     // vpunpcklqdq   %xmm3,%xmm9,%xmm2
  .byte  196,226,125,19,210                  // vcvtph2ps     %xmm2,%ymm2
  .byte  197,177,109,219                     // vpunpckhqdq   %xmm3,%xmm9,%xmm3
  .byte  196,226,125,19,219                  // vcvtph2ps     %xmm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  197,123,16,4,248                    // vmovsd        (%rax,%rdi,8),%xmm8
  .byte  196,65,49,239,201                   // vpxor         %xmm9,%xmm9,%xmm9
  .byte  72,131,249,1                        // cmp           $0x1,%rcx
  .byte  116,79                              // je            2f57 <_sk_load_f16_hsw+0xca>
  .byte  197,57,22,68,248,8                  // vmovhpd       0x8(%rax,%rdi,8),%xmm8,%xmm8
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  114,67                              // jb            2f57 <_sk_load_f16_hsw+0xca>
  .byte  197,251,16,84,248,16                // vmovsd        0x10(%rax,%rdi,8),%xmm2
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  116,68                              // je            2f64 <_sk_load_f16_hsw+0xd7>
  .byte  197,233,22,84,248,24                // vmovhpd       0x18(%rax,%rdi,8),%xmm2,%xmm2
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  114,56                              // jb            2f64 <_sk_load_f16_hsw+0xd7>
  .byte  197,251,16,92,248,32                // vmovsd        0x20(%rax,%rdi,8),%xmm3
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  15,132,114,255,255,255              // je            2eae <_sk_load_f16_hsw+0x21>
  .byte  197,225,22,92,248,40                // vmovhpd       0x28(%rax,%rdi,8),%xmm3,%xmm3
  .byte  72,131,249,7                        // cmp           $0x7,%rcx
  .byte  15,130,98,255,255,255               // jb            2eae <_sk_load_f16_hsw+0x21>
  .byte  197,122,126,76,248,48               // vmovq         0x30(%rax,%rdi,8),%xmm9
  .byte  233,87,255,255,255                  // jmpq          2eae <_sk_load_f16_hsw+0x21>
  .byte  197,225,87,219                      // vxorpd        %xmm3,%xmm3,%xmm3
  .byte  197,233,87,210                      // vxorpd        %xmm2,%xmm2,%xmm2
  .byte  233,74,255,255,255                  // jmpq          2eae <_sk_load_f16_hsw+0x21>
  .byte  197,225,87,219                      // vxorpd        %xmm3,%xmm3,%xmm3
  .byte  233,65,255,255,255                  // jmpq          2eae <_sk_load_f16_hsw+0x21>

HIDDEN _sk_gather_f16_hsw
.globl _sk_gather_f16_hsw
FUNCTION(_sk_gather_f16_hsw)
_sk_gather_f16_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  197,254,91,201                      // vcvttps2dq    %ymm1,%ymm1
  .byte  196,226,125,88,80,16                // vpbroadcastd  0x10(%rax),%ymm2
  .byte  196,226,109,64,201                  // vpmulld       %ymm1,%ymm2,%ymm1
  .byte  197,254,91,192                      // vcvttps2dq    %ymm0,%ymm0
  .byte  197,245,254,192                     // vpaddd        %ymm0,%ymm1,%ymm0
  .byte  197,245,118,201                     // vpcmpeqd      %ymm1,%ymm1,%ymm1
  .byte  197,237,118,210                     // vpcmpeqd      %ymm2,%ymm2,%ymm2
  .byte  196,194,237,144,28,192              // vpgatherdq    %ymm2,(%r8,%xmm0,8),%ymm3
  .byte  196,227,125,57,192,1                // vextracti128  $0x1,%ymm0,%xmm0
  .byte  196,194,245,144,20,192              // vpgatherdq    %ymm1,(%r8,%xmm0,8),%ymm2
  .byte  196,227,125,57,216,1                // vextracti128  $0x1,%ymm3,%xmm0
  .byte  196,227,125,57,209,1                // vextracti128  $0x1,%ymm2,%xmm1
  .byte  197,97,97,192                       // vpunpcklwd    %xmm0,%xmm3,%xmm8
  .byte  197,225,105,192                     // vpunpckhwd    %xmm0,%xmm3,%xmm0
  .byte  197,233,97,217                      // vpunpcklwd    %xmm1,%xmm2,%xmm3
  .byte  197,233,105,201                     // vpunpckhwd    %xmm1,%xmm2,%xmm1
  .byte  197,57,97,200                       // vpunpcklwd    %xmm0,%xmm8,%xmm9
  .byte  197,57,105,192                      // vpunpckhwd    %xmm0,%xmm8,%xmm8
  .byte  197,225,97,209                      // vpunpcklwd    %xmm1,%xmm3,%xmm2
  .byte  197,225,105,217                     // vpunpckhwd    %xmm1,%xmm3,%xmm3
  .byte  197,177,108,194                     // vpunpcklqdq   %xmm2,%xmm9,%xmm0
  .byte  196,226,125,19,192                  // vcvtph2ps     %xmm0,%ymm0
  .byte  197,177,109,202                     // vpunpckhqdq   %xmm2,%xmm9,%xmm1
  .byte  196,226,125,19,201                  // vcvtph2ps     %xmm1,%ymm1
  .byte  197,185,108,211                     // vpunpcklqdq   %xmm3,%xmm8,%xmm2
  .byte  196,226,125,19,210                  // vcvtph2ps     %xmm2,%ymm2
  .byte  197,185,109,219                     // vpunpckhqdq   %xmm3,%xmm8,%xmm3
  .byte  196,226,125,19,219                  // vcvtph2ps     %xmm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_f16_hsw
.globl _sk_store_f16_hsw
FUNCTION(_sk_store_f16_hsw)
_sk_store_f16_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  196,195,125,29,192,4                // vcvtps2ph     $0x4,%ymm0,%xmm8
  .byte  196,195,125,29,201,4                // vcvtps2ph     $0x4,%ymm1,%xmm9
  .byte  196,195,125,29,210,4                // vcvtps2ph     $0x4,%ymm2,%xmm10
  .byte  196,195,125,29,219,4                // vcvtps2ph     $0x4,%ymm3,%xmm11
  .byte  196,65,57,97,225                    // vpunpcklwd    %xmm9,%xmm8,%xmm12
  .byte  196,65,57,105,193                   // vpunpckhwd    %xmm9,%xmm8,%xmm8
  .byte  196,65,41,97,203                    // vpunpcklwd    %xmm11,%xmm10,%xmm9
  .byte  196,65,41,105,235                   // vpunpckhwd    %xmm11,%xmm10,%xmm13
  .byte  196,65,25,98,217                    // vpunpckldq    %xmm9,%xmm12,%xmm11
  .byte  196,65,25,106,209                   // vpunpckhdq    %xmm9,%xmm12,%xmm10
  .byte  196,65,57,98,205                    // vpunpckldq    %xmm13,%xmm8,%xmm9
  .byte  196,65,57,106,197                   // vpunpckhdq    %xmm13,%xmm8,%xmm8
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  117,27                              // jne           305c <_sk_store_f16_hsw+0x65>
  .byte  197,120,17,28,248                   // vmovups       %xmm11,(%rax,%rdi,8)
  .byte  197,120,17,84,248,16                // vmovups       %xmm10,0x10(%rax,%rdi,8)
  .byte  197,120,17,76,248,32                // vmovups       %xmm9,0x20(%rax,%rdi,8)
  .byte  197,122,127,68,248,48               // vmovdqu       %xmm8,0x30(%rax,%rdi,8)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  197,121,214,28,248                  // vmovq         %xmm11,(%rax,%rdi,8)
  .byte  72,131,249,1                        // cmp           $0x1,%rcx
  .byte  116,241                             // je            3058 <_sk_store_f16_hsw+0x61>
  .byte  197,121,23,92,248,8                 // vmovhpd       %xmm11,0x8(%rax,%rdi,8)
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  114,229                             // jb            3058 <_sk_store_f16_hsw+0x61>
  .byte  197,121,214,84,248,16               // vmovq         %xmm10,0x10(%rax,%rdi,8)
  .byte  116,221                             // je            3058 <_sk_store_f16_hsw+0x61>
  .byte  197,121,23,84,248,24                // vmovhpd       %xmm10,0x18(%rax,%rdi,8)
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  114,209                             // jb            3058 <_sk_store_f16_hsw+0x61>
  .byte  197,121,214,76,248,32               // vmovq         %xmm9,0x20(%rax,%rdi,8)
  .byte  116,201                             // je            3058 <_sk_store_f16_hsw+0x61>
  .byte  197,121,23,76,248,40                // vmovhpd       %xmm9,0x28(%rax,%rdi,8)
  .byte  72,131,249,7                        // cmp           $0x7,%rcx
  .byte  114,189                             // jb            3058 <_sk_store_f16_hsw+0x61>
  .byte  197,121,214,68,248,48               // vmovq         %xmm8,0x30(%rax,%rdi,8)
  .byte  235,181                             // jmp           3058 <_sk_store_f16_hsw+0x61>

HIDDEN _sk_load_u16_be_hsw
.globl _sk_load_u16_be_hsw
FUNCTION(_sk_load_u16_be_hsw)
_sk_load_u16_be_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  72,141,4,189,0,0,0,0                // lea           0x0(,%rdi,4),%rax
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  15,133,205,0,0,0                    // jne           3186 <_sk_load_u16_be_hsw+0xe3>
  .byte  196,65,121,16,4,64                  // vmovupd       (%r8,%rax,2),%xmm8
  .byte  196,193,121,16,84,64,16             // vmovupd       0x10(%r8,%rax,2),%xmm2
  .byte  196,193,121,16,92,64,32             // vmovupd       0x20(%r8,%rax,2),%xmm3
  .byte  196,65,122,111,76,64,48             // vmovdqu       0x30(%r8,%rax,2),%xmm9
  .byte  197,185,97,194                      // vpunpcklwd    %xmm2,%xmm8,%xmm0
  .byte  197,185,105,210                     // vpunpckhwd    %xmm2,%xmm8,%xmm2
  .byte  196,193,97,97,201                   // vpunpcklwd    %xmm9,%xmm3,%xmm1
  .byte  196,193,97,105,217                  // vpunpckhwd    %xmm9,%xmm3,%xmm3
  .byte  197,121,97,194                      // vpunpcklwd    %xmm2,%xmm0,%xmm8
  .byte  197,121,105,202                     // vpunpckhwd    %xmm2,%xmm0,%xmm9
  .byte  197,241,97,211                      // vpunpcklwd    %xmm3,%xmm1,%xmm2
  .byte  197,113,105,219                     // vpunpckhwd    %xmm3,%xmm1,%xmm11
  .byte  184,128,0,128,55                    // mov           $0x37800080,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,98,125,88,208                   // vpbroadcastd  %xmm0,%ymm10
  .byte  197,185,108,194                     // vpunpcklqdq   %xmm2,%xmm8,%xmm0
  .byte  197,241,113,240,8                   // vpsllw        $0x8,%xmm0,%xmm1
  .byte  197,249,113,208,8                   // vpsrlw        $0x8,%xmm0,%xmm0
  .byte  197,241,235,192                     // vpor          %xmm0,%xmm1,%xmm0
  .byte  196,226,125,51,192                  // vpmovzxwd     %xmm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  197,172,89,192                      // vmulps        %ymm0,%ymm10,%ymm0
  .byte  197,185,109,202                     // vpunpckhqdq   %xmm2,%xmm8,%xmm1
  .byte  197,233,113,241,8                   // vpsllw        $0x8,%xmm1,%xmm2
  .byte  197,241,113,209,8                   // vpsrlw        $0x8,%xmm1,%xmm1
  .byte  197,233,235,201                     // vpor          %xmm1,%xmm2,%xmm1
  .byte  196,226,125,51,201                  // vpmovzxwd     %xmm1,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  197,172,89,201                      // vmulps        %ymm1,%ymm10,%ymm1
  .byte  196,193,49,108,211                  // vpunpcklqdq   %xmm11,%xmm9,%xmm2
  .byte  197,225,113,242,8                   // vpsllw        $0x8,%xmm2,%xmm3
  .byte  197,233,113,210,8                   // vpsrlw        $0x8,%xmm2,%xmm2
  .byte  197,225,235,210                     // vpor          %xmm2,%xmm3,%xmm2
  .byte  196,226,125,51,210                  // vpmovzxwd     %xmm2,%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  197,172,89,210                      // vmulps        %ymm2,%ymm10,%ymm2
  .byte  196,193,49,109,219                  // vpunpckhqdq   %xmm11,%xmm9,%xmm3
  .byte  197,185,113,243,8                   // vpsllw        $0x8,%xmm3,%xmm8
  .byte  197,225,113,211,8                   // vpsrlw        $0x8,%xmm3,%xmm3
  .byte  197,185,235,219                     // vpor          %xmm3,%xmm8,%xmm3
  .byte  196,226,125,51,219                  // vpmovzxwd     %xmm3,%ymm3
  .byte  197,252,91,219                      // vcvtdq2ps     %ymm3,%ymm3
  .byte  197,172,89,219                      // vmulps        %ymm3,%ymm10,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,65,123,16,4,64                  // vmovsd        (%r8,%rax,2),%xmm8
  .byte  196,65,49,239,201                   // vpxor         %xmm9,%xmm9,%xmm9
  .byte  72,131,249,1                        // cmp           $0x1,%rcx
  .byte  116,85                              // je            31ec <_sk_load_u16_be_hsw+0x149>
  .byte  196,65,57,22,68,64,8                // vmovhpd       0x8(%r8,%rax,2),%xmm8,%xmm8
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  114,72                              // jb            31ec <_sk_load_u16_be_hsw+0x149>
  .byte  196,193,123,16,84,64,16             // vmovsd        0x10(%r8,%rax,2),%xmm2
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  116,72                              // je            31f9 <_sk_load_u16_be_hsw+0x156>
  .byte  196,193,105,22,84,64,24             // vmovhpd       0x18(%r8,%rax,2),%xmm2,%xmm2
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  114,59                              // jb            31f9 <_sk_load_u16_be_hsw+0x156>
  .byte  196,193,123,16,92,64,32             // vmovsd        0x20(%r8,%rax,2),%xmm3
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  15,132,5,255,255,255                // je            30d4 <_sk_load_u16_be_hsw+0x31>
  .byte  196,193,97,22,92,64,40              // vmovhpd       0x28(%r8,%rax,2),%xmm3,%xmm3
  .byte  72,131,249,7                        // cmp           $0x7,%rcx
  .byte  15,130,244,254,255,255              // jb            30d4 <_sk_load_u16_be_hsw+0x31>
  .byte  196,65,122,126,76,64,48             // vmovq         0x30(%r8,%rax,2),%xmm9
  .byte  233,232,254,255,255                 // jmpq          30d4 <_sk_load_u16_be_hsw+0x31>
  .byte  197,225,87,219                      // vxorpd        %xmm3,%xmm3,%xmm3
  .byte  197,233,87,210                      // vxorpd        %xmm2,%xmm2,%xmm2
  .byte  233,219,254,255,255                 // jmpq          30d4 <_sk_load_u16_be_hsw+0x31>
  .byte  197,225,87,219                      // vxorpd        %xmm3,%xmm3,%xmm3
  .byte  233,210,254,255,255                 // jmpq          30d4 <_sk_load_u16_be_hsw+0x31>

HIDDEN _sk_load_rgb_u16_be_hsw
.globl _sk_load_rgb_u16_be_hsw
FUNCTION(_sk_load_rgb_u16_be_hsw)
_sk_load_rgb_u16_be_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  72,141,4,127                        // lea           (%rdi,%rdi,2),%rax
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  15,133,211,0,0,0                    // jne           32e7 <_sk_load_rgb_u16_be_hsw+0xe5>
  .byte  196,193,122,111,4,64                // vmovdqu       (%r8,%rax,2),%xmm0
  .byte  196,193,122,111,84,64,12            // vmovdqu       0xc(%r8,%rax,2),%xmm2
  .byte  196,193,122,111,76,64,24            // vmovdqu       0x18(%r8,%rax,2),%xmm1
  .byte  196,193,122,111,92,64,32            // vmovdqu       0x20(%r8,%rax,2),%xmm3
  .byte  197,225,115,219,4                   // vpsrldq       $0x4,%xmm3,%xmm3
  .byte  197,185,115,216,6                   // vpsrldq       $0x6,%xmm0,%xmm8
  .byte  197,177,115,218,6                   // vpsrldq       $0x6,%xmm2,%xmm9
  .byte  197,161,115,217,6                   // vpsrldq       $0x6,%xmm1,%xmm11
  .byte  197,169,115,219,6                   // vpsrldq       $0x6,%xmm3,%xmm10
  .byte  197,249,97,194                      // vpunpcklwd    %xmm2,%xmm0,%xmm0
  .byte  196,193,57,97,209                   // vpunpcklwd    %xmm9,%xmm8,%xmm2
  .byte  197,241,97,203                      // vpunpcklwd    %xmm3,%xmm1,%xmm1
  .byte  196,193,33,97,218                   // vpunpcklwd    %xmm10,%xmm11,%xmm3
  .byte  197,121,97,194                      // vpunpcklwd    %xmm2,%xmm0,%xmm8
  .byte  197,121,105,202                     // vpunpckhwd    %xmm2,%xmm0,%xmm9
  .byte  197,241,97,211                      // vpunpcklwd    %xmm3,%xmm1,%xmm2
  .byte  197,241,105,219                     // vpunpckhwd    %xmm3,%xmm1,%xmm3
  .byte  184,128,0,128,55                    // mov           $0x37800080,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,98,125,88,208                   // vpbroadcastd  %xmm0,%ymm10
  .byte  197,185,108,194                     // vpunpcklqdq   %xmm2,%xmm8,%xmm0
  .byte  197,241,113,240,8                   // vpsllw        $0x8,%xmm0,%xmm1
  .byte  197,249,113,208,8                   // vpsrlw        $0x8,%xmm0,%xmm0
  .byte  197,241,235,192                     // vpor          %xmm0,%xmm1,%xmm0
  .byte  196,226,125,51,192                  // vpmovzxwd     %xmm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  197,172,89,192                      // vmulps        %ymm0,%ymm10,%ymm0
  .byte  197,185,109,202                     // vpunpckhqdq   %xmm2,%xmm8,%xmm1
  .byte  197,233,113,241,8                   // vpsllw        $0x8,%xmm1,%xmm2
  .byte  197,241,113,209,8                   // vpsrlw        $0x8,%xmm1,%xmm1
  .byte  197,233,235,201                     // vpor          %xmm1,%xmm2,%xmm1
  .byte  196,226,125,51,201                  // vpmovzxwd     %xmm1,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  197,172,89,201                      // vmulps        %ymm1,%ymm10,%ymm1
  .byte  197,177,108,211                     // vpunpcklqdq   %xmm3,%xmm9,%xmm2
  .byte  197,225,113,242,8                   // vpsllw        $0x8,%xmm2,%xmm3
  .byte  197,233,113,210,8                   // vpsrlw        $0x8,%xmm2,%xmm2
  .byte  197,225,235,210                     // vpor          %xmm2,%xmm3,%xmm2
  .byte  196,226,125,51,210                  // vpmovzxwd     %xmm2,%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  197,172,89,210                      // vmulps        %ymm2,%ymm10,%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,193,121,110,4,64                // vmovd         (%r8,%rax,2),%xmm0
  .byte  196,193,121,196,68,64,4,2           // vpinsrw       $0x2,0x4(%r8,%rax,2),%xmm0,%xmm0
  .byte  72,131,249,1                        // cmp           $0x1,%rcx
  .byte  117,5                               // jne           3300 <_sk_load_rgb_u16_be_hsw+0xfe>
  .byte  233,72,255,255,255                  // jmpq          3248 <_sk_load_rgb_u16_be_hsw+0x46>
  .byte  196,193,121,110,76,64,6             // vmovd         0x6(%r8,%rax,2),%xmm1
  .byte  196,65,113,196,68,64,10,2           // vpinsrw       $0x2,0xa(%r8,%rax,2),%xmm1,%xmm8
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  114,26                              // jb            332f <_sk_load_rgb_u16_be_hsw+0x12d>
  .byte  196,193,121,110,76,64,12            // vmovd         0xc(%r8,%rax,2),%xmm1
  .byte  196,193,113,196,84,64,16,2          // vpinsrw       $0x2,0x10(%r8,%rax,2),%xmm1,%xmm2
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  117,10                              // jne           3334 <_sk_load_rgb_u16_be_hsw+0x132>
  .byte  233,25,255,255,255                  // jmpq          3248 <_sk_load_rgb_u16_be_hsw+0x46>
  .byte  233,20,255,255,255                  // jmpq          3248 <_sk_load_rgb_u16_be_hsw+0x46>
  .byte  196,193,121,110,76,64,18            // vmovd         0x12(%r8,%rax,2),%xmm1
  .byte  196,65,113,196,76,64,22,2           // vpinsrw       $0x2,0x16(%r8,%rax,2),%xmm1,%xmm9
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  114,26                              // jb            3363 <_sk_load_rgb_u16_be_hsw+0x161>
  .byte  196,193,121,110,76,64,24            // vmovd         0x18(%r8,%rax,2),%xmm1
  .byte  196,193,113,196,76,64,28,2          // vpinsrw       $0x2,0x1c(%r8,%rax,2),%xmm1,%xmm1
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  117,10                              // jne           3368 <_sk_load_rgb_u16_be_hsw+0x166>
  .byte  233,229,254,255,255                 // jmpq          3248 <_sk_load_rgb_u16_be_hsw+0x46>
  .byte  233,224,254,255,255                 // jmpq          3248 <_sk_load_rgb_u16_be_hsw+0x46>
  .byte  196,193,121,110,92,64,30            // vmovd         0x1e(%r8,%rax,2),%xmm3
  .byte  196,65,97,196,92,64,34,2            // vpinsrw       $0x2,0x22(%r8,%rax,2),%xmm3,%xmm11
  .byte  72,131,249,7                        // cmp           $0x7,%rcx
  .byte  114,20                              // jb            3391 <_sk_load_rgb_u16_be_hsw+0x18f>
  .byte  196,193,121,110,92,64,36            // vmovd         0x24(%r8,%rax,2),%xmm3
  .byte  196,193,97,196,92,64,40,2           // vpinsrw       $0x2,0x28(%r8,%rax,2),%xmm3,%xmm3
  .byte  233,183,254,255,255                 // jmpq          3248 <_sk_load_rgb_u16_be_hsw+0x46>
  .byte  233,178,254,255,255                 // jmpq          3248 <_sk_load_rgb_u16_be_hsw+0x46>

HIDDEN _sk_store_u16_be_hsw
.globl _sk_store_u16_be_hsw
FUNCTION(_sk_store_u16_be_hsw)
_sk_store_u16_be_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  76,141,12,189,0,0,0,0               // lea           0x0(,%rdi,4),%r9
  .byte  184,0,255,127,71                    // mov           $0x477fff00,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,89,200                       // vmulps        %ymm0,%ymm8,%ymm9
  .byte  196,65,125,91,201                   // vcvtps2dq     %ymm9,%ymm9
  .byte  196,67,125,25,202,1                 // vextractf128  $0x1,%ymm9,%xmm10
  .byte  196,66,49,43,202                    // vpackusdw     %xmm10,%xmm9,%xmm9
  .byte  196,193,41,113,241,8                // vpsllw        $0x8,%xmm9,%xmm10
  .byte  196,193,49,113,209,8                // vpsrlw        $0x8,%xmm9,%xmm9
  .byte  196,65,41,235,201                   // vpor          %xmm9,%xmm10,%xmm9
  .byte  197,60,89,209                       // vmulps        %ymm1,%ymm8,%ymm10
  .byte  196,65,125,91,210                   // vcvtps2dq     %ymm10,%ymm10
  .byte  196,67,125,25,211,1                 // vextractf128  $0x1,%ymm10,%xmm11
  .byte  196,66,41,43,211                    // vpackusdw     %xmm11,%xmm10,%xmm10
  .byte  196,193,33,113,242,8                // vpsllw        $0x8,%xmm10,%xmm11
  .byte  196,193,41,113,210,8                // vpsrlw        $0x8,%xmm10,%xmm10
  .byte  196,65,33,235,210                   // vpor          %xmm10,%xmm11,%xmm10
  .byte  197,60,89,218                       // vmulps        %ymm2,%ymm8,%ymm11
  .byte  196,65,125,91,219                   // vcvtps2dq     %ymm11,%ymm11
  .byte  196,67,125,25,220,1                 // vextractf128  $0x1,%ymm11,%xmm12
  .byte  196,66,33,43,220                    // vpackusdw     %xmm12,%xmm11,%xmm11
  .byte  196,193,25,113,243,8                // vpsllw        $0x8,%xmm11,%xmm12
  .byte  196,193,33,113,211,8                // vpsrlw        $0x8,%xmm11,%xmm11
  .byte  196,65,25,235,219                   // vpor          %xmm11,%xmm12,%xmm11
  .byte  197,60,89,195                       // vmulps        %ymm3,%ymm8,%ymm8
  .byte  196,65,125,91,192                   // vcvtps2dq     %ymm8,%ymm8
  .byte  196,67,125,25,196,1                 // vextractf128  $0x1,%ymm8,%xmm12
  .byte  196,66,57,43,196                    // vpackusdw     %xmm12,%xmm8,%xmm8
  .byte  196,193,25,113,240,8                // vpsllw        $0x8,%xmm8,%xmm12
  .byte  196,193,57,113,208,8                // vpsrlw        $0x8,%xmm8,%xmm8
  .byte  196,65,25,235,192                   // vpor          %xmm8,%xmm12,%xmm8
  .byte  196,65,49,97,226                    // vpunpcklwd    %xmm10,%xmm9,%xmm12
  .byte  196,65,49,105,234                   // vpunpckhwd    %xmm10,%xmm9,%xmm13
  .byte  196,65,33,97,200                    // vpunpcklwd    %xmm8,%xmm11,%xmm9
  .byte  196,65,33,105,192                   // vpunpckhwd    %xmm8,%xmm11,%xmm8
  .byte  196,65,25,98,217                    // vpunpckldq    %xmm9,%xmm12,%xmm11
  .byte  196,65,25,106,209                   // vpunpckhdq    %xmm9,%xmm12,%xmm10
  .byte  196,65,17,98,200                    // vpunpckldq    %xmm8,%xmm13,%xmm9
  .byte  196,65,17,106,192                   // vpunpckhdq    %xmm8,%xmm13,%xmm8
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  117,31                              // jne           3491 <_sk_store_u16_be_hsw+0xfb>
  .byte  196,1,120,17,28,72                  // vmovups       %xmm11,(%r8,%r9,2)
  .byte  196,1,120,17,84,72,16               // vmovups       %xmm10,0x10(%r8,%r9,2)
  .byte  196,1,120,17,76,72,32               // vmovups       %xmm9,0x20(%r8,%r9,2)
  .byte  196,1,122,127,68,72,48              // vmovdqu       %xmm8,0x30(%r8,%r9,2)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,1,121,214,28,72                 // vmovq         %xmm11,(%r8,%r9,2)
  .byte  72,131,249,1                        // cmp           $0x1,%rcx
  .byte  116,240                             // je            348d <_sk_store_u16_be_hsw+0xf7>
  .byte  196,1,121,23,92,72,8                // vmovhpd       %xmm11,0x8(%r8,%r9,2)
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  114,227                             // jb            348d <_sk_store_u16_be_hsw+0xf7>
  .byte  196,1,121,214,84,72,16              // vmovq         %xmm10,0x10(%r8,%r9,2)
  .byte  116,218                             // je            348d <_sk_store_u16_be_hsw+0xf7>
  .byte  196,1,121,23,84,72,24               // vmovhpd       %xmm10,0x18(%r8,%r9,2)
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  114,205                             // jb            348d <_sk_store_u16_be_hsw+0xf7>
  .byte  196,1,121,214,76,72,32              // vmovq         %xmm9,0x20(%r8,%r9,2)
  .byte  116,196                             // je            348d <_sk_store_u16_be_hsw+0xf7>
  .byte  196,1,121,23,76,72,40               // vmovhpd       %xmm9,0x28(%r8,%r9,2)
  .byte  72,131,249,7                        // cmp           $0x7,%rcx
  .byte  114,183                             // jb            348d <_sk_store_u16_be_hsw+0xf7>
  .byte  196,1,121,214,68,72,48              // vmovq         %xmm8,0x30(%r8,%r9,2)
  .byte  235,174                             // jmp           348d <_sk_store_u16_be_hsw+0xf7>

HIDDEN _sk_load_f32_hsw
.globl _sk_load_f32_hsw
FUNCTION(_sk_load_f32_hsw)
_sk_load_f32_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,131,249,7                        // cmp           $0x7,%rcx
  .byte  119,110                             // ja            3555 <_sk_load_f32_hsw+0x76>
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  76,141,12,189,0,0,0,0               // lea           0x0(,%rdi,4),%r9
  .byte  76,141,21,135,0,0,0                 // lea           0x87(%rip),%r10        # 3580 <_sk_load_f32_hsw+0xa1>
  .byte  73,99,4,138                         // movslq        (%r10,%rcx,4),%rax
  .byte  76,1,208                            // add           %r10,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,3,125,24,68,136,112,1           // vinsertf128   $0x1,0x70(%r8,%r9,4),%ymm0,%ymm8
  .byte  196,131,125,24,92,136,96,1          // vinsertf128   $0x1,0x60(%r8,%r9,4),%ymm0,%ymm3
  .byte  196,131,125,24,76,136,80,1          // vinsertf128   $0x1,0x50(%r8,%r9,4),%ymm0,%ymm1
  .byte  196,131,125,24,84,136,64,1          // vinsertf128   $0x1,0x40(%r8,%r9,4),%ymm0,%ymm2
  .byte  196,129,121,16,68,136,48            // vmovupd       0x30(%r8,%r9,4),%xmm0
  .byte  196,195,125,13,192,12               // vblendpd      $0xc,%ymm8,%ymm0,%ymm0
  .byte  196,1,121,16,68,136,32              // vmovupd       0x20(%r8,%r9,4),%xmm8
  .byte  196,99,61,13,203,12                 // vblendpd      $0xc,%ymm3,%ymm8,%ymm9
  .byte  196,129,121,16,92,136,16            // vmovupd       0x10(%r8,%r9,4),%xmm3
  .byte  196,99,101,13,209,12                // vblendpd      $0xc,%ymm1,%ymm3,%ymm10
  .byte  196,129,121,16,12,136               // vmovupd       (%r8,%r9,4),%xmm1
  .byte  196,227,117,13,202,12               // vblendpd      $0xc,%ymm2,%ymm1,%ymm1
  .byte  196,193,116,20,210                  // vunpcklps     %ymm10,%ymm1,%ymm2
  .byte  196,193,116,21,218                  // vunpckhps     %ymm10,%ymm1,%ymm3
  .byte  197,180,20,200                      // vunpcklps     %ymm0,%ymm9,%ymm1
  .byte  197,52,21,192                       // vunpckhps     %ymm0,%ymm9,%ymm8
  .byte  197,237,20,193                      // vunpcklpd     %ymm1,%ymm2,%ymm0
  .byte  197,237,21,201                      // vunpckhpd     %ymm1,%ymm2,%ymm1
  .byte  196,193,101,20,208                  // vunpcklpd     %ymm8,%ymm3,%ymm2
  .byte  196,193,101,21,216                  // vunpckhpd     %ymm8,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  15,31,0                             // nopl          (%rax)
  .byte  130                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,201                             // dec           %ecx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  188,255,255,255,175                 // mov           $0xafffffff,%esp
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,162,255,255,255,154             // jmpq          *-0x65000001(%rdx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,146,255,255,255,138             // callq         *-0x75000001(%rdx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_store_f32_hsw
.globl _sk_store_f32_hsw
FUNCTION(_sk_store_f32_hsw)
_sk_store_f32_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  72,141,4,189,0,0,0,0                // lea           0x0(,%rdi,4),%rax
  .byte  197,124,20,193                      // vunpcklps     %ymm1,%ymm0,%ymm8
  .byte  197,124,21,217                      // vunpckhps     %ymm1,%ymm0,%ymm11
  .byte  197,108,20,203                      // vunpcklps     %ymm3,%ymm2,%ymm9
  .byte  197,108,21,227                      // vunpckhps     %ymm3,%ymm2,%ymm12
  .byte  196,65,61,20,209                    // vunpcklpd     %ymm9,%ymm8,%ymm10
  .byte  196,65,61,21,201                    // vunpckhpd     %ymm9,%ymm8,%ymm9
  .byte  196,65,37,20,196                    // vunpcklpd     %ymm12,%ymm11,%ymm8
  .byte  196,65,37,21,220                    // vunpckhpd     %ymm12,%ymm11,%ymm11
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  117,55                              // jne           360d <_sk_store_f32_hsw+0x6d>
  .byte  196,67,45,24,225,1                  // vinsertf128   $0x1,%xmm9,%ymm10,%ymm12
  .byte  196,67,61,24,235,1                  // vinsertf128   $0x1,%xmm11,%ymm8,%ymm13
  .byte  196,67,45,6,201,49                  // vperm2f128    $0x31,%ymm9,%ymm10,%ymm9
  .byte  196,67,61,6,195,49                  // vperm2f128    $0x31,%ymm11,%ymm8,%ymm8
  .byte  196,65,125,17,36,128                // vmovupd       %ymm12,(%r8,%rax,4)
  .byte  196,65,125,17,108,128,32            // vmovupd       %ymm13,0x20(%r8,%rax,4)
  .byte  196,65,125,17,76,128,64             // vmovupd       %ymm9,0x40(%r8,%rax,4)
  .byte  196,65,125,17,68,128,96             // vmovupd       %ymm8,0x60(%r8,%rax,4)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,65,121,17,20,128                // vmovupd       %xmm10,(%r8,%rax,4)
  .byte  72,131,249,1                        // cmp           $0x1,%rcx
  .byte  116,240                             // je            3609 <_sk_store_f32_hsw+0x69>
  .byte  196,65,121,17,76,128,16             // vmovupd       %xmm9,0x10(%r8,%rax,4)
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  114,227                             // jb            3609 <_sk_store_f32_hsw+0x69>
  .byte  196,65,121,17,68,128,32             // vmovupd       %xmm8,0x20(%r8,%rax,4)
  .byte  116,218                             // je            3609 <_sk_store_f32_hsw+0x69>
  .byte  196,65,121,17,92,128,48             // vmovupd       %xmm11,0x30(%r8,%rax,4)
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  114,205                             // jb            3609 <_sk_store_f32_hsw+0x69>
  .byte  196,67,125,25,84,128,64,1           // vextractf128  $0x1,%ymm10,0x40(%r8,%rax,4)
  .byte  116,195                             // je            3609 <_sk_store_f32_hsw+0x69>
  .byte  196,67,125,25,76,128,80,1           // vextractf128  $0x1,%ymm9,0x50(%r8,%rax,4)
  .byte  72,131,249,7                        // cmp           $0x7,%rcx
  .byte  114,181                             // jb            3609 <_sk_store_f32_hsw+0x69>
  .byte  196,67,125,25,68,128,96,1           // vextractf128  $0x1,%ymm8,0x60(%r8,%rax,4)
  .byte  235,171                             // jmp           3609 <_sk_store_f32_hsw+0x69>

HIDDEN _sk_clamp_x_hsw
.globl _sk_clamp_x_hsw
FUNCTION(_sk_clamp_x_hsw)
_sk_clamp_x_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  197,188,95,192                      // vmaxps        %ymm0,%ymm8,%ymm0
  .byte  196,98,125,88,0                     // vpbroadcastd  (%rax),%ymm8
  .byte  196,65,53,118,201                   // vpcmpeqd      %ymm9,%ymm9,%ymm9
  .byte  196,65,61,254,193                   // vpaddd        %ymm9,%ymm8,%ymm8
  .byte  196,193,124,93,192                  // vminps        %ymm8,%ymm0,%ymm0
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_y_hsw
.globl _sk_clamp_y_hsw
FUNCTION(_sk_clamp_y_hsw)
_sk_clamp_y_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  197,188,95,201                      // vmaxps        %ymm1,%ymm8,%ymm1
  .byte  196,98,125,88,0                     // vpbroadcastd  (%rax),%ymm8
  .byte  196,65,53,118,201                   // vpcmpeqd      %ymm9,%ymm9,%ymm9
  .byte  196,65,61,254,193                   // vpaddd        %ymm9,%ymm8,%ymm8
  .byte  196,193,116,93,200                  // vminps        %ymm8,%ymm1,%ymm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_repeat_x_hsw
.globl _sk_repeat_x_hsw
FUNCTION(_sk_repeat_x_hsw)
_sk_repeat_x_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,0                     // vbroadcastss  (%rax),%ymm8
  .byte  196,65,124,94,200                   // vdivps        %ymm8,%ymm0,%ymm9
  .byte  196,67,125,8,201,1                  // vroundps      $0x1,%ymm9,%ymm9
  .byte  196,98,61,172,200                   // vfnmadd213ps  %ymm0,%ymm8,%ymm9
  .byte  197,253,118,192                     // vpcmpeqd      %ymm0,%ymm0,%ymm0
  .byte  197,189,254,192                     // vpaddd        %ymm0,%ymm8,%ymm0
  .byte  197,180,93,192                      // vminps        %ymm0,%ymm9,%ymm0
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_repeat_y_hsw
.globl _sk_repeat_y_hsw
FUNCTION(_sk_repeat_y_hsw)
_sk_repeat_y_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,0                     // vbroadcastss  (%rax),%ymm8
  .byte  196,65,116,94,200                   // vdivps        %ymm8,%ymm1,%ymm9
  .byte  196,67,125,8,201,1                  // vroundps      $0x1,%ymm9,%ymm9
  .byte  196,98,61,172,201                   // vfnmadd213ps  %ymm1,%ymm8,%ymm9
  .byte  197,245,118,201                     // vpcmpeqd      %ymm1,%ymm1,%ymm1
  .byte  197,189,254,201                     // vpaddd        %ymm1,%ymm8,%ymm1
  .byte  197,180,93,201                      // vminps        %ymm1,%ymm9,%ymm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_mirror_x_hsw
.globl _sk_mirror_x_hsw
FUNCTION(_sk_mirror_x_hsw)
_sk_mirror_x_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,122,16,0                        // vmovss        (%rax),%xmm8
  .byte  196,66,125,24,200                   // vbroadcastss  %xmm8,%ymm9
  .byte  196,65,124,92,209                   // vsubps        %ymm9,%ymm0,%ymm10
  .byte  196,193,58,88,192                   // vaddss        %xmm8,%xmm8,%xmm0
  .byte  196,226,125,24,192                  // vbroadcastss  %xmm0,%ymm0
  .byte  197,44,94,192                       // vdivps        %ymm0,%ymm10,%ymm8
  .byte  196,67,125,8,192,1                  // vroundps      $0x1,%ymm8,%ymm8
  .byte  196,66,125,172,194                  // vfnmadd213ps  %ymm10,%ymm0,%ymm8
  .byte  196,193,60,92,193                   // vsubps        %ymm9,%ymm8,%ymm0
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  197,60,92,192                       // vsubps        %ymm0,%ymm8,%ymm8
  .byte  197,188,84,192                      // vandps        %ymm0,%ymm8,%ymm0
  .byte  196,65,61,118,192                   // vpcmpeqd      %ymm8,%ymm8,%ymm8
  .byte  196,65,53,254,192                   // vpaddd        %ymm8,%ymm9,%ymm8
  .byte  196,193,124,93,192                  // vminps        %ymm8,%ymm0,%ymm0
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_mirror_y_hsw
.globl _sk_mirror_y_hsw
FUNCTION(_sk_mirror_y_hsw)
_sk_mirror_y_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,122,16,0                        // vmovss        (%rax),%xmm8
  .byte  196,66,125,24,200                   // vbroadcastss  %xmm8,%ymm9
  .byte  196,65,116,92,209                   // vsubps        %ymm9,%ymm1,%ymm10
  .byte  196,193,58,88,200                   // vaddss        %xmm8,%xmm8,%xmm1
  .byte  196,226,125,24,201                  // vbroadcastss  %xmm1,%ymm1
  .byte  197,44,94,193                       // vdivps        %ymm1,%ymm10,%ymm8
  .byte  196,67,125,8,192,1                  // vroundps      $0x1,%ymm8,%ymm8
  .byte  196,66,117,172,194                  // vfnmadd213ps  %ymm10,%ymm1,%ymm8
  .byte  196,193,60,92,201                   // vsubps        %ymm9,%ymm8,%ymm1
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  197,60,92,193                       // vsubps        %ymm1,%ymm8,%ymm8
  .byte  197,188,84,201                      // vandps        %ymm1,%ymm8,%ymm1
  .byte  196,65,61,118,192                   // vpcmpeqd      %ymm8,%ymm8,%ymm8
  .byte  196,65,53,254,192                   // vpaddd        %ymm8,%ymm9,%ymm8
  .byte  196,193,116,93,200                  // vminps        %ymm8,%ymm1,%ymm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_luminance_to_alpha_hsw
.globl _sk_luminance_to_alpha_hsw
FUNCTION(_sk_luminance_to_alpha_hsw)
_sk_luminance_to_alpha_hsw:
  .byte  184,208,179,89,62                   // mov           $0x3e59b3d0,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,98,125,88,195                   // vpbroadcastd  %xmm3,%ymm8
  .byte  184,89,23,55,63                     // mov           $0x3f371759,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,226,125,88,219                  // vpbroadcastd  %xmm3,%ymm3
  .byte  197,228,89,201                      // vmulps        %ymm1,%ymm3,%ymm1
  .byte  196,98,125,168,193                  // vfmadd213ps   %ymm1,%ymm0,%ymm8
  .byte  184,152,221,147,61                  // mov           $0x3d93dd98,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,226,125,88,216                  // vpbroadcastd  %xmm0,%ymm3
  .byte  196,194,109,168,216                 // vfmadd213ps   %ymm8,%ymm2,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,253,239,192                     // vpxor         %ymm0,%ymm0,%ymm0
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  197,236,87,210                      // vxorps        %ymm2,%ymm2,%ymm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_2x3_hsw
.globl _sk_matrix_2x3_hsw
FUNCTION(_sk_matrix_2x3_hsw)
_sk_matrix_2x3_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,8                     // vbroadcastss  (%rax),%ymm9
  .byte  196,98,125,24,80,8                  // vbroadcastss  0x8(%rax),%ymm10
  .byte  196,98,125,24,64,16                 // vbroadcastss  0x10(%rax),%ymm8
  .byte  196,66,117,184,194                  // vfmadd231ps   %ymm10,%ymm1,%ymm8
  .byte  196,66,125,184,193                  // vfmadd231ps   %ymm9,%ymm0,%ymm8
  .byte  196,98,125,24,80,4                  // vbroadcastss  0x4(%rax),%ymm10
  .byte  196,98,125,24,88,12                 // vbroadcastss  0xc(%rax),%ymm11
  .byte  196,98,125,24,72,20                 // vbroadcastss  0x14(%rax),%ymm9
  .byte  196,66,117,184,203                  // vfmadd231ps   %ymm11,%ymm1,%ymm9
  .byte  196,66,125,184,202                  // vfmadd231ps   %ymm10,%ymm0,%ymm9
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,124,41,192                      // vmovaps       %ymm8,%ymm0
  .byte  197,124,41,201                      // vmovaps       %ymm9,%ymm1
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_3x4_hsw
.globl _sk_matrix_3x4_hsw
FUNCTION(_sk_matrix_3x4_hsw)
_sk_matrix_3x4_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,8                     // vbroadcastss  (%rax),%ymm9
  .byte  196,98,125,24,80,12                 // vbroadcastss  0xc(%rax),%ymm10
  .byte  196,98,125,24,88,24                 // vbroadcastss  0x18(%rax),%ymm11
  .byte  196,98,125,24,64,36                 // vbroadcastss  0x24(%rax),%ymm8
  .byte  196,66,109,184,195                  // vfmadd231ps   %ymm11,%ymm2,%ymm8
  .byte  196,66,117,184,194                  // vfmadd231ps   %ymm10,%ymm1,%ymm8
  .byte  196,66,125,184,193                  // vfmadd231ps   %ymm9,%ymm0,%ymm8
  .byte  196,98,125,24,80,4                  // vbroadcastss  0x4(%rax),%ymm10
  .byte  196,98,125,24,88,16                 // vbroadcastss  0x10(%rax),%ymm11
  .byte  196,98,125,24,96,28                 // vbroadcastss  0x1c(%rax),%ymm12
  .byte  196,98,125,24,72,40                 // vbroadcastss  0x28(%rax),%ymm9
  .byte  196,66,109,184,204                  // vfmadd231ps   %ymm12,%ymm2,%ymm9
  .byte  196,66,117,184,203                  // vfmadd231ps   %ymm11,%ymm1,%ymm9
  .byte  196,66,125,184,202                  // vfmadd231ps   %ymm10,%ymm0,%ymm9
  .byte  196,98,125,24,88,8                  // vbroadcastss  0x8(%rax),%ymm11
  .byte  196,98,125,24,96,20                 // vbroadcastss  0x14(%rax),%ymm12
  .byte  196,98,125,24,104,32                // vbroadcastss  0x20(%rax),%ymm13
  .byte  196,98,125,24,80,44                 // vbroadcastss  0x2c(%rax),%ymm10
  .byte  196,66,109,184,213                  // vfmadd231ps   %ymm13,%ymm2,%ymm10
  .byte  196,66,117,184,212                  // vfmadd231ps   %ymm12,%ymm1,%ymm10
  .byte  196,66,125,184,211                  // vfmadd231ps   %ymm11,%ymm0,%ymm10
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,124,41,192                      // vmovaps       %ymm8,%ymm0
  .byte  197,124,41,201                      // vmovaps       %ymm9,%ymm1
  .byte  197,124,41,210                      // vmovaps       %ymm10,%ymm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_4x5_hsw
.globl _sk_matrix_4x5_hsw
FUNCTION(_sk_matrix_4x5_hsw)
_sk_matrix_4x5_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,8                     // vbroadcastss  (%rax),%ymm9
  .byte  196,98,125,24,80,16                 // vbroadcastss  0x10(%rax),%ymm10
  .byte  196,98,125,24,88,32                 // vbroadcastss  0x20(%rax),%ymm11
  .byte  196,98,125,24,96,48                 // vbroadcastss  0x30(%rax),%ymm12
  .byte  196,98,125,24,64,64                 // vbroadcastss  0x40(%rax),%ymm8
  .byte  196,66,101,184,196                  // vfmadd231ps   %ymm12,%ymm3,%ymm8
  .byte  196,66,109,184,195                  // vfmadd231ps   %ymm11,%ymm2,%ymm8
  .byte  196,66,117,184,194                  // vfmadd231ps   %ymm10,%ymm1,%ymm8
  .byte  196,66,125,184,193                  // vfmadd231ps   %ymm9,%ymm0,%ymm8
  .byte  196,98,125,24,80,4                  // vbroadcastss  0x4(%rax),%ymm10
  .byte  196,98,125,24,88,20                 // vbroadcastss  0x14(%rax),%ymm11
  .byte  196,98,125,24,96,36                 // vbroadcastss  0x24(%rax),%ymm12
  .byte  196,98,125,24,104,52                // vbroadcastss  0x34(%rax),%ymm13
  .byte  196,98,125,24,72,68                 // vbroadcastss  0x44(%rax),%ymm9
  .byte  196,66,101,184,205                  // vfmadd231ps   %ymm13,%ymm3,%ymm9
  .byte  196,66,109,184,204                  // vfmadd231ps   %ymm12,%ymm2,%ymm9
  .byte  196,66,117,184,203                  // vfmadd231ps   %ymm11,%ymm1,%ymm9
  .byte  196,66,125,184,202                  // vfmadd231ps   %ymm10,%ymm0,%ymm9
  .byte  196,98,125,24,88,8                  // vbroadcastss  0x8(%rax),%ymm11
  .byte  196,98,125,24,96,24                 // vbroadcastss  0x18(%rax),%ymm12
  .byte  196,98,125,24,104,40                // vbroadcastss  0x28(%rax),%ymm13
  .byte  196,98,125,24,112,56                // vbroadcastss  0x38(%rax),%ymm14
  .byte  196,98,125,24,80,72                 // vbroadcastss  0x48(%rax),%ymm10
  .byte  196,66,101,184,214                  // vfmadd231ps   %ymm14,%ymm3,%ymm10
  .byte  196,66,109,184,213                  // vfmadd231ps   %ymm13,%ymm2,%ymm10
  .byte  196,66,117,184,212                  // vfmadd231ps   %ymm12,%ymm1,%ymm10
  .byte  196,66,125,184,211                  // vfmadd231ps   %ymm11,%ymm0,%ymm10
  .byte  196,98,125,24,96,12                 // vbroadcastss  0xc(%rax),%ymm12
  .byte  196,98,125,24,104,28                // vbroadcastss  0x1c(%rax),%ymm13
  .byte  196,98,125,24,112,44                // vbroadcastss  0x2c(%rax),%ymm14
  .byte  196,98,125,24,120,60                // vbroadcastss  0x3c(%rax),%ymm15
  .byte  196,98,125,24,88,76                 // vbroadcastss  0x4c(%rax),%ymm11
  .byte  196,66,101,184,223                  // vfmadd231ps   %ymm15,%ymm3,%ymm11
  .byte  196,66,109,184,222                  // vfmadd231ps   %ymm14,%ymm2,%ymm11
  .byte  196,66,117,184,221                  // vfmadd231ps   %ymm13,%ymm1,%ymm11
  .byte  196,66,125,184,220                  // vfmadd231ps   %ymm12,%ymm0,%ymm11
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,124,41,192                      // vmovaps       %ymm8,%ymm0
  .byte  197,124,41,201                      // vmovaps       %ymm9,%ymm1
  .byte  197,124,41,210                      // vmovaps       %ymm10,%ymm2
  .byte  197,124,41,219                      // vmovaps       %ymm11,%ymm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_perspective_hsw
.globl _sk_matrix_perspective_hsw
FUNCTION(_sk_matrix_perspective_hsw)
_sk_matrix_perspective_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,0                     // vbroadcastss  (%rax),%ymm8
  .byte  196,98,125,24,72,4                  // vbroadcastss  0x4(%rax),%ymm9
  .byte  196,98,125,24,80,8                  // vbroadcastss  0x8(%rax),%ymm10
  .byte  196,66,117,184,209                  // vfmadd231ps   %ymm9,%ymm1,%ymm10
  .byte  196,66,125,184,208                  // vfmadd231ps   %ymm8,%ymm0,%ymm10
  .byte  196,98,125,24,64,12                 // vbroadcastss  0xc(%rax),%ymm8
  .byte  196,98,125,24,72,16                 // vbroadcastss  0x10(%rax),%ymm9
  .byte  196,98,125,24,88,20                 // vbroadcastss  0x14(%rax),%ymm11
  .byte  196,66,117,184,217                  // vfmadd231ps   %ymm9,%ymm1,%ymm11
  .byte  196,66,125,184,216                  // vfmadd231ps   %ymm8,%ymm0,%ymm11
  .byte  196,98,125,24,64,24                 // vbroadcastss  0x18(%rax),%ymm8
  .byte  196,98,125,24,72,28                 // vbroadcastss  0x1c(%rax),%ymm9
  .byte  196,98,125,24,96,32                 // vbroadcastss  0x20(%rax),%ymm12
  .byte  196,66,117,184,225                  // vfmadd231ps   %ymm9,%ymm1,%ymm12
  .byte  196,66,125,184,224                  // vfmadd231ps   %ymm8,%ymm0,%ymm12
  .byte  196,193,124,83,204                  // vrcpps        %ymm12,%ymm1
  .byte  197,172,89,193                      // vmulps        %ymm1,%ymm10,%ymm0
  .byte  197,164,89,201                      // vmulps        %ymm1,%ymm11,%ymm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_linear_gradient_hsw
.globl _sk_linear_gradient_hsw
FUNCTION(_sk_linear_gradient_hsw)
_sk_linear_gradient_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,64,16                 // vbroadcastss  0x10(%rax),%ymm8
  .byte  196,98,125,24,88,20                 // vbroadcastss  0x14(%rax),%ymm11
  .byte  196,98,125,24,80,24                 // vbroadcastss  0x18(%rax),%ymm10
  .byte  196,98,125,24,72,28                 // vbroadcastss  0x1c(%rax),%ymm9
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  77,133,192                          // test          %r8,%r8
  .byte  15,132,143,0,0,0                    // je            3a99 <_sk_linear_gradient_hsw+0xb5>
  .byte  72,139,64,8                         // mov           0x8(%rax),%rax
  .byte  72,131,192,32                       // add           $0x20,%rax
  .byte  196,65,28,87,228                    // vxorps        %ymm12,%ymm12,%ymm12
  .byte  197,228,87,219                      // vxorps        %ymm3,%ymm3,%ymm3
  .byte  197,236,87,210                      // vxorps        %ymm2,%ymm2,%ymm2
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  196,98,125,24,104,224               // vbroadcastss  -0x20(%rax),%ymm13
  .byte  196,65,124,194,237,1                // vcmpltps      %ymm13,%ymm0,%ymm13
  .byte  196,98,125,24,112,228               // vbroadcastss  -0x1c(%rax),%ymm14
  .byte  196,67,13,74,228,208                // vblendvps     %ymm13,%ymm12,%ymm14,%ymm12
  .byte  196,98,125,24,112,232               // vbroadcastss  -0x18(%rax),%ymm14
  .byte  196,227,13,74,201,208               // vblendvps     %ymm13,%ymm1,%ymm14,%ymm1
  .byte  196,98,125,24,112,236               // vbroadcastss  -0x14(%rax),%ymm14
  .byte  196,227,13,74,210,208               // vblendvps     %ymm13,%ymm2,%ymm14,%ymm2
  .byte  196,98,125,24,112,240               // vbroadcastss  -0x10(%rax),%ymm14
  .byte  196,227,13,74,219,208               // vblendvps     %ymm13,%ymm3,%ymm14,%ymm3
  .byte  196,98,125,24,112,244               // vbroadcastss  -0xc(%rax),%ymm14
  .byte  196,67,13,74,192,208                // vblendvps     %ymm13,%ymm8,%ymm14,%ymm8
  .byte  196,98,125,24,112,248               // vbroadcastss  -0x8(%rax),%ymm14
  .byte  196,67,13,74,219,208                // vblendvps     %ymm13,%ymm11,%ymm14,%ymm11
  .byte  196,98,125,24,112,252               // vbroadcastss  -0x4(%rax),%ymm14
  .byte  196,67,13,74,210,208                // vblendvps     %ymm13,%ymm10,%ymm14,%ymm10
  .byte  196,98,125,24,48                    // vbroadcastss  (%rax),%ymm14
  .byte  196,67,13,74,201,208                // vblendvps     %ymm13,%ymm9,%ymm14,%ymm9
  .byte  72,131,192,36                       // add           $0x24,%rax
  .byte  73,255,200                          // dec           %r8
  .byte  117,140                             // jne           3a23 <_sk_linear_gradient_hsw+0x3f>
  .byte  235,17                              // jmp           3aaa <_sk_linear_gradient_hsw+0xc6>
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  197,236,87,210                      // vxorps        %ymm2,%ymm2,%ymm2
  .byte  197,228,87,219                      // vxorps        %ymm3,%ymm3,%ymm3
  .byte  196,65,28,87,228                    // vxorps        %ymm12,%ymm12,%ymm12
  .byte  196,66,125,184,196                  // vfmadd231ps   %ymm12,%ymm0,%ymm8
  .byte  196,194,125,168,203                 // vfmadd213ps   %ymm11,%ymm0,%ymm1
  .byte  196,194,125,168,210                 // vfmadd213ps   %ymm10,%ymm0,%ymm2
  .byte  196,194,125,168,217                 // vfmadd213ps   %ymm9,%ymm0,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,124,41,192                      // vmovaps       %ymm8,%ymm0
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_linear_gradient_2stops_hsw
.globl _sk_linear_gradient_2stops_hsw
FUNCTION(_sk_linear_gradient_2stops_hsw)
_sk_linear_gradient_2stops_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,226,125,24,8                    // vbroadcastss  (%rax),%ymm1
  .byte  196,98,125,24,64,16                 // vbroadcastss  0x10(%rax),%ymm8
  .byte  196,98,125,184,193                  // vfmadd231ps   %ymm1,%ymm0,%ymm8
  .byte  196,226,125,24,80,4                 // vbroadcastss  0x4(%rax),%ymm2
  .byte  196,226,125,24,72,20                // vbroadcastss  0x14(%rax),%ymm1
  .byte  196,226,125,184,202                 // vfmadd231ps   %ymm2,%ymm0,%ymm1
  .byte  196,226,125,24,88,8                 // vbroadcastss  0x8(%rax),%ymm3
  .byte  196,226,125,24,80,24                // vbroadcastss  0x18(%rax),%ymm2
  .byte  196,226,125,184,211                 // vfmadd231ps   %ymm3,%ymm0,%ymm2
  .byte  196,98,125,24,72,12                 // vbroadcastss  0xc(%rax),%ymm9
  .byte  196,226,125,24,88,28                // vbroadcastss  0x1c(%rax),%ymm3
  .byte  196,194,125,184,217                 // vfmadd231ps   %ymm9,%ymm0,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,124,41,192                      // vmovaps       %ymm8,%ymm0
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_save_xy_hsw
.globl _sk_save_xy_hsw
FUNCTION(_sk_save_xy_hsw)
_sk_save_xy_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,63                     // mov           $0x3f000000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,88,200                       // vaddps        %ymm0,%ymm8,%ymm9
  .byte  196,67,125,8,209,1                  // vroundps      $0x1,%ymm9,%ymm10
  .byte  196,65,52,92,202                    // vsubps        %ymm10,%ymm9,%ymm9
  .byte  197,60,88,193                       // vaddps        %ymm1,%ymm8,%ymm8
  .byte  196,67,125,8,208,1                  // vroundps      $0x1,%ymm8,%ymm10
  .byte  196,65,60,92,194                    // vsubps        %ymm10,%ymm8,%ymm8
  .byte  197,252,17,0                        // vmovups       %ymm0,(%rax)
  .byte  197,252,17,72,32                    // vmovups       %ymm1,0x20(%rax)
  .byte  197,124,17,72,64                    // vmovups       %ymm9,0x40(%rax)
  .byte  197,124,17,64,96                    // vmovups       %ymm8,0x60(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_accumulate_hsw
.globl _sk_accumulate_hsw
FUNCTION(_sk_accumulate_hsw)
_sk_accumulate_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,124,16,128,128,0,0,0            // vmovups       0x80(%rax),%ymm8
  .byte  197,60,89,128,160,0,0,0             // vmulps        0xa0(%rax),%ymm8,%ymm8
  .byte  196,226,61,184,224                  // vfmadd231ps   %ymm0,%ymm8,%ymm4
  .byte  196,226,61,184,233                  // vfmadd231ps   %ymm1,%ymm8,%ymm5
  .byte  196,226,61,184,242                  // vfmadd231ps   %ymm2,%ymm8,%ymm6
  .byte  196,98,101,168,199                  // vfmadd213ps   %ymm7,%ymm3,%ymm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,124,41,199                      // vmovaps       %ymm8,%ymm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_nx_hsw
.globl _sk_bilinear_nx_hsw
FUNCTION(_sk_bilinear_nx_hsw)
_sk_bilinear_nx_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,191                    // mov           $0xbf000000,%r8d
  .byte  196,193,121,110,192                 // vmovd         %r8d,%xmm0
  .byte  196,226,125,88,192                  // vpbroadcastd  %xmm0,%ymm0
  .byte  197,252,88,0                        // vaddps        (%rax),%ymm0,%ymm0
  .byte  65,184,0,0,128,63                   // mov           $0x3f800000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,64,64                     // vsubps        0x40(%rax),%ymm8,%ymm8
  .byte  197,124,17,128,128,0,0,0            // vmovups       %ymm8,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_px_hsw
.globl _sk_bilinear_px_hsw
FUNCTION(_sk_bilinear_px_hsw)
_sk_bilinear_px_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,63                     // mov           $0x3f000000,%r8d
  .byte  196,193,121,110,192                 // vmovd         %r8d,%xmm0
  .byte  196,226,125,88,192                  // vpbroadcastd  %xmm0,%ymm0
  .byte  197,252,88,0                        // vaddps        (%rax),%ymm0,%ymm0
  .byte  197,124,16,64,64                    // vmovups       0x40(%rax),%ymm8
  .byte  197,124,17,128,128,0,0,0            // vmovups       %ymm8,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_ny_hsw
.globl _sk_bilinear_ny_hsw
FUNCTION(_sk_bilinear_ny_hsw)
_sk_bilinear_ny_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,191                    // mov           $0xbf000000,%r8d
  .byte  196,193,121,110,200                 // vmovd         %r8d,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,244,88,72,32                    // vaddps        0x20(%rax),%ymm1,%ymm1
  .byte  65,184,0,0,128,63                   // mov           $0x3f800000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,64,96                     // vsubps        0x60(%rax),%ymm8,%ymm8
  .byte  197,124,17,128,160,0,0,0            // vmovups       %ymm8,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_py_hsw
.globl _sk_bilinear_py_hsw
FUNCTION(_sk_bilinear_py_hsw)
_sk_bilinear_py_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,63                     // mov           $0x3f000000,%r8d
  .byte  196,193,121,110,200                 // vmovd         %r8d,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,244,88,72,32                    // vaddps        0x20(%rax),%ymm1,%ymm1
  .byte  197,124,16,64,96                    // vmovups       0x60(%rax),%ymm8
  .byte  197,124,17,128,160,0,0,0            // vmovups       %ymm8,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n3x_hsw
.globl _sk_bicubic_n3x_hsw
FUNCTION(_sk_bicubic_n3x_hsw)
_sk_bicubic_n3x_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,192,191                  // mov           $0xbfc00000,%r8d
  .byte  196,193,121,110,192                 // vmovd         %r8d,%xmm0
  .byte  196,226,125,88,192                  // vpbroadcastd  %xmm0,%ymm0
  .byte  197,252,88,0                        // vaddps        (%rax),%ymm0,%ymm0
  .byte  65,184,0,0,128,63                   // mov           $0x3f800000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,64,64                     // vsubps        0x40(%rax),%ymm8,%ymm8
  .byte  196,65,60,89,200                    // vmulps        %ymm8,%ymm8,%ymm9
  .byte  65,184,114,28,199,62                // mov           $0x3ec71c72,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,66,125,88,210                   // vpbroadcastd  %xmm10,%ymm10
  .byte  65,184,171,170,170,190              // mov           $0xbeaaaaab,%r8d
  .byte  196,65,121,110,216                  // vmovd         %r8d,%xmm11
  .byte  196,66,125,88,219                   // vpbroadcastd  %xmm11,%ymm11
  .byte  196,66,61,168,211                   // vfmadd213ps   %ymm11,%ymm8,%ymm10
  .byte  196,65,44,89,193                    // vmulps        %ymm9,%ymm10,%ymm8
  .byte  197,124,17,128,128,0,0,0            // vmovups       %ymm8,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n1x_hsw
.globl _sk_bicubic_n1x_hsw
FUNCTION(_sk_bicubic_n1x_hsw)
_sk_bicubic_n1x_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,191                    // mov           $0xbf000000,%r8d
  .byte  196,193,121,110,192                 // vmovd         %r8d,%xmm0
  .byte  196,226,125,88,192                  // vpbroadcastd  %xmm0,%ymm0
  .byte  197,252,88,0                        // vaddps        (%rax),%ymm0,%ymm0
  .byte  65,184,0,0,128,63                   // mov           $0x3f800000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,64,64                     // vsubps        0x40(%rax),%ymm8,%ymm8
  .byte  65,184,85,85,149,191                // mov           $0xbf955555,%r8d
  .byte  196,65,121,110,200                  // vmovd         %r8d,%xmm9
  .byte  196,66,125,88,201                   // vpbroadcastd  %xmm9,%ymm9
  .byte  65,184,0,0,192,63                   // mov           $0x3fc00000,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,66,125,88,210                   // vpbroadcastd  %xmm10,%ymm10
  .byte  196,66,61,168,202                   // vfmadd213ps   %ymm10,%ymm8,%ymm9
  .byte  65,184,0,0,0,63                     // mov           $0x3f000000,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,66,125,88,210                   // vpbroadcastd  %xmm10,%ymm10
  .byte  196,66,61,184,209                   // vfmadd231ps   %ymm9,%ymm8,%ymm10
  .byte  65,184,57,142,99,61                 // mov           $0x3d638e39,%r8d
  .byte  196,65,121,110,200                  // vmovd         %r8d,%xmm9
  .byte  196,66,125,88,201                   // vpbroadcastd  %xmm9,%ymm9
  .byte  196,66,61,184,202                   // vfmadd231ps   %ymm10,%ymm8,%ymm9
  .byte  197,124,17,136,128,0,0,0            // vmovups       %ymm9,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p1x_hsw
.globl _sk_bicubic_p1x_hsw
FUNCTION(_sk_bicubic_p1x_hsw)
_sk_bicubic_p1x_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,63                     // mov           $0x3f000000,%r8d
  .byte  196,193,121,110,192                 // vmovd         %r8d,%xmm0
  .byte  196,98,125,88,192                   // vpbroadcastd  %xmm0,%ymm8
  .byte  197,188,88,0                        // vaddps        (%rax),%ymm8,%ymm0
  .byte  197,124,16,72,64                    // vmovups       0x40(%rax),%ymm9
  .byte  65,184,85,85,149,191                // mov           $0xbf955555,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,66,125,88,210                   // vpbroadcastd  %xmm10,%ymm10
  .byte  65,184,0,0,192,63                   // mov           $0x3fc00000,%r8d
  .byte  196,65,121,110,216                  // vmovd         %r8d,%xmm11
  .byte  196,66,125,88,219                   // vpbroadcastd  %xmm11,%ymm11
  .byte  196,66,53,168,211                   // vfmadd213ps   %ymm11,%ymm9,%ymm10
  .byte  196,66,53,168,208                   // vfmadd213ps   %ymm8,%ymm9,%ymm10
  .byte  65,184,57,142,99,61                 // mov           $0x3d638e39,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  196,66,53,184,194                   // vfmadd231ps   %ymm10,%ymm9,%ymm8
  .byte  197,124,17,128,128,0,0,0            // vmovups       %ymm8,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p3x_hsw
.globl _sk_bicubic_p3x_hsw
FUNCTION(_sk_bicubic_p3x_hsw)
_sk_bicubic_p3x_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,192,63                   // mov           $0x3fc00000,%r8d
  .byte  196,193,121,110,192                 // vmovd         %r8d,%xmm0
  .byte  196,226,125,88,192                  // vpbroadcastd  %xmm0,%ymm0
  .byte  197,252,88,0                        // vaddps        (%rax),%ymm0,%ymm0
  .byte  197,124,16,64,64                    // vmovups       0x40(%rax),%ymm8
  .byte  196,65,60,89,200                    // vmulps        %ymm8,%ymm8,%ymm9
  .byte  65,184,114,28,199,62                // mov           $0x3ec71c72,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,66,125,88,210                   // vpbroadcastd  %xmm10,%ymm10
  .byte  65,184,171,170,170,190              // mov           $0xbeaaaaab,%r8d
  .byte  196,65,121,110,216                  // vmovd         %r8d,%xmm11
  .byte  196,66,125,88,219                   // vpbroadcastd  %xmm11,%ymm11
  .byte  196,66,61,168,211                   // vfmadd213ps   %ymm11,%ymm8,%ymm10
  .byte  196,65,52,89,194                    // vmulps        %ymm10,%ymm9,%ymm8
  .byte  197,124,17,128,128,0,0,0            // vmovups       %ymm8,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n3y_hsw
.globl _sk_bicubic_n3y_hsw
FUNCTION(_sk_bicubic_n3y_hsw)
_sk_bicubic_n3y_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,192,191                  // mov           $0xbfc00000,%r8d
  .byte  196,193,121,110,200                 // vmovd         %r8d,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,244,88,72,32                    // vaddps        0x20(%rax),%ymm1,%ymm1
  .byte  65,184,0,0,128,63                   // mov           $0x3f800000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,64,96                     // vsubps        0x60(%rax),%ymm8,%ymm8
  .byte  196,65,60,89,200                    // vmulps        %ymm8,%ymm8,%ymm9
  .byte  65,184,114,28,199,62                // mov           $0x3ec71c72,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,66,125,88,210                   // vpbroadcastd  %xmm10,%ymm10
  .byte  65,184,171,170,170,190              // mov           $0xbeaaaaab,%r8d
  .byte  196,65,121,110,216                  // vmovd         %r8d,%xmm11
  .byte  196,66,125,88,219                   // vpbroadcastd  %xmm11,%ymm11
  .byte  196,66,61,168,211                   // vfmadd213ps   %ymm11,%ymm8,%ymm10
  .byte  196,65,44,89,193                    // vmulps        %ymm9,%ymm10,%ymm8
  .byte  197,124,17,128,160,0,0,0            // vmovups       %ymm8,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n1y_hsw
.globl _sk_bicubic_n1y_hsw
FUNCTION(_sk_bicubic_n1y_hsw)
_sk_bicubic_n1y_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,191                    // mov           $0xbf000000,%r8d
  .byte  196,193,121,110,200                 // vmovd         %r8d,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,244,88,72,32                    // vaddps        0x20(%rax),%ymm1,%ymm1
  .byte  65,184,0,0,128,63                   // mov           $0x3f800000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  197,60,92,64,96                     // vsubps        0x60(%rax),%ymm8,%ymm8
  .byte  65,184,85,85,149,191                // mov           $0xbf955555,%r8d
  .byte  196,65,121,110,200                  // vmovd         %r8d,%xmm9
  .byte  196,66,125,88,201                   // vpbroadcastd  %xmm9,%ymm9
  .byte  65,184,0,0,192,63                   // mov           $0x3fc00000,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,66,125,88,210                   // vpbroadcastd  %xmm10,%ymm10
  .byte  196,66,61,168,202                   // vfmadd213ps   %ymm10,%ymm8,%ymm9
  .byte  65,184,0,0,0,63                     // mov           $0x3f000000,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,66,125,88,210                   // vpbroadcastd  %xmm10,%ymm10
  .byte  196,66,61,184,209                   // vfmadd231ps   %ymm9,%ymm8,%ymm10
  .byte  65,184,57,142,99,61                 // mov           $0x3d638e39,%r8d
  .byte  196,65,121,110,200                  // vmovd         %r8d,%xmm9
  .byte  196,66,125,88,201                   // vpbroadcastd  %xmm9,%ymm9
  .byte  196,66,61,184,202                   // vfmadd231ps   %ymm10,%ymm8,%ymm9
  .byte  197,124,17,136,160,0,0,0            // vmovups       %ymm9,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p1y_hsw
.globl _sk_bicubic_p1y_hsw
FUNCTION(_sk_bicubic_p1y_hsw)
_sk_bicubic_p1y_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,63                     // mov           $0x3f000000,%r8d
  .byte  196,193,121,110,200                 // vmovd         %r8d,%xmm1
  .byte  196,98,125,88,193                   // vpbroadcastd  %xmm1,%ymm8
  .byte  197,188,88,72,32                    // vaddps        0x20(%rax),%ymm8,%ymm1
  .byte  197,124,16,72,96                    // vmovups       0x60(%rax),%ymm9
  .byte  65,184,85,85,149,191                // mov           $0xbf955555,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,66,125,88,210                   // vpbroadcastd  %xmm10,%ymm10
  .byte  65,184,0,0,192,63                   // mov           $0x3fc00000,%r8d
  .byte  196,65,121,110,216                  // vmovd         %r8d,%xmm11
  .byte  196,66,125,88,219                   // vpbroadcastd  %xmm11,%ymm11
  .byte  196,66,53,168,211                   // vfmadd213ps   %ymm11,%ymm9,%ymm10
  .byte  196,66,53,168,208                   // vfmadd213ps   %ymm8,%ymm9,%ymm10
  .byte  65,184,57,142,99,61                 // mov           $0x3d638e39,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,66,125,88,192                   // vpbroadcastd  %xmm8,%ymm8
  .byte  196,66,53,184,194                   // vfmadd231ps   %ymm10,%ymm9,%ymm8
  .byte  197,124,17,128,160,0,0,0            // vmovups       %ymm8,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p3y_hsw
.globl _sk_bicubic_p3y_hsw
FUNCTION(_sk_bicubic_p3y_hsw)
_sk_bicubic_p3y_hsw:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,192,63                   // mov           $0x3fc00000,%r8d
  .byte  196,193,121,110,200                 // vmovd         %r8d,%xmm1
  .byte  196,226,125,88,201                  // vpbroadcastd  %xmm1,%ymm1
  .byte  197,244,88,72,32                    // vaddps        0x20(%rax),%ymm1,%ymm1
  .byte  197,124,16,64,96                    // vmovups       0x60(%rax),%ymm8
  .byte  196,65,60,89,200                    // vmulps        %ymm8,%ymm8,%ymm9
  .byte  65,184,114,28,199,62                // mov           $0x3ec71c72,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,66,125,88,210                   // vpbroadcastd  %xmm10,%ymm10
  .byte  65,184,171,170,170,190              // mov           $0xbeaaaaab,%r8d
  .byte  196,65,121,110,216                  // vmovd         %r8d,%xmm11
  .byte  196,66,125,88,219                   // vpbroadcastd  %xmm11,%ymm11
  .byte  196,66,61,168,211                   // vfmadd213ps   %ymm11,%ymm8,%ymm10
  .byte  196,65,52,89,194                    // vmulps        %ymm10,%ymm9,%ymm8
  .byte  197,124,17,128,160,0,0,0            // vmovups       %ymm8,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_callback_hsw
.globl _sk_callback_hsw
FUNCTION(_sk_callback_hsw)
_sk_callback_hsw:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,85                               // push          %r13
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,129,236,144,0,0,0                // sub           $0x90,%rsp
  .byte  197,252,17,124,36,96                // vmovups       %ymm7,0x60(%rsp)
  .byte  197,252,17,116,36,64                // vmovups       %ymm6,0x40(%rsp)
  .byte  197,252,17,108,36,32                // vmovups       %ymm5,0x20(%rsp)
  .byte  197,252,17,36,36                    // vmovups       %ymm4,(%rsp)
  .byte  73,137,205                          // mov           %rcx,%r13
  .byte  73,137,214                          // mov           %rdx,%r14
  .byte  73,137,255                          // mov           %rdi,%r15
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,137,195                          // mov           %rax,%rbx
  .byte  73,137,244                          // mov           %rsi,%r12
  .byte  197,252,20,225                      // vunpcklps     %ymm1,%ymm0,%ymm4
  .byte  197,252,21,193                      // vunpckhps     %ymm1,%ymm0,%ymm0
  .byte  197,236,20,203                      // vunpcklps     %ymm3,%ymm2,%ymm1
  .byte  197,236,21,211                      // vunpckhps     %ymm3,%ymm2,%ymm2
  .byte  197,221,20,217                      // vunpcklpd     %ymm1,%ymm4,%ymm3
  .byte  197,221,21,201                      // vunpckhpd     %ymm1,%ymm4,%ymm1
  .byte  197,253,20,226                      // vunpcklpd     %ymm2,%ymm0,%ymm4
  .byte  197,253,21,194                      // vunpckhpd     %ymm2,%ymm0,%ymm0
  .byte  196,227,101,24,209,1                // vinsertf128   $0x1,%xmm1,%ymm3,%ymm2
  .byte  196,227,93,24,232,1                 // vinsertf128   $0x1,%xmm0,%ymm4,%ymm5
  .byte  196,227,101,6,201,49                // vperm2f128    $0x31,%ymm1,%ymm3,%ymm1
  .byte  196,227,93,6,192,49                 // vperm2f128    $0x31,%ymm0,%ymm4,%ymm0
  .byte  197,253,17,83,8                     // vmovupd       %ymm2,0x8(%rbx)
  .byte  197,253,17,107,40                   // vmovupd       %ymm5,0x28(%rbx)
  .byte  197,253,17,75,72                    // vmovupd       %ymm1,0x48(%rbx)
  .byte  197,253,17,67,104                   // vmovupd       %ymm0,0x68(%rbx)
  .byte  77,133,237                          // test          %r13,%r13
  .byte  190,8,0,0,0                         // mov           $0x8,%esi
  .byte  65,15,69,245                        // cmovne        %r13d,%esi
  .byte  72,137,223                          // mov           %rbx,%rdi
  .byte  197,248,119                         // vzeroupper
  .byte  255,19                              // callq         *(%rbx)
  .byte  72,139,131,136,0,0,0                // mov           0x88(%rbx),%rax
  .byte  197,248,16,0                        // vmovups       (%rax),%xmm0
  .byte  197,248,16,72,16                    // vmovups       0x10(%rax),%xmm1
  .byte  197,248,16,80,32                    // vmovups       0x20(%rax),%xmm2
  .byte  197,248,16,88,48                    // vmovups       0x30(%rax),%xmm3
  .byte  196,227,101,24,88,112,1             // vinsertf128   $0x1,0x70(%rax),%ymm3,%ymm3
  .byte  196,227,109,24,80,96,1              // vinsertf128   $0x1,0x60(%rax),%ymm2,%ymm2
  .byte  196,227,117,24,72,80,1              // vinsertf128   $0x1,0x50(%rax),%ymm1,%ymm1
  .byte  196,227,125,24,64,64,1              // vinsertf128   $0x1,0x40(%rax),%ymm0,%ymm0
  .byte  197,252,20,225                      // vunpcklps     %ymm1,%ymm0,%ymm4
  .byte  197,252,21,233                      // vunpckhps     %ymm1,%ymm0,%ymm5
  .byte  197,236,20,203                      // vunpcklps     %ymm3,%ymm2,%ymm1
  .byte  197,236,21,219                      // vunpckhps     %ymm3,%ymm2,%ymm3
  .byte  197,221,20,193                      // vunpcklpd     %ymm1,%ymm4,%ymm0
  .byte  197,221,21,201                      // vunpckhpd     %ymm1,%ymm4,%ymm1
  .byte  197,213,20,211                      // vunpcklpd     %ymm3,%ymm5,%ymm2
  .byte  197,213,21,219                      // vunpckhpd     %ymm3,%ymm5,%ymm3
  .byte  76,137,230                          // mov           %r12,%rsi
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,137,255                          // mov           %r15,%rdi
  .byte  76,137,242                          // mov           %r14,%rdx
  .byte  76,137,233                          // mov           %r13,%rcx
  .byte  197,252,16,36,36                    // vmovups       (%rsp),%ymm4
  .byte  197,252,16,108,36,32                // vmovups       0x20(%rsp),%ymm5
  .byte  197,252,16,116,36,64                // vmovups       0x40(%rsp),%ymm6
  .byte  197,252,16,124,36,96                // vmovups       0x60(%rsp),%ymm7
  .byte  72,129,196,144,0,0,0                // add           $0x90,%rsp
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,93                               // pop           %r13
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  255,224                             // jmpq          *%rax

BALIGN4
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  128,63,0                            // cmpb          $0x0,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,255                              // xor           $0xff,%al
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            40d0 <.literal4+0x10>
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  119,115                             // ja            4149 <.literal4+0x89>
  .byte  248                                 // clc
  .byte  194,117,191                         // retq          $0xbf75
  .byte  191,63,249,68,180                   // mov           $0xb444f93f,%edi
  .byte  62,163,233,220,63,81,140,242,66,141 // movabs        %eax,%ds:0x8d42f28c513fdce9
  .byte  188,190,63,248,245                  // mov           $0xf5f83fbe,%esp
  .byte  154                                 // (bad)
  .byte  64,254                              // rex           (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,0,0                              // add           %al,(%r8)
  .byte  0,75,0                              // add           %cl,0x0(%rbx)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,255                              // xor           $0xff,%al
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            4100 <.literal4+0x40>
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  119,115                             // ja            4179 <.literal4+0xb9>
  .byte  248                                 // clc
  .byte  194,117,191                         // retq          $0xbf75
  .byte  191,63,249,68,180                   // mov           $0xb444f93f,%edi
  .byte  62,163,233,220,63,81,140,242,66,141 // movabs        %eax,%ds:0x8d42f28c513fdce9
  .byte  188,190,63,248,245                  // mov           $0xf5f83fbe,%esp
  .byte  154                                 // (bad)
  .byte  64,254                              // rex           (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,0,0                              // add           %al,(%r8)
  .byte  0,75,0                              // add           %cl,0x0(%rbx)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,255                              // xor           $0xff,%al
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            4130 <.literal4+0x70>
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  119,115                             // ja            41a9 <_sk_callback_hsw+0x20f>
  .byte  248                                 // clc
  .byte  194,117,191                         // retq          $0xbf75
  .byte  191,63,249,68,180                   // mov           $0xb444f93f,%edi
  .byte  62,163,233,220,63,81,140,242,66,141 // movabs        %eax,%ds:0x8d42f28c513fdce9
  .byte  188,190,63,248,245                  // mov           $0xf5f83fbe,%esp
  .byte  154                                 // (bad)
  .byte  64,254                              // rex           (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,0,0                              // add           %al,(%r8)
  .byte  0,75,0                              // add           %cl,0x0(%rbx)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,255                              // xor           $0xff,%al
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            4160 <.literal4+0xa0>
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  119,115                             // ja            41d9 <_sk_callback_hsw+0x23f>
  .byte  248                                 // clc
  .byte  194,117,191                         // retq          $0xbf75
  .byte  191,63,249,68,180                   // mov           $0xb444f93f,%edi
  .byte  62,163,233,220,63,81,140,242,66,141 // movabs        %eax,%ds:0x8d42f28c513fdce9
  .byte  188,190,63,248,245                  // mov           $0xf5f83fbe,%esp
  .byte  154                                 // (bad)
  .byte  64,254                              // rex           (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,0,0                              // add           %al,(%r8)
  .byte  0                                   // .byte         0x0
  .byte  75                                  // rex.WXB

BALIGN32
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  1,255                               // add           %edi,%edi
  .byte  255                                 // (bad)
  .byte  255,5,255,255,255,9                 // incl          0x9ffffff(%rip)        # a0041c8 <_sk_callback_hsw+0xa00022e>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,13,255,255,255,17               // decl          0x11ffffff(%rip)        # 120041d0 <_sk_callback_hsw+0x12000236>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,21,255,255,255,25               // callq         *0x19ffffff(%rip)        # 1a0041d8 <_sk_callback_hsw+0x1a00023e>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,29,255,255,255,2                // lcall         *0x2ffffff(%rip)        # 30041e0 <_sk_callback_hsw+0x3000246>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,6                               // incl          (%rsi)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,10                              // decl          (%rdx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,14                              // decl          (%rsi)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,18                              // callq         *(%rdx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,22                              // callq         *(%rsi)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,26                              // lcall         *(%rdx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,30                              // lcall         *(%rsi)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  1,255                               // add           %edi,%edi
  .byte  255                                 // (bad)
  .byte  255,5,255,255,255,9                 // incl          0x9ffffff(%rip)        # a004228 <_sk_callback_hsw+0xa00028e>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,13,255,255,255,17               // decl          0x11ffffff(%rip)        # 12004230 <_sk_callback_hsw+0x12000296>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,21,255,255,255,25               // callq         *0x19ffffff(%rip)        # 1a004238 <_sk_callback_hsw+0x1a00029e>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,29,255,255,255,2                // lcall         *0x2ffffff(%rip)        # 3004240 <_sk_callback_hsw+0x30002a6>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,6                               // incl          (%rsi)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,10                              // decl          (%rdx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,14                              // decl          (%rsi)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,18                              // callq         *(%rdx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,22                              // callq         *(%rsi)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,26                              // lcall         *(%rdx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,30                              // lcall         *(%rsi)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  1,255                               // add           %edi,%edi
  .byte  255                                 // (bad)
  .byte  255,5,255,255,255,9                 // incl          0x9ffffff(%rip)        # a004288 <_sk_callback_hsw+0xa0002ee>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,13,255,255,255,17               // decl          0x11ffffff(%rip)        # 12004290 <_sk_callback_hsw+0x120002f6>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,21,255,255,255,25               // callq         *0x19ffffff(%rip)        # 1a004298 <_sk_callback_hsw+0x1a0002fe>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,29,255,255,255,2                // lcall         *0x2ffffff(%rip)        # 30042a0 <_sk_callback_hsw+0x3000306>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,6                               // incl          (%rsi)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,10                              // decl          (%rdx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,14                              // decl          (%rsi)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,18                              // callq         *(%rdx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,22                              // callq         *(%rsi)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,26                              // lcall         *(%rdx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,30                              // lcall         *(%rsi)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  1,255                               // add           %edi,%edi
  .byte  255                                 // (bad)
  .byte  255,5,255,255,255,9                 // incl          0x9ffffff(%rip)        # a0042e8 <_sk_callback_hsw+0xa00034e>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,13,255,255,255,17               // decl          0x11ffffff(%rip)        # 120042f0 <_sk_callback_hsw+0x12000356>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,21,255,255,255,25               // callq         *0x19ffffff(%rip)        # 1a0042f8 <_sk_callback_hsw+0x1a00035e>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,29,255,255,255,2                // lcall         *0x2ffffff(%rip)        # 3004300 <_sk_callback_hsw+0x3000366>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,6                               // incl          (%rsi)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,10                              // decl          (%rdx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,14                              // decl          (%rsi)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,18                              // callq         *(%rdx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,22                              // callq         *(%rsi)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,26                              // lcall         *(%rdx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,30                              // lcall         *(%rsi)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

BALIGN16
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
BALIGN32

HIDDEN _sk_start_pipeline_avx
.globl _sk_start_pipeline_avx
FUNCTION(_sk_start_pipeline_avx)
_sk_start_pipeline_avx:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,85                               // push          %r13
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  73,137,205                          // mov           %rcx,%r13
  .byte  73,137,214                          // mov           %rdx,%r14
  .byte  72,137,251                          // mov           %rdi,%rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  73,137,199                          // mov           %rax,%r15
  .byte  73,137,244                          // mov           %rsi,%r12
  .byte  72,141,67,8                         // lea           0x8(%rbx),%rax
  .byte  76,57,232                           // cmp           %r13,%rax
  .byte  118,5                               // jbe           28 <_sk_start_pipeline_avx+0x28>
  .byte  72,137,223                          // mov           %rbx,%rdi
  .byte  235,65                              // jmp           69 <_sk_start_pipeline_avx+0x69>
  .byte  185,0,0,0,0                         // mov           $0x0,%ecx
  .byte  197,252,87,192                      // vxorps        %ymm0,%ymm0,%ymm0
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  197,236,87,210                      // vxorps        %ymm2,%ymm2,%ymm2
  .byte  197,228,87,219                      // vxorps        %ymm3,%ymm3,%ymm3
  .byte  197,220,87,228                      // vxorps        %ymm4,%ymm4,%ymm4
  .byte  197,212,87,237                      // vxorps        %ymm5,%ymm5,%ymm5
  .byte  197,204,87,246                      // vxorps        %ymm6,%ymm6,%ymm6
  .byte  197,196,87,255                      // vxorps        %ymm7,%ymm7,%ymm7
  .byte  72,137,223                          // mov           %rbx,%rdi
  .byte  76,137,230                          // mov           %r12,%rsi
  .byte  76,137,242                          // mov           %r14,%rdx
  .byte  65,255,215                          // callq         *%r15
  .byte  72,141,123,8                        // lea           0x8(%rbx),%rdi
  .byte  72,131,195,16                       // add           $0x10,%rbx
  .byte  76,57,235                           // cmp           %r13,%rbx
  .byte  72,137,251                          // mov           %rdi,%rbx
  .byte  118,191                             // jbe           28 <_sk_start_pipeline_avx+0x28>
  .byte  76,137,233                          // mov           %r13,%rcx
  .byte  72,41,249                           // sub           %rdi,%rcx
  .byte  116,41                              // je            9a <_sk_start_pipeline_avx+0x9a>
  .byte  197,252,87,192                      // vxorps        %ymm0,%ymm0,%ymm0
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  197,236,87,210                      // vxorps        %ymm2,%ymm2,%ymm2
  .byte  197,228,87,219                      // vxorps        %ymm3,%ymm3,%ymm3
  .byte  197,220,87,228                      // vxorps        %ymm4,%ymm4,%ymm4
  .byte  197,212,87,237                      // vxorps        %ymm5,%ymm5,%ymm5
  .byte  197,204,87,246                      // vxorps        %ymm6,%ymm6,%ymm6
  .byte  197,196,87,255                      // vxorps        %ymm7,%ymm7,%ymm7
  .byte  76,137,230                          // mov           %r12,%rsi
  .byte  76,137,242                          // mov           %r14,%rdx
  .byte  65,255,215                          // callq         *%r15
  .byte  76,137,232                          // mov           %r13,%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,93                               // pop           %r13
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  197,248,119                         // vzeroupper
  .byte  195                                 // retq

HIDDEN _sk_just_return_avx
.globl _sk_just_return_avx
FUNCTION(_sk_just_return_avx)
_sk_just_return_avx:
  .byte  195                                 // retq

HIDDEN _sk_seed_shader_avx
.globl _sk_seed_shader_avx
FUNCTION(_sk_seed_shader_avx)
_sk_seed_shader_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,249,110,199                     // vmovd         %edi,%xmm0
  .byte  197,249,112,192,0                   // vpshufd       $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  196,226,125,24,13,11,91,0,0         // vbroadcastss  0x5b0b(%rip),%ymm1        # 5bd4 <_sk_callback_avx+0x126>
  .byte  197,252,88,193                      // vaddps        %ymm1,%ymm0,%ymm0
  .byte  197,252,88,2                        // vaddps        (%rdx),%ymm0,%ymm0
  .byte  196,226,125,24,16                   // vbroadcastss  (%rax),%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  197,236,88,201                      // vaddps        %ymm1,%ymm2,%ymm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,226,125,24,21,239,90,0,0        // vbroadcastss  0x5aef(%rip),%ymm2        # 5bd8 <_sk_callback_avx+0x12a>
  .byte  197,228,87,219                      // vxorps        %ymm3,%ymm3,%ymm3
  .byte  197,220,87,228                      // vxorps        %ymm4,%ymm4,%ymm4
  .byte  197,212,87,237                      // vxorps        %ymm5,%ymm5,%ymm5
  .byte  197,204,87,246                      // vxorps        %ymm6,%ymm6,%ymm6
  .byte  197,196,87,255                      // vxorps        %ymm7,%ymm7,%ymm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_constant_color_avx
.globl _sk_constant_color_avx
FUNCTION(_sk_constant_color_avx)
_sk_constant_color_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,226,125,24,0                    // vbroadcastss  (%rax),%ymm0
  .byte  196,226,125,24,72,4                 // vbroadcastss  0x4(%rax),%ymm1
  .byte  196,226,125,24,80,8                 // vbroadcastss  0x8(%rax),%ymm2
  .byte  196,226,125,24,88,12                // vbroadcastss  0xc(%rax),%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clear_avx
.globl _sk_clear_avx
FUNCTION(_sk_clear_avx)
_sk_clear_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,87,192                      // vxorps        %ymm0,%ymm0,%ymm0
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  197,236,87,210                      // vxorps        %ymm2,%ymm2,%ymm2
  .byte  197,228,87,219                      // vxorps        %ymm3,%ymm3,%ymm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcatop_avx
.globl _sk_srcatop_avx
FUNCTION(_sk_srcatop_avx)
_sk_srcatop_avx:
  .byte  197,124,89,199                      // vmulps        %ymm7,%ymm0,%ymm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,124,92,203                      // vsubps        %ymm3,%ymm0,%ymm9
  .byte  197,180,89,196                      // vmulps        %ymm4,%ymm9,%ymm0
  .byte  197,188,88,192                      // vaddps        %ymm0,%ymm8,%ymm0
  .byte  197,244,89,207                      // vmulps        %ymm7,%ymm1,%ymm1
  .byte  197,52,89,197                       // vmulps        %ymm5,%ymm9,%ymm8
  .byte  196,193,116,88,200                  // vaddps        %ymm8,%ymm1,%ymm1
  .byte  197,236,89,215                      // vmulps        %ymm7,%ymm2,%ymm2
  .byte  197,52,89,198                       // vmulps        %ymm6,%ymm9,%ymm8
  .byte  196,193,108,88,208                  // vaddps        %ymm8,%ymm2,%ymm2
  .byte  197,228,89,223                      // vmulps        %ymm7,%ymm3,%ymm3
  .byte  197,52,89,199                       // vmulps        %ymm7,%ymm9,%ymm8
  .byte  196,193,100,88,216                  // vaddps        %ymm8,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstatop_avx
.globl _sk_dstatop_avx
FUNCTION(_sk_dstatop_avx)
_sk_dstatop_avx:
  .byte  197,100,89,196                      // vmulps        %ymm4,%ymm3,%ymm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,200                     // vmovd         %eax,%xmm9
  .byte  196,67,121,4,201,0                  // vpermilps     $0x0,%xmm9,%xmm9
  .byte  196,67,53,24,201,1                  // vinsertf128   $0x1,%xmm9,%ymm9,%ymm9
  .byte  197,52,92,207                       // vsubps        %ymm7,%ymm9,%ymm9
  .byte  197,180,89,192                      // vmulps        %ymm0,%ymm9,%ymm0
  .byte  197,188,88,192                      // vaddps        %ymm0,%ymm8,%ymm0
  .byte  197,100,89,197                      // vmulps        %ymm5,%ymm3,%ymm8
  .byte  197,180,89,201                      // vmulps        %ymm1,%ymm9,%ymm1
  .byte  197,188,88,201                      // vaddps        %ymm1,%ymm8,%ymm1
  .byte  197,100,89,198                      // vmulps        %ymm6,%ymm3,%ymm8
  .byte  197,180,89,210                      // vmulps        %ymm2,%ymm9,%ymm2
  .byte  197,188,88,210                      // vaddps        %ymm2,%ymm8,%ymm2
  .byte  197,100,89,199                      // vmulps        %ymm7,%ymm3,%ymm8
  .byte  197,180,89,219                      // vmulps        %ymm3,%ymm9,%ymm3
  .byte  197,188,88,219                      // vaddps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcin_avx
.globl _sk_srcin_avx
FUNCTION(_sk_srcin_avx)
_sk_srcin_avx:
  .byte  197,252,89,199                      // vmulps        %ymm7,%ymm0,%ymm0
  .byte  197,244,89,207                      // vmulps        %ymm7,%ymm1,%ymm1
  .byte  197,236,89,215                      // vmulps        %ymm7,%ymm2,%ymm2
  .byte  197,228,89,223                      // vmulps        %ymm7,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstin_avx
.globl _sk_dstin_avx
FUNCTION(_sk_dstin_avx)
_sk_dstin_avx:
  .byte  197,228,89,196                      // vmulps        %ymm4,%ymm3,%ymm0
  .byte  197,228,89,205                      // vmulps        %ymm5,%ymm3,%ymm1
  .byte  197,228,89,214                      // vmulps        %ymm6,%ymm3,%ymm2
  .byte  197,228,89,223                      // vmulps        %ymm7,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcout_avx
.globl _sk_srcout_avx
FUNCTION(_sk_srcout_avx)
_sk_srcout_avx:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,199                       // vsubps        %ymm7,%ymm8,%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstout_avx
.globl _sk_dstout_avx
FUNCTION(_sk_dstout_avx)
_sk_dstout_avx:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,252,92,219                      // vsubps        %ymm3,%ymm0,%ymm3
  .byte  197,228,89,196                      // vmulps        %ymm4,%ymm3,%ymm0
  .byte  197,228,89,205                      // vmulps        %ymm5,%ymm3,%ymm1
  .byte  197,228,89,214                      // vmulps        %ymm6,%ymm3,%ymm2
  .byte  197,228,89,223                      // vmulps        %ymm7,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcover_avx
.globl _sk_srcover_avx
FUNCTION(_sk_srcover_avx)
_sk_srcover_avx:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,204                       // vmulps        %ymm4,%ymm8,%ymm9
  .byte  197,180,88,192                      // vaddps        %ymm0,%ymm9,%ymm0
  .byte  197,60,89,205                       // vmulps        %ymm5,%ymm8,%ymm9
  .byte  197,180,88,201                      // vaddps        %ymm1,%ymm9,%ymm1
  .byte  197,60,89,206                       // vmulps        %ymm6,%ymm8,%ymm9
  .byte  197,180,88,210                      // vaddps        %ymm2,%ymm9,%ymm2
  .byte  197,60,89,199                       // vmulps        %ymm7,%ymm8,%ymm8
  .byte  197,188,88,219                      // vaddps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstover_avx
.globl _sk_dstover_avx
FUNCTION(_sk_dstover_avx)
_sk_dstover_avx:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,199                       // vsubps        %ymm7,%ymm8,%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  197,252,88,196                      // vaddps        %ymm4,%ymm0,%ymm0
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  197,244,88,205                      // vaddps        %ymm5,%ymm1,%ymm1
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  197,236,88,214                      // vaddps        %ymm6,%ymm2,%ymm2
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  197,228,88,223                      // vaddps        %ymm7,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_modulate_avx
.globl _sk_modulate_avx
FUNCTION(_sk_modulate_avx)
_sk_modulate_avx:
  .byte  197,252,89,196                      // vmulps        %ymm4,%ymm0,%ymm0
  .byte  197,244,89,205                      // vmulps        %ymm5,%ymm1,%ymm1
  .byte  197,236,89,214                      // vmulps        %ymm6,%ymm2,%ymm2
  .byte  197,228,89,223                      // vmulps        %ymm7,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_multiply_avx
.globl _sk_multiply_avx
FUNCTION(_sk_multiply_avx)
_sk_multiply_avx:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,207                       // vsubps        %ymm7,%ymm8,%ymm9
  .byte  197,52,89,208                       // vmulps        %ymm0,%ymm9,%ymm10
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,220                       // vmulps        %ymm4,%ymm8,%ymm11
  .byte  196,65,44,88,211                    // vaddps        %ymm11,%ymm10,%ymm10
  .byte  197,252,89,196                      // vmulps        %ymm4,%ymm0,%ymm0
  .byte  196,193,124,88,194                  // vaddps        %ymm10,%ymm0,%ymm0
  .byte  197,52,89,209                       // vmulps        %ymm1,%ymm9,%ymm10
  .byte  197,60,89,221                       // vmulps        %ymm5,%ymm8,%ymm11
  .byte  196,65,36,88,210                    // vaddps        %ymm10,%ymm11,%ymm10
  .byte  197,244,89,205                      // vmulps        %ymm5,%ymm1,%ymm1
  .byte  196,193,116,88,202                  // vaddps        %ymm10,%ymm1,%ymm1
  .byte  197,52,89,210                       // vmulps        %ymm2,%ymm9,%ymm10
  .byte  197,60,89,222                       // vmulps        %ymm6,%ymm8,%ymm11
  .byte  196,65,36,88,210                    // vaddps        %ymm10,%ymm11,%ymm10
  .byte  197,236,89,214                      // vmulps        %ymm6,%ymm2,%ymm2
  .byte  196,193,108,88,210                  // vaddps        %ymm10,%ymm2,%ymm2
  .byte  197,52,89,203                       // vmulps        %ymm3,%ymm9,%ymm9
  .byte  197,60,89,199                       // vmulps        %ymm7,%ymm8,%ymm8
  .byte  196,65,60,88,193                    // vaddps        %ymm9,%ymm8,%ymm8
  .byte  197,228,89,223                      // vmulps        %ymm7,%ymm3,%ymm3
  .byte  196,193,100,88,216                  // vaddps        %ymm8,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_plus__avx
.globl _sk_plus__avx
FUNCTION(_sk_plus__avx)
_sk_plus__avx:
  .byte  197,252,88,196                      // vaddps        %ymm4,%ymm0,%ymm0
  .byte  197,244,88,205                      // vaddps        %ymm5,%ymm1,%ymm1
  .byte  197,236,88,214                      // vaddps        %ymm6,%ymm2,%ymm2
  .byte  197,228,88,223                      // vaddps        %ymm7,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_screen_avx
.globl _sk_screen_avx
FUNCTION(_sk_screen_avx)
_sk_screen_avx:
  .byte  197,124,88,196                      // vaddps        %ymm4,%ymm0,%ymm8
  .byte  197,252,89,196                      // vmulps        %ymm4,%ymm0,%ymm0
  .byte  197,188,92,192                      // vsubps        %ymm0,%ymm8,%ymm0
  .byte  197,116,88,197                      // vaddps        %ymm5,%ymm1,%ymm8
  .byte  197,244,89,205                      // vmulps        %ymm5,%ymm1,%ymm1
  .byte  197,188,92,201                      // vsubps        %ymm1,%ymm8,%ymm1
  .byte  197,108,88,198                      // vaddps        %ymm6,%ymm2,%ymm8
  .byte  197,236,89,214                      // vmulps        %ymm6,%ymm2,%ymm2
  .byte  197,188,92,210                      // vsubps        %ymm2,%ymm8,%ymm2
  .byte  197,100,88,199                      // vaddps        %ymm7,%ymm3,%ymm8
  .byte  197,228,89,223                      // vmulps        %ymm7,%ymm3,%ymm3
  .byte  197,188,92,219                      // vsubps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_xor__avx
.globl _sk_xor__avx
FUNCTION(_sk_xor__avx)
_sk_xor__avx:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,207                       // vsubps        %ymm7,%ymm8,%ymm9
  .byte  197,180,89,192                      // vmulps        %ymm0,%ymm9,%ymm0
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,212                       // vmulps        %ymm4,%ymm8,%ymm10
  .byte  196,193,124,88,194                  // vaddps        %ymm10,%ymm0,%ymm0
  .byte  197,180,89,201                      // vmulps        %ymm1,%ymm9,%ymm1
  .byte  197,60,89,213                       // vmulps        %ymm5,%ymm8,%ymm10
  .byte  197,172,88,201                      // vaddps        %ymm1,%ymm10,%ymm1
  .byte  197,180,89,210                      // vmulps        %ymm2,%ymm9,%ymm2
  .byte  197,60,89,214                       // vmulps        %ymm6,%ymm8,%ymm10
  .byte  197,172,88,210                      // vaddps        %ymm2,%ymm10,%ymm2
  .byte  197,180,89,219                      // vmulps        %ymm3,%ymm9,%ymm3
  .byte  197,60,89,199                       // vmulps        %ymm7,%ymm8,%ymm8
  .byte  197,188,88,219                      // vaddps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_darken_avx
.globl _sk_darken_avx
FUNCTION(_sk_darken_avx)
_sk_darken_avx:
  .byte  197,124,88,196                      // vaddps        %ymm4,%ymm0,%ymm8
  .byte  197,252,89,199                      // vmulps        %ymm7,%ymm0,%ymm0
  .byte  197,100,89,204                      // vmulps        %ymm4,%ymm3,%ymm9
  .byte  196,193,124,95,193                  // vmaxps        %ymm9,%ymm0,%ymm0
  .byte  197,188,92,192                      // vsubps        %ymm0,%ymm8,%ymm0
  .byte  197,116,88,197                      // vaddps        %ymm5,%ymm1,%ymm8
  .byte  197,244,89,207                      // vmulps        %ymm7,%ymm1,%ymm1
  .byte  197,100,89,205                      // vmulps        %ymm5,%ymm3,%ymm9
  .byte  196,193,116,95,201                  // vmaxps        %ymm9,%ymm1,%ymm1
  .byte  197,188,92,201                      // vsubps        %ymm1,%ymm8,%ymm1
  .byte  197,108,88,198                      // vaddps        %ymm6,%ymm2,%ymm8
  .byte  197,236,89,215                      // vmulps        %ymm7,%ymm2,%ymm2
  .byte  197,100,89,206                      // vmulps        %ymm6,%ymm3,%ymm9
  .byte  196,193,108,95,209                  // vmaxps        %ymm9,%ymm2,%ymm2
  .byte  197,188,92,210                      // vsubps        %ymm2,%ymm8,%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,199                       // vmulps        %ymm7,%ymm8,%ymm8
  .byte  197,188,88,219                      // vaddps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_lighten_avx
.globl _sk_lighten_avx
FUNCTION(_sk_lighten_avx)
_sk_lighten_avx:
  .byte  197,124,88,196                      // vaddps        %ymm4,%ymm0,%ymm8
  .byte  197,252,89,199                      // vmulps        %ymm7,%ymm0,%ymm0
  .byte  197,100,89,204                      // vmulps        %ymm4,%ymm3,%ymm9
  .byte  196,193,124,93,193                  // vminps        %ymm9,%ymm0,%ymm0
  .byte  197,188,92,192                      // vsubps        %ymm0,%ymm8,%ymm0
  .byte  197,116,88,197                      // vaddps        %ymm5,%ymm1,%ymm8
  .byte  197,244,89,207                      // vmulps        %ymm7,%ymm1,%ymm1
  .byte  197,100,89,205                      // vmulps        %ymm5,%ymm3,%ymm9
  .byte  196,193,116,93,201                  // vminps        %ymm9,%ymm1,%ymm1
  .byte  197,188,92,201                      // vsubps        %ymm1,%ymm8,%ymm1
  .byte  197,108,88,198                      // vaddps        %ymm6,%ymm2,%ymm8
  .byte  197,236,89,215                      // vmulps        %ymm7,%ymm2,%ymm2
  .byte  197,100,89,206                      // vmulps        %ymm6,%ymm3,%ymm9
  .byte  196,193,108,93,209                  // vminps        %ymm9,%ymm2,%ymm2
  .byte  197,188,92,210                      // vsubps        %ymm2,%ymm8,%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,199                       // vmulps        %ymm7,%ymm8,%ymm8
  .byte  197,188,88,219                      // vaddps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_difference_avx
.globl _sk_difference_avx
FUNCTION(_sk_difference_avx)
_sk_difference_avx:
  .byte  197,124,88,196                      // vaddps        %ymm4,%ymm0,%ymm8
  .byte  197,252,89,199                      // vmulps        %ymm7,%ymm0,%ymm0
  .byte  197,100,89,204                      // vmulps        %ymm4,%ymm3,%ymm9
  .byte  196,193,124,93,193                  // vminps        %ymm9,%ymm0,%ymm0
  .byte  197,252,88,192                      // vaddps        %ymm0,%ymm0,%ymm0
  .byte  197,188,92,192                      // vsubps        %ymm0,%ymm8,%ymm0
  .byte  197,116,88,197                      // vaddps        %ymm5,%ymm1,%ymm8
  .byte  197,244,89,207                      // vmulps        %ymm7,%ymm1,%ymm1
  .byte  197,100,89,205                      // vmulps        %ymm5,%ymm3,%ymm9
  .byte  196,193,116,93,201                  // vminps        %ymm9,%ymm1,%ymm1
  .byte  197,244,88,201                      // vaddps        %ymm1,%ymm1,%ymm1
  .byte  197,188,92,201                      // vsubps        %ymm1,%ymm8,%ymm1
  .byte  197,108,88,198                      // vaddps        %ymm6,%ymm2,%ymm8
  .byte  197,236,89,215                      // vmulps        %ymm7,%ymm2,%ymm2
  .byte  197,100,89,206                      // vmulps        %ymm6,%ymm3,%ymm9
  .byte  196,193,108,93,209                  // vminps        %ymm9,%ymm2,%ymm2
  .byte  197,236,88,210                      // vaddps        %ymm2,%ymm2,%ymm2
  .byte  197,188,92,210                      // vsubps        %ymm2,%ymm8,%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,199                       // vmulps        %ymm7,%ymm8,%ymm8
  .byte  197,188,88,219                      // vaddps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_exclusion_avx
.globl _sk_exclusion_avx
FUNCTION(_sk_exclusion_avx)
_sk_exclusion_avx:
  .byte  197,124,88,196                      // vaddps        %ymm4,%ymm0,%ymm8
  .byte  197,252,89,196                      // vmulps        %ymm4,%ymm0,%ymm0
  .byte  197,252,88,192                      // vaddps        %ymm0,%ymm0,%ymm0
  .byte  197,188,92,192                      // vsubps        %ymm0,%ymm8,%ymm0
  .byte  197,116,88,197                      // vaddps        %ymm5,%ymm1,%ymm8
  .byte  197,244,89,205                      // vmulps        %ymm5,%ymm1,%ymm1
  .byte  197,244,88,201                      // vaddps        %ymm1,%ymm1,%ymm1
  .byte  197,188,92,201                      // vsubps        %ymm1,%ymm8,%ymm1
  .byte  197,108,88,198                      // vaddps        %ymm6,%ymm2,%ymm8
  .byte  197,236,89,214                      // vmulps        %ymm6,%ymm2,%ymm2
  .byte  197,236,88,210                      // vaddps        %ymm2,%ymm2,%ymm2
  .byte  197,188,92,210                      // vsubps        %ymm2,%ymm8,%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,199                       // vmulps        %ymm7,%ymm8,%ymm8
  .byte  197,188,88,219                      // vaddps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_colorburn_avx
.globl _sk_colorburn_avx
FUNCTION(_sk_colorburn_avx)
_sk_colorburn_avx:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,207                       // vsubps        %ymm7,%ymm8,%ymm9
  .byte  197,52,89,216                       // vmulps        %ymm0,%ymm9,%ymm11
  .byte  196,65,44,87,210                    // vxorps        %ymm10,%ymm10,%ymm10
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,228                       // vmulps        %ymm4,%ymm8,%ymm12
  .byte  197,68,92,236                       // vsubps        %ymm4,%ymm7,%ymm13
  .byte  197,20,89,235                       // vmulps        %ymm3,%ymm13,%ymm13
  .byte  197,20,94,232                       // vdivps        %ymm0,%ymm13,%ymm13
  .byte  196,65,68,93,237                    // vminps        %ymm13,%ymm7,%ymm13
  .byte  196,65,68,92,237                    // vsubps        %ymm13,%ymm7,%ymm13
  .byte  197,20,89,235                       // vmulps        %ymm3,%ymm13,%ymm13
  .byte  196,65,20,88,235                    // vaddps        %ymm11,%ymm13,%ymm13
  .byte  196,65,28,88,237                    // vaddps        %ymm13,%ymm12,%ymm13
  .byte  197,28,88,224                       // vaddps        %ymm0,%ymm12,%ymm12
  .byte  196,193,124,194,194,0               // vcmpeqps      %ymm10,%ymm0,%ymm0
  .byte  196,195,21,74,196,0                 // vblendvps     %ymm0,%ymm12,%ymm13,%ymm0
  .byte  197,92,194,231,0                    // vcmpeqps      %ymm7,%ymm4,%ymm12
  .byte  197,36,88,220                       // vaddps        %ymm4,%ymm11,%ymm11
  .byte  196,195,125,74,195,192              // vblendvps     %ymm12,%ymm11,%ymm0,%ymm0
  .byte  197,52,89,217                       // vmulps        %ymm1,%ymm9,%ymm11
  .byte  197,60,89,229                       // vmulps        %ymm5,%ymm8,%ymm12
  .byte  197,68,92,237                       // vsubps        %ymm5,%ymm7,%ymm13
  .byte  197,20,89,235                       // vmulps        %ymm3,%ymm13,%ymm13
  .byte  197,20,94,233                       // vdivps        %ymm1,%ymm13,%ymm13
  .byte  196,65,68,93,237                    // vminps        %ymm13,%ymm7,%ymm13
  .byte  196,65,68,92,237                    // vsubps        %ymm13,%ymm7,%ymm13
  .byte  197,20,89,235                       // vmulps        %ymm3,%ymm13,%ymm13
  .byte  196,65,36,88,237                    // vaddps        %ymm13,%ymm11,%ymm13
  .byte  196,65,28,88,237                    // vaddps        %ymm13,%ymm12,%ymm13
  .byte  197,28,88,225                       // vaddps        %ymm1,%ymm12,%ymm12
  .byte  196,193,116,194,202,0               // vcmpeqps      %ymm10,%ymm1,%ymm1
  .byte  196,195,21,74,204,16                // vblendvps     %ymm1,%ymm12,%ymm13,%ymm1
  .byte  197,84,194,231,0                    // vcmpeqps      %ymm7,%ymm5,%ymm12
  .byte  197,36,88,221                       // vaddps        %ymm5,%ymm11,%ymm11
  .byte  196,195,117,74,203,192              // vblendvps     %ymm12,%ymm11,%ymm1,%ymm1
  .byte  197,52,89,202                       // vmulps        %ymm2,%ymm9,%ymm9
  .byte  196,65,108,194,210,0                // vcmpeqps      %ymm10,%ymm2,%ymm10
  .byte  197,60,89,222                       // vmulps        %ymm6,%ymm8,%ymm11
  .byte  197,68,92,230                       // vsubps        %ymm6,%ymm7,%ymm12
  .byte  197,28,89,227                       // vmulps        %ymm3,%ymm12,%ymm12
  .byte  197,28,94,226                       // vdivps        %ymm2,%ymm12,%ymm12
  .byte  197,164,88,210                      // vaddps        %ymm2,%ymm11,%ymm2
  .byte  196,65,68,93,228                    // vminps        %ymm12,%ymm7,%ymm12
  .byte  196,65,68,92,228                    // vsubps        %ymm12,%ymm7,%ymm12
  .byte  197,28,89,227                       // vmulps        %ymm3,%ymm12,%ymm12
  .byte  196,65,52,88,228                    // vaddps        %ymm12,%ymm9,%ymm12
  .byte  196,65,36,88,220                    // vaddps        %ymm12,%ymm11,%ymm11
  .byte  196,227,37,74,210,160               // vblendvps     %ymm10,%ymm2,%ymm11,%ymm2
  .byte  197,76,194,215,0                    // vcmpeqps      %ymm7,%ymm6,%ymm10
  .byte  197,52,88,206                       // vaddps        %ymm6,%ymm9,%ymm9
  .byte  196,195,109,74,209,160              // vblendvps     %ymm10,%ymm9,%ymm2,%ymm2
  .byte  197,60,89,199                       // vmulps        %ymm7,%ymm8,%ymm8
  .byte  197,188,88,219                      // vaddps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_colordodge_avx
.globl _sk_colordodge_avx
FUNCTION(_sk_colordodge_avx)
_sk_colordodge_avx:
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,200                     // vmovd         %eax,%xmm9
  .byte  196,67,121,4,201,0                  // vpermilps     $0x0,%xmm9,%xmm9
  .byte  196,67,53,24,201,1                  // vinsertf128   $0x1,%xmm9,%ymm9,%ymm9
  .byte  197,52,92,215                       // vsubps        %ymm7,%ymm9,%ymm10
  .byte  197,44,89,216                       // vmulps        %ymm0,%ymm10,%ymm11
  .byte  197,52,92,203                       // vsubps        %ymm3,%ymm9,%ymm9
  .byte  197,100,89,228                      // vmulps        %ymm4,%ymm3,%ymm12
  .byte  197,100,92,232                      // vsubps        %ymm0,%ymm3,%ymm13
  .byte  196,65,28,94,229                    // vdivps        %ymm13,%ymm12,%ymm12
  .byte  197,52,89,236                       // vmulps        %ymm4,%ymm9,%ymm13
  .byte  196,65,68,93,228                    // vminps        %ymm12,%ymm7,%ymm12
  .byte  197,28,89,227                       // vmulps        %ymm3,%ymm12,%ymm12
  .byte  196,65,28,88,227                    // vaddps        %ymm11,%ymm12,%ymm12
  .byte  196,65,20,88,228                    // vaddps        %ymm12,%ymm13,%ymm12
  .byte  197,20,88,232                       // vaddps        %ymm0,%ymm13,%ymm13
  .byte  197,252,194,195,0                   // vcmpeqps      %ymm3,%ymm0,%ymm0
  .byte  196,195,29,74,197,0                 // vblendvps     %ymm0,%ymm13,%ymm12,%ymm0
  .byte  196,65,92,194,224,0                 // vcmpeqps      %ymm8,%ymm4,%ymm12
  .byte  197,36,88,220                       // vaddps        %ymm4,%ymm11,%ymm11
  .byte  196,195,125,74,195,192              // vblendvps     %ymm12,%ymm11,%ymm0,%ymm0
  .byte  197,44,89,217                       // vmulps        %ymm1,%ymm10,%ymm11
  .byte  197,100,89,229                      // vmulps        %ymm5,%ymm3,%ymm12
  .byte  197,100,92,233                      // vsubps        %ymm1,%ymm3,%ymm13
  .byte  196,65,28,94,229                    // vdivps        %ymm13,%ymm12,%ymm12
  .byte  197,52,89,237                       // vmulps        %ymm5,%ymm9,%ymm13
  .byte  196,65,68,93,228                    // vminps        %ymm12,%ymm7,%ymm12
  .byte  197,28,89,227                       // vmulps        %ymm3,%ymm12,%ymm12
  .byte  196,65,28,88,227                    // vaddps        %ymm11,%ymm12,%ymm12
  .byte  196,65,20,88,228                    // vaddps        %ymm12,%ymm13,%ymm12
  .byte  197,20,88,233                       // vaddps        %ymm1,%ymm13,%ymm13
  .byte  197,244,194,203,0                   // vcmpeqps      %ymm3,%ymm1,%ymm1
  .byte  196,195,29,74,205,16                // vblendvps     %ymm1,%ymm13,%ymm12,%ymm1
  .byte  196,65,84,194,224,0                 // vcmpeqps      %ymm8,%ymm5,%ymm12
  .byte  197,36,88,221                       // vaddps        %ymm5,%ymm11,%ymm11
  .byte  196,195,117,74,203,192              // vblendvps     %ymm12,%ymm11,%ymm1,%ymm1
  .byte  197,44,89,210                       // vmulps        %ymm2,%ymm10,%ymm10
  .byte  197,100,89,222                      // vmulps        %ymm6,%ymm3,%ymm11
  .byte  197,100,92,226                      // vsubps        %ymm2,%ymm3,%ymm12
  .byte  196,65,36,94,220                    // vdivps        %ymm12,%ymm11,%ymm11
  .byte  197,52,89,230                       // vmulps        %ymm6,%ymm9,%ymm12
  .byte  196,65,68,93,219                    // vminps        %ymm11,%ymm7,%ymm11
  .byte  197,36,89,219                       // vmulps        %ymm3,%ymm11,%ymm11
  .byte  196,65,44,88,219                    // vaddps        %ymm11,%ymm10,%ymm11
  .byte  196,65,28,88,219                    // vaddps        %ymm11,%ymm12,%ymm11
  .byte  197,28,88,226                       // vaddps        %ymm2,%ymm12,%ymm12
  .byte  197,236,194,211,0                   // vcmpeqps      %ymm3,%ymm2,%ymm2
  .byte  196,195,37,74,212,32                // vblendvps     %ymm2,%ymm12,%ymm11,%ymm2
  .byte  196,65,76,194,192,0                 // vcmpeqps      %ymm8,%ymm6,%ymm8
  .byte  197,44,88,214                       // vaddps        %ymm6,%ymm10,%ymm10
  .byte  196,195,109,74,210,128              // vblendvps     %ymm8,%ymm10,%ymm2,%ymm2
  .byte  197,52,89,199                       // vmulps        %ymm7,%ymm9,%ymm8
  .byte  197,188,88,219                      // vaddps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_hardlight_avx
.globl _sk_hardlight_avx
FUNCTION(_sk_hardlight_avx)
_sk_hardlight_avx:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,215                       // vsubps        %ymm7,%ymm8,%ymm10
  .byte  197,44,89,200                       // vmulps        %ymm0,%ymm10,%ymm9
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,220                       // vmulps        %ymm4,%ymm8,%ymm11
  .byte  196,65,52,88,219                    // vaddps        %ymm11,%ymm9,%ymm11
  .byte  197,124,88,200                      // vaddps        %ymm0,%ymm0,%ymm9
  .byte  197,52,194,227,2                    // vcmpleps      %ymm3,%ymm9,%ymm12
  .byte  197,124,89,204                      // vmulps        %ymm4,%ymm0,%ymm9
  .byte  196,65,52,88,233                    // vaddps        %ymm9,%ymm9,%ymm13
  .byte  197,100,89,207                      // vmulps        %ymm7,%ymm3,%ymm9
  .byte  197,68,92,244                       // vsubps        %ymm4,%ymm7,%ymm14
  .byte  197,228,92,192                      // vsubps        %ymm0,%ymm3,%ymm0
  .byte  196,193,124,89,198                  // vmulps        %ymm14,%ymm0,%ymm0
  .byte  197,252,88,192                      // vaddps        %ymm0,%ymm0,%ymm0
  .byte  197,180,92,192                      // vsubps        %ymm0,%ymm9,%ymm0
  .byte  196,195,125,74,197,192              // vblendvps     %ymm12,%ymm13,%ymm0,%ymm0
  .byte  196,193,124,88,195                  // vaddps        %ymm11,%ymm0,%ymm0
  .byte  197,44,89,217                       // vmulps        %ymm1,%ymm10,%ymm11
  .byte  197,60,89,229                       // vmulps        %ymm5,%ymm8,%ymm12
  .byte  196,65,28,88,219                    // vaddps        %ymm11,%ymm12,%ymm11
  .byte  197,116,88,225                      // vaddps        %ymm1,%ymm1,%ymm12
  .byte  197,28,194,227,2                    // vcmpleps      %ymm3,%ymm12,%ymm12
  .byte  197,116,89,237                      // vmulps        %ymm5,%ymm1,%ymm13
  .byte  196,65,20,88,237                    // vaddps        %ymm13,%ymm13,%ymm13
  .byte  197,68,92,245                       // vsubps        %ymm5,%ymm7,%ymm14
  .byte  197,228,92,201                      // vsubps        %ymm1,%ymm3,%ymm1
  .byte  196,193,116,89,206                  // vmulps        %ymm14,%ymm1,%ymm1
  .byte  197,244,88,201                      // vaddps        %ymm1,%ymm1,%ymm1
  .byte  197,180,92,201                      // vsubps        %ymm1,%ymm9,%ymm1
  .byte  196,195,117,74,205,192              // vblendvps     %ymm12,%ymm13,%ymm1,%ymm1
  .byte  196,193,116,88,203                  // vaddps        %ymm11,%ymm1,%ymm1
  .byte  197,44,89,210                       // vmulps        %ymm2,%ymm10,%ymm10
  .byte  197,60,89,222                       // vmulps        %ymm6,%ymm8,%ymm11
  .byte  196,65,36,88,210                    // vaddps        %ymm10,%ymm11,%ymm10
  .byte  197,108,88,218                      // vaddps        %ymm2,%ymm2,%ymm11
  .byte  197,36,194,219,2                    // vcmpleps      %ymm3,%ymm11,%ymm11
  .byte  197,108,89,230                      // vmulps        %ymm6,%ymm2,%ymm12
  .byte  196,65,28,88,228                    // vaddps        %ymm12,%ymm12,%ymm12
  .byte  197,68,92,238                       // vsubps        %ymm6,%ymm7,%ymm13
  .byte  197,228,92,210                      // vsubps        %ymm2,%ymm3,%ymm2
  .byte  196,193,108,89,213                  // vmulps        %ymm13,%ymm2,%ymm2
  .byte  197,236,88,210                      // vaddps        %ymm2,%ymm2,%ymm2
  .byte  197,180,92,210                      // vsubps        %ymm2,%ymm9,%ymm2
  .byte  196,195,109,74,212,176              // vblendvps     %ymm11,%ymm12,%ymm2,%ymm2
  .byte  196,193,108,88,210                  // vaddps        %ymm10,%ymm2,%ymm2
  .byte  197,60,89,199                       // vmulps        %ymm7,%ymm8,%ymm8
  .byte  197,188,88,219                      // vaddps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_overlay_avx
.globl _sk_overlay_avx
FUNCTION(_sk_overlay_avx)
_sk_overlay_avx:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,215                       // vsubps        %ymm7,%ymm8,%ymm10
  .byte  197,44,89,200                       // vmulps        %ymm0,%ymm10,%ymm9
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,220                       // vmulps        %ymm4,%ymm8,%ymm11
  .byte  196,65,52,88,219                    // vaddps        %ymm11,%ymm9,%ymm11
  .byte  197,92,88,204                       // vaddps        %ymm4,%ymm4,%ymm9
  .byte  197,52,194,231,2                    // vcmpleps      %ymm7,%ymm9,%ymm12
  .byte  197,124,89,204                      // vmulps        %ymm4,%ymm0,%ymm9
  .byte  196,65,52,88,233                    // vaddps        %ymm9,%ymm9,%ymm13
  .byte  197,100,89,207                      // vmulps        %ymm7,%ymm3,%ymm9
  .byte  197,68,92,244                       // vsubps        %ymm4,%ymm7,%ymm14
  .byte  197,228,92,192                      // vsubps        %ymm0,%ymm3,%ymm0
  .byte  196,193,124,89,198                  // vmulps        %ymm14,%ymm0,%ymm0
  .byte  197,252,88,192                      // vaddps        %ymm0,%ymm0,%ymm0
  .byte  197,180,92,192                      // vsubps        %ymm0,%ymm9,%ymm0
  .byte  196,195,125,74,197,192              // vblendvps     %ymm12,%ymm13,%ymm0,%ymm0
  .byte  196,193,124,88,195                  // vaddps        %ymm11,%ymm0,%ymm0
  .byte  197,44,89,217                       // vmulps        %ymm1,%ymm10,%ymm11
  .byte  197,60,89,229                       // vmulps        %ymm5,%ymm8,%ymm12
  .byte  196,65,28,88,219                    // vaddps        %ymm11,%ymm12,%ymm11
  .byte  197,84,88,229                       // vaddps        %ymm5,%ymm5,%ymm12
  .byte  197,28,194,231,2                    // vcmpleps      %ymm7,%ymm12,%ymm12
  .byte  197,116,89,237                      // vmulps        %ymm5,%ymm1,%ymm13
  .byte  196,65,20,88,237                    // vaddps        %ymm13,%ymm13,%ymm13
  .byte  197,68,92,245                       // vsubps        %ymm5,%ymm7,%ymm14
  .byte  197,228,92,201                      // vsubps        %ymm1,%ymm3,%ymm1
  .byte  196,193,116,89,206                  // vmulps        %ymm14,%ymm1,%ymm1
  .byte  197,244,88,201                      // vaddps        %ymm1,%ymm1,%ymm1
  .byte  197,180,92,201                      // vsubps        %ymm1,%ymm9,%ymm1
  .byte  196,195,117,74,205,192              // vblendvps     %ymm12,%ymm13,%ymm1,%ymm1
  .byte  196,193,116,88,203                  // vaddps        %ymm11,%ymm1,%ymm1
  .byte  197,44,89,210                       // vmulps        %ymm2,%ymm10,%ymm10
  .byte  197,60,89,222                       // vmulps        %ymm6,%ymm8,%ymm11
  .byte  196,65,36,88,210                    // vaddps        %ymm10,%ymm11,%ymm10
  .byte  197,76,88,222                       // vaddps        %ymm6,%ymm6,%ymm11
  .byte  197,36,194,223,2                    // vcmpleps      %ymm7,%ymm11,%ymm11
  .byte  197,108,89,230                      // vmulps        %ymm6,%ymm2,%ymm12
  .byte  196,65,28,88,228                    // vaddps        %ymm12,%ymm12,%ymm12
  .byte  197,68,92,238                       // vsubps        %ymm6,%ymm7,%ymm13
  .byte  197,228,92,210                      // vsubps        %ymm2,%ymm3,%ymm2
  .byte  196,193,108,89,213                  // vmulps        %ymm13,%ymm2,%ymm2
  .byte  197,236,88,210                      // vaddps        %ymm2,%ymm2,%ymm2
  .byte  197,180,92,210                      // vsubps        %ymm2,%ymm9,%ymm2
  .byte  196,195,109,74,212,176              // vblendvps     %ymm11,%ymm12,%ymm2,%ymm2
  .byte  196,193,108,88,210                  // vaddps        %ymm10,%ymm2,%ymm2
  .byte  197,60,89,199                       // vmulps        %ymm7,%ymm8,%ymm8
  .byte  197,188,88,219                      // vaddps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_softlight_avx
.globl _sk_softlight_avx
FUNCTION(_sk_softlight_avx)
_sk_softlight_avx:
  .byte  197,252,17,84,36,200                // vmovups       %ymm2,-0x38(%rsp)
  .byte  197,252,40,209                      // vmovaps       %ymm1,%ymm2
  .byte  196,65,52,87,201                    // vxorps        %ymm9,%ymm9,%ymm9
  .byte  197,52,194,215,1                    // vcmpltps      %ymm7,%ymm9,%ymm10
  .byte  197,92,94,199                       // vdivps        %ymm7,%ymm4,%ymm8
  .byte  196,67,53,74,216,160                // vblendvps     %ymm10,%ymm8,%ymm9,%ymm11
  .byte  196,65,36,88,195                    // vaddps        %ymm11,%ymm11,%ymm8
  .byte  196,65,60,88,224                    // vaddps        %ymm8,%ymm8,%ymm12
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  196,65,28,89,236                    // vmulps        %ymm12,%ymm12,%ymm13
  .byte  196,65,28,88,229                    // vaddps        %ymm13,%ymm12,%ymm12
  .byte  196,65,36,92,232                    // vsubps        %ymm8,%ymm11,%ymm13
  .byte  196,65,28,89,237                    // vmulps        %ymm13,%ymm12,%ymm13
  .byte  184,0,0,224,64                      // mov           $0x40e00000,%eax
  .byte  197,121,110,224                     // vmovd         %eax,%xmm12
  .byte  196,67,121,4,228,0                  // vpermilps     $0x0,%xmm12,%xmm12
  .byte  196,67,29,24,228,1                  // vinsertf128   $0x1,%xmm12,%ymm12,%ymm12
  .byte  196,65,36,89,244                    // vmulps        %ymm12,%ymm11,%ymm14
  .byte  196,65,20,88,238                    // vaddps        %ymm14,%ymm13,%ymm13
  .byte  196,65,124,82,243                   // vrsqrtps      %ymm11,%ymm14
  .byte  196,65,124,83,246                   // vrcpps        %ymm14,%ymm14
  .byte  196,65,12,92,243                    // vsubps        %ymm11,%ymm14,%ymm14
  .byte  197,92,88,252                       // vaddps        %ymm4,%ymm4,%ymm15
  .byte  196,65,4,88,255                     // vaddps        %ymm15,%ymm15,%ymm15
  .byte  197,4,194,255,2                     // vcmpleps      %ymm7,%ymm15,%ymm15
  .byte  196,67,13,74,237,240                // vblendvps     %ymm15,%ymm13,%ymm14,%ymm13
  .byte  197,124,88,240                      // vaddps        %ymm0,%ymm0,%ymm14
  .byte  197,12,92,251                       // vsubps        %ymm3,%ymm14,%ymm15
  .byte  196,65,60,92,219                    // vsubps        %ymm11,%ymm8,%ymm11
  .byte  196,65,4,89,219                     // vmulps        %ymm11,%ymm15,%ymm11
  .byte  197,36,88,219                       // vaddps        %ymm3,%ymm11,%ymm11
  .byte  197,36,89,220                       // vmulps        %ymm4,%ymm11,%ymm11
  .byte  197,4,89,255                        // vmulps        %ymm7,%ymm15,%ymm15
  .byte  196,65,4,89,237                     // vmulps        %ymm13,%ymm15,%ymm13
  .byte  197,100,89,252                      // vmulps        %ymm4,%ymm3,%ymm15
  .byte  196,65,4,88,237                     // vaddps        %ymm13,%ymm15,%ymm13
  .byte  197,12,194,243,2                    // vcmpleps      %ymm3,%ymm14,%ymm14
  .byte  196,195,21,74,203,224               // vblendvps     %ymm14,%ymm11,%ymm13,%ymm1
  .byte  197,84,94,239                       // vdivps        %ymm7,%ymm5,%ymm13
  .byte  196,67,53,74,237,160                // vblendvps     %ymm10,%ymm13,%ymm9,%ymm13
  .byte  196,65,20,88,245                    // vaddps        %ymm13,%ymm13,%ymm14
  .byte  196,65,12,88,246                    // vaddps        %ymm14,%ymm14,%ymm14
  .byte  196,65,12,89,254                    // vmulps        %ymm14,%ymm14,%ymm15
  .byte  196,65,12,88,247                    // vaddps        %ymm15,%ymm14,%ymm14
  .byte  196,65,20,92,248                    // vsubps        %ymm8,%ymm13,%ymm15
  .byte  196,65,4,89,246                     // vmulps        %ymm14,%ymm15,%ymm14
  .byte  196,65,28,89,253                    // vmulps        %ymm13,%ymm12,%ymm15
  .byte  196,65,4,88,246                     // vaddps        %ymm14,%ymm15,%ymm14
  .byte  196,65,124,82,253                   // vrsqrtps      %ymm13,%ymm15
  .byte  196,65,124,83,255                   // vrcpps        %ymm15,%ymm15
  .byte  196,65,4,92,253                     // vsubps        %ymm13,%ymm15,%ymm15
  .byte  197,84,88,221                       // vaddps        %ymm5,%ymm5,%ymm11
  .byte  196,65,36,88,219                    // vaddps        %ymm11,%ymm11,%ymm11
  .byte  197,36,194,223,2                    // vcmpleps      %ymm7,%ymm11,%ymm11
  .byte  196,67,5,74,222,176                 // vblendvps     %ymm11,%ymm14,%ymm15,%ymm11
  .byte  197,108,88,242                      // vaddps        %ymm2,%ymm2,%ymm14
  .byte  196,65,60,92,237                    // vsubps        %ymm13,%ymm8,%ymm13
  .byte  197,12,92,251                       // vsubps        %ymm3,%ymm14,%ymm15
  .byte  196,65,4,89,237                     // vmulps        %ymm13,%ymm15,%ymm13
  .byte  197,4,89,255                        // vmulps        %ymm7,%ymm15,%ymm15
  .byte  196,65,4,89,219                     // vmulps        %ymm11,%ymm15,%ymm11
  .byte  197,100,89,253                      // vmulps        %ymm5,%ymm3,%ymm15
  .byte  196,65,4,88,219                     // vaddps        %ymm11,%ymm15,%ymm11
  .byte  197,20,88,235                       // vaddps        %ymm3,%ymm13,%ymm13
  .byte  197,20,89,237                       // vmulps        %ymm5,%ymm13,%ymm13
  .byte  197,12,194,243,2                    // vcmpleps      %ymm3,%ymm14,%ymm14
  .byte  196,67,37,74,237,224                // vblendvps     %ymm14,%ymm13,%ymm11,%ymm13
  .byte  197,76,94,223                       // vdivps        %ymm7,%ymm6,%ymm11
  .byte  196,67,53,74,203,160                // vblendvps     %ymm10,%ymm11,%ymm9,%ymm9
  .byte  196,65,52,88,209                    // vaddps        %ymm9,%ymm9,%ymm10
  .byte  196,65,44,88,210                    // vaddps        %ymm10,%ymm10,%ymm10
  .byte  196,65,44,89,218                    // vmulps        %ymm10,%ymm10,%ymm11
  .byte  196,65,44,88,211                    // vaddps        %ymm11,%ymm10,%ymm10
  .byte  196,65,52,92,216                    // vsubps        %ymm8,%ymm9,%ymm11
  .byte  196,65,36,89,210                    // vmulps        %ymm10,%ymm11,%ymm10
  .byte  196,65,28,89,217                    // vmulps        %ymm9,%ymm12,%ymm11
  .byte  196,65,36,88,210                    // vaddps        %ymm10,%ymm11,%ymm10
  .byte  196,65,124,82,217                   // vrsqrtps      %ymm9,%ymm11
  .byte  196,65,124,83,219                   // vrcpps        %ymm11,%ymm11
  .byte  196,65,36,92,217                    // vsubps        %ymm9,%ymm11,%ymm11
  .byte  197,76,88,230                       // vaddps        %ymm6,%ymm6,%ymm12
  .byte  196,65,28,88,228                    // vaddps        %ymm12,%ymm12,%ymm12
  .byte  197,28,194,231,2                    // vcmpleps      %ymm7,%ymm12,%ymm12
  .byte  196,67,37,74,210,192                // vblendvps     %ymm12,%ymm10,%ymm11,%ymm10
  .byte  197,124,16,116,36,200               // vmovups       -0x38(%rsp),%ymm14
  .byte  196,65,12,88,222                    // vaddps        %ymm14,%ymm14,%ymm11
  .byte  197,36,92,227                       // vsubps        %ymm3,%ymm11,%ymm12
  .byte  196,65,60,92,201                    // vsubps        %ymm9,%ymm8,%ymm9
  .byte  196,65,28,89,201                    // vmulps        %ymm9,%ymm12,%ymm9
  .byte  197,28,89,231                       // vmulps        %ymm7,%ymm12,%ymm12
  .byte  196,65,28,89,210                    // vmulps        %ymm10,%ymm12,%ymm10
  .byte  197,100,89,230                      // vmulps        %ymm6,%ymm3,%ymm12
  .byte  196,65,28,88,210                    // vaddps        %ymm10,%ymm12,%ymm10
  .byte  197,52,88,203                       // vaddps        %ymm3,%ymm9,%ymm9
  .byte  197,52,89,206                       // vmulps        %ymm6,%ymm9,%ymm9
  .byte  197,36,194,219,2                    // vcmpleps      %ymm3,%ymm11,%ymm11
  .byte  196,67,45,74,201,176                // vblendvps     %ymm11,%ymm9,%ymm10,%ymm9
  .byte  197,60,92,215                       // vsubps        %ymm7,%ymm8,%ymm10
  .byte  197,172,89,192                      // vmulps        %ymm0,%ymm10,%ymm0
  .byte  197,60,92,195                       // vsubps        %ymm3,%ymm8,%ymm8
  .byte  197,60,89,220                       // vmulps        %ymm4,%ymm8,%ymm11
  .byte  196,193,124,88,195                  // vaddps        %ymm11,%ymm0,%ymm0
  .byte  197,244,88,192                      // vaddps        %ymm0,%ymm1,%ymm0
  .byte  197,172,89,202                      // vmulps        %ymm2,%ymm10,%ymm1
  .byte  197,188,89,213                      // vmulps        %ymm5,%ymm8,%ymm2
  .byte  197,236,88,201                      // vaddps        %ymm1,%ymm2,%ymm1
  .byte  196,193,116,88,205                  // vaddps        %ymm13,%ymm1,%ymm1
  .byte  196,193,44,89,214                   // vmulps        %ymm14,%ymm10,%ymm2
  .byte  197,60,89,214                       // vmulps        %ymm6,%ymm8,%ymm10
  .byte  197,172,88,210                      // vaddps        %ymm2,%ymm10,%ymm2
  .byte  196,193,108,88,209                  // vaddps        %ymm9,%ymm2,%ymm2
  .byte  197,60,89,199                       // vmulps        %ymm7,%ymm8,%ymm8
  .byte  197,188,88,219                      // vaddps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_0_avx
.globl _sk_clamp_0_avx
FUNCTION(_sk_clamp_0_avx)
_sk_clamp_0_avx:
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  196,193,124,95,192                  // vmaxps        %ymm8,%ymm0,%ymm0
  .byte  196,193,116,95,200                  // vmaxps        %ymm8,%ymm1,%ymm1
  .byte  196,193,108,95,208                  // vmaxps        %ymm8,%ymm2,%ymm2
  .byte  196,193,100,95,216                  // vmaxps        %ymm8,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_1_avx
.globl _sk_clamp_1_avx
FUNCTION(_sk_clamp_1_avx)
_sk_clamp_1_avx:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  196,193,124,93,192                  // vminps        %ymm8,%ymm0,%ymm0
  .byte  196,193,116,93,200                  // vminps        %ymm8,%ymm1,%ymm1
  .byte  196,193,108,93,208                  // vminps        %ymm8,%ymm2,%ymm2
  .byte  196,193,100,93,216                  // vminps        %ymm8,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_a_avx
.globl _sk_clamp_a_avx
FUNCTION(_sk_clamp_a_avx)
_sk_clamp_a_avx:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  196,193,100,93,216                  // vminps        %ymm8,%ymm3,%ymm3
  .byte  197,252,93,195                      // vminps        %ymm3,%ymm0,%ymm0
  .byte  197,244,93,203                      // vminps        %ymm3,%ymm1,%ymm1
  .byte  197,236,93,211                      // vminps        %ymm3,%ymm2,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_set_rgb_avx
.globl _sk_set_rgb_avx
FUNCTION(_sk_set_rgb_avx)
_sk_set_rgb_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,226,125,24,0                    // vbroadcastss  (%rax),%ymm0
  .byte  196,226,125,24,72,4                 // vbroadcastss  0x4(%rax),%ymm1
  .byte  196,226,125,24,80,8                 // vbroadcastss  0x8(%rax),%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_swap_rb_avx
.globl _sk_swap_rb_avx
FUNCTION(_sk_swap_rb_avx)
_sk_swap_rb_avx:
  .byte  197,124,40,192                      // vmovaps       %ymm0,%ymm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,40,194                      // vmovaps       %ymm2,%ymm0
  .byte  197,124,41,194                      // vmovaps       %ymm8,%ymm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_swap_avx
.globl _sk_swap_avx
FUNCTION(_sk_swap_avx)
_sk_swap_avx:
  .byte  197,124,40,195                      // vmovaps       %ymm3,%ymm8
  .byte  197,124,40,202                      // vmovaps       %ymm2,%ymm9
  .byte  197,124,40,209                      // vmovaps       %ymm1,%ymm10
  .byte  197,124,40,216                      // vmovaps       %ymm0,%ymm11
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,40,196                      // vmovaps       %ymm4,%ymm0
  .byte  197,252,40,205                      // vmovaps       %ymm5,%ymm1
  .byte  197,252,40,214                      // vmovaps       %ymm6,%ymm2
  .byte  197,252,40,223                      // vmovaps       %ymm7,%ymm3
  .byte  197,124,41,220                      // vmovaps       %ymm11,%ymm4
  .byte  197,124,41,213                      // vmovaps       %ymm10,%ymm5
  .byte  197,124,41,206                      // vmovaps       %ymm9,%ymm6
  .byte  197,124,41,199                      // vmovaps       %ymm8,%ymm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_move_src_dst_avx
.globl _sk_move_src_dst_avx
FUNCTION(_sk_move_src_dst_avx)
_sk_move_src_dst_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,40,224                      // vmovaps       %ymm0,%ymm4
  .byte  197,252,40,233                      // vmovaps       %ymm1,%ymm5
  .byte  197,252,40,242                      // vmovaps       %ymm2,%ymm6
  .byte  197,252,40,251                      // vmovaps       %ymm3,%ymm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_move_dst_src_avx
.globl _sk_move_dst_src_avx
FUNCTION(_sk_move_dst_src_avx)
_sk_move_dst_src_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,40,196                      // vmovaps       %ymm4,%ymm0
  .byte  197,252,40,205                      // vmovaps       %ymm5,%ymm1
  .byte  197,252,40,214                      // vmovaps       %ymm6,%ymm2
  .byte  197,252,40,223                      // vmovaps       %ymm7,%ymm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_premul_avx
.globl _sk_premul_avx
FUNCTION(_sk_premul_avx)
_sk_premul_avx:
  .byte  197,252,89,195                      // vmulps        %ymm3,%ymm0,%ymm0
  .byte  197,244,89,203                      // vmulps        %ymm3,%ymm1,%ymm1
  .byte  197,236,89,211                      // vmulps        %ymm3,%ymm2,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_unpremul_avx
.globl _sk_unpremul_avx
FUNCTION(_sk_unpremul_avx)
_sk_unpremul_avx:
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  196,65,100,194,200,0                // vcmpeqps      %ymm8,%ymm3,%ymm9
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,208                     // vmovd         %eax,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  197,44,94,211                       // vdivps        %ymm3,%ymm10,%ymm10
  .byte  196,67,45,74,192,144                // vblendvps     %ymm9,%ymm8,%ymm10,%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_from_srgb_avx
.globl _sk_from_srgb_avx
FUNCTION(_sk_from_srgb_avx)
_sk_from_srgb_avx:
  .byte  184,145,131,158,61                  // mov           $0x3d9e8391,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,89,200                       // vmulps        %ymm0,%ymm8,%ymm9
  .byte  197,124,89,208                      // vmulps        %ymm0,%ymm0,%ymm10
  .byte  184,154,153,153,62                  // mov           $0x3e99999a,%eax
  .byte  197,121,110,216                     // vmovd         %eax,%xmm11
  .byte  196,67,121,4,219,0                  // vpermilps     $0x0,%xmm11,%xmm11
  .byte  196,67,37,24,219,1                  // vinsertf128   $0x1,%xmm11,%ymm11,%ymm11
  .byte  184,92,143,50,63                    // mov           $0x3f328f5c,%eax
  .byte  197,121,110,224                     // vmovd         %eax,%xmm12
  .byte  196,67,121,4,228,0                  // vpermilps     $0x0,%xmm12,%xmm12
  .byte  196,67,29,24,228,1                  // vinsertf128   $0x1,%xmm12,%ymm12,%ymm12
  .byte  197,36,89,232                       // vmulps        %ymm0,%ymm11,%ymm13
  .byte  196,65,20,88,236                    // vaddps        %ymm12,%ymm13,%ymm13
  .byte  184,10,215,35,59                    // mov           $0x3b23d70a,%eax
  .byte  197,121,110,240                     // vmovd         %eax,%xmm14
  .byte  196,67,121,4,246,0                  // vpermilps     $0x0,%xmm14,%xmm14
  .byte  196,67,13,24,246,1                  // vinsertf128   $0x1,%xmm14,%ymm14,%ymm14
  .byte  196,65,44,89,213                    // vmulps        %ymm13,%ymm10,%ymm10
  .byte  196,65,12,88,210                    // vaddps        %ymm10,%ymm14,%ymm10
  .byte  184,174,71,97,61                    // mov           $0x3d6147ae,%eax
  .byte  197,121,110,232                     // vmovd         %eax,%xmm13
  .byte  196,67,121,4,237,0                  // vpermilps     $0x0,%xmm13,%xmm13
  .byte  196,67,21,24,237,1                  // vinsertf128   $0x1,%xmm13,%ymm13,%ymm13
  .byte  196,193,124,194,197,1               // vcmpltps      %ymm13,%ymm0,%ymm0
  .byte  196,195,45,74,193,0                 // vblendvps     %ymm0,%ymm9,%ymm10,%ymm0
  .byte  197,60,89,201                       // vmulps        %ymm1,%ymm8,%ymm9
  .byte  197,116,89,209                      // vmulps        %ymm1,%ymm1,%ymm10
  .byte  197,36,89,249                       // vmulps        %ymm1,%ymm11,%ymm15
  .byte  196,65,28,88,255                    // vaddps        %ymm15,%ymm12,%ymm15
  .byte  196,65,44,89,215                    // vmulps        %ymm15,%ymm10,%ymm10
  .byte  196,65,12,88,210                    // vaddps        %ymm10,%ymm14,%ymm10
  .byte  196,193,116,194,205,1               // vcmpltps      %ymm13,%ymm1,%ymm1
  .byte  196,195,45,74,201,16                // vblendvps     %ymm1,%ymm9,%ymm10,%ymm1
  .byte  197,60,89,194                       // vmulps        %ymm2,%ymm8,%ymm8
  .byte  197,108,89,202                      // vmulps        %ymm2,%ymm2,%ymm9
  .byte  197,36,89,210                       // vmulps        %ymm2,%ymm11,%ymm10
  .byte  196,65,28,88,210                    // vaddps        %ymm10,%ymm12,%ymm10
  .byte  196,65,52,89,202                    // vmulps        %ymm10,%ymm9,%ymm9
  .byte  196,65,12,88,201                    // vaddps        %ymm9,%ymm14,%ymm9
  .byte  196,193,108,194,213,1               // vcmpltps      %ymm13,%ymm2,%ymm2
  .byte  196,195,53,74,208,32                // vblendvps     %ymm2,%ymm8,%ymm9,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_to_srgb_avx
.globl _sk_to_srgb_avx
FUNCTION(_sk_to_srgb_avx)
_sk_to_srgb_avx:
  .byte  197,124,82,192                      // vrsqrtps      %ymm0,%ymm8
  .byte  196,65,124,83,232                   // vrcpps        %ymm8,%ymm13
  .byte  196,65,124,82,240                   // vrsqrtps      %ymm8,%ymm14
  .byte  184,41,92,71,65                     // mov           $0x41475c29,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,89,224                       // vmulps        %ymm0,%ymm8,%ymm12
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,200                     // vmovd         %eax,%xmm9
  .byte  196,67,121,4,201,0                  // vpermilps     $0x0,%xmm9,%xmm9
  .byte  196,67,53,24,201,1                  // vinsertf128   $0x1,%xmm9,%ymm9,%ymm9
  .byte  184,194,135,210,62                  // mov           $0x3ed287c2,%eax
  .byte  197,121,110,208                     // vmovd         %eax,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  184,206,111,48,63                   // mov           $0x3f306fce,%eax
  .byte  197,121,110,216                     // vmovd         %eax,%xmm11
  .byte  196,67,121,4,219,0                  // vpermilps     $0x0,%xmm11,%xmm11
  .byte  196,67,37,24,219,1                  // vinsertf128   $0x1,%xmm11,%ymm11,%ymm11
  .byte  184,168,87,202,61                   // mov           $0x3dca57a8,%eax
  .byte  53,0,0,0,128                        // xor           $0x80000000,%eax
  .byte  197,121,110,248                     // vmovd         %eax,%xmm15
  .byte  196,67,121,4,255,0                  // vpermilps     $0x0,%xmm15,%xmm15
  .byte  196,67,5,24,255,1                   // vinsertf128   $0x1,%xmm15,%ymm15,%ymm15
  .byte  196,65,20,89,235                    // vmulps        %ymm11,%ymm13,%ymm13
  .byte  196,65,20,88,239                    // vaddps        %ymm15,%ymm13,%ymm13
  .byte  196,65,12,89,242                    // vmulps        %ymm10,%ymm14,%ymm14
  .byte  196,65,12,88,237                    // vaddps        %ymm13,%ymm14,%ymm13
  .byte  196,65,52,93,237                    // vminps        %ymm13,%ymm9,%ymm13
  .byte  184,4,231,140,59                    // mov           $0x3b8ce704,%eax
  .byte  197,121,110,240                     // vmovd         %eax,%xmm14
  .byte  196,67,121,4,246,0                  // vpermilps     $0x0,%xmm14,%xmm14
  .byte  196,67,13,24,246,1                  // vinsertf128   $0x1,%xmm14,%ymm14,%ymm14
  .byte  196,193,124,194,198,1               // vcmpltps      %ymm14,%ymm0,%ymm0
  .byte  196,195,21,74,196,0                 // vblendvps     %ymm0,%ymm12,%ymm13,%ymm0
  .byte  197,124,82,225                      // vrsqrtps      %ymm1,%ymm12
  .byte  196,65,124,83,236                   // vrcpps        %ymm12,%ymm13
  .byte  196,65,124,82,228                   // vrsqrtps      %ymm12,%ymm12
  .byte  196,65,36,89,237                    // vmulps        %ymm13,%ymm11,%ymm13
  .byte  196,65,4,88,237                     // vaddps        %ymm13,%ymm15,%ymm13
  .byte  196,65,44,89,228                    // vmulps        %ymm12,%ymm10,%ymm12
  .byte  196,65,28,88,229                    // vaddps        %ymm13,%ymm12,%ymm12
  .byte  197,60,89,233                       // vmulps        %ymm1,%ymm8,%ymm13
  .byte  196,65,52,93,228                    // vminps        %ymm12,%ymm9,%ymm12
  .byte  196,193,116,194,206,1               // vcmpltps      %ymm14,%ymm1,%ymm1
  .byte  196,195,29,74,205,16                // vblendvps     %ymm1,%ymm13,%ymm12,%ymm1
  .byte  197,124,82,226                      // vrsqrtps      %ymm2,%ymm12
  .byte  196,65,124,83,236                   // vrcpps        %ymm12,%ymm13
  .byte  196,65,36,89,221                    // vmulps        %ymm13,%ymm11,%ymm11
  .byte  196,65,4,88,219                     // vaddps        %ymm11,%ymm15,%ymm11
  .byte  196,65,124,82,228                   // vrsqrtps      %ymm12,%ymm12
  .byte  196,65,44,89,212                    // vmulps        %ymm12,%ymm10,%ymm10
  .byte  196,65,44,88,211                    // vaddps        %ymm11,%ymm10,%ymm10
  .byte  196,65,52,93,202                    // vminps        %ymm10,%ymm9,%ymm9
  .byte  197,60,89,194                       // vmulps        %ymm2,%ymm8,%ymm8
  .byte  196,193,108,194,214,1               // vcmpltps      %ymm14,%ymm2,%ymm2
  .byte  196,195,53,74,208,32                // vblendvps     %ymm2,%ymm8,%ymm9,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_rgb_to_hsl_avx
.globl _sk_rgb_to_hsl_avx
FUNCTION(_sk_rgb_to_hsl_avx)
_sk_rgb_to_hsl_avx:
  .byte  197,124,95,193                      // vmaxps        %ymm1,%ymm0,%ymm8
  .byte  197,60,95,194                       // vmaxps        %ymm2,%ymm8,%ymm8
  .byte  197,124,93,201                      // vminps        %ymm1,%ymm0,%ymm9
  .byte  197,52,93,202                       // vminps        %ymm2,%ymm9,%ymm9
  .byte  196,65,60,92,209                    // vsubps        %ymm9,%ymm8,%ymm10
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,121,110,216                     // vmovd         %eax,%xmm11
  .byte  196,67,121,4,219,0                  // vpermilps     $0x0,%xmm11,%xmm11
  .byte  196,67,37,24,219,1                  // vinsertf128   $0x1,%xmm11,%ymm11,%ymm11
  .byte  196,65,36,94,218                    // vdivps        %ymm10,%ymm11,%ymm11
  .byte  65,184,171,170,42,62                // mov           $0x3e2aaaab,%r8d
  .byte  197,116,92,226                      // vsubps        %ymm2,%ymm1,%ymm12
  .byte  196,65,28,89,227                    // vmulps        %ymm11,%ymm12,%ymm12
  .byte  65,185,0,0,192,64                   // mov           $0x40c00000,%r9d
  .byte  197,108,92,232                      // vsubps        %ymm0,%ymm2,%ymm13
  .byte  196,65,20,89,235                    // vmulps        %ymm11,%ymm13,%ymm13
  .byte  65,186,0,0,0,64                     // mov           $0x40000000,%r10d
  .byte  197,124,92,241                      // vsubps        %ymm1,%ymm0,%ymm14
  .byte  196,65,12,89,219                    // vmulps        %ymm11,%ymm14,%ymm11
  .byte  184,0,0,128,64                      // mov           $0x40800000,%eax
  .byte  197,121,110,240                     // vmovd         %eax,%xmm14
  .byte  196,67,121,4,246,0                  // vpermilps     $0x0,%xmm14,%xmm14
  .byte  196,67,13,24,246,1                  // vinsertf128   $0x1,%xmm14,%ymm14,%ymm14
  .byte  196,65,36,88,222                    // vaddps        %ymm14,%ymm11,%ymm11
  .byte  196,65,121,110,242                  // vmovd         %r10d,%xmm14
  .byte  197,244,194,210,1                   // vcmpltps      %ymm2,%ymm1,%ymm2
  .byte  197,188,194,201,0                   // vcmpeqps      %ymm1,%ymm8,%ymm1
  .byte  196,67,121,4,246,0                  // vpermilps     $0x0,%xmm14,%xmm14
  .byte  196,67,13,24,246,1                  // vinsertf128   $0x1,%xmm14,%ymm14,%ymm14
  .byte  196,65,20,88,238                    // vaddps        %ymm14,%ymm13,%ymm13
  .byte  196,67,37,74,221,16                 // vblendvps     %ymm1,%ymm13,%ymm11,%ymm11
  .byte  196,193,121,110,201                 // vmovd         %r9d,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  196,65,20,87,237                    // vxorps        %ymm13,%ymm13,%ymm13
  .byte  196,227,21,74,201,32                // vblendvps     %ymm2,%ymm1,%ymm13,%ymm1
  .byte  196,193,116,88,204                  // vaddps        %ymm12,%ymm1,%ymm1
  .byte  184,0,0,0,63                        // mov           $0x3f000000,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  197,188,194,192,0                   // vcmpeqps      %ymm0,%ymm8,%ymm0
  .byte  196,227,37,74,193,0                 // vblendvps     %ymm0,%ymm1,%ymm11,%ymm0
  .byte  196,193,60,88,201                   // vaddps        %ymm9,%ymm8,%ymm1
  .byte  196,227,121,4,210,0                 // vpermilps     $0x0,%xmm2,%xmm2
  .byte  196,99,109,24,218,1                 // vinsertf128   $0x1,%xmm2,%ymm2,%ymm11
  .byte  196,193,116,89,211                  // vmulps        %ymm11,%ymm1,%ymm2
  .byte  197,36,194,218,1                    // vcmpltps      %ymm2,%ymm11,%ymm11
  .byte  196,65,12,92,224                    // vsubps        %ymm8,%ymm14,%ymm12
  .byte  196,65,28,92,225                    // vsubps        %ymm9,%ymm12,%ymm12
  .byte  196,195,117,74,204,176              // vblendvps     %ymm11,%ymm12,%ymm1,%ymm1
  .byte  196,65,60,194,193,0                 // vcmpeqps      %ymm9,%ymm8,%ymm8
  .byte  197,172,94,201                      // vdivps        %ymm1,%ymm10,%ymm1
  .byte  196,67,125,74,205,128               // vblendvps     %ymm8,%ymm13,%ymm0,%ymm9
  .byte  196,195,117,74,205,128              // vblendvps     %ymm8,%ymm13,%ymm1,%ymm1
  .byte  196,193,121,110,192                 // vmovd         %r8d,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  196,193,124,89,193                  // vmulps        %ymm9,%ymm0,%ymm0
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_hsl_to_rgb_avx
.globl _sk_hsl_to_rgb_avx
FUNCTION(_sk_hsl_to_rgb_avx)
_sk_hsl_to_rgb_avx:
  .byte  72,131,236,56                       // sub           $0x38,%rsp
  .byte  197,252,17,60,36                    // vmovups       %ymm7,(%rsp)
  .byte  197,252,17,116,36,224               // vmovups       %ymm6,-0x20(%rsp)
  .byte  197,252,17,108,36,192               // vmovups       %ymm5,-0x40(%rsp)
  .byte  197,252,17,100,36,160               // vmovups       %ymm4,-0x60(%rsp)
  .byte  197,252,17,92,36,128                // vmovups       %ymm3,-0x80(%rsp)
  .byte  197,252,40,226                      // vmovaps       %ymm2,%ymm4
  .byte  197,252,40,233                      // vmovaps       %ymm1,%ymm5
  .byte  197,252,40,216                      // vmovaps       %ymm0,%ymm3
  .byte  184,0,0,0,63                        // mov           $0x3f000000,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,99,125,24,192,1                 // vinsertf128   $0x1,%xmm0,%ymm0,%ymm8
  .byte  196,193,92,194,192,1                // vcmpltps      %ymm8,%ymm4,%ymm0
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,227,121,4,210,0                 // vpermilps     $0x0,%xmm2,%xmm2
  .byte  196,99,109,24,210,1                 // vinsertf128   $0x1,%xmm2,%ymm2,%ymm10
  .byte  197,172,88,213                      // vaddps        %ymm5,%ymm10,%ymm2
  .byte  197,236,89,212                      // vmulps        %ymm4,%ymm2,%ymm2
  .byte  197,84,88,204                       // vaddps        %ymm4,%ymm5,%ymm9
  .byte  197,84,89,220                       // vmulps        %ymm4,%ymm5,%ymm11
  .byte  196,65,52,92,203                    // vsubps        %ymm11,%ymm9,%ymm9
  .byte  196,99,53,74,202,0                  // vblendvps     %ymm0,%ymm2,%ymm9,%ymm9
  .byte  65,184,0,0,0,64                     // mov           $0x40000000,%r8d
  .byte  184,171,170,170,62                  // mov           $0x3eaaaaab,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,99,125,24,224,1                 // vinsertf128   $0x1,%xmm0,%ymm0,%ymm12
  .byte  197,28,88,251                       // vaddps        %ymm3,%ymm12,%ymm15
  .byte  184,0,0,0,0                         // mov           $0x0,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,99,125,24,232,1                 // vinsertf128   $0x1,%xmm0,%ymm0,%ymm13
  .byte  196,193,44,194,199,1                // vcmpltps      %ymm15,%ymm10,%ymm0
  .byte  196,193,4,92,210                    // vsubps        %ymm10,%ymm15,%ymm2
  .byte  196,227,5,74,194,0                  // vblendvps     %ymm0,%ymm2,%ymm15,%ymm0
  .byte  196,193,4,194,213,1                 // vcmpltps      %ymm13,%ymm15,%ymm2
  .byte  196,65,44,88,223                    // vaddps        %ymm15,%ymm10,%ymm11
  .byte  196,195,125,74,203,32               // vblendvps     %ymm2,%ymm11,%ymm0,%ymm1
  .byte  196,193,121,110,192                 // vmovd         %r8d,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,252,89,196                      // vmulps        %ymm4,%ymm0,%ymm0
  .byte  196,65,124,92,217                   // vsubps        %ymm9,%ymm0,%ymm11
  .byte  65,184,171,170,42,62                // mov           $0x3e2aaaab,%r8d
  .byte  184,0,0,192,64                      // mov           $0x40c00000,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  196,193,52,92,211                   // vsubps        %ymm11,%ymm9,%ymm2
  .byte  197,108,89,240                      // vmulps        %ymm0,%ymm2,%ymm14
  .byte  184,171,170,42,63                   // mov           $0x3f2aaaab,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,252,92,209                      // vsubps        %ymm1,%ymm0,%ymm2
  .byte  197,140,89,210                      // vmulps        %ymm2,%ymm14,%ymm2
  .byte  197,164,88,210                      // vaddps        %ymm2,%ymm11,%ymm2
  .byte  197,244,194,248,1                   // vcmpltps      %ymm0,%ymm1,%ymm7
  .byte  196,227,37,74,210,112               // vblendvps     %ymm7,%ymm2,%ymm11,%ymm2
  .byte  196,193,116,194,248,1               // vcmpltps      %ymm8,%ymm1,%ymm7
  .byte  196,195,109,74,249,112              // vblendvps     %ymm7,%ymm9,%ymm2,%ymm7
  .byte  196,193,121,110,208                 // vmovd         %r8d,%xmm2
  .byte  196,227,121,4,210,0                 // vpermilps     $0x0,%xmm2,%xmm2
  .byte  196,227,109,24,210,1                // vinsertf128   $0x1,%xmm2,%ymm2,%ymm2
  .byte  197,244,194,202,1                   // vcmpltps      %ymm2,%ymm1,%ymm1
  .byte  196,65,4,89,254                     // vmulps        %ymm14,%ymm15,%ymm15
  .byte  196,65,36,88,255                    // vaddps        %ymm15,%ymm11,%ymm15
  .byte  196,67,69,74,255,16                 // vblendvps     %ymm1,%ymm15,%ymm7,%ymm15
  .byte  197,172,194,203,1                   // vcmpltps      %ymm3,%ymm10,%ymm1
  .byte  196,193,100,92,250                  // vsubps        %ymm10,%ymm3,%ymm7
  .byte  196,227,101,74,207,16               // vblendvps     %ymm1,%ymm7,%ymm3,%ymm1
  .byte  196,193,100,194,253,1               // vcmpltps      %ymm13,%ymm3,%ymm7
  .byte  197,172,88,243                      // vaddps        %ymm3,%ymm10,%ymm6
  .byte  196,227,117,74,206,112              // vblendvps     %ymm7,%ymm6,%ymm1,%ymm1
  .byte  197,252,92,241                      // vsubps        %ymm1,%ymm0,%ymm6
  .byte  197,140,89,246                      // vmulps        %ymm6,%ymm14,%ymm6
  .byte  197,164,88,246                      // vaddps        %ymm6,%ymm11,%ymm6
  .byte  197,244,194,248,1                   // vcmpltps      %ymm0,%ymm1,%ymm7
  .byte  196,227,37,74,246,112               // vblendvps     %ymm7,%ymm6,%ymm11,%ymm6
  .byte  196,193,116,194,248,1               // vcmpltps      %ymm8,%ymm1,%ymm7
  .byte  196,195,77,74,241,112               // vblendvps     %ymm7,%ymm9,%ymm6,%ymm6
  .byte  197,244,194,202,1                   // vcmpltps      %ymm2,%ymm1,%ymm1
  .byte  197,140,89,251                      // vmulps        %ymm3,%ymm14,%ymm7
  .byte  197,164,88,255                      // vaddps        %ymm7,%ymm11,%ymm7
  .byte  196,227,77,74,207,16                // vblendvps     %ymm1,%ymm7,%ymm6,%ymm1
  .byte  196,193,100,92,220                  // vsubps        %ymm12,%ymm3,%ymm3
  .byte  197,172,194,243,1                   // vcmpltps      %ymm3,%ymm10,%ymm6
  .byte  196,193,100,92,250                  // vsubps        %ymm10,%ymm3,%ymm7
  .byte  196,227,101,74,247,96               // vblendvps     %ymm6,%ymm7,%ymm3,%ymm6
  .byte  196,193,100,194,253,1               // vcmpltps      %ymm13,%ymm3,%ymm7
  .byte  197,44,88,211                       // vaddps        %ymm3,%ymm10,%ymm10
  .byte  196,195,77,74,242,112               // vblendvps     %ymm7,%ymm10,%ymm6,%ymm6
  .byte  197,204,194,248,1                   // vcmpltps      %ymm0,%ymm6,%ymm7
  .byte  197,252,92,198                      // vsubps        %ymm6,%ymm0,%ymm0
  .byte  197,140,89,192                      // vmulps        %ymm0,%ymm14,%ymm0
  .byte  197,164,88,192                      // vaddps        %ymm0,%ymm11,%ymm0
  .byte  196,227,37,74,192,112               // vblendvps     %ymm7,%ymm0,%ymm11,%ymm0
  .byte  196,193,76,194,248,1                // vcmpltps      %ymm8,%ymm6,%ymm7
  .byte  196,195,125,74,193,112              // vblendvps     %ymm7,%ymm9,%ymm0,%ymm0
  .byte  197,204,194,210,1                   // vcmpltps      %ymm2,%ymm6,%ymm2
  .byte  196,193,100,89,222                  // vmulps        %ymm14,%ymm3,%ymm3
  .byte  197,164,88,219                      // vaddps        %ymm3,%ymm11,%ymm3
  .byte  196,227,125,74,211,32               // vblendvps     %ymm2,%ymm3,%ymm0,%ymm2
  .byte  197,252,87,192                      // vxorps        %ymm0,%ymm0,%ymm0
  .byte  197,212,194,216,0                   // vcmpeqps      %ymm0,%ymm5,%ymm3
  .byte  196,227,5,74,196,48                 // vblendvps     %ymm3,%ymm4,%ymm15,%ymm0
  .byte  196,227,117,74,204,48               // vblendvps     %ymm3,%ymm4,%ymm1,%ymm1
  .byte  196,227,109,74,212,48               // vblendvps     %ymm3,%ymm4,%ymm2,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,16,92,36,128                // vmovups       -0x80(%rsp),%ymm3
  .byte  197,252,16,100,36,160               // vmovups       -0x60(%rsp),%ymm4
  .byte  197,252,16,108,36,192               // vmovups       -0x40(%rsp),%ymm5
  .byte  197,252,16,116,36,224               // vmovups       -0x20(%rsp),%ymm6
  .byte  197,252,16,60,36                    // vmovups       (%rsp),%ymm7
  .byte  72,131,196,56                       // add           $0x38,%rsp
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_scale_1_float_avx
.globl _sk_scale_1_float_avx
FUNCTION(_sk_scale_1_float_avx)
_sk_scale_1_float_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,0                     // vbroadcastss  (%rax),%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_scale_u8_avx
.globl _sk_scale_u8_avx
FUNCTION(_sk_scale_u8_avx)
_sk_scale_u8_avx:
  .byte  73,137,200                          // mov           %rcx,%r8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,1,248                            // add           %rdi,%rax
  .byte  77,133,192                          // test          %r8,%r8
  .byte  117,80                              // jne           12e6 <_sk_scale_u8_avx+0x60>
  .byte  197,122,126,0                       // vmovq         (%rax),%xmm8
  .byte  196,66,121,49,200                   // vpmovzxbd     %xmm8,%xmm9
  .byte  196,67,121,4,192,229                // vpermilps     $0xe5,%xmm8,%xmm8
  .byte  196,66,121,49,192                   // vpmovzxbd     %xmm8,%xmm8
  .byte  196,67,53,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm9,%ymm8
  .byte  196,65,124,91,192                   // vcvtdq2ps     %ymm8,%ymm8
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,121,110,200                     // vmovd         %eax,%xmm9
  .byte  196,67,121,4,201,0                  // vpermilps     $0x0,%xmm9,%xmm9
  .byte  196,67,53,24,201,1                  // vinsertf128   $0x1,%xmm9,%ymm9,%ymm9
  .byte  196,65,60,89,193                    // vmulps        %ymm9,%ymm8,%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,137,193                          // mov           %r8,%rcx
  .byte  255,224                             // jmpq          *%rax
  .byte  49,201                              // xor           %ecx,%ecx
  .byte  77,137,194                          // mov           %r8,%r10
  .byte  69,49,201                           // xor           %r9d,%r9d
  .byte  68,15,182,24                        // movzbl        (%rax),%r11d
  .byte  72,255,192                          // inc           %rax
  .byte  73,211,227                          // shl           %cl,%r11
  .byte  77,9,217                            // or            %r11,%r9
  .byte  72,131,193,8                        // add           $0x8,%rcx
  .byte  73,255,202                          // dec           %r10
  .byte  117,234                             // jne           12ee <_sk_scale_u8_avx+0x68>
  .byte  196,65,249,110,193                  // vmovq         %r9,%xmm8
  .byte  235,143                             // jmp           129a <_sk_scale_u8_avx+0x14>

HIDDEN _sk_lerp_1_float_avx
.globl _sk_lerp_1_float_avx
FUNCTION(_sk_lerp_1_float_avx)
_sk_lerp_1_float_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,0                     // vbroadcastss  (%rax),%ymm8
  .byte  197,252,92,196                      // vsubps        %ymm4,%ymm0,%ymm0
  .byte  196,193,124,89,192                  // vmulps        %ymm8,%ymm0,%ymm0
  .byte  197,252,88,196                      // vaddps        %ymm4,%ymm0,%ymm0
  .byte  197,244,92,205                      // vsubps        %ymm5,%ymm1,%ymm1
  .byte  196,193,116,89,200                  // vmulps        %ymm8,%ymm1,%ymm1
  .byte  197,244,88,205                      // vaddps        %ymm5,%ymm1,%ymm1
  .byte  197,236,92,214                      // vsubps        %ymm6,%ymm2,%ymm2
  .byte  196,193,108,89,208                  // vmulps        %ymm8,%ymm2,%ymm2
  .byte  197,236,88,214                      // vaddps        %ymm6,%ymm2,%ymm2
  .byte  197,228,92,223                      // vsubps        %ymm7,%ymm3,%ymm3
  .byte  196,193,100,89,216                  // vmulps        %ymm8,%ymm3,%ymm3
  .byte  197,228,88,223                      // vaddps        %ymm7,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_lerp_u8_avx
.globl _sk_lerp_u8_avx
FUNCTION(_sk_lerp_u8_avx)
_sk_lerp_u8_avx:
  .byte  73,137,200                          // mov           %rcx,%r8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,1,248                            // add           %rdi,%rax
  .byte  77,133,192                          // test          %r8,%r8
  .byte  117,116                             // jne           13ce <_sk_lerp_u8_avx+0x84>
  .byte  197,122,126,0                       // vmovq         (%rax),%xmm8
  .byte  196,66,121,49,200                   // vpmovzxbd     %xmm8,%xmm9
  .byte  196,67,121,4,192,229                // vpermilps     $0xe5,%xmm8,%xmm8
  .byte  196,66,121,49,192                   // vpmovzxbd     %xmm8,%xmm8
  .byte  196,67,53,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm9,%ymm8
  .byte  196,65,124,91,192                   // vcvtdq2ps     %ymm8,%ymm8
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,121,110,200                     // vmovd         %eax,%xmm9
  .byte  196,67,121,4,201,0                  // vpermilps     $0x0,%xmm9,%xmm9
  .byte  196,67,53,24,201,1                  // vinsertf128   $0x1,%xmm9,%ymm9,%ymm9
  .byte  196,65,60,89,193                    // vmulps        %ymm9,%ymm8,%ymm8
  .byte  197,252,92,196                      // vsubps        %ymm4,%ymm0,%ymm0
  .byte  196,193,124,89,192                  // vmulps        %ymm8,%ymm0,%ymm0
  .byte  197,252,88,196                      // vaddps        %ymm4,%ymm0,%ymm0
  .byte  197,244,92,205                      // vsubps        %ymm5,%ymm1,%ymm1
  .byte  196,193,116,89,200                  // vmulps        %ymm8,%ymm1,%ymm1
  .byte  197,244,88,205                      // vaddps        %ymm5,%ymm1,%ymm1
  .byte  197,236,92,214                      // vsubps        %ymm6,%ymm2,%ymm2
  .byte  196,193,108,89,208                  // vmulps        %ymm8,%ymm2,%ymm2
  .byte  197,236,88,214                      // vaddps        %ymm6,%ymm2,%ymm2
  .byte  197,228,92,223                      // vsubps        %ymm7,%ymm3,%ymm3
  .byte  196,193,100,89,216                  // vmulps        %ymm8,%ymm3,%ymm3
  .byte  197,228,88,223                      // vaddps        %ymm7,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,137,193                          // mov           %r8,%rcx
  .byte  255,224                             // jmpq          *%rax
  .byte  49,201                              // xor           %ecx,%ecx
  .byte  77,137,194                          // mov           %r8,%r10
  .byte  69,49,201                           // xor           %r9d,%r9d
  .byte  68,15,182,24                        // movzbl        (%rax),%r11d
  .byte  72,255,192                          // inc           %rax
  .byte  73,211,227                          // shl           %cl,%r11
  .byte  77,9,217                            // or            %r11,%r9
  .byte  72,131,193,8                        // add           $0x8,%rcx
  .byte  73,255,202                          // dec           %r10
  .byte  117,234                             // jne           13d6 <_sk_lerp_u8_avx+0x8c>
  .byte  196,65,249,110,193                  // vmovq         %r9,%xmm8
  .byte  233,104,255,255,255                 // jmpq          135e <_sk_lerp_u8_avx+0x14>

HIDDEN _sk_lerp_565_avx
.globl _sk_lerp_565_avx
FUNCTION(_sk_lerp_565_avx)
_sk_lerp_565_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,16                           // mov           (%rax),%r10
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  15,133,250,0,0,0                    // jne           14fe <_sk_lerp_565_avx+0x108>
  .byte  196,65,122,111,4,122                // vmovdqu       (%r10,%rdi,2),%xmm8
  .byte  197,225,239,219                     // vpxor         %xmm3,%xmm3,%xmm3
  .byte  197,185,105,219                     // vpunpckhwd    %xmm3,%xmm8,%xmm3
  .byte  196,66,121,51,192                   // vpmovzxwd     %xmm8,%xmm8
  .byte  196,99,61,24,195,1                  // vinsertf128   $0x1,%xmm3,%ymm8,%ymm8
  .byte  184,0,248,0,0                       // mov           $0xf800,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  197,249,112,219,0                   // vpshufd       $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  196,193,100,84,216                  // vandps        %ymm8,%ymm3,%ymm3
  .byte  197,124,91,203                      // vcvtdq2ps     %ymm3,%ymm9
  .byte  184,8,33,132,55                     // mov           $0x37842108,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  197,52,89,203                       // vmulps        %ymm3,%ymm9,%ymm9
  .byte  184,224,7,0,0                       // mov           $0x7e0,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  197,249,112,219,0                   // vpshufd       $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  196,193,100,84,216                  // vandps        %ymm8,%ymm3,%ymm3
  .byte  197,124,91,211                      // vcvtdq2ps     %ymm3,%ymm10
  .byte  184,33,8,2,58                       // mov           $0x3a020821,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  197,44,89,211                       // vmulps        %ymm3,%ymm10,%ymm10
  .byte  184,31,0,0,0                        // mov           $0x1f,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  197,249,112,219,0                   // vpshufd       $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  196,193,100,84,216                  // vandps        %ymm8,%ymm3,%ymm3
  .byte  197,124,91,195                      // vcvtdq2ps     %ymm3,%ymm8
  .byte  184,8,33,4,61                       // mov           $0x3d042108,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  197,252,92,196                      // vsubps        %ymm4,%ymm0,%ymm0
  .byte  196,193,124,89,193                  // vmulps        %ymm9,%ymm0,%ymm0
  .byte  197,252,88,196                      // vaddps        %ymm4,%ymm0,%ymm0
  .byte  197,244,92,205                      // vsubps        %ymm5,%ymm1,%ymm1
  .byte  196,193,116,89,202                  // vmulps        %ymm10,%ymm1,%ymm1
  .byte  197,244,88,205                      // vaddps        %ymm5,%ymm1,%ymm1
  .byte  197,236,92,214                      // vsubps        %ymm6,%ymm2,%ymm2
  .byte  197,236,89,211                      // vmulps        %ymm3,%ymm2,%ymm2
  .byte  197,236,88,214                      // vaddps        %ymm6,%ymm2,%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  65,128,224,7                        // and           $0x7,%r8b
  .byte  196,65,57,239,192                   // vpxor         %xmm8,%xmm8,%xmm8
  .byte  65,254,200                          // dec           %r8b
  .byte  65,128,248,6                        // cmp           $0x6,%r8b
  .byte  15,135,243,254,255,255              // ja            140a <_sk_lerp_565_avx+0x14>
  .byte  69,15,182,192                       // movzbl        %r8b,%r8d
  .byte  76,141,13,74,0,0,0                  // lea           0x4a(%rip),%r9        # 156c <_sk_lerp_565_avx+0x176>
  .byte  75,99,4,129                         // movslq        (%r9,%r8,4),%rax
  .byte  76,1,200                            // add           %r9,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  197,225,239,219                     // vpxor         %xmm3,%xmm3,%xmm3
  .byte  196,65,97,196,68,122,12,6           // vpinsrw       $0x6,0xc(%r10,%rdi,2),%xmm3,%xmm8
  .byte  196,65,57,196,68,122,10,5           // vpinsrw       $0x5,0xa(%r10,%rdi,2),%xmm8,%xmm8
  .byte  196,65,57,196,68,122,8,4            // vpinsrw       $0x4,0x8(%r10,%rdi,2),%xmm8,%xmm8
  .byte  196,65,57,196,68,122,6,3            // vpinsrw       $0x3,0x6(%r10,%rdi,2),%xmm8,%xmm8
  .byte  196,65,57,196,68,122,4,2            // vpinsrw       $0x2,0x4(%r10,%rdi,2),%xmm8,%xmm8
  .byte  196,65,57,196,68,122,2,1            // vpinsrw       $0x1,0x2(%r10,%rdi,2),%xmm8,%xmm8
  .byte  196,65,57,196,4,122,0               // vpinsrw       $0x0,(%r10,%rdi,2),%xmm8,%xmm8
  .byte  233,159,254,255,255                 // jmpq          140a <_sk_lerp_565_avx+0x14>
  .byte  144                                 // nop
  .byte  243,255                             // repz          (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  235,255                             // jmp           1571 <_sk_lerp_565_avx+0x17b>
  .byte  255                                 // (bad)
  .byte  255,227                             // jmpq          *%rbx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  219,255                             // (bad)
  .byte  255                                 // (bad)
  .byte  255,211                             // callq         *%rbx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,203                             // dec           %ebx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  191                                 // .byte         0xbf
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_load_tables_avx
.globl _sk_load_tables_avx
FUNCTION(_sk_load_tables_avx)
_sk_load_tables_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  15,133,37,2,0,0                     // jne           17bb <_sk_load_tables_avx+0x233>
  .byte  196,65,124,16,4,184                 // vmovups       (%r8,%rdi,4),%ymm8
  .byte  85                                  // push          %rbp
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,85                               // push          %r13
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  197,124,40,13,50,71,0,0             // vmovaps       0x4732(%rip),%ymm9        # 5ce0 <_sk_callback_avx+0x232>
  .byte  196,193,60,84,193                   // vandps        %ymm9,%ymm8,%ymm0
  .byte  196,193,249,126,193                 // vmovq         %xmm0,%r9
  .byte  69,137,203                          // mov           %r9d,%r11d
  .byte  196,195,249,22,194,1                // vpextrq       $0x1,%xmm0,%r10
  .byte  69,137,214                          // mov           %r10d,%r14d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  73,193,233,32                       // shr           $0x20,%r9
  .byte  196,227,125,25,192,1                // vextractf128  $0x1,%ymm0,%xmm0
  .byte  196,193,249,126,196                 // vmovq         %xmm0,%r12
  .byte  69,137,231                          // mov           %r12d,%r15d
  .byte  196,227,249,22,195,1                // vpextrq       $0x1,%xmm0,%rbx
  .byte  65,137,221                          // mov           %ebx,%r13d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  73,193,236,32                       // shr           $0x20,%r12
  .byte  72,139,104,8                        // mov           0x8(%rax),%rbp
  .byte  76,139,64,16                        // mov           0x10(%rax),%r8
  .byte  196,161,122,16,68,189,0             // vmovss        0x0(%rbp,%r15,4),%xmm0
  .byte  196,163,121,33,68,165,0,16          // vinsertps     $0x10,0x0(%rbp,%r12,4),%xmm0,%xmm0
  .byte  196,163,121,33,68,173,0,32          // vinsertps     $0x20,0x0(%rbp,%r13,4),%xmm0,%xmm0
  .byte  196,227,121,33,68,157,0,48          // vinsertps     $0x30,0x0(%rbp,%rbx,4),%xmm0,%xmm0
  .byte  196,161,122,16,76,157,0             // vmovss        0x0(%rbp,%r11,4),%xmm1
  .byte  196,163,113,33,76,141,0,16          // vinsertps     $0x10,0x0(%rbp,%r9,4),%xmm1,%xmm1
  .byte  196,163,113,33,76,181,0,32          // vinsertps     $0x20,0x0(%rbp,%r14,4),%xmm1,%xmm1
  .byte  196,163,113,33,76,149,0,48          // vinsertps     $0x30,0x0(%rbp,%r10,4),%xmm1,%xmm1
  .byte  196,227,117,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm1,%ymm0
  .byte  196,193,113,114,208,8               // vpsrld        $0x8,%xmm8,%xmm1
  .byte  196,67,125,25,194,1                 // vextractf128  $0x1,%ymm8,%xmm10
  .byte  196,193,105,114,210,8               // vpsrld        $0x8,%xmm10,%xmm2
  .byte  196,227,117,24,202,1                // vinsertf128   $0x1,%xmm2,%ymm1,%ymm1
  .byte  196,193,116,84,201                  // vandps        %ymm9,%ymm1,%ymm1
  .byte  196,193,249,126,201                 // vmovq         %xmm1,%r9
  .byte  69,137,203                          // mov           %r9d,%r11d
  .byte  196,195,249,22,202,1                // vpextrq       $0x1,%xmm1,%r10
  .byte  69,137,214                          // mov           %r10d,%r14d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  73,193,233,32                       // shr           $0x20,%r9
  .byte  196,227,125,25,201,1                // vextractf128  $0x1,%ymm1,%xmm1
  .byte  196,225,249,126,205                 // vmovq         %xmm1,%rbp
  .byte  65,137,239                          // mov           %ebp,%r15d
  .byte  196,227,249,22,203,1                // vpextrq       $0x1,%xmm1,%rbx
  .byte  65,137,220                          // mov           %ebx,%r12d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  72,193,237,32                       // shr           $0x20,%rbp
  .byte  196,129,122,16,12,184               // vmovss        (%r8,%r15,4),%xmm1
  .byte  196,195,113,33,12,168,16            // vinsertps     $0x10,(%r8,%rbp,4),%xmm1,%xmm1
  .byte  196,129,122,16,20,160               // vmovss        (%r8,%r12,4),%xmm2
  .byte  196,227,113,33,202,32               // vinsertps     $0x20,%xmm2,%xmm1,%xmm1
  .byte  196,193,122,16,20,152               // vmovss        (%r8,%rbx,4),%xmm2
  .byte  196,227,113,33,202,48               // vinsertps     $0x30,%xmm2,%xmm1,%xmm1
  .byte  196,129,122,16,20,152               // vmovss        (%r8,%r11,4),%xmm2
  .byte  196,131,105,33,20,136,16            // vinsertps     $0x10,(%r8,%r9,4),%xmm2,%xmm2
  .byte  196,129,122,16,28,176               // vmovss        (%r8,%r14,4),%xmm3
  .byte  196,227,105,33,211,32               // vinsertps     $0x20,%xmm3,%xmm2,%xmm2
  .byte  196,129,122,16,28,144               // vmovss        (%r8,%r10,4),%xmm3
  .byte  196,227,105,33,211,48               // vinsertps     $0x30,%xmm3,%xmm2,%xmm2
  .byte  196,227,109,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm2,%ymm1
  .byte  72,139,64,24                        // mov           0x18(%rax),%rax
  .byte  196,193,105,114,208,16              // vpsrld        $0x10,%xmm8,%xmm2
  .byte  196,193,97,114,210,16               // vpsrld        $0x10,%xmm10,%xmm3
  .byte  196,227,109,24,211,1                // vinsertf128   $0x1,%xmm3,%ymm2,%ymm2
  .byte  196,193,108,84,209                  // vandps        %ymm9,%ymm2,%ymm2
  .byte  196,193,249,126,208                 // vmovq         %xmm2,%r8
  .byte  69,137,194                          // mov           %r8d,%r10d
  .byte  196,195,249,22,209,1                // vpextrq       $0x1,%xmm2,%r9
  .byte  69,137,203                          // mov           %r9d,%r11d
  .byte  73,193,233,32                       // shr           $0x20,%r9
  .byte  73,193,232,32                       // shr           $0x20,%r8
  .byte  196,227,125,25,210,1                // vextractf128  $0x1,%ymm2,%xmm2
  .byte  196,225,249,126,213                 // vmovq         %xmm2,%rbp
  .byte  65,137,238                          // mov           %ebp,%r14d
  .byte  196,227,249,22,211,1                // vpextrq       $0x1,%xmm2,%rbx
  .byte  65,137,223                          // mov           %ebx,%r15d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  72,193,237,32                       // shr           $0x20,%rbp
  .byte  196,161,122,16,20,176               // vmovss        (%rax,%r14,4),%xmm2
  .byte  196,227,105,33,20,168,16            // vinsertps     $0x10,(%rax,%rbp,4),%xmm2,%xmm2
  .byte  196,161,122,16,28,184               // vmovss        (%rax,%r15,4),%xmm3
  .byte  196,227,105,33,211,32               // vinsertps     $0x20,%xmm3,%xmm2,%xmm2
  .byte  197,250,16,28,152                   // vmovss        (%rax,%rbx,4),%xmm3
  .byte  196,99,105,33,203,48                // vinsertps     $0x30,%xmm3,%xmm2,%xmm9
  .byte  196,161,122,16,28,144               // vmovss        (%rax,%r10,4),%xmm3
  .byte  196,163,97,33,28,128,16             // vinsertps     $0x10,(%rax,%r8,4),%xmm3,%xmm3
  .byte  196,161,122,16,20,152               // vmovss        (%rax,%r11,4),%xmm2
  .byte  196,227,97,33,210,32                // vinsertps     $0x20,%xmm2,%xmm3,%xmm2
  .byte  196,161,122,16,28,136               // vmovss        (%rax,%r9,4),%xmm3
  .byte  196,227,105,33,211,48               // vinsertps     $0x30,%xmm3,%xmm2,%xmm2
  .byte  196,195,109,24,209,1                // vinsertf128   $0x1,%xmm9,%ymm2,%ymm2
  .byte  196,193,57,114,208,24               // vpsrld        $0x18,%xmm8,%xmm8
  .byte  196,193,97,114,210,24               // vpsrld        $0x18,%xmm10,%xmm3
  .byte  196,227,61,24,219,1                 // vinsertf128   $0x1,%xmm3,%ymm8,%ymm3
  .byte  197,124,91,195                      // vcvtdq2ps     %ymm3,%ymm8
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,93                               // pop           %r13
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  93                                  // pop           %rbp
  .byte  255,224                             // jmpq          *%rax
  .byte  65,137,201                          // mov           %ecx,%r9d
  .byte  65,128,225,7                        // and           $0x7,%r9b
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  65,254,201                          // dec           %r9b
  .byte  65,128,249,6                        // cmp           $0x6,%r9b
  .byte  15,135,200,253,255,255              // ja            159c <_sk_load_tables_avx+0x14>
  .byte  69,15,182,201                       // movzbl        %r9b,%r9d
  .byte  76,141,21,141,0,0,0                 // lea           0x8d(%rip),%r10        # 186c <_sk_load_tables_avx+0x2e4>
  .byte  79,99,12,138                        // movslq        (%r10,%r9,4),%r9
  .byte  77,1,209                            // add           %r10,%r9
  .byte  65,255,225                          // jmpq          *%r9
  .byte  196,193,121,110,68,184,24           // vmovd         0x18(%r8,%rdi,4),%xmm0
  .byte  197,249,112,192,68                  // vpshufd       $0x44,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  196,99,117,12,192,64                // vblendps      $0x40,%ymm0,%ymm1,%ymm8
  .byte  196,99,125,25,192,1                 // vextractf128  $0x1,%ymm8,%xmm0
  .byte  196,195,121,34,68,184,20,1          // vpinsrd       $0x1,0x14(%r8,%rdi,4),%xmm0,%xmm0
  .byte  196,99,61,24,192,1                  // vinsertf128   $0x1,%xmm0,%ymm8,%ymm8
  .byte  196,99,125,25,192,1                 // vextractf128  $0x1,%ymm8,%xmm0
  .byte  196,195,121,34,68,184,16,0          // vpinsrd       $0x0,0x10(%r8,%rdi,4),%xmm0,%xmm0
  .byte  196,99,61,24,192,1                  // vinsertf128   $0x1,%xmm0,%ymm8,%ymm8
  .byte  196,195,57,34,68,184,12,3           // vpinsrd       $0x3,0xc(%r8,%rdi,4),%xmm8,%xmm0
  .byte  196,99,61,12,192,15                 // vblendps      $0xf,%ymm0,%ymm8,%ymm8
  .byte  196,195,57,34,68,184,8,2            // vpinsrd       $0x2,0x8(%r8,%rdi,4),%xmm8,%xmm0
  .byte  196,99,61,12,192,15                 // vblendps      $0xf,%ymm0,%ymm8,%ymm8
  .byte  196,195,57,34,68,184,4,1            // vpinsrd       $0x1,0x4(%r8,%rdi,4),%xmm8,%xmm0
  .byte  196,99,61,12,192,15                 // vblendps      $0xf,%ymm0,%ymm8,%ymm8
  .byte  196,195,57,34,4,184,0               // vpinsrd       $0x0,(%r8,%rdi,4),%xmm8,%xmm0
  .byte  196,99,61,12,192,15                 // vblendps      $0xf,%ymm0,%ymm8,%ymm8
  .byte  233,51,253,255,255                  // jmpq          159c <_sk_load_tables_avx+0x14>
  .byte  15,31,0                             // nopl          (%rax)
  .byte  235,255                             // jmp           186d <_sk_load_tables_avx+0x2e5>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  221,255                             // (bad)
  .byte  255                                 // (bad)
  .byte  255,207                             // dec           %edi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,193                             // inc           %ecx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,173,255,255,255,153             // ljmp          *-0x66000001(%rbp)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  125,255                             // jge           1885 <_sk_load_tables_avx+0x2fd>
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_load_tables_u16_be_avx
.globl _sk_load_tables_u16_be_avx
FUNCTION(_sk_load_tables_u16_be_avx)
_sk_load_tables_u16_be_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  76,141,12,189,0,0,0,0               // lea           0x0(,%rdi,4),%r9
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  15,133,125,2,0,0                    // jne           1b1b <_sk_load_tables_u16_be_avx+0x293>
  .byte  196,1,121,16,4,72                   // vmovupd       (%r8,%r9,2),%xmm8
  .byte  196,129,121,16,84,72,16             // vmovupd       0x10(%r8,%r9,2),%xmm2
  .byte  196,129,121,16,92,72,32             // vmovupd       0x20(%r8,%r9,2),%xmm3
  .byte  196,1,122,111,76,72,48              // vmovdqu       0x30(%r8,%r9,2),%xmm9
  .byte  85                                  // push          %rbp
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,85                               // push          %r13
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  197,185,97,194                      // vpunpcklwd    %xmm2,%xmm8,%xmm0
  .byte  197,185,105,210                     // vpunpckhwd    %xmm2,%xmm8,%xmm2
  .byte  196,193,97,97,201                   // vpunpcklwd    %xmm9,%xmm3,%xmm1
  .byte  196,193,97,105,217                  // vpunpckhwd    %xmm9,%xmm3,%xmm3
  .byte  197,121,97,202                      // vpunpcklwd    %xmm2,%xmm0,%xmm9
  .byte  197,121,105,194                     // vpunpckhwd    %xmm2,%xmm0,%xmm8
  .byte  197,241,97,195                      // vpunpcklwd    %xmm3,%xmm1,%xmm0
  .byte  197,113,105,227                     // vpunpckhwd    %xmm3,%xmm1,%xmm12
  .byte  197,177,108,208                     // vpunpcklqdq   %xmm0,%xmm9,%xmm2
  .byte  197,177,109,200                     // vpunpckhqdq   %xmm0,%xmm9,%xmm1
  .byte  196,65,57,108,212                   // vpunpcklqdq   %xmm12,%xmm8,%xmm10
  .byte  197,121,111,29,102,68,0,0           // vmovdqa       0x4466(%rip),%xmm11        # 5d60 <_sk_callback_avx+0x2b2>
  .byte  196,193,105,219,195                 // vpand         %xmm11,%xmm2,%xmm0
  .byte  196,65,49,239,201                   // vpxor         %xmm9,%xmm9,%xmm9
  .byte  196,193,121,105,209                 // vpunpckhwd    %xmm9,%xmm0,%xmm2
  .byte  196,195,249,22,208,1                // vpextrq       $0x1,%xmm2,%r8
  .byte  69,137,193                          // mov           %r8d,%r9d
  .byte  77,137,194                          // mov           %r8,%r10
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  196,193,249,126,208                 // vmovq         %xmm2,%r8
  .byte  69,137,195                          // mov           %r8d,%r11d
  .byte  77,137,198                          // mov           %r8,%r14
  .byte  73,193,238,32                       // shr           $0x20,%r14
  .byte  196,226,121,51,192                  // vpmovzxwd     %xmm0,%xmm0
  .byte  196,225,249,126,195                 // vmovq         %xmm0,%rbx
  .byte  65,137,223                          // mov           %ebx,%r15d
  .byte  72,193,235,30                       // shr           $0x1e,%rbx
  .byte  196,195,249,22,196,1                // vpextrq       $0x1,%xmm0,%r12
  .byte  69,137,229                          // mov           %r12d,%r13d
  .byte  73,193,236,30                       // shr           $0x1e,%r12
  .byte  72,139,104,8                        // mov           0x8(%rax),%rbp
  .byte  76,139,64,16                        // mov           0x10(%rax),%r8
  .byte  196,161,122,16,68,157,0             // vmovss        0x0(%rbp,%r11,4),%xmm0
  .byte  196,163,121,33,68,181,0,16          // vinsertps     $0x10,0x0(%rbp,%r14,4),%xmm0,%xmm0
  .byte  196,161,122,16,84,141,0             // vmovss        0x0(%rbp,%r9,4),%xmm2
  .byte  196,227,121,33,194,32               // vinsertps     $0x20,%xmm2,%xmm0,%xmm0
  .byte  196,161,122,16,84,149,0             // vmovss        0x0(%rbp,%r10,4),%xmm2
  .byte  196,227,121,33,194,48               // vinsertps     $0x30,%xmm2,%xmm0,%xmm0
  .byte  196,161,122,16,84,189,0             // vmovss        0x0(%rbp,%r15,4),%xmm2
  .byte  196,227,105,33,84,29,0,16           // vinsertps     $0x10,0x0(%rbp,%rbx,1),%xmm2,%xmm2
  .byte  196,161,122,16,92,173,0             // vmovss        0x0(%rbp,%r13,4),%xmm3
  .byte  196,227,105,33,211,32               // vinsertps     $0x20,%xmm3,%xmm2,%xmm2
  .byte  196,161,122,16,92,37,0              // vmovss        0x0(%rbp,%r12,1),%xmm3
  .byte  196,227,105,33,211,48               // vinsertps     $0x30,%xmm3,%xmm2,%xmm2
  .byte  196,227,109,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm2,%ymm0
  .byte  196,193,113,219,203                 // vpand         %xmm11,%xmm1,%xmm1
  .byte  196,193,113,105,209                 // vpunpckhwd    %xmm9,%xmm1,%xmm2
  .byte  196,227,249,22,213,1                // vpextrq       $0x1,%xmm2,%rbp
  .byte  65,137,233                          // mov           %ebp,%r9d
  .byte  72,193,237,32                       // shr           $0x20,%rbp
  .byte  196,225,249,126,211                 // vmovq         %xmm2,%rbx
  .byte  65,137,218                          // mov           %ebx,%r10d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,226,121,51,201                  // vpmovzxwd     %xmm1,%xmm1
  .byte  196,193,249,126,203                 // vmovq         %xmm1,%r11
  .byte  69,137,222                          // mov           %r11d,%r14d
  .byte  73,193,235,30                       // shr           $0x1e,%r11
  .byte  196,195,249,22,207,1                // vpextrq       $0x1,%xmm1,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,30                       // shr           $0x1e,%r15
  .byte  196,129,122,16,12,144               // vmovss        (%r8,%r10,4),%xmm1
  .byte  196,195,113,33,12,152,16            // vinsertps     $0x10,(%r8,%rbx,4),%xmm1,%xmm1
  .byte  196,129,122,16,20,136               // vmovss        (%r8,%r9,4),%xmm2
  .byte  196,227,113,33,202,32               // vinsertps     $0x20,%xmm2,%xmm1,%xmm1
  .byte  196,193,122,16,20,168               // vmovss        (%r8,%rbp,4),%xmm2
  .byte  196,227,113,33,202,48               // vinsertps     $0x30,%xmm2,%xmm1,%xmm1
  .byte  196,129,122,16,20,176               // vmovss        (%r8,%r14,4),%xmm2
  .byte  196,131,105,33,20,24,16             // vinsertps     $0x10,(%r8,%r11,1),%xmm2,%xmm2
  .byte  196,129,122,16,28,160               // vmovss        (%r8,%r12,4),%xmm3
  .byte  196,227,105,33,211,32               // vinsertps     $0x20,%xmm3,%xmm2,%xmm2
  .byte  196,129,122,16,28,56                // vmovss        (%r8,%r15,1),%xmm3
  .byte  196,227,105,33,211,48               // vinsertps     $0x30,%xmm3,%xmm2,%xmm2
  .byte  196,227,109,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm2,%ymm1
  .byte  76,139,80,24                        // mov           0x18(%rax),%r10
  .byte  196,193,41,219,211                  // vpand         %xmm11,%xmm10,%xmm2
  .byte  196,193,105,105,217                 // vpunpckhwd    %xmm9,%xmm2,%xmm3
  .byte  196,227,249,22,221,1                // vpextrq       $0x1,%xmm3,%rbp
  .byte  65,137,232                          // mov           %ebp,%r8d
  .byte  72,193,237,32                       // shr           $0x20,%rbp
  .byte  196,225,249,126,219                 // vmovq         %xmm3,%rbx
  .byte  65,137,217                          // mov           %ebx,%r9d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,226,121,51,210                  // vpmovzxwd     %xmm2,%xmm2
  .byte  196,225,249,126,208                 // vmovq         %xmm2,%rax
  .byte  65,137,195                          // mov           %eax,%r11d
  .byte  72,193,232,30                       // shr           $0x1e,%rax
  .byte  196,195,249,22,214,1                // vpextrq       $0x1,%xmm2,%r14
  .byte  69,137,247                          // mov           %r14d,%r15d
  .byte  73,193,238,30                       // shr           $0x1e,%r14
  .byte  196,129,122,16,20,138               // vmovss        (%r10,%r9,4),%xmm2
  .byte  196,195,105,33,20,154,16            // vinsertps     $0x10,(%r10,%rbx,4),%xmm2,%xmm2
  .byte  196,129,122,16,28,130               // vmovss        (%r10,%r8,4),%xmm3
  .byte  196,227,105,33,211,32               // vinsertps     $0x20,%xmm3,%xmm2,%xmm2
  .byte  196,193,122,16,28,170               // vmovss        (%r10,%rbp,4),%xmm3
  .byte  196,99,105,33,211,48                // vinsertps     $0x30,%xmm3,%xmm2,%xmm10
  .byte  196,129,122,16,28,154               // vmovss        (%r10,%r11,4),%xmm3
  .byte  196,195,97,33,28,2,16               // vinsertps     $0x10,(%r10,%rax,1),%xmm3,%xmm3
  .byte  196,129,122,16,20,186               // vmovss        (%r10,%r15,4),%xmm2
  .byte  196,227,97,33,210,32                // vinsertps     $0x20,%xmm2,%xmm3,%xmm2
  .byte  196,129,122,16,28,50                // vmovss        (%r10,%r14,1),%xmm3
  .byte  196,227,105,33,211,48               // vinsertps     $0x30,%xmm3,%xmm2,%xmm2
  .byte  196,195,109,24,210,1                // vinsertf128   $0x1,%xmm10,%ymm2,%ymm2
  .byte  184,128,0,128,55                    // mov           $0x37800080,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,99,101,24,211,1                 // vinsertf128   $0x1,%xmm3,%ymm3,%ymm10
  .byte  196,193,57,109,220                  // vpunpckhqdq   %xmm12,%xmm8,%xmm3
  .byte  197,185,113,243,8                   // vpsllw        $0x8,%xmm3,%xmm8
  .byte  197,225,113,211,8                   // vpsrlw        $0x8,%xmm3,%xmm3
  .byte  197,185,235,219                     // vpor          %xmm3,%xmm8,%xmm3
  .byte  196,65,97,105,193                   // vpunpckhwd    %xmm9,%xmm3,%xmm8
  .byte  196,226,121,51,219                  // vpmovzxwd     %xmm3,%xmm3
  .byte  196,195,101,24,216,1                // vinsertf128   $0x1,%xmm8,%ymm3,%ymm3
  .byte  197,252,91,219                      // vcvtdq2ps     %ymm3,%ymm3
  .byte  196,193,100,89,218                  // vmulps        %ymm10,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,93                               // pop           %r13
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  93                                  // pop           %rbp
  .byte  255,224                             // jmpq          *%rax
  .byte  196,1,123,16,4,72                   // vmovsd        (%r8,%r9,2),%xmm8
  .byte  196,65,49,239,201                   // vpxor         %xmm9,%xmm9,%xmm9
  .byte  72,131,249,1                        // cmp           $0x1,%rcx
  .byte  116,85                              // je            1b81 <_sk_load_tables_u16_be_avx+0x2f9>
  .byte  196,1,57,22,68,72,8                 // vmovhpd       0x8(%r8,%r9,2),%xmm8,%xmm8
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  114,72                              // jb            1b81 <_sk_load_tables_u16_be_avx+0x2f9>
  .byte  196,129,123,16,84,72,16             // vmovsd        0x10(%r8,%r9,2),%xmm2
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  116,72                              // je            1b8e <_sk_load_tables_u16_be_avx+0x306>
  .byte  196,129,105,22,84,72,24             // vmovhpd       0x18(%r8,%r9,2),%xmm2,%xmm2
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  114,59                              // jb            1b8e <_sk_load_tables_u16_be_avx+0x306>
  .byte  196,129,123,16,92,72,32             // vmovsd        0x20(%r8,%r9,2),%xmm3
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  15,132,85,253,255,255               // je            18b9 <_sk_load_tables_u16_be_avx+0x31>
  .byte  196,129,97,22,92,72,40              // vmovhpd       0x28(%r8,%r9,2),%xmm3,%xmm3
  .byte  72,131,249,7                        // cmp           $0x7,%rcx
  .byte  15,130,68,253,255,255               // jb            18b9 <_sk_load_tables_u16_be_avx+0x31>
  .byte  196,1,122,126,76,72,48              // vmovq         0x30(%r8,%r9,2),%xmm9
  .byte  233,56,253,255,255                  // jmpq          18b9 <_sk_load_tables_u16_be_avx+0x31>
  .byte  197,225,87,219                      // vxorpd        %xmm3,%xmm3,%xmm3
  .byte  197,233,87,210                      // vxorpd        %xmm2,%xmm2,%xmm2
  .byte  233,43,253,255,255                  // jmpq          18b9 <_sk_load_tables_u16_be_avx+0x31>
  .byte  197,225,87,219                      // vxorpd        %xmm3,%xmm3,%xmm3
  .byte  233,34,253,255,255                  // jmpq          18b9 <_sk_load_tables_u16_be_avx+0x31>

HIDDEN _sk_load_tables_rgb_u16_be_avx
.globl _sk_load_tables_rgb_u16_be_avx
FUNCTION(_sk_load_tables_rgb_u16_be_avx)
_sk_load_tables_rgb_u16_be_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  76,141,12,127                       // lea           (%rdi,%rdi,2),%r9
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  15,133,105,2,0,0                    // jne           1e12 <_sk_load_tables_rgb_u16_be_avx+0x27b>
  .byte  196,129,122,111,4,72                // vmovdqu       (%r8,%r9,2),%xmm0
  .byte  196,129,122,111,84,72,12            // vmovdqu       0xc(%r8,%r9,2),%xmm2
  .byte  196,129,122,111,76,72,24            // vmovdqu       0x18(%r8,%r9,2),%xmm1
  .byte  196,129,122,111,92,72,32            // vmovdqu       0x20(%r8,%r9,2),%xmm3
  .byte  197,225,115,219,4                   // vpsrldq       $0x4,%xmm3,%xmm3
  .byte  197,185,115,216,6                   // vpsrldq       $0x6,%xmm0,%xmm8
  .byte  197,177,115,218,6                   // vpsrldq       $0x6,%xmm2,%xmm9
  .byte  197,161,115,217,6                   // vpsrldq       $0x6,%xmm1,%xmm11
  .byte  197,169,115,219,6                   // vpsrldq       $0x6,%xmm3,%xmm10
  .byte  85                                  // push          %rbp
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,85                               // push          %r13
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  197,249,97,194                      // vpunpcklwd    %xmm2,%xmm0,%xmm0
  .byte  196,193,57,97,209                   // vpunpcklwd    %xmm9,%xmm8,%xmm2
  .byte  197,241,97,203                      // vpunpcklwd    %xmm3,%xmm1,%xmm1
  .byte  196,193,33,97,218                   // vpunpcklwd    %xmm10,%xmm11,%xmm3
  .byte  197,121,97,194                      // vpunpcklwd    %xmm2,%xmm0,%xmm8
  .byte  197,249,105,194                     // vpunpckhwd    %xmm2,%xmm0,%xmm0
  .byte  197,241,97,211                      // vpunpcklwd    %xmm3,%xmm1,%xmm2
  .byte  197,241,105,219                     // vpunpckhwd    %xmm3,%xmm1,%xmm3
  .byte  197,185,108,202                     // vpunpcklqdq   %xmm2,%xmm8,%xmm1
  .byte  197,185,109,210                     // vpunpckhqdq   %xmm2,%xmm8,%xmm2
  .byte  197,121,108,195                     // vpunpcklqdq   %xmm3,%xmm0,%xmm8
  .byte  197,121,111,13,83,65,0,0            // vmovdqa       0x4153(%rip),%xmm9        # 5d70 <_sk_callback_avx+0x2c2>
  .byte  196,193,113,219,193                 // vpand         %xmm9,%xmm1,%xmm0
  .byte  196,65,41,239,210                   // vpxor         %xmm10,%xmm10,%xmm10
  .byte  196,193,121,105,202                 // vpunpckhwd    %xmm10,%xmm0,%xmm1
  .byte  196,195,249,22,200,1                // vpextrq       $0x1,%xmm1,%r8
  .byte  69,137,193                          // mov           %r8d,%r9d
  .byte  77,137,194                          // mov           %r8,%r10
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  196,193,249,126,200                 // vmovq         %xmm1,%r8
  .byte  69,137,195                          // mov           %r8d,%r11d
  .byte  77,137,198                          // mov           %r8,%r14
  .byte  73,193,238,32                       // shr           $0x20,%r14
  .byte  196,226,121,51,192                  // vpmovzxwd     %xmm0,%xmm0
  .byte  196,225,249,126,195                 // vmovq         %xmm0,%rbx
  .byte  65,137,223                          // mov           %ebx,%r15d
  .byte  72,193,235,30                       // shr           $0x1e,%rbx
  .byte  196,195,249,22,196,1                // vpextrq       $0x1,%xmm0,%r12
  .byte  69,137,229                          // mov           %r12d,%r13d
  .byte  73,193,236,30                       // shr           $0x1e,%r12
  .byte  72,139,104,8                        // mov           0x8(%rax),%rbp
  .byte  76,139,64,16                        // mov           0x10(%rax),%r8
  .byte  196,161,122,16,68,157,0             // vmovss        0x0(%rbp,%r11,4),%xmm0
  .byte  196,163,121,33,68,181,0,16          // vinsertps     $0x10,0x0(%rbp,%r14,4),%xmm0,%xmm0
  .byte  196,161,122,16,76,141,0             // vmovss        0x0(%rbp,%r9,4),%xmm1
  .byte  196,227,121,33,193,32               // vinsertps     $0x20,%xmm1,%xmm0,%xmm0
  .byte  196,161,122,16,76,149,0             // vmovss        0x0(%rbp,%r10,4),%xmm1
  .byte  196,227,121,33,193,48               // vinsertps     $0x30,%xmm1,%xmm0,%xmm0
  .byte  196,161,122,16,76,189,0             // vmovss        0x0(%rbp,%r15,4),%xmm1
  .byte  196,227,113,33,76,29,0,16           // vinsertps     $0x10,0x0(%rbp,%rbx,1),%xmm1,%xmm1
  .byte  196,161,122,16,92,173,0             // vmovss        0x0(%rbp,%r13,4),%xmm3
  .byte  196,227,113,33,203,32               // vinsertps     $0x20,%xmm3,%xmm1,%xmm1
  .byte  196,161,122,16,92,37,0              // vmovss        0x0(%rbp,%r12,1),%xmm3
  .byte  196,227,113,33,203,48               // vinsertps     $0x30,%xmm3,%xmm1,%xmm1
  .byte  196,227,117,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm1,%ymm0
  .byte  196,193,105,219,201                 // vpand         %xmm9,%xmm2,%xmm1
  .byte  196,193,113,105,210                 // vpunpckhwd    %xmm10,%xmm1,%xmm2
  .byte  196,227,249,22,213,1                // vpextrq       $0x1,%xmm2,%rbp
  .byte  65,137,233                          // mov           %ebp,%r9d
  .byte  72,193,237,32                       // shr           $0x20,%rbp
  .byte  196,225,249,126,211                 // vmovq         %xmm2,%rbx
  .byte  65,137,218                          // mov           %ebx,%r10d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,226,121,51,201                  // vpmovzxwd     %xmm1,%xmm1
  .byte  196,193,249,126,203                 // vmovq         %xmm1,%r11
  .byte  69,137,222                          // mov           %r11d,%r14d
  .byte  73,193,235,30                       // shr           $0x1e,%r11
  .byte  196,195,249,22,207,1                // vpextrq       $0x1,%xmm1,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,30                       // shr           $0x1e,%r15
  .byte  196,129,122,16,12,144               // vmovss        (%r8,%r10,4),%xmm1
  .byte  196,195,113,33,12,152,16            // vinsertps     $0x10,(%r8,%rbx,4),%xmm1,%xmm1
  .byte  196,129,122,16,20,136               // vmovss        (%r8,%r9,4),%xmm2
  .byte  196,227,113,33,202,32               // vinsertps     $0x20,%xmm2,%xmm1,%xmm1
  .byte  196,193,122,16,20,168               // vmovss        (%r8,%rbp,4),%xmm2
  .byte  196,227,113,33,202,48               // vinsertps     $0x30,%xmm2,%xmm1,%xmm1
  .byte  196,129,122,16,20,176               // vmovss        (%r8,%r14,4),%xmm2
  .byte  196,131,105,33,20,24,16             // vinsertps     $0x10,(%r8,%r11,1),%xmm2,%xmm2
  .byte  196,129,122,16,28,160               // vmovss        (%r8,%r12,4),%xmm3
  .byte  196,227,105,33,211,32               // vinsertps     $0x20,%xmm3,%xmm2,%xmm2
  .byte  196,129,122,16,28,56                // vmovss        (%r8,%r15,1),%xmm3
  .byte  196,227,105,33,211,48               // vinsertps     $0x30,%xmm3,%xmm2,%xmm2
  .byte  196,227,109,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm2,%ymm1
  .byte  76,139,80,24                        // mov           0x18(%rax),%r10
  .byte  196,193,57,219,209                  // vpand         %xmm9,%xmm8,%xmm2
  .byte  196,193,105,105,218                 // vpunpckhwd    %xmm10,%xmm2,%xmm3
  .byte  196,227,249,22,221,1                // vpextrq       $0x1,%xmm3,%rbp
  .byte  65,137,232                          // mov           %ebp,%r8d
  .byte  72,193,237,32                       // shr           $0x20,%rbp
  .byte  196,225,249,126,219                 // vmovq         %xmm3,%rbx
  .byte  65,137,217                          // mov           %ebx,%r9d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,226,121,51,210                  // vpmovzxwd     %xmm2,%xmm2
  .byte  196,225,249,126,208                 // vmovq         %xmm2,%rax
  .byte  65,137,195                          // mov           %eax,%r11d
  .byte  72,193,232,30                       // shr           $0x1e,%rax
  .byte  196,195,249,22,214,1                // vpextrq       $0x1,%xmm2,%r14
  .byte  69,137,247                          // mov           %r14d,%r15d
  .byte  73,193,238,30                       // shr           $0x1e,%r14
  .byte  196,129,122,16,20,138               // vmovss        (%r10,%r9,4),%xmm2
  .byte  196,195,105,33,20,154,16            // vinsertps     $0x10,(%r10,%rbx,4),%xmm2,%xmm2
  .byte  196,129,122,16,28,130               // vmovss        (%r10,%r8,4),%xmm3
  .byte  196,227,105,33,211,32               // vinsertps     $0x20,%xmm3,%xmm2,%xmm2
  .byte  196,193,122,16,28,170               // vmovss        (%r10,%rbp,4),%xmm3
  .byte  196,99,105,33,195,48                // vinsertps     $0x30,%xmm3,%xmm2,%xmm8
  .byte  196,129,122,16,28,154               // vmovss        (%r10,%r11,4),%xmm3
  .byte  196,195,97,33,28,2,16               // vinsertps     $0x10,(%r10,%rax,1),%xmm3,%xmm3
  .byte  196,129,122,16,20,186               // vmovss        (%r10,%r15,4),%xmm2
  .byte  196,227,97,33,210,32                // vinsertps     $0x20,%xmm2,%xmm3,%xmm2
  .byte  196,129,122,16,28,50                // vmovss        (%r10,%r14,1),%xmm3
  .byte  196,227,105,33,211,48               // vinsertps     $0x30,%xmm3,%xmm2,%xmm2
  .byte  196,195,109,24,208,1                // vinsertf128   $0x1,%xmm8,%ymm2,%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,93                               // pop           %r13
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  93                                  // pop           %rbp
  .byte  255,224                             // jmpq          *%rax
  .byte  196,129,121,110,4,72                // vmovd         (%r8,%r9,2),%xmm0
  .byte  196,129,121,196,68,72,4,2           // vpinsrw       $0x2,0x4(%r8,%r9,2),%xmm0,%xmm0
  .byte  72,131,249,1                        // cmp           $0x1,%rcx
  .byte  117,5                               // jne           1e2b <_sk_load_tables_rgb_u16_be_avx+0x294>
  .byte  233,178,253,255,255                 // jmpq          1bdd <_sk_load_tables_rgb_u16_be_avx+0x46>
  .byte  196,129,121,110,76,72,6             // vmovd         0x6(%r8,%r9,2),%xmm1
  .byte  196,1,113,196,68,72,10,2            // vpinsrw       $0x2,0xa(%r8,%r9,2),%xmm1,%xmm8
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  114,26                              // jb            1e5a <_sk_load_tables_rgb_u16_be_avx+0x2c3>
  .byte  196,129,121,110,76,72,12            // vmovd         0xc(%r8,%r9,2),%xmm1
  .byte  196,129,113,196,84,72,16,2          // vpinsrw       $0x2,0x10(%r8,%r9,2),%xmm1,%xmm2
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  117,10                              // jne           1e5f <_sk_load_tables_rgb_u16_be_avx+0x2c8>
  .byte  233,131,253,255,255                 // jmpq          1bdd <_sk_load_tables_rgb_u16_be_avx+0x46>
  .byte  233,126,253,255,255                 // jmpq          1bdd <_sk_load_tables_rgb_u16_be_avx+0x46>
  .byte  196,129,121,110,76,72,18            // vmovd         0x12(%r8,%r9,2),%xmm1
  .byte  196,1,113,196,76,72,22,2            // vpinsrw       $0x2,0x16(%r8,%r9,2),%xmm1,%xmm9
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  114,26                              // jb            1e8e <_sk_load_tables_rgb_u16_be_avx+0x2f7>
  .byte  196,129,121,110,76,72,24            // vmovd         0x18(%r8,%r9,2),%xmm1
  .byte  196,129,113,196,76,72,28,2          // vpinsrw       $0x2,0x1c(%r8,%r9,2),%xmm1,%xmm1
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  117,10                              // jne           1e93 <_sk_load_tables_rgb_u16_be_avx+0x2fc>
  .byte  233,79,253,255,255                  // jmpq          1bdd <_sk_load_tables_rgb_u16_be_avx+0x46>
  .byte  233,74,253,255,255                  // jmpq          1bdd <_sk_load_tables_rgb_u16_be_avx+0x46>
  .byte  196,129,121,110,92,72,30            // vmovd         0x1e(%r8,%r9,2),%xmm3
  .byte  196,1,97,196,92,72,34,2             // vpinsrw       $0x2,0x22(%r8,%r9,2),%xmm3,%xmm11
  .byte  72,131,249,7                        // cmp           $0x7,%rcx
  .byte  114,20                              // jb            1ebc <_sk_load_tables_rgb_u16_be_avx+0x325>
  .byte  196,129,121,110,92,72,36            // vmovd         0x24(%r8,%r9,2),%xmm3
  .byte  196,129,97,196,92,72,40,2           // vpinsrw       $0x2,0x28(%r8,%r9,2),%xmm3,%xmm3
  .byte  233,33,253,255,255                  // jmpq          1bdd <_sk_load_tables_rgb_u16_be_avx+0x46>
  .byte  233,28,253,255,255                  // jmpq          1bdd <_sk_load_tables_rgb_u16_be_avx+0x46>

HIDDEN _sk_byte_tables_avx
.globl _sk_byte_tables_avx
FUNCTION(_sk_byte_tables_avx)
_sk_byte_tables_avx:
  .byte  85                                  // push          %rbp
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,85                               // push          %r13
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,127,67                   // mov           $0x437f0000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  197,253,91,192                      // vcvtps2dq     %ymm0,%ymm0
  .byte  196,195,249,22,192,1                // vpextrq       $0x1,%xmm0,%r8
  .byte  68,137,197                          // mov           %r8d,%ebp
  .byte  77,137,194                          // mov           %r8,%r10
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  196,193,249,126,192                 // vmovq         %xmm0,%r8
  .byte  69,137,195                          // mov           %r8d,%r11d
  .byte  77,137,199                          // mov           %r8,%r15
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  196,227,125,25,192,1                // vextractf128  $0x1,%ymm0,%xmm0
  .byte  196,195,249,22,192,1                // vpextrq       $0x1,%xmm0,%r8
  .byte  69,137,198                          // mov           %r8d,%r14d
  .byte  77,137,196                          // mov           %r8,%r12
  .byte  73,193,236,32                       // shr           $0x20,%r12
  .byte  196,225,249,126,195                 // vmovq         %xmm0,%rbx
  .byte  65,137,221                          // mov           %ebx,%r13d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  76,139,64,8                         // mov           0x8(%rax),%r8
  .byte  196,131,121,32,4,25,0               // vpinsrb       $0x0,(%r9,%r11,1),%xmm0,%xmm0
  .byte  196,131,121,32,4,57,1               // vpinsrb       $0x1,(%r9,%r15,1),%xmm0,%xmm0
  .byte  65,15,182,44,41                     // movzbl        (%r9,%rbp,1),%ebp
  .byte  196,227,121,32,197,2                // vpinsrb       $0x2,%ebp,%xmm0,%xmm0
  .byte  67,15,182,44,17                     // movzbl        (%r9,%r10,1),%ebp
  .byte  196,227,121,32,197,3                // vpinsrb       $0x3,%ebp,%xmm0,%xmm0
  .byte  196,98,121,49,200                   // vpmovzxbd     %xmm0,%xmm9
  .byte  196,131,121,32,4,41,0               // vpinsrb       $0x0,(%r9,%r13,1),%xmm0,%xmm0
  .byte  196,195,121,32,4,25,1               // vpinsrb       $0x1,(%r9,%rbx,1),%xmm0,%xmm0
  .byte  67,15,182,44,49                     // movzbl        (%r9,%r14,1),%ebp
  .byte  196,227,121,32,197,2                // vpinsrb       $0x2,%ebp,%xmm0,%xmm0
  .byte  67,15,182,44,33                     // movzbl        (%r9,%r12,1),%ebp
  .byte  196,227,121,32,197,3                // vpinsrb       $0x3,%ebp,%xmm0,%xmm0
  .byte  196,226,121,49,192                  // vpmovzxbd     %xmm0,%xmm0
  .byte  196,227,53,24,192,1                 // vinsertf128   $0x1,%xmm0,%ymm9,%ymm0
  .byte  197,124,91,208                      // vcvtdq2ps     %ymm0,%ymm10
  .byte  189,129,128,128,59                  // mov           $0x3b808081,%ebp
  .byte  197,249,110,197                     // vmovd         %ebp,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,99,125,24,200,1                 // vinsertf128   $0x1,%xmm0,%ymm0,%ymm9
  .byte  196,193,44,89,193                   // vmulps        %ymm9,%ymm10,%ymm0
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  197,253,91,201                      // vcvtps2dq     %ymm1,%ymm1
  .byte  196,227,249,22,205,1                // vpextrq       $0x1,%xmm1,%rbp
  .byte  65,137,233                          // mov           %ebp,%r9d
  .byte  72,193,237,32                       // shr           $0x20,%rbp
  .byte  196,225,249,126,203                 // vmovq         %xmm1,%rbx
  .byte  65,137,218                          // mov           %ebx,%r10d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,227,125,25,201,1                // vextractf128  $0x1,%ymm1,%xmm1
  .byte  196,195,249,22,203,1                // vpextrq       $0x1,%xmm1,%r11
  .byte  69,137,222                          // mov           %r11d,%r14d
  .byte  73,193,235,32                       // shr           $0x20,%r11
  .byte  196,193,249,126,207                 // vmovq         %xmm1,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  196,131,121,32,12,16,0              // vpinsrb       $0x0,(%r8,%r10,1),%xmm0,%xmm1
  .byte  196,195,113,32,12,24,1              // vpinsrb       $0x1,(%r8,%rbx,1),%xmm1,%xmm1
  .byte  67,15,182,28,8                      // movzbl        (%r8,%r9,1),%ebx
  .byte  196,227,113,32,203,2                // vpinsrb       $0x2,%ebx,%xmm1,%xmm1
  .byte  65,15,182,44,40                     // movzbl        (%r8,%rbp,1),%ebp
  .byte  196,227,113,32,205,3                // vpinsrb       $0x3,%ebp,%xmm1,%xmm1
  .byte  196,98,121,49,209                   // vpmovzxbd     %xmm1,%xmm10
  .byte  196,131,121,32,12,32,0              // vpinsrb       $0x0,(%r8,%r12,1),%xmm0,%xmm1
  .byte  196,131,113,32,12,56,1              // vpinsrb       $0x1,(%r8,%r15,1),%xmm1,%xmm1
  .byte  67,15,182,44,48                     // movzbl        (%r8,%r14,1),%ebp
  .byte  196,227,113,32,205,2                // vpinsrb       $0x2,%ebp,%xmm1,%xmm1
  .byte  67,15,182,44,24                     // movzbl        (%r8,%r11,1),%ebp
  .byte  196,227,113,32,205,3                // vpinsrb       $0x3,%ebp,%xmm1,%xmm1
  .byte  196,226,121,49,201                  // vpmovzxbd     %xmm1,%xmm1
  .byte  196,227,45,24,201,1                 // vinsertf128   $0x1,%xmm1,%ymm10,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  197,180,89,201                      // vmulps        %ymm1,%ymm9,%ymm1
  .byte  76,139,64,16                        // mov           0x10(%rax),%r8
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  197,253,91,210                      // vcvtps2dq     %ymm2,%ymm2
  .byte  196,227,249,22,213,1                // vpextrq       $0x1,%xmm2,%rbp
  .byte  65,137,233                          // mov           %ebp,%r9d
  .byte  72,193,237,32                       // shr           $0x20,%rbp
  .byte  196,225,249,126,211                 // vmovq         %xmm2,%rbx
  .byte  65,137,218                          // mov           %ebx,%r10d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,227,125,25,210,1                // vextractf128  $0x1,%ymm2,%xmm2
  .byte  196,195,249,22,211,1                // vpextrq       $0x1,%xmm2,%r11
  .byte  69,137,222                          // mov           %r11d,%r14d
  .byte  73,193,235,32                       // shr           $0x20,%r11
  .byte  196,193,249,126,215                 // vmovq         %xmm2,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  196,131,121,32,20,16,0              // vpinsrb       $0x0,(%r8,%r10,1),%xmm0,%xmm2
  .byte  196,195,105,32,20,24,1              // vpinsrb       $0x1,(%r8,%rbx,1),%xmm2,%xmm2
  .byte  67,15,182,28,8                      // movzbl        (%r8,%r9,1),%ebx
  .byte  196,227,105,32,211,2                // vpinsrb       $0x2,%ebx,%xmm2,%xmm2
  .byte  65,15,182,44,40                     // movzbl        (%r8,%rbp,1),%ebp
  .byte  196,227,105,32,213,3                // vpinsrb       $0x3,%ebp,%xmm2,%xmm2
  .byte  196,98,121,49,210                   // vpmovzxbd     %xmm2,%xmm10
  .byte  196,131,121,32,20,32,0              // vpinsrb       $0x0,(%r8,%r12,1),%xmm0,%xmm2
  .byte  196,131,105,32,20,56,1              // vpinsrb       $0x1,(%r8,%r15,1),%xmm2,%xmm2
  .byte  67,15,182,44,48                     // movzbl        (%r8,%r14,1),%ebp
  .byte  196,227,105,32,213,2                // vpinsrb       $0x2,%ebp,%xmm2,%xmm2
  .byte  67,15,182,44,24                     // movzbl        (%r8,%r11,1),%ebp
  .byte  196,227,105,32,213,3                // vpinsrb       $0x3,%ebp,%xmm2,%xmm2
  .byte  196,226,121,49,210                  // vpmovzxbd     %xmm2,%xmm2
  .byte  196,227,45,24,210,1                 // vinsertf128   $0x1,%xmm2,%ymm10,%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  197,180,89,210                      // vmulps        %ymm2,%ymm9,%ymm2
  .byte  72,139,64,24                        // mov           0x18(%rax),%rax
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  197,253,91,219                      // vcvtps2dq     %ymm3,%ymm3
  .byte  196,227,249,22,221,1                // vpextrq       $0x1,%xmm3,%rbp
  .byte  65,137,232                          // mov           %ebp,%r8d
  .byte  72,193,237,32                       // shr           $0x20,%rbp
  .byte  196,225,249,126,219                 // vmovq         %xmm3,%rbx
  .byte  65,137,217                          // mov           %ebx,%r9d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,227,125,25,219,1                // vextractf128  $0x1,%ymm3,%xmm3
  .byte  196,195,249,22,218,1                // vpextrq       $0x1,%xmm3,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  196,193,249,126,222                 // vmovq         %xmm3,%r14
  .byte  69,137,247                          // mov           %r14d,%r15d
  .byte  73,193,238,32                       // shr           $0x20,%r14
  .byte  196,163,121,32,28,8,0               // vpinsrb       $0x0,(%rax,%r9,1),%xmm0,%xmm3
  .byte  196,227,97,32,28,24,1               // vpinsrb       $0x1,(%rax,%rbx,1),%xmm3,%xmm3
  .byte  66,15,182,28,0                      // movzbl        (%rax,%r8,1),%ebx
  .byte  196,227,97,32,219,2                 // vpinsrb       $0x2,%ebx,%xmm3,%xmm3
  .byte  15,182,44,40                        // movzbl        (%rax,%rbp,1),%ebp
  .byte  196,227,97,32,221,3                 // vpinsrb       $0x3,%ebp,%xmm3,%xmm3
  .byte  196,98,121,49,195                   // vpmovzxbd     %xmm3,%xmm8
  .byte  196,163,121,32,28,56,0              // vpinsrb       $0x0,(%rax,%r15,1),%xmm0,%xmm3
  .byte  196,163,97,32,28,48,1               // vpinsrb       $0x1,(%rax,%r14,1),%xmm3,%xmm3
  .byte  66,15,182,44,24                     // movzbl        (%rax,%r11,1),%ebp
  .byte  196,227,97,32,221,2                 // vpinsrb       $0x2,%ebp,%xmm3,%xmm3
  .byte  66,15,182,4,16                      // movzbl        (%rax,%r10,1),%eax
  .byte  196,227,97,32,216,3                 // vpinsrb       $0x3,%eax,%xmm3,%xmm3
  .byte  196,226,121,49,219                  // vpmovzxbd     %xmm3,%xmm3
  .byte  196,227,61,24,219,1                 // vinsertf128   $0x1,%xmm3,%ymm8,%ymm3
  .byte  197,252,91,219                      // vcvtdq2ps     %ymm3,%ymm3
  .byte  197,180,89,219                      // vmulps        %ymm3,%ymm9,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,93                               // pop           %r13
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  93                                  // pop           %rbp
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_byte_tables_rgb_avx
.globl _sk_byte_tables_rgb_avx
FUNCTION(_sk_byte_tables_rgb_avx)
_sk_byte_tables_rgb_avx:
  .byte  85                                  // push          %rbp
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,85                               // push          %r13
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  68,139,64,24                        // mov           0x18(%rax),%r8d
  .byte  65,255,200                          // dec           %r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,65,121,112,192,0                // vpshufd       $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  196,65,124,91,192                   // vcvtdq2ps     %ymm8,%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  197,253,91,192                      // vcvtps2dq     %ymm0,%ymm0
  .byte  196,195,249,22,192,1                // vpextrq       $0x1,%xmm0,%r8
  .byte  68,137,197                          // mov           %r8d,%ebp
  .byte  77,137,194                          // mov           %r8,%r10
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  196,193,249,126,192                 // vmovq         %xmm0,%r8
  .byte  69,137,195                          // mov           %r8d,%r11d
  .byte  77,137,199                          // mov           %r8,%r15
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  196,227,125,25,192,1                // vextractf128  $0x1,%ymm0,%xmm0
  .byte  196,195,249,22,192,1                // vpextrq       $0x1,%xmm0,%r8
  .byte  69,137,198                          // mov           %r8d,%r14d
  .byte  77,137,196                          // mov           %r8,%r12
  .byte  73,193,236,32                       // shr           $0x20,%r12
  .byte  196,225,249,126,195                 // vmovq         %xmm0,%rbx
  .byte  65,137,221                          // mov           %ebx,%r13d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  76,139,64,8                         // mov           0x8(%rax),%r8
  .byte  196,131,121,32,4,25,0               // vpinsrb       $0x0,(%r9,%r11,1),%xmm0,%xmm0
  .byte  196,131,121,32,4,57,1               // vpinsrb       $0x1,(%r9,%r15,1),%xmm0,%xmm0
  .byte  65,15,182,44,41                     // movzbl        (%r9,%rbp,1),%ebp
  .byte  196,227,121,32,197,2                // vpinsrb       $0x2,%ebp,%xmm0,%xmm0
  .byte  67,15,182,44,17                     // movzbl        (%r9,%r10,1),%ebp
  .byte  196,227,121,32,197,3                // vpinsrb       $0x3,%ebp,%xmm0,%xmm0
  .byte  196,98,121,49,200                   // vpmovzxbd     %xmm0,%xmm9
  .byte  196,131,121,32,4,41,0               // vpinsrb       $0x0,(%r9,%r13,1),%xmm0,%xmm0
  .byte  196,195,121,32,4,25,1               // vpinsrb       $0x1,(%r9,%rbx,1),%xmm0,%xmm0
  .byte  67,15,182,44,49                     // movzbl        (%r9,%r14,1),%ebp
  .byte  196,227,121,32,197,2                // vpinsrb       $0x2,%ebp,%xmm0,%xmm0
  .byte  67,15,182,44,33                     // movzbl        (%r9,%r12,1),%ebp
  .byte  196,227,121,32,197,3                // vpinsrb       $0x3,%ebp,%xmm0,%xmm0
  .byte  196,226,121,49,192                  // vpmovzxbd     %xmm0,%xmm0
  .byte  196,227,53,24,192,1                 // vinsertf128   $0x1,%xmm0,%ymm9,%ymm0
  .byte  197,124,91,208                      // vcvtdq2ps     %ymm0,%ymm10
  .byte  189,129,128,128,59                  // mov           $0x3b808081,%ebp
  .byte  197,249,110,197                     // vmovd         %ebp,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,99,125,24,200,1                 // vinsertf128   $0x1,%xmm0,%ymm0,%ymm9
  .byte  196,193,44,89,193                   // vmulps        %ymm9,%ymm10,%ymm0
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  197,253,91,201                      // vcvtps2dq     %ymm1,%ymm1
  .byte  196,227,249,22,205,1                // vpextrq       $0x1,%xmm1,%rbp
  .byte  65,137,233                          // mov           %ebp,%r9d
  .byte  72,193,237,32                       // shr           $0x20,%rbp
  .byte  196,225,249,126,203                 // vmovq         %xmm1,%rbx
  .byte  65,137,218                          // mov           %ebx,%r10d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,227,125,25,201,1                // vextractf128  $0x1,%ymm1,%xmm1
  .byte  196,195,249,22,203,1                // vpextrq       $0x1,%xmm1,%r11
  .byte  69,137,222                          // mov           %r11d,%r14d
  .byte  73,193,235,32                       // shr           $0x20,%r11
  .byte  196,193,249,126,207                 // vmovq         %xmm1,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  196,131,121,32,12,16,0              // vpinsrb       $0x0,(%r8,%r10,1),%xmm0,%xmm1
  .byte  196,195,113,32,12,24,1              // vpinsrb       $0x1,(%r8,%rbx,1),%xmm1,%xmm1
  .byte  67,15,182,28,8                      // movzbl        (%r8,%r9,1),%ebx
  .byte  196,227,113,32,203,2                // vpinsrb       $0x2,%ebx,%xmm1,%xmm1
  .byte  65,15,182,44,40                     // movzbl        (%r8,%rbp,1),%ebp
  .byte  196,227,113,32,205,3                // vpinsrb       $0x3,%ebp,%xmm1,%xmm1
  .byte  196,98,121,49,209                   // vpmovzxbd     %xmm1,%xmm10
  .byte  196,131,121,32,12,32,0              // vpinsrb       $0x0,(%r8,%r12,1),%xmm0,%xmm1
  .byte  196,131,113,32,12,56,1              // vpinsrb       $0x1,(%r8,%r15,1),%xmm1,%xmm1
  .byte  67,15,182,44,48                     // movzbl        (%r8,%r14,1),%ebp
  .byte  196,227,113,32,205,2                // vpinsrb       $0x2,%ebp,%xmm1,%xmm1
  .byte  67,15,182,44,24                     // movzbl        (%r8,%r11,1),%ebp
  .byte  196,227,113,32,205,3                // vpinsrb       $0x3,%ebp,%xmm1,%xmm1
  .byte  196,226,121,49,201                  // vpmovzxbd     %xmm1,%xmm1
  .byte  196,227,45,24,201,1                 // vinsertf128   $0x1,%xmm1,%ymm10,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  197,180,89,201                      // vmulps        %ymm1,%ymm9,%ymm1
  .byte  72,139,64,16                        // mov           0x10(%rax),%rax
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  197,253,91,210                      // vcvtps2dq     %ymm2,%ymm2
  .byte  196,227,249,22,213,1                // vpextrq       $0x1,%xmm2,%rbp
  .byte  65,137,232                          // mov           %ebp,%r8d
  .byte  72,193,237,32                       // shr           $0x20,%rbp
  .byte  196,225,249,126,211                 // vmovq         %xmm2,%rbx
  .byte  65,137,217                          // mov           %ebx,%r9d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,227,125,25,210,1                // vextractf128  $0x1,%ymm2,%xmm2
  .byte  196,195,249,22,210,1                // vpextrq       $0x1,%xmm2,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  196,193,249,126,214                 // vmovq         %xmm2,%r14
  .byte  69,137,247                          // mov           %r14d,%r15d
  .byte  73,193,238,32                       // shr           $0x20,%r14
  .byte  196,163,121,32,20,8,0               // vpinsrb       $0x0,(%rax,%r9,1),%xmm0,%xmm2
  .byte  196,227,105,32,20,24,1              // vpinsrb       $0x1,(%rax,%rbx,1),%xmm2,%xmm2
  .byte  66,15,182,28,0                      // movzbl        (%rax,%r8,1),%ebx
  .byte  196,227,105,32,211,2                // vpinsrb       $0x2,%ebx,%xmm2,%xmm2
  .byte  15,182,44,40                        // movzbl        (%rax,%rbp,1),%ebp
  .byte  196,227,105,32,213,3                // vpinsrb       $0x3,%ebp,%xmm2,%xmm2
  .byte  196,98,121,49,194                   // vpmovzxbd     %xmm2,%xmm8
  .byte  196,163,121,32,20,56,0              // vpinsrb       $0x0,(%rax,%r15,1),%xmm0,%xmm2
  .byte  196,163,105,32,20,48,1              // vpinsrb       $0x1,(%rax,%r14,1),%xmm2,%xmm2
  .byte  66,15,182,44,24                     // movzbl        (%rax,%r11,1),%ebp
  .byte  196,227,105,32,213,2                // vpinsrb       $0x2,%ebp,%xmm2,%xmm2
  .byte  66,15,182,4,16                      // movzbl        (%rax,%r10,1),%eax
  .byte  196,227,105,32,208,3                // vpinsrb       $0x3,%eax,%xmm2,%xmm2
  .byte  196,226,121,49,210                  // vpmovzxbd     %xmm2,%xmm2
  .byte  196,227,61,24,210,1                 // vinsertf128   $0x1,%xmm2,%ymm8,%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  197,180,89,210                      // vmulps        %ymm2,%ymm9,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,93                               // pop           %r13
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  93                                  // pop           %rbp
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_table_r_avx
.globl _sk_table_r_avx
FUNCTION(_sk_table_r_avx)
_sk_table_r_avx:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  139,64,8                            // mov           0x8(%rax),%eax
  .byte  255,200                             // dec           %eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,65,121,112,192,0                // vpshufd       $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  196,65,124,91,192                   // vcvtdq2ps     %ymm8,%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  197,253,91,192                      // vcvtps2dq     %ymm0,%ymm0
  .byte  196,227,249,22,192,1                // vpextrq       $0x1,%xmm0,%rax
  .byte  65,137,193                          // mov           %eax,%r9d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  196,193,249,126,194                 // vmovq         %xmm0,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  196,227,125,25,192,1                // vextractf128  $0x1,%ymm0,%xmm0
  .byte  196,227,249,22,195,1                // vpextrq       $0x1,%xmm0,%rbx
  .byte  65,137,222                          // mov           %ebx,%r14d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,193,249,126,199                 // vmovq         %xmm0,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  196,129,122,16,4,160                // vmovss        (%r8,%r12,4),%xmm0
  .byte  196,3,121,33,4,184,16               // vinsertps     $0x10,(%r8,%r15,4),%xmm0,%xmm8
  .byte  196,129,122,16,4,176                // vmovss        (%r8,%r14,4),%xmm0
  .byte  196,99,57,33,192,32                 // vinsertps     $0x20,%xmm0,%xmm8,%xmm8
  .byte  196,193,122,16,4,152                // vmovss        (%r8,%rbx,4),%xmm0
  .byte  196,99,57,33,192,48                 // vinsertps     $0x30,%xmm0,%xmm8,%xmm8
  .byte  196,129,122,16,4,152                // vmovss        (%r8,%r11,4),%xmm0
  .byte  196,3,121,33,12,144,16              // vinsertps     $0x10,(%r8,%r10,4),%xmm0,%xmm9
  .byte  196,129,122,16,4,136                // vmovss        (%r8,%r9,4),%xmm0
  .byte  196,99,49,33,200,32                 // vinsertps     $0x20,%xmm0,%xmm9,%xmm9
  .byte  196,193,122,16,4,128                // vmovss        (%r8,%rax,4),%xmm0
  .byte  196,227,49,33,192,48                // vinsertps     $0x30,%xmm0,%xmm9,%xmm0
  .byte  196,195,125,24,192,1                // vinsertf128   $0x1,%xmm8,%ymm0,%ymm0
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_table_g_avx
.globl _sk_table_g_avx
FUNCTION(_sk_table_g_avx)
_sk_table_g_avx:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  139,64,8                            // mov           0x8(%rax),%eax
  .byte  255,200                             // dec           %eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,65,121,112,192,0                // vpshufd       $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  196,65,124,91,192                   // vcvtdq2ps     %ymm8,%ymm8
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  197,253,91,201                      // vcvtps2dq     %ymm1,%ymm1
  .byte  196,227,249,22,200,1                // vpextrq       $0x1,%xmm1,%rax
  .byte  65,137,193                          // mov           %eax,%r9d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  196,193,249,126,202                 // vmovq         %xmm1,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  196,227,125,25,201,1                // vextractf128  $0x1,%ymm1,%xmm1
  .byte  196,227,249,22,203,1                // vpextrq       $0x1,%xmm1,%rbx
  .byte  65,137,222                          // mov           %ebx,%r14d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,193,249,126,207                 // vmovq         %xmm1,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  196,129,122,16,12,160               // vmovss        (%r8,%r12,4),%xmm1
  .byte  196,3,113,33,4,184,16               // vinsertps     $0x10,(%r8,%r15,4),%xmm1,%xmm8
  .byte  196,129,122,16,12,176               // vmovss        (%r8,%r14,4),%xmm1
  .byte  196,99,57,33,193,32                 // vinsertps     $0x20,%xmm1,%xmm8,%xmm8
  .byte  196,193,122,16,12,152               // vmovss        (%r8,%rbx,4),%xmm1
  .byte  196,99,57,33,193,48                 // vinsertps     $0x30,%xmm1,%xmm8,%xmm8
  .byte  196,129,122,16,12,152               // vmovss        (%r8,%r11,4),%xmm1
  .byte  196,3,113,33,12,144,16              // vinsertps     $0x10,(%r8,%r10,4),%xmm1,%xmm9
  .byte  196,129,122,16,12,136               // vmovss        (%r8,%r9,4),%xmm1
  .byte  196,99,49,33,201,32                 // vinsertps     $0x20,%xmm1,%xmm9,%xmm9
  .byte  196,193,122,16,12,128               // vmovss        (%r8,%rax,4),%xmm1
  .byte  196,227,49,33,201,48                // vinsertps     $0x30,%xmm1,%xmm9,%xmm1
  .byte  196,195,117,24,200,1                // vinsertf128   $0x1,%xmm8,%ymm1,%ymm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_table_b_avx
.globl _sk_table_b_avx
FUNCTION(_sk_table_b_avx)
_sk_table_b_avx:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  139,64,8                            // mov           0x8(%rax),%eax
  .byte  255,200                             // dec           %eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,65,121,112,192,0                // vpshufd       $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  196,65,124,91,192                   // vcvtdq2ps     %ymm8,%ymm8
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  197,253,91,210                      // vcvtps2dq     %ymm2,%ymm2
  .byte  196,227,249,22,208,1                // vpextrq       $0x1,%xmm2,%rax
  .byte  65,137,193                          // mov           %eax,%r9d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  196,193,249,126,210                 // vmovq         %xmm2,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  196,227,125,25,210,1                // vextractf128  $0x1,%ymm2,%xmm2
  .byte  196,227,249,22,211,1                // vpextrq       $0x1,%xmm2,%rbx
  .byte  65,137,222                          // mov           %ebx,%r14d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,193,249,126,215                 // vmovq         %xmm2,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  196,129,122,16,20,160               // vmovss        (%r8,%r12,4),%xmm2
  .byte  196,3,105,33,4,184,16               // vinsertps     $0x10,(%r8,%r15,4),%xmm2,%xmm8
  .byte  196,129,122,16,20,176               // vmovss        (%r8,%r14,4),%xmm2
  .byte  196,99,57,33,194,32                 // vinsertps     $0x20,%xmm2,%xmm8,%xmm8
  .byte  196,193,122,16,20,152               // vmovss        (%r8,%rbx,4),%xmm2
  .byte  196,99,57,33,194,48                 // vinsertps     $0x30,%xmm2,%xmm8,%xmm8
  .byte  196,129,122,16,20,152               // vmovss        (%r8,%r11,4),%xmm2
  .byte  196,3,105,33,12,144,16              // vinsertps     $0x10,(%r8,%r10,4),%xmm2,%xmm9
  .byte  196,129,122,16,20,136               // vmovss        (%r8,%r9,4),%xmm2
  .byte  196,99,49,33,202,32                 // vinsertps     $0x20,%xmm2,%xmm9,%xmm9
  .byte  196,193,122,16,20,128               // vmovss        (%r8,%rax,4),%xmm2
  .byte  196,227,49,33,210,48                // vinsertps     $0x30,%xmm2,%xmm9,%xmm2
  .byte  196,195,109,24,208,1                // vinsertf128   $0x1,%xmm8,%ymm2,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_table_a_avx
.globl _sk_table_a_avx
FUNCTION(_sk_table_a_avx)
_sk_table_a_avx:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  139,64,8                            // mov           0x8(%rax),%eax
  .byte  255,200                             // dec           %eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,65,121,112,192,0                // vpshufd       $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  196,65,124,91,192                   // vcvtdq2ps     %ymm8,%ymm8
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  197,253,91,219                      // vcvtps2dq     %ymm3,%ymm3
  .byte  196,227,249,22,216,1                // vpextrq       $0x1,%xmm3,%rax
  .byte  65,137,193                          // mov           %eax,%r9d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  196,193,249,126,218                 // vmovq         %xmm3,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  196,227,125,25,219,1                // vextractf128  $0x1,%ymm3,%xmm3
  .byte  196,227,249,22,219,1                // vpextrq       $0x1,%xmm3,%rbx
  .byte  65,137,222                          // mov           %ebx,%r14d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,193,249,126,223                 // vmovq         %xmm3,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  196,129,122,16,28,160               // vmovss        (%r8,%r12,4),%xmm3
  .byte  196,3,97,33,4,184,16                // vinsertps     $0x10,(%r8,%r15,4),%xmm3,%xmm8
  .byte  196,129,122,16,28,176               // vmovss        (%r8,%r14,4),%xmm3
  .byte  196,99,57,33,195,32                 // vinsertps     $0x20,%xmm3,%xmm8,%xmm8
  .byte  196,193,122,16,28,152               // vmovss        (%r8,%rbx,4),%xmm3
  .byte  196,99,57,33,195,48                 // vinsertps     $0x30,%xmm3,%xmm8,%xmm8
  .byte  196,129,122,16,28,152               // vmovss        (%r8,%r11,4),%xmm3
  .byte  196,3,97,33,12,144,16               // vinsertps     $0x10,(%r8,%r10,4),%xmm3,%xmm9
  .byte  196,129,122,16,28,136               // vmovss        (%r8,%r9,4),%xmm3
  .byte  196,99,49,33,203,32                 // vinsertps     $0x20,%xmm3,%xmm9,%xmm9
  .byte  196,193,122,16,28,128               // vmovss        (%r8,%rax,4),%xmm3
  .byte  196,227,49,33,219,48                // vinsertps     $0x30,%xmm3,%xmm9,%xmm3
  .byte  196,195,101,24,216,1                // vinsertf128   $0x1,%xmm8,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_parametric_r_avx
.globl _sk_parametric_r_avx
FUNCTION(_sk_parametric_r_avx)
_sk_parametric_r_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,64,16                 // vbroadcastss  0x10(%rax),%ymm8
  .byte  196,65,124,194,192,2                // vcmpleps      %ymm8,%ymm0,%ymm8
  .byte  196,98,125,24,72,12                 // vbroadcastss  0xc(%rax),%ymm9
  .byte  196,98,125,24,80,24                 // vbroadcastss  0x18(%rax),%ymm10
  .byte  197,52,89,200                       // vmulps        %ymm0,%ymm9,%ymm9
  .byte  196,65,52,88,202                    // vaddps        %ymm10,%ymm9,%ymm9
  .byte  196,98,125,24,80,4                  // vbroadcastss  0x4(%rax),%ymm10
  .byte  196,98,125,24,88,8                  // vbroadcastss  0x8(%rax),%ymm11
  .byte  197,172,89,192                      // vmulps        %ymm0,%ymm10,%ymm0
  .byte  196,193,124,88,195                  // vaddps        %ymm11,%ymm0,%ymm0
  .byte  196,98,125,24,16                    // vbroadcastss  (%rax),%ymm10
  .byte  197,124,91,216                      // vcvtdq2ps     %ymm0,%ymm11
  .byte  196,98,125,24,37,175,52,0,0         // vbroadcastss  0x34af(%rip),%ymm12        # 5bdc <_sk_callback_avx+0x12e>
  .byte  196,65,36,89,220                    // vmulps        %ymm12,%ymm11,%ymm11
  .byte  196,98,125,24,37,165,52,0,0         // vbroadcastss  0x34a5(%rip),%ymm12        # 5be0 <_sk_callback_avx+0x132>
  .byte  196,193,124,84,196                  // vandps        %ymm12,%ymm0,%ymm0
  .byte  196,98,125,24,37,155,52,0,0         // vbroadcastss  0x349b(%rip),%ymm12        # 5be4 <_sk_callback_avx+0x136>
  .byte  196,193,124,86,196                  // vorps         %ymm12,%ymm0,%ymm0
  .byte  196,98,125,24,37,145,52,0,0         // vbroadcastss  0x3491(%rip),%ymm12        # 5be8 <_sk_callback_avx+0x13a>
  .byte  196,65,36,88,220                    // vaddps        %ymm12,%ymm11,%ymm11
  .byte  196,98,125,24,37,135,52,0,0         // vbroadcastss  0x3487(%rip),%ymm12        # 5bec <_sk_callback_avx+0x13e>
  .byte  196,65,124,89,228                   // vmulps        %ymm12,%ymm0,%ymm12
  .byte  196,65,36,92,220                    // vsubps        %ymm12,%ymm11,%ymm11
  .byte  196,98,125,24,37,120,52,0,0         // vbroadcastss  0x3478(%rip),%ymm12        # 5bf0 <_sk_callback_avx+0x142>
  .byte  196,193,124,88,196                  // vaddps        %ymm12,%ymm0,%ymm0
  .byte  196,98,125,24,37,110,52,0,0         // vbroadcastss  0x346e(%rip),%ymm12        # 5bf4 <_sk_callback_avx+0x146>
  .byte  197,156,94,192                      // vdivps        %ymm0,%ymm12,%ymm0
  .byte  197,164,92,192                      // vsubps        %ymm0,%ymm11,%ymm0
  .byte  197,172,89,192                      // vmulps        %ymm0,%ymm10,%ymm0
  .byte  196,99,125,8,208,1                  // vroundps      $0x1,%ymm0,%ymm10
  .byte  196,65,124,92,210                   // vsubps        %ymm10,%ymm0,%ymm10
  .byte  196,98,125,24,29,82,52,0,0          // vbroadcastss  0x3452(%rip),%ymm11        # 5bf8 <_sk_callback_avx+0x14a>
  .byte  196,193,124,88,195                  // vaddps        %ymm11,%ymm0,%ymm0
  .byte  196,98,125,24,29,72,52,0,0          // vbroadcastss  0x3448(%rip),%ymm11        # 5bfc <_sk_callback_avx+0x14e>
  .byte  196,65,44,89,219                    // vmulps        %ymm11,%ymm10,%ymm11
  .byte  196,193,124,92,195                  // vsubps        %ymm11,%ymm0,%ymm0
  .byte  196,98,125,24,29,57,52,0,0          // vbroadcastss  0x3439(%rip),%ymm11        # 5c00 <_sk_callback_avx+0x152>
  .byte  196,65,36,92,210                    // vsubps        %ymm10,%ymm11,%ymm10
  .byte  196,98,125,24,29,47,52,0,0          // vbroadcastss  0x342f(%rip),%ymm11        # 5c04 <_sk_callback_avx+0x156>
  .byte  196,65,36,94,210                    // vdivps        %ymm10,%ymm11,%ymm10
  .byte  196,193,124,88,194                  // vaddps        %ymm10,%ymm0,%ymm0
  .byte  196,98,125,24,21,32,52,0,0          // vbroadcastss  0x3420(%rip),%ymm10        # 5c08 <_sk_callback_avx+0x15a>
  .byte  196,193,124,89,194                  // vmulps        %ymm10,%ymm0,%ymm0
  .byte  197,253,91,192                      // vcvtps2dq     %ymm0,%ymm0
  .byte  196,98,125,24,80,20                 // vbroadcastss  0x14(%rax),%ymm10
  .byte  196,193,124,88,194                  // vaddps        %ymm10,%ymm0,%ymm0
  .byte  196,195,125,74,193,128              // vblendvps     %ymm8,%ymm9,%ymm0,%ymm0
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  196,65,124,95,192                   // vmaxps        %ymm8,%ymm0,%ymm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,188,93,192                      // vminps        %ymm0,%ymm8,%ymm0
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_parametric_g_avx
.globl _sk_parametric_g_avx
FUNCTION(_sk_parametric_g_avx)
_sk_parametric_g_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,64,16                 // vbroadcastss  0x10(%rax),%ymm8
  .byte  196,65,116,194,192,2                // vcmpleps      %ymm8,%ymm1,%ymm8
  .byte  196,98,125,24,72,12                 // vbroadcastss  0xc(%rax),%ymm9
  .byte  196,98,125,24,80,24                 // vbroadcastss  0x18(%rax),%ymm10
  .byte  197,52,89,201                       // vmulps        %ymm1,%ymm9,%ymm9
  .byte  196,65,52,88,202                    // vaddps        %ymm10,%ymm9,%ymm9
  .byte  196,98,125,24,80,4                  // vbroadcastss  0x4(%rax),%ymm10
  .byte  196,98,125,24,88,8                  // vbroadcastss  0x8(%rax),%ymm11
  .byte  197,172,89,201                      // vmulps        %ymm1,%ymm10,%ymm1
  .byte  196,193,116,88,203                  // vaddps        %ymm11,%ymm1,%ymm1
  .byte  196,98,125,24,16                    // vbroadcastss  (%rax),%ymm10
  .byte  197,124,91,217                      // vcvtdq2ps     %ymm1,%ymm11
  .byte  196,98,125,24,37,153,51,0,0         // vbroadcastss  0x3399(%rip),%ymm12        # 5c0c <_sk_callback_avx+0x15e>
  .byte  196,65,36,89,220                    // vmulps        %ymm12,%ymm11,%ymm11
  .byte  196,98,125,24,37,143,51,0,0         // vbroadcastss  0x338f(%rip),%ymm12        # 5c10 <_sk_callback_avx+0x162>
  .byte  196,193,116,84,204                  // vandps        %ymm12,%ymm1,%ymm1
  .byte  196,98,125,24,37,133,51,0,0         // vbroadcastss  0x3385(%rip),%ymm12        # 5c14 <_sk_callback_avx+0x166>
  .byte  196,193,116,86,204                  // vorps         %ymm12,%ymm1,%ymm1
  .byte  196,98,125,24,37,123,51,0,0         // vbroadcastss  0x337b(%rip),%ymm12        # 5c18 <_sk_callback_avx+0x16a>
  .byte  196,65,36,88,220                    // vaddps        %ymm12,%ymm11,%ymm11
  .byte  196,98,125,24,37,113,51,0,0         // vbroadcastss  0x3371(%rip),%ymm12        # 5c1c <_sk_callback_avx+0x16e>
  .byte  196,65,116,89,228                   // vmulps        %ymm12,%ymm1,%ymm12
  .byte  196,65,36,92,220                    // vsubps        %ymm12,%ymm11,%ymm11
  .byte  196,98,125,24,37,98,51,0,0          // vbroadcastss  0x3362(%rip),%ymm12        # 5c20 <_sk_callback_avx+0x172>
  .byte  196,193,116,88,204                  // vaddps        %ymm12,%ymm1,%ymm1
  .byte  196,98,125,24,37,88,51,0,0          // vbroadcastss  0x3358(%rip),%ymm12        # 5c24 <_sk_callback_avx+0x176>
  .byte  197,156,94,201                      // vdivps        %ymm1,%ymm12,%ymm1
  .byte  197,164,92,201                      // vsubps        %ymm1,%ymm11,%ymm1
  .byte  197,172,89,201                      // vmulps        %ymm1,%ymm10,%ymm1
  .byte  196,99,125,8,209,1                  // vroundps      $0x1,%ymm1,%ymm10
  .byte  196,65,116,92,210                   // vsubps        %ymm10,%ymm1,%ymm10
  .byte  196,98,125,24,29,60,51,0,0          // vbroadcastss  0x333c(%rip),%ymm11        # 5c28 <_sk_callback_avx+0x17a>
  .byte  196,193,116,88,203                  // vaddps        %ymm11,%ymm1,%ymm1
  .byte  196,98,125,24,29,50,51,0,0          // vbroadcastss  0x3332(%rip),%ymm11        # 5c2c <_sk_callback_avx+0x17e>
  .byte  196,65,44,89,219                    // vmulps        %ymm11,%ymm10,%ymm11
  .byte  196,193,116,92,203                  // vsubps        %ymm11,%ymm1,%ymm1
  .byte  196,98,125,24,29,35,51,0,0          // vbroadcastss  0x3323(%rip),%ymm11        # 5c30 <_sk_callback_avx+0x182>
  .byte  196,65,36,92,210                    // vsubps        %ymm10,%ymm11,%ymm10
  .byte  196,98,125,24,29,25,51,0,0          // vbroadcastss  0x3319(%rip),%ymm11        # 5c34 <_sk_callback_avx+0x186>
  .byte  196,65,36,94,210                    // vdivps        %ymm10,%ymm11,%ymm10
  .byte  196,193,116,88,202                  // vaddps        %ymm10,%ymm1,%ymm1
  .byte  196,98,125,24,21,10,51,0,0          // vbroadcastss  0x330a(%rip),%ymm10        # 5c38 <_sk_callback_avx+0x18a>
  .byte  196,193,116,89,202                  // vmulps        %ymm10,%ymm1,%ymm1
  .byte  197,253,91,201                      // vcvtps2dq     %ymm1,%ymm1
  .byte  196,98,125,24,80,20                 // vbroadcastss  0x14(%rax),%ymm10
  .byte  196,193,116,88,202                  // vaddps        %ymm10,%ymm1,%ymm1
  .byte  196,195,117,74,201,128              // vblendvps     %ymm8,%ymm9,%ymm1,%ymm1
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  196,65,116,95,192                   // vmaxps        %ymm8,%ymm1,%ymm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,188,93,201                      // vminps        %ymm1,%ymm8,%ymm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_parametric_b_avx
.globl _sk_parametric_b_avx
FUNCTION(_sk_parametric_b_avx)
_sk_parametric_b_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,64,16                 // vbroadcastss  0x10(%rax),%ymm8
  .byte  196,65,108,194,192,2                // vcmpleps      %ymm8,%ymm2,%ymm8
  .byte  196,98,125,24,72,12                 // vbroadcastss  0xc(%rax),%ymm9
  .byte  196,98,125,24,80,24                 // vbroadcastss  0x18(%rax),%ymm10
  .byte  197,52,89,202                       // vmulps        %ymm2,%ymm9,%ymm9
  .byte  196,65,52,88,202                    // vaddps        %ymm10,%ymm9,%ymm9
  .byte  196,98,125,24,80,4                  // vbroadcastss  0x4(%rax),%ymm10
  .byte  196,98,125,24,88,8                  // vbroadcastss  0x8(%rax),%ymm11
  .byte  197,172,89,210                      // vmulps        %ymm2,%ymm10,%ymm2
  .byte  196,193,108,88,211                  // vaddps        %ymm11,%ymm2,%ymm2
  .byte  196,98,125,24,16                    // vbroadcastss  (%rax),%ymm10
  .byte  197,124,91,218                      // vcvtdq2ps     %ymm2,%ymm11
  .byte  196,98,125,24,37,131,50,0,0         // vbroadcastss  0x3283(%rip),%ymm12        # 5c3c <_sk_callback_avx+0x18e>
  .byte  196,65,36,89,220                    // vmulps        %ymm12,%ymm11,%ymm11
  .byte  196,98,125,24,37,121,50,0,0         // vbroadcastss  0x3279(%rip),%ymm12        # 5c40 <_sk_callback_avx+0x192>
  .byte  196,193,108,84,212                  // vandps        %ymm12,%ymm2,%ymm2
  .byte  196,98,125,24,37,111,50,0,0         // vbroadcastss  0x326f(%rip),%ymm12        # 5c44 <_sk_callback_avx+0x196>
  .byte  196,193,108,86,212                  // vorps         %ymm12,%ymm2,%ymm2
  .byte  196,98,125,24,37,101,50,0,0         // vbroadcastss  0x3265(%rip),%ymm12        # 5c48 <_sk_callback_avx+0x19a>
  .byte  196,65,36,88,220                    // vaddps        %ymm12,%ymm11,%ymm11
  .byte  196,98,125,24,37,91,50,0,0          // vbroadcastss  0x325b(%rip),%ymm12        # 5c4c <_sk_callback_avx+0x19e>
  .byte  196,65,108,89,228                   // vmulps        %ymm12,%ymm2,%ymm12
  .byte  196,65,36,92,220                    // vsubps        %ymm12,%ymm11,%ymm11
  .byte  196,98,125,24,37,76,50,0,0          // vbroadcastss  0x324c(%rip),%ymm12        # 5c50 <_sk_callback_avx+0x1a2>
  .byte  196,193,108,88,212                  // vaddps        %ymm12,%ymm2,%ymm2
  .byte  196,98,125,24,37,66,50,0,0          // vbroadcastss  0x3242(%rip),%ymm12        # 5c54 <_sk_callback_avx+0x1a6>
  .byte  197,156,94,210                      // vdivps        %ymm2,%ymm12,%ymm2
  .byte  197,164,92,210                      // vsubps        %ymm2,%ymm11,%ymm2
  .byte  197,172,89,210                      // vmulps        %ymm2,%ymm10,%ymm2
  .byte  196,99,125,8,210,1                  // vroundps      $0x1,%ymm2,%ymm10
  .byte  196,65,108,92,210                   // vsubps        %ymm10,%ymm2,%ymm10
  .byte  196,98,125,24,29,38,50,0,0          // vbroadcastss  0x3226(%rip),%ymm11        # 5c58 <_sk_callback_avx+0x1aa>
  .byte  196,193,108,88,211                  // vaddps        %ymm11,%ymm2,%ymm2
  .byte  196,98,125,24,29,28,50,0,0          // vbroadcastss  0x321c(%rip),%ymm11        # 5c5c <_sk_callback_avx+0x1ae>
  .byte  196,65,44,89,219                    // vmulps        %ymm11,%ymm10,%ymm11
  .byte  196,193,108,92,211                  // vsubps        %ymm11,%ymm2,%ymm2
  .byte  196,98,125,24,29,13,50,0,0          // vbroadcastss  0x320d(%rip),%ymm11        # 5c60 <_sk_callback_avx+0x1b2>
  .byte  196,65,36,92,210                    // vsubps        %ymm10,%ymm11,%ymm10
  .byte  196,98,125,24,29,3,50,0,0           // vbroadcastss  0x3203(%rip),%ymm11        # 5c64 <_sk_callback_avx+0x1b6>
  .byte  196,65,36,94,210                    // vdivps        %ymm10,%ymm11,%ymm10
  .byte  196,193,108,88,210                  // vaddps        %ymm10,%ymm2,%ymm2
  .byte  196,98,125,24,21,244,49,0,0         // vbroadcastss  0x31f4(%rip),%ymm10        # 5c68 <_sk_callback_avx+0x1ba>
  .byte  196,193,108,89,210                  // vmulps        %ymm10,%ymm2,%ymm2
  .byte  197,253,91,210                      // vcvtps2dq     %ymm2,%ymm2
  .byte  196,98,125,24,80,20                 // vbroadcastss  0x14(%rax),%ymm10
  .byte  196,193,108,88,210                  // vaddps        %ymm10,%ymm2,%ymm2
  .byte  196,195,109,74,209,128              // vblendvps     %ymm8,%ymm9,%ymm2,%ymm2
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  196,65,108,95,192                   // vmaxps        %ymm8,%ymm2,%ymm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,227,121,4,210,0                 // vpermilps     $0x0,%xmm2,%xmm2
  .byte  196,227,109,24,210,1                // vinsertf128   $0x1,%xmm2,%ymm2,%ymm2
  .byte  197,188,93,210                      // vminps        %ymm2,%ymm8,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_parametric_a_avx
.globl _sk_parametric_a_avx
FUNCTION(_sk_parametric_a_avx)
_sk_parametric_a_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,64,16                 // vbroadcastss  0x10(%rax),%ymm8
  .byte  196,65,100,194,192,2                // vcmpleps      %ymm8,%ymm3,%ymm8
  .byte  196,98,125,24,72,12                 // vbroadcastss  0xc(%rax),%ymm9
  .byte  196,98,125,24,80,24                 // vbroadcastss  0x18(%rax),%ymm10
  .byte  197,52,89,203                       // vmulps        %ymm3,%ymm9,%ymm9
  .byte  196,65,52,88,202                    // vaddps        %ymm10,%ymm9,%ymm9
  .byte  196,98,125,24,80,4                  // vbroadcastss  0x4(%rax),%ymm10
  .byte  196,98,125,24,88,8                  // vbroadcastss  0x8(%rax),%ymm11
  .byte  197,172,89,219                      // vmulps        %ymm3,%ymm10,%ymm3
  .byte  196,193,100,88,219                  // vaddps        %ymm11,%ymm3,%ymm3
  .byte  196,98,125,24,16                    // vbroadcastss  (%rax),%ymm10
  .byte  197,124,91,219                      // vcvtdq2ps     %ymm3,%ymm11
  .byte  196,98,125,24,37,109,49,0,0         // vbroadcastss  0x316d(%rip),%ymm12        # 5c6c <_sk_callback_avx+0x1be>
  .byte  196,65,36,89,220                    // vmulps        %ymm12,%ymm11,%ymm11
  .byte  196,98,125,24,37,99,49,0,0          // vbroadcastss  0x3163(%rip),%ymm12        # 5c70 <_sk_callback_avx+0x1c2>
  .byte  196,193,100,84,220                  // vandps        %ymm12,%ymm3,%ymm3
  .byte  196,98,125,24,37,89,49,0,0          // vbroadcastss  0x3159(%rip),%ymm12        # 5c74 <_sk_callback_avx+0x1c6>
  .byte  196,193,100,86,220                  // vorps         %ymm12,%ymm3,%ymm3
  .byte  196,98,125,24,37,79,49,0,0          // vbroadcastss  0x314f(%rip),%ymm12        # 5c78 <_sk_callback_avx+0x1ca>
  .byte  196,65,36,88,220                    // vaddps        %ymm12,%ymm11,%ymm11
  .byte  196,98,125,24,37,69,49,0,0          // vbroadcastss  0x3145(%rip),%ymm12        # 5c7c <_sk_callback_avx+0x1ce>
  .byte  196,65,100,89,228                   // vmulps        %ymm12,%ymm3,%ymm12
  .byte  196,65,36,92,220                    // vsubps        %ymm12,%ymm11,%ymm11
  .byte  196,98,125,24,37,54,49,0,0          // vbroadcastss  0x3136(%rip),%ymm12        # 5c80 <_sk_callback_avx+0x1d2>
  .byte  196,193,100,88,220                  // vaddps        %ymm12,%ymm3,%ymm3
  .byte  196,98,125,24,37,44,49,0,0          // vbroadcastss  0x312c(%rip),%ymm12        # 5c84 <_sk_callback_avx+0x1d6>
  .byte  197,156,94,219                      // vdivps        %ymm3,%ymm12,%ymm3
  .byte  197,164,92,219                      // vsubps        %ymm3,%ymm11,%ymm3
  .byte  197,172,89,219                      // vmulps        %ymm3,%ymm10,%ymm3
  .byte  196,99,125,8,211,1                  // vroundps      $0x1,%ymm3,%ymm10
  .byte  196,65,100,92,210                   // vsubps        %ymm10,%ymm3,%ymm10
  .byte  196,98,125,24,29,16,49,0,0          // vbroadcastss  0x3110(%rip),%ymm11        # 5c88 <_sk_callback_avx+0x1da>
  .byte  196,193,100,88,219                  // vaddps        %ymm11,%ymm3,%ymm3
  .byte  196,98,125,24,29,6,49,0,0           // vbroadcastss  0x3106(%rip),%ymm11        # 5c8c <_sk_callback_avx+0x1de>
  .byte  196,65,44,89,219                    // vmulps        %ymm11,%ymm10,%ymm11
  .byte  196,193,100,92,219                  // vsubps        %ymm11,%ymm3,%ymm3
  .byte  196,98,125,24,29,247,48,0,0         // vbroadcastss  0x30f7(%rip),%ymm11        # 5c90 <_sk_callback_avx+0x1e2>
  .byte  196,65,36,92,210                    // vsubps        %ymm10,%ymm11,%ymm10
  .byte  196,98,125,24,29,237,48,0,0         // vbroadcastss  0x30ed(%rip),%ymm11        # 5c94 <_sk_callback_avx+0x1e6>
  .byte  196,65,36,94,210                    // vdivps        %ymm10,%ymm11,%ymm10
  .byte  196,193,100,88,218                  // vaddps        %ymm10,%ymm3,%ymm3
  .byte  196,98,125,24,21,222,48,0,0         // vbroadcastss  0x30de(%rip),%ymm10        # 5c98 <_sk_callback_avx+0x1ea>
  .byte  196,193,100,89,218                  // vmulps        %ymm10,%ymm3,%ymm3
  .byte  197,253,91,219                      // vcvtps2dq     %ymm3,%ymm3
  .byte  196,98,125,24,80,20                 // vbroadcastss  0x14(%rax),%ymm10
  .byte  196,193,100,88,218                  // vaddps        %ymm10,%ymm3,%ymm3
  .byte  196,195,101,74,217,128              // vblendvps     %ymm8,%ymm9,%ymm3,%ymm3
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  196,65,100,95,192                   // vmaxps        %ymm8,%ymm3,%ymm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  197,188,93,219                      // vminps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_lab_to_xyz_avx
.globl _sk_lab_to_xyz_avx
FUNCTION(_sk_lab_to_xyz_avx)
_sk_lab_to_xyz_avx:
  .byte  184,0,0,200,66                      // mov           $0x42c80000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,89,192                       // vmulps        %ymm0,%ymm8,%ymm8
  .byte  184,0,0,127,67                      // mov           $0x437f0000,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,124,89,201                      // vmulps        %ymm1,%ymm0,%ymm9
  .byte  184,0,0,0,67                        // mov           $0x43000000,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,52,92,201                       // vsubps        %ymm1,%ymm9,%ymm9
  .byte  197,252,89,194                      // vmulps        %ymm2,%ymm0,%ymm0
  .byte  197,124,92,209                      // vsubps        %ymm1,%ymm0,%ymm10
  .byte  184,0,0,128,65                      // mov           $0x41800000,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,188,88,192                      // vaddps        %ymm0,%ymm8,%ymm0
  .byte  184,203,61,13,60                    // mov           $0x3c0d3dcb,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,227,121,4,210,0                 // vpermilps     $0x0,%xmm2,%xmm2
  .byte  196,227,109,24,210,1                // vinsertf128   $0x1,%xmm2,%ymm2,%ymm2
  .byte  197,252,89,194                      // vmulps        %ymm2,%ymm0,%ymm0
  .byte  184,111,18,3,59                     // mov           $0x3b03126f,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,227,121,4,210,0                 // vpermilps     $0x0,%xmm2,%xmm2
  .byte  196,227,109,24,210,1                // vinsertf128   $0x1,%xmm2,%ymm2,%ymm2
  .byte  197,180,89,210                      // vmulps        %ymm2,%ymm9,%ymm2
  .byte  197,252,88,210                      // vaddps        %ymm2,%ymm0,%ymm2
  .byte  184,10,215,163,59                   // mov           $0x3ba3d70a,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,172,89,201                      // vmulps        %ymm1,%ymm10,%ymm1
  .byte  197,124,92,193                      // vsubps        %ymm1,%ymm0,%ymm8
  .byte  197,236,89,202                      // vmulps        %ymm2,%ymm2,%ymm1
  .byte  197,108,89,201                      // vmulps        %ymm1,%ymm2,%ymm9
  .byte  184,194,24,17,60                    // mov           $0x3c1118c2,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,99,117,24,209,1                 // vinsertf128   $0x1,%xmm1,%ymm1,%ymm10
  .byte  196,65,44,194,217,1                 // vcmpltps      %ymm9,%ymm10,%ymm11
  .byte  184,203,61,13,62                    // mov           $0x3e0d3dcb,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,99,117,24,225,1                 // vinsertf128   $0x1,%xmm1,%ymm1,%ymm12
  .byte  196,193,108,92,204                  // vsubps        %ymm12,%ymm2,%ymm1
  .byte  184,80,128,3,62                     // mov           $0x3e038050,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,227,121,4,210,0                 // vpermilps     $0x0,%xmm2,%xmm2
  .byte  196,227,109,24,210,1                // vinsertf128   $0x1,%xmm2,%ymm2,%ymm2
  .byte  197,244,89,202                      // vmulps        %ymm2,%ymm1,%ymm1
  .byte  196,67,117,74,201,176               // vblendvps     %ymm11,%ymm9,%ymm1,%ymm9
  .byte  197,252,89,200                      // vmulps        %ymm0,%ymm0,%ymm1
  .byte  197,252,89,201                      // vmulps        %ymm1,%ymm0,%ymm1
  .byte  197,44,194,217,1                    // vcmpltps      %ymm1,%ymm10,%ymm11
  .byte  196,193,124,92,196                  // vsubps        %ymm12,%ymm0,%ymm0
  .byte  197,252,89,194                      // vmulps        %ymm2,%ymm0,%ymm0
  .byte  196,227,125,74,201,176              // vblendvps     %ymm11,%ymm1,%ymm0,%ymm1
  .byte  196,193,60,89,192                   // vmulps        %ymm8,%ymm8,%ymm0
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  197,44,194,208,1                    // vcmpltps      %ymm0,%ymm10,%ymm10
  .byte  196,65,60,92,196                    // vsubps        %ymm12,%ymm8,%ymm8
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  196,99,109,74,192,160               // vblendvps     %ymm10,%ymm0,%ymm2,%ymm8
  .byte  184,31,215,118,63                   // mov           $0x3f76d71f,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,180,89,192                      // vmulps        %ymm0,%ymm9,%ymm0
  .byte  184,246,64,83,63                    // mov           $0x3f5340f6,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,227,121,4,210,0                 // vpermilps     $0x0,%xmm2,%xmm2
  .byte  196,227,109,24,210,1                // vinsertf128   $0x1,%xmm2,%ymm2,%ymm2
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_a8_avx
.globl _sk_load_a8_avx
FUNCTION(_sk_load_a8_avx)
_sk_load_a8_avx:
  .byte  73,137,200                          // mov           %rcx,%r8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,1,248                            // add           %rdi,%rax
  .byte  77,133,192                          // test          %r8,%r8
  .byte  117,74                              // jne           2ddf <_sk_load_a8_avx+0x5a>
  .byte  197,250,126,0                       // vmovq         (%rax),%xmm0
  .byte  196,226,121,49,200                  // vpmovzxbd     %xmm0,%xmm1
  .byte  196,227,121,4,192,229               // vpermilps     $0xe5,%xmm0,%xmm0
  .byte  196,226,121,49,192                  // vpmovzxbd     %xmm0,%xmm0
  .byte  196,227,117,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm1,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,252,89,217                      // vmulps        %ymm1,%ymm0,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,87,192                      // vxorps        %ymm0,%ymm0,%ymm0
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  197,236,87,210                      // vxorps        %ymm2,%ymm2,%ymm2
  .byte  76,137,193                          // mov           %r8,%rcx
  .byte  255,224                             // jmpq          *%rax
  .byte  49,201                              // xor           %ecx,%ecx
  .byte  77,137,194                          // mov           %r8,%r10
  .byte  69,49,201                           // xor           %r9d,%r9d
  .byte  68,15,182,24                        // movzbl        (%rax),%r11d
  .byte  72,255,192                          // inc           %rax
  .byte  73,211,227                          // shl           %cl,%r11
  .byte  77,9,217                            // or            %r11,%r9
  .byte  72,131,193,8                        // add           $0x8,%rcx
  .byte  73,255,202                          // dec           %r10
  .byte  117,234                             // jne           2de7 <_sk_load_a8_avx+0x62>
  .byte  196,193,249,110,193                 // vmovq         %r9,%xmm0
  .byte  235,149                             // jmp           2d99 <_sk_load_a8_avx+0x14>

HIDDEN _sk_gather_a8_avx
.globl _sk_gather_a8_avx
FUNCTION(_sk_gather_a8_avx)
_sk_gather_a8_avx:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  197,254,91,209                      // vcvttps2dq    %ymm1,%ymm2
  .byte  197,249,110,72,16                   // vmovd         0x10(%rax),%xmm1
  .byte  197,249,112,217,0                   // vpshufd       $0x0,%xmm1,%xmm3
  .byte  196,226,97,64,202                   // vpmulld       %xmm2,%xmm3,%xmm1
  .byte  196,227,125,25,210,1                // vextractf128  $0x1,%ymm2,%xmm2
  .byte  196,226,97,64,210                   // vpmulld       %xmm2,%xmm3,%xmm2
  .byte  197,254,91,192                      // vcvttps2dq    %ymm0,%ymm0
  .byte  196,227,125,25,195,1                // vextractf128  $0x1,%ymm0,%xmm3
  .byte  197,233,254,211                     // vpaddd        %xmm3,%xmm2,%xmm2
  .byte  196,227,249,22,208,1                // vpextrq       $0x1,%xmm2,%rax
  .byte  65,137,193                          // mov           %eax,%r9d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  196,193,249,126,210                 // vmovq         %xmm2,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  197,241,254,192                     // vpaddd        %xmm0,%xmm1,%xmm0
  .byte  196,225,249,126,195                 // vmovq         %xmm0,%rbx
  .byte  65,137,222                          // mov           %ebx,%r14d
  .byte  196,195,249,22,199,1                // vpextrq       $0x1,%xmm0,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,131,121,32,4,48,0               // vpinsrb       $0x0,(%r8,%r14,1),%xmm0,%xmm0
  .byte  196,195,121,32,4,24,1               // vpinsrb       $0x1,(%r8,%rbx,1),%xmm0,%xmm0
  .byte  67,15,182,28,32                     // movzbl        (%r8,%r12,1),%ebx
  .byte  196,227,121,32,195,2                // vpinsrb       $0x2,%ebx,%xmm0,%xmm0
  .byte  67,15,182,28,56                     // movzbl        (%r8,%r15,1),%ebx
  .byte  196,227,121,32,195,3                // vpinsrb       $0x3,%ebx,%xmm0,%xmm0
  .byte  196,226,121,49,192                  // vpmovzxbd     %xmm0,%xmm0
  .byte  196,131,121,32,12,24,0              // vpinsrb       $0x0,(%r8,%r11,1),%xmm0,%xmm1
  .byte  196,131,113,32,12,16,1              // vpinsrb       $0x1,(%r8,%r10,1),%xmm1,%xmm1
  .byte  67,15,182,28,8                      // movzbl        (%r8,%r9,1),%ebx
  .byte  196,227,113,32,203,2                // vpinsrb       $0x2,%ebx,%xmm1,%xmm1
  .byte  65,15,182,4,0                       // movzbl        (%r8,%rax,1),%eax
  .byte  196,227,113,32,200,3                // vpinsrb       $0x3,%eax,%xmm1,%xmm1
  .byte  196,226,121,49,201                  // vpmovzxbd     %xmm1,%xmm1
  .byte  196,227,125,24,193,1                // vinsertf128   $0x1,%xmm1,%ymm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,252,89,217                      // vmulps        %ymm1,%ymm0,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,87,192                      // vxorps        %ymm0,%ymm0,%ymm0
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  197,236,87,210                      // vxorps        %ymm2,%ymm2,%ymm2
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_a8_avx
.globl _sk_store_a8_avx
FUNCTION(_sk_store_a8_avx)
_sk_store_a8_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  184,0,0,127,67                      // mov           $0x437f0000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,89,195                       // vmulps        %ymm3,%ymm8,%ymm8
  .byte  196,65,125,91,192                   // vcvtps2dq     %ymm8,%ymm8
  .byte  196,67,125,25,193,1                 // vextractf128  $0x1,%ymm8,%xmm9
  .byte  196,66,57,43,193                    // vpackusdw     %xmm9,%xmm8,%xmm8
  .byte  196,65,57,103,192                   // vpackuswb     %xmm8,%xmm8,%xmm8
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  117,10                              // jne           2f40 <_sk_store_a8_avx+0x42>
  .byte  196,65,123,17,4,57                  // vmovsd        %xmm8,(%r9,%rdi,1)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  65,128,224,7                        // and           $0x7,%r8b
  .byte  65,254,200                          // dec           %r8b
  .byte  65,128,248,6                        // cmp           $0x6,%r8b
  .byte  119,236                             // ja            2f3c <_sk_store_a8_avx+0x3e>
  .byte  196,66,121,48,192                   // vpmovzxbw     %xmm8,%xmm8
  .byte  65,15,182,192                       // movzbl        %r8b,%eax
  .byte  76,141,5,68,0,0,0                   // lea           0x44(%rip),%r8        # 2fa4 <_sk_store_a8_avx+0xa6>
  .byte  73,99,4,128                         // movslq        (%r8,%rax,4),%rax
  .byte  76,1,192                            // add           %r8,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,67,121,20,68,57,6,12            // vpextrb       $0xc,%xmm8,0x6(%r9,%rdi,1)
  .byte  196,67,121,20,68,57,5,10            // vpextrb       $0xa,%xmm8,0x5(%r9,%rdi,1)
  .byte  196,67,121,20,68,57,4,8             // vpextrb       $0x8,%xmm8,0x4(%r9,%rdi,1)
  .byte  196,67,121,20,68,57,3,6             // vpextrb       $0x6,%xmm8,0x3(%r9,%rdi,1)
  .byte  196,67,121,20,68,57,2,4             // vpextrb       $0x4,%xmm8,0x2(%r9,%rdi,1)
  .byte  196,67,121,20,68,57,1,2             // vpextrb       $0x2,%xmm8,0x1(%r9,%rdi,1)
  .byte  196,67,121,20,4,57,0                // vpextrb       $0x0,%xmm8,(%r9,%rdi,1)
  .byte  235,154                             // jmp           2f3c <_sk_store_a8_avx+0x3e>
  .byte  102,144                             // xchg          %ax,%ax
  .byte  245                                 // cmc
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  237                                 // in            (%dx),%eax
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,229                             // jmpq          *%rbp
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  221,255                             // (bad)
  .byte  255                                 // (bad)
  .byte  255,213                             // callq         *%rbp
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,205                             // dec           %ebp
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,197                             // inc           %ebp
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_load_g8_avx
.globl _sk_load_g8_avx
FUNCTION(_sk_load_g8_avx)
_sk_load_g8_avx:
  .byte  73,137,200                          // mov           %rcx,%r8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,1,248                            // add           %rdi,%rax
  .byte  77,133,192                          // test          %r8,%r8
  .byte  117,91                              // jne           302b <_sk_load_g8_avx+0x6b>
  .byte  197,250,126,0                       // vmovq         (%rax),%xmm0
  .byte  196,226,121,49,200                  // vpmovzxbd     %xmm0,%xmm1
  .byte  196,227,121,4,192,229               // vpermilps     $0xe5,%xmm0,%xmm0
  .byte  196,226,121,49,192                  // vpmovzxbd     %xmm0,%xmm0
  .byte  196,227,117,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm1,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,252,89,193                      // vmulps        %ymm1,%ymm0,%ymm0
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,217,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,137,193                          // mov           %r8,%rcx
  .byte  197,252,40,200                      // vmovaps       %ymm0,%ymm1
  .byte  197,252,40,208                      // vmovaps       %ymm0,%ymm2
  .byte  255,224                             // jmpq          *%rax
  .byte  49,201                              // xor           %ecx,%ecx
  .byte  77,137,194                          // mov           %r8,%r10
  .byte  69,49,201                           // xor           %r9d,%r9d
  .byte  68,15,182,24                        // movzbl        (%rax),%r11d
  .byte  72,255,192                          // inc           %rax
  .byte  73,211,227                          // shl           %cl,%r11
  .byte  77,9,217                            // or            %r11,%r9
  .byte  72,131,193,8                        // add           $0x8,%rcx
  .byte  73,255,202                          // dec           %r10
  .byte  117,234                             // jne           3033 <_sk_load_g8_avx+0x73>
  .byte  196,193,249,110,193                 // vmovq         %r9,%xmm0
  .byte  235,132                             // jmp           2fd4 <_sk_load_g8_avx+0x14>

HIDDEN _sk_gather_g8_avx
.globl _sk_gather_g8_avx
FUNCTION(_sk_gather_g8_avx)
_sk_gather_g8_avx:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  197,254,91,209                      // vcvttps2dq    %ymm1,%ymm2
  .byte  197,249,110,72,16                   // vmovd         0x10(%rax),%xmm1
  .byte  197,249,112,217,0                   // vpshufd       $0x0,%xmm1,%xmm3
  .byte  196,226,97,64,202                   // vpmulld       %xmm2,%xmm3,%xmm1
  .byte  196,227,125,25,210,1                // vextractf128  $0x1,%ymm2,%xmm2
  .byte  196,226,97,64,210                   // vpmulld       %xmm2,%xmm3,%xmm2
  .byte  197,254,91,192                      // vcvttps2dq    %ymm0,%ymm0
  .byte  196,227,125,25,195,1                // vextractf128  $0x1,%ymm0,%xmm3
  .byte  197,233,254,211                     // vpaddd        %xmm3,%xmm2,%xmm2
  .byte  196,227,249,22,208,1                // vpextrq       $0x1,%xmm2,%rax
  .byte  65,137,193                          // mov           %eax,%r9d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  196,193,249,126,210                 // vmovq         %xmm2,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  197,241,254,192                     // vpaddd        %xmm0,%xmm1,%xmm0
  .byte  196,225,249,126,195                 // vmovq         %xmm0,%rbx
  .byte  65,137,222                          // mov           %ebx,%r14d
  .byte  196,195,249,22,199,1                // vpextrq       $0x1,%xmm0,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,131,121,32,4,48,0               // vpinsrb       $0x0,(%r8,%r14,1),%xmm0,%xmm0
  .byte  196,195,121,32,4,24,1               // vpinsrb       $0x1,(%r8,%rbx,1),%xmm0,%xmm0
  .byte  67,15,182,28,32                     // movzbl        (%r8,%r12,1),%ebx
  .byte  196,227,121,32,195,2                // vpinsrb       $0x2,%ebx,%xmm0,%xmm0
  .byte  67,15,182,28,56                     // movzbl        (%r8,%r15,1),%ebx
  .byte  196,227,121,32,195,3                // vpinsrb       $0x3,%ebx,%xmm0,%xmm0
  .byte  196,226,121,49,192                  // vpmovzxbd     %xmm0,%xmm0
  .byte  196,131,121,32,12,24,0              // vpinsrb       $0x0,(%r8,%r11,1),%xmm0,%xmm1
  .byte  196,131,113,32,12,16,1              // vpinsrb       $0x1,(%r8,%r10,1),%xmm1,%xmm1
  .byte  67,15,182,28,8                      // movzbl        (%r8,%r9,1),%ebx
  .byte  196,227,113,32,203,2                // vpinsrb       $0x2,%ebx,%xmm1,%xmm1
  .byte  65,15,182,4,0                       // movzbl        (%r8,%rax,1),%eax
  .byte  196,227,113,32,200,3                // vpinsrb       $0x3,%eax,%xmm1,%xmm1
  .byte  196,226,121,49,201                  // vpmovzxbd     %xmm1,%xmm1
  .byte  196,227,125,24,193,1                // vinsertf128   $0x1,%xmm1,%ymm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,252,89,193                      // vmulps        %ymm1,%ymm0,%ymm0
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,217,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,40,200                      // vmovaps       %ymm0,%ymm1
  .byte  197,252,40,208                      // vmovaps       %ymm0,%ymm2
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_i8_avx
.globl _sk_gather_i8_avx
FUNCTION(_sk_gather_i8_avx)
_sk_gather_i8_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  73,137,192                          // mov           %rax,%r8
  .byte  77,133,192                          // test          %r8,%r8
  .byte  116,5                               // je            316a <_sk_gather_i8_avx+0xf>
  .byte  76,137,192                          // mov           %r8,%rax
  .byte  235,2                               // jmp           316c <_sk_gather_i8_avx+0x11>
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,85                               // push          %r13
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  197,254,91,209                      // vcvttps2dq    %ymm1,%ymm2
  .byte  197,249,110,72,16                   // vmovd         0x10(%rax),%xmm1
  .byte  197,249,112,217,0                   // vpshufd       $0x0,%xmm1,%xmm3
  .byte  196,226,97,64,202                   // vpmulld       %xmm2,%xmm3,%xmm1
  .byte  196,227,125,25,210,1                // vextractf128  $0x1,%ymm2,%xmm2
  .byte  196,226,97,64,210                   // vpmulld       %xmm2,%xmm3,%xmm2
  .byte  197,254,91,192                      // vcvttps2dq    %ymm0,%ymm0
  .byte  196,227,125,25,195,1                // vextractf128  $0x1,%ymm0,%xmm3
  .byte  197,233,254,211                     // vpaddd        %xmm3,%xmm2,%xmm2
  .byte  196,227,249,22,208,1                // vpextrq       $0x1,%xmm2,%rax
  .byte  65,137,194                          // mov           %eax,%r10d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  196,193,249,126,211                 // vmovq         %xmm2,%r11
  .byte  69,137,222                          // mov           %r11d,%r14d
  .byte  73,193,235,32                       // shr           $0x20,%r11
  .byte  197,241,254,192                     // vpaddd        %xmm0,%xmm1,%xmm0
  .byte  196,225,249,126,195                 // vmovq         %xmm0,%rbx
  .byte  65,137,223                          // mov           %ebx,%r15d
  .byte  196,195,249,22,196,1                // vpextrq       $0x1,%xmm0,%r12
  .byte  69,137,229                          // mov           %r12d,%r13d
  .byte  73,193,236,32                       // shr           $0x20,%r12
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,131,121,32,4,49,0               // vpinsrb       $0x0,(%r9,%r14,1),%xmm0,%xmm0
  .byte  196,131,121,32,4,25,1               // vpinsrb       $0x1,(%r9,%r11,1),%xmm0,%xmm0
  .byte  196,131,121,32,4,17,2               // vpinsrb       $0x2,(%r9,%r10,1),%xmm0,%xmm0
  .byte  196,195,121,32,4,1,3                // vpinsrb       $0x3,(%r9,%rax,1),%xmm0,%xmm0
  .byte  196,226,121,49,192                  // vpmovzxbd     %xmm0,%xmm0
  .byte  196,195,249,22,194,1                // vpextrq       $0x1,%xmm0,%r10
  .byte  196,193,249,126,195                 // vmovq         %xmm0,%r11
  .byte  196,131,121,32,4,57,0               // vpinsrb       $0x0,(%r9,%r15,1),%xmm0,%xmm0
  .byte  196,195,121,32,4,25,1               // vpinsrb       $0x1,(%r9,%rbx,1),%xmm0,%xmm0
  .byte  196,131,121,32,4,41,2               // vpinsrb       $0x2,(%r9,%r13,1),%xmm0,%xmm0
  .byte  196,131,121,32,4,33,3               // vpinsrb       $0x3,(%r9,%r12,1),%xmm0,%xmm0
  .byte  196,226,121,49,192                  // vpmovzxbd     %xmm0,%xmm0
  .byte  73,139,88,8                         // mov           0x8(%r8),%rbx
  .byte  196,193,249,126,193                 // vmovq         %xmm0,%r9
  .byte  69,137,200                          // mov           %r9d,%r8d
  .byte  73,193,233,30                       // shr           $0x1e,%r9
  .byte  196,227,249,22,192,1                // vpextrq       $0x1,%xmm0,%rax
  .byte  65,137,198                          // mov           %eax,%r14d
  .byte  72,193,232,30                       // shr           $0x1e,%rax
  .byte  69,137,223                          // mov           %r11d,%r15d
  .byte  73,193,235,30                       // shr           $0x1e,%r11
  .byte  69,137,212                          // mov           %r10d,%r12d
  .byte  73,193,234,30                       // shr           $0x1e,%r10
  .byte  196,161,121,110,4,131               // vmovd         (%rbx,%r8,4),%xmm0
  .byte  196,163,121,34,4,11,1               // vpinsrd       $0x1,(%rbx,%r9,1),%xmm0,%xmm0
  .byte  196,163,121,34,4,179,2              // vpinsrd       $0x2,(%rbx,%r14,4),%xmm0,%xmm0
  .byte  196,99,121,34,4,3,3                 // vpinsrd       $0x3,(%rbx,%rax,1),%xmm0,%xmm8
  .byte  196,161,121,110,4,187               // vmovd         (%rbx,%r15,4),%xmm0
  .byte  196,163,121,34,4,27,1               // vpinsrd       $0x1,(%rbx,%r11,1),%xmm0,%xmm0
  .byte  196,163,121,34,4,163,2              // vpinsrd       $0x2,(%rbx,%r12,4),%xmm0,%xmm0
  .byte  196,163,121,34,28,19,3              // vpinsrd       $0x3,(%rbx,%r10,1),%xmm0,%xmm3
  .byte  196,227,61,24,195,1                 // vinsertf128   $0x1,%xmm3,%ymm8,%ymm0
  .byte  197,124,40,21,106,42,0,0            // vmovaps       0x2a6a(%rip),%ymm10        # 5d00 <_sk_callback_avx+0x252>
  .byte  196,193,124,84,194                  // vandps        %ymm10,%ymm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,99,117,24,201,1                 // vinsertf128   $0x1,%xmm1,%ymm1,%ymm9
  .byte  196,193,124,89,193                  // vmulps        %ymm9,%ymm0,%ymm0
  .byte  196,193,113,114,208,8               // vpsrld        $0x8,%xmm8,%xmm1
  .byte  197,233,114,211,8                   // vpsrld        $0x8,%xmm3,%xmm2
  .byte  196,227,117,24,202,1                // vinsertf128   $0x1,%xmm2,%ymm1,%ymm1
  .byte  196,193,116,84,202                  // vandps        %ymm10,%ymm1,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  196,193,116,89,201                  // vmulps        %ymm9,%ymm1,%ymm1
  .byte  196,193,33,114,208,16               // vpsrld        $0x10,%xmm8,%xmm11
  .byte  197,233,114,211,16                  // vpsrld        $0x10,%xmm3,%xmm2
  .byte  196,227,37,24,210,1                 // vinsertf128   $0x1,%xmm2,%ymm11,%ymm2
  .byte  196,193,108,84,210                  // vandps        %ymm10,%ymm2,%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  196,193,108,89,209                  // vmulps        %ymm9,%ymm2,%ymm2
  .byte  196,193,57,114,208,24               // vpsrld        $0x18,%xmm8,%xmm8
  .byte  197,225,114,211,24                  // vpsrld        $0x18,%xmm3,%xmm3
  .byte  196,227,61,24,219,1                 // vinsertf128   $0x1,%xmm3,%ymm8,%ymm3
  .byte  197,252,91,219                      // vcvtdq2ps     %ymm3,%ymm3
  .byte  196,193,100,89,217                  // vmulps        %ymm9,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,93                               // pop           %r13
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_565_avx
.globl _sk_load_565_avx
FUNCTION(_sk_load_565_avx)
_sk_load_565_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,16                           // mov           (%rax),%r10
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  15,133,209,0,0,0                    // jne           33fd <_sk_load_565_avx+0xdf>
  .byte  196,193,122,111,4,122               // vmovdqu       (%r10,%rdi,2),%xmm0
  .byte  197,241,239,201                     // vpxor         %xmm1,%xmm1,%xmm1
  .byte  197,249,105,201                     // vpunpckhwd    %xmm1,%xmm0,%xmm1
  .byte  196,226,121,51,192                  // vpmovzxwd     %xmm0,%xmm0
  .byte  196,227,125,24,209,1                // vinsertf128   $0x1,%xmm1,%ymm0,%ymm2
  .byte  184,0,248,0,0                       // mov           $0xf800,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  197,249,112,192,0                   // vpshufd       $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,252,84,194                      // vandps        %ymm2,%ymm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,8,33,132,55                     // mov           $0x37842108,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,252,89,193                      // vmulps        %ymm1,%ymm0,%ymm0
  .byte  184,224,7,0,0                       // mov           $0x7e0,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  197,249,112,201,0                   // vpshufd       $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,244,84,202                      // vandps        %ymm2,%ymm1,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  184,33,8,2,58                       // mov           $0x3a020821,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  197,244,89,203                      // vmulps        %ymm3,%ymm1,%ymm1
  .byte  184,31,0,0,0                        // mov           $0x1f,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  197,249,112,219,0                   // vpshufd       $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  197,228,84,210                      // vandps        %ymm2,%ymm3,%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  184,8,33,4,61                       // mov           $0x3d042108,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  197,236,89,211                      // vmulps        %ymm3,%ymm2,%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  65,128,224,7                        // and           $0x7,%r8b
  .byte  197,249,239,192                     // vpxor         %xmm0,%xmm0,%xmm0
  .byte  65,254,200                          // dec           %r8b
  .byte  65,128,248,6                        // cmp           $0x6,%r8b
  .byte  15,135,29,255,255,255               // ja            3332 <_sk_load_565_avx+0x14>
  .byte  69,15,182,192                       // movzbl        %r8b,%r8d
  .byte  76,141,13,76,0,0,0                  // lea           0x4c(%rip),%r9        # 346c <_sk_load_565_avx+0x14e>
  .byte  75,99,4,129                         // movslq        (%r9,%r8,4),%rax
  .byte  76,1,200                            // add           %r9,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  197,249,239,192                     // vpxor         %xmm0,%xmm0,%xmm0
  .byte  196,193,121,196,68,122,12,6         // vpinsrw       $0x6,0xc(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,10,5         // vpinsrw       $0x5,0xa(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,8,4          // vpinsrw       $0x4,0x8(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,6,3          // vpinsrw       $0x3,0x6(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,4,2          // vpinsrw       $0x2,0x4(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,2,1          // vpinsrw       $0x1,0x2(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,4,122,0             // vpinsrw       $0x0,(%r10,%rdi,2),%xmm0,%xmm0
  .byte  233,201,254,255,255                 // jmpq          3332 <_sk_load_565_avx+0x14>
  .byte  15,31,0                             // nopl          (%rax)
  .byte  241                                 // icebp
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  233,255,255,255,225                 // jmpq          ffffffffe2003474 <_sk_callback_avx+0xffffffffe1ffd9c6>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  217,255                             // fcos
  .byte  255                                 // (bad)
  .byte  255,209                             // callq         *%rcx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,201                             // dec           %ecx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  189                                 // .byte         0xbd
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_gather_565_avx
.globl _sk_gather_565_avx
FUNCTION(_sk_gather_565_avx)
_sk_gather_565_avx:
  .byte  85                                  // push          %rbp
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  197,254,91,209                      // vcvttps2dq    %ymm1,%ymm2
  .byte  197,249,110,72,16                   // vmovd         0x10(%rax),%xmm1
  .byte  197,249,112,217,0                   // vpshufd       $0x0,%xmm1,%xmm3
  .byte  196,226,97,64,202                   // vpmulld       %xmm2,%xmm3,%xmm1
  .byte  196,227,125,25,210,1                // vextractf128  $0x1,%ymm2,%xmm2
  .byte  196,226,97,64,210                   // vpmulld       %xmm2,%xmm3,%xmm2
  .byte  197,254,91,192                      // vcvttps2dq    %ymm0,%ymm0
  .byte  196,227,125,25,195,1                // vextractf128  $0x1,%ymm0,%xmm3
  .byte  197,233,254,211                     // vpaddd        %xmm3,%xmm2,%xmm2
  .byte  196,227,249,22,208,1                // vpextrq       $0x1,%xmm2,%rax
  .byte  65,137,193                          // mov           %eax,%r9d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  196,193,249,126,210                 // vmovq         %xmm2,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  197,241,254,192                     // vpaddd        %xmm0,%xmm1,%xmm0
  .byte  196,225,249,126,195                 // vmovq         %xmm0,%rbx
  .byte  65,137,222                          // mov           %ebx,%r14d
  .byte  196,195,249,22,199,1                // vpextrq       $0x1,%xmm0,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  65,15,183,28,88                     // movzwl        (%r8,%rbx,2),%ebx
  .byte  67,15,183,44,112                    // movzwl        (%r8,%r14,2),%ebp
  .byte  197,249,110,197                     // vmovd         %ebp,%xmm0
  .byte  197,249,196,195,1                   // vpinsrw       $0x1,%ebx,%xmm0,%xmm0
  .byte  67,15,183,28,96                     // movzwl        (%r8,%r12,2),%ebx
  .byte  197,249,196,195,2                   // vpinsrw       $0x2,%ebx,%xmm0,%xmm0
  .byte  67,15,183,28,120                    // movzwl        (%r8,%r15,2),%ebx
  .byte  197,249,196,195,3                   // vpinsrw       $0x3,%ebx,%xmm0,%xmm0
  .byte  67,15,183,44,88                     // movzwl        (%r8,%r11,2),%ebp
  .byte  197,249,196,197,4                   // vpinsrw       $0x4,%ebp,%xmm0,%xmm0
  .byte  67,15,183,44,80                     // movzwl        (%r8,%r10,2),%ebp
  .byte  197,249,196,197,5                   // vpinsrw       $0x5,%ebp,%xmm0,%xmm0
  .byte  67,15,183,44,72                     // movzwl        (%r8,%r9,2),%ebp
  .byte  197,249,196,197,6                   // vpinsrw       $0x6,%ebp,%xmm0,%xmm0
  .byte  65,15,183,4,64                      // movzwl        (%r8,%rax,2),%eax
  .byte  197,249,196,192,7                   // vpinsrw       $0x7,%eax,%xmm0,%xmm0
  .byte  197,241,239,201                     // vpxor         %xmm1,%xmm1,%xmm1
  .byte  197,249,105,201                     // vpunpckhwd    %xmm1,%xmm0,%xmm1
  .byte  196,226,121,51,192                  // vpmovzxwd     %xmm0,%xmm0
  .byte  196,227,125,24,209,1                // vinsertf128   $0x1,%xmm1,%ymm0,%ymm2
  .byte  184,0,248,0,0                       // mov           $0xf800,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  197,249,112,192,0                   // vpshufd       $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,252,84,194                      // vandps        %ymm2,%ymm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,8,33,132,55                     // mov           $0x37842108,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,252,89,193                      // vmulps        %ymm1,%ymm0,%ymm0
  .byte  184,224,7,0,0                       // mov           $0x7e0,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  197,249,112,201,0                   // vpshufd       $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,244,84,202                      // vandps        %ymm2,%ymm1,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  184,33,8,2,58                       // mov           $0x3a020821,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  197,244,89,203                      // vmulps        %ymm3,%ymm1,%ymm1
  .byte  184,31,0,0,0                        // mov           $0x1f,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  197,249,112,219,0                   // vpshufd       $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  197,228,84,210                      // vandps        %ymm2,%ymm3,%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  184,8,33,4,61                       // mov           $0x3d042108,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  197,236,89,211                      // vmulps        %ymm3,%ymm2,%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  93                                  // pop           %rbp
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_565_avx
.globl _sk_store_565_avx
FUNCTION(_sk_store_565_avx)
_sk_store_565_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  184,0,0,248,65                      // mov           $0x41f80000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,89,200                       // vmulps        %ymm0,%ymm8,%ymm9
  .byte  196,65,125,91,201                   // vcvtps2dq     %ymm9,%ymm9
  .byte  196,193,41,114,241,11               // vpslld        $0xb,%xmm9,%xmm10
  .byte  196,67,125,25,201,1                 // vextractf128  $0x1,%ymm9,%xmm9
  .byte  196,193,49,114,241,11               // vpslld        $0xb,%xmm9,%xmm9
  .byte  196,67,45,24,201,1                  // vinsertf128   $0x1,%xmm9,%ymm10,%ymm9
  .byte  184,0,0,124,66                      // mov           $0x427c0000,%eax
  .byte  197,121,110,208                     // vmovd         %eax,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  197,44,89,209                       // vmulps        %ymm1,%ymm10,%ymm10
  .byte  196,65,125,91,210                   // vcvtps2dq     %ymm10,%ymm10
  .byte  196,193,33,114,242,5                // vpslld        $0x5,%xmm10,%xmm11
  .byte  196,67,125,25,210,1                 // vextractf128  $0x1,%ymm10,%xmm10
  .byte  196,193,41,114,242,5                // vpslld        $0x5,%xmm10,%xmm10
  .byte  196,67,37,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm11,%ymm10
  .byte  196,65,45,86,201                    // vorpd         %ymm9,%ymm10,%ymm9
  .byte  197,60,89,194                       // vmulps        %ymm2,%ymm8,%ymm8
  .byte  196,65,125,91,192                   // vcvtps2dq     %ymm8,%ymm8
  .byte  196,65,53,86,192                    // vorpd         %ymm8,%ymm9,%ymm8
  .byte  196,67,125,25,193,1                 // vextractf128  $0x1,%ymm8,%xmm9
  .byte  196,66,57,43,193                    // vpackusdw     %xmm9,%xmm8,%xmm8
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  117,10                              // jne           36b7 <_sk_store_565_avx+0x9e>
  .byte  196,65,122,127,4,121                // vmovdqu       %xmm8,(%r9,%rdi,2)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  65,128,224,7                        // and           $0x7,%r8b
  .byte  65,254,200                          // dec           %r8b
  .byte  65,128,248,6                        // cmp           $0x6,%r8b
  .byte  119,236                             // ja            36b3 <_sk_store_565_avx+0x9a>
  .byte  65,15,182,192                       // movzbl        %r8b,%eax
  .byte  76,141,5,66,0,0,0                   // lea           0x42(%rip),%r8        # 3714 <_sk_store_565_avx+0xfb>
  .byte  73,99,4,128                         // movslq        (%r8,%rax,4),%rax
  .byte  76,1,192                            // add           %r8,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,67,121,21,68,121,12,6           // vpextrw       $0x6,%xmm8,0xc(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,10,5           // vpextrw       $0x5,%xmm8,0xa(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,8,4            // vpextrw       $0x4,%xmm8,0x8(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,6,3            // vpextrw       $0x3,%xmm8,0x6(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,4,2            // vpextrw       $0x2,%xmm8,0x4(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,2,1            // vpextrw       $0x1,%xmm8,0x2(%r9,%rdi,2)
  .byte  196,67,121,21,4,121,0               // vpextrw       $0x0,%xmm8,(%r9,%rdi,2)
  .byte  235,159                             // jmp           36b3 <_sk_store_565_avx+0x9a>
  .byte  247,255                             // idiv          %edi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  239                                 // out           %eax,(%dx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,231                             // jmpq          *%rdi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  223,255                             // (bad)
  .byte  255                                 // (bad)
  .byte  255,215                             // callq         *%rdi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,207                             // dec           %edi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,199                             // inc           %edi
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_load_4444_avx
.globl _sk_load_4444_avx
FUNCTION(_sk_load_4444_avx)
_sk_load_4444_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,16                           // mov           (%rax),%r10
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  15,133,245,0,0,0                    // jne           3833 <_sk_load_4444_avx+0x103>
  .byte  196,193,122,111,4,122               // vmovdqu       (%r10,%rdi,2),%xmm0
  .byte  197,241,239,201                     // vpxor         %xmm1,%xmm1,%xmm1
  .byte  197,249,105,201                     // vpunpckhwd    %xmm1,%xmm0,%xmm1
  .byte  196,226,121,51,192                  // vpmovzxwd     %xmm0,%xmm0
  .byte  196,99,125,24,201,1                 // vinsertf128   $0x1,%xmm1,%ymm0,%ymm9
  .byte  184,0,240,0,0                       // mov           $0xf000,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  197,249,112,192,0                   // vpshufd       $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  196,193,124,84,193                  // vandps        %ymm9,%ymm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,137,136,136,55                  // mov           $0x37888889,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,252,89,193                      // vmulps        %ymm1,%ymm0,%ymm0
  .byte  184,0,15,0,0                        // mov           $0xf00,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  197,249,112,201,0                   // vpshufd       $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  196,193,116,84,201                  // vandps        %ymm9,%ymm1,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  184,137,136,136,57                  // mov           $0x39888889,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,227,121,4,210,0                 // vpermilps     $0x0,%xmm2,%xmm2
  .byte  196,227,109,24,210,1                // vinsertf128   $0x1,%xmm2,%ymm2,%ymm2
  .byte  197,244,89,202                      // vmulps        %ymm2,%ymm1,%ymm1
  .byte  184,240,0,0,0                       // mov           $0xf0,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  197,249,112,210,0                   // vpshufd       $0x0,%xmm2,%xmm2
  .byte  196,227,109,24,210,1                // vinsertf128   $0x1,%xmm2,%ymm2,%ymm2
  .byte  196,193,108,84,209                  // vandps        %ymm9,%ymm2,%ymm2
  .byte  197,124,91,194                      // vcvtdq2ps     %ymm2,%ymm8
  .byte  184,137,136,136,59                  // mov           $0x3b888889,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,227,121,4,210,0                 // vpermilps     $0x0,%xmm2,%xmm2
  .byte  196,227,109,24,210,1                // vinsertf128   $0x1,%xmm2,%ymm2,%ymm2
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  184,15,0,0,0                        // mov           $0xf,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  197,249,112,219,0                   // vpshufd       $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  196,193,100,84,217                  // vandps        %ymm9,%ymm3,%ymm3
  .byte  197,124,91,195                      // vcvtdq2ps     %ymm3,%ymm8
  .byte  184,137,136,136,61                  // mov           $0x3d888889,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  65,128,224,7                        // and           $0x7,%r8b
  .byte  197,249,239,192                     // vpxor         %xmm0,%xmm0,%xmm0
  .byte  65,254,200                          // dec           %r8b
  .byte  65,128,248,6                        // cmp           $0x6,%r8b
  .byte  15,135,249,254,255,255              // ja            3744 <_sk_load_4444_avx+0x14>
  .byte  69,15,182,192                       // movzbl        %r8b,%r8d
  .byte  76,141,13,74,0,0,0                  // lea           0x4a(%rip),%r9        # 38a0 <_sk_load_4444_avx+0x170>
  .byte  75,99,4,129                         // movslq        (%r9,%r8,4),%rax
  .byte  76,1,200                            // add           %r9,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  197,249,239,192                     // vpxor         %xmm0,%xmm0,%xmm0
  .byte  196,193,121,196,68,122,12,6         // vpinsrw       $0x6,0xc(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,10,5         // vpinsrw       $0x5,0xa(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,8,4          // vpinsrw       $0x4,0x8(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,6,3          // vpinsrw       $0x3,0x6(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,4,2          // vpinsrw       $0x2,0x4(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,68,122,2,1          // vpinsrw       $0x1,0x2(%r10,%rdi,2),%xmm0,%xmm0
  .byte  196,193,121,196,4,122,0             // vpinsrw       $0x0,(%r10,%rdi,2),%xmm0,%xmm0
  .byte  233,165,254,255,255                 // jmpq          3744 <_sk_load_4444_avx+0x14>
  .byte  144                                 // nop
  .byte  243,255                             // repz          (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  235,255                             // jmp           38a5 <_sk_load_4444_avx+0x175>
  .byte  255                                 // (bad)
  .byte  255,227                             // jmpq          *%rbx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  219,255                             // (bad)
  .byte  255                                 // (bad)
  .byte  255,211                             // callq         *%rbx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,203                             // dec           %ebx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  191                                 // .byte         0xbf
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_gather_4444_avx
.globl _sk_gather_4444_avx
FUNCTION(_sk_gather_4444_avx)
_sk_gather_4444_avx:
  .byte  85                                  // push          %rbp
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  197,254,91,209                      // vcvttps2dq    %ymm1,%ymm2
  .byte  197,249,110,72,16                   // vmovd         0x10(%rax),%xmm1
  .byte  197,249,112,217,0                   // vpshufd       $0x0,%xmm1,%xmm3
  .byte  196,226,97,64,202                   // vpmulld       %xmm2,%xmm3,%xmm1
  .byte  196,227,125,25,210,1                // vextractf128  $0x1,%ymm2,%xmm2
  .byte  196,226,97,64,210                   // vpmulld       %xmm2,%xmm3,%xmm2
  .byte  197,254,91,192                      // vcvttps2dq    %ymm0,%ymm0
  .byte  196,227,125,25,195,1                // vextractf128  $0x1,%ymm0,%xmm3
  .byte  197,233,254,211                     // vpaddd        %xmm3,%xmm2,%xmm2
  .byte  196,227,249,22,208,1                // vpextrq       $0x1,%xmm2,%rax
  .byte  65,137,193                          // mov           %eax,%r9d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  196,193,249,126,210                 // vmovq         %xmm2,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  197,241,254,192                     // vpaddd        %xmm0,%xmm1,%xmm0
  .byte  196,225,249,126,195                 // vmovq         %xmm0,%rbx
  .byte  65,137,222                          // mov           %ebx,%r14d
  .byte  196,195,249,22,199,1                // vpextrq       $0x1,%xmm0,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  65,15,183,28,88                     // movzwl        (%r8,%rbx,2),%ebx
  .byte  67,15,183,44,112                    // movzwl        (%r8,%r14,2),%ebp
  .byte  197,249,110,197                     // vmovd         %ebp,%xmm0
  .byte  197,249,196,195,1                   // vpinsrw       $0x1,%ebx,%xmm0,%xmm0
  .byte  67,15,183,28,96                     // movzwl        (%r8,%r12,2),%ebx
  .byte  197,249,196,195,2                   // vpinsrw       $0x2,%ebx,%xmm0,%xmm0
  .byte  67,15,183,28,120                    // movzwl        (%r8,%r15,2),%ebx
  .byte  197,249,196,195,3                   // vpinsrw       $0x3,%ebx,%xmm0,%xmm0
  .byte  67,15,183,44,88                     // movzwl        (%r8,%r11,2),%ebp
  .byte  197,249,196,197,4                   // vpinsrw       $0x4,%ebp,%xmm0,%xmm0
  .byte  67,15,183,44,80                     // movzwl        (%r8,%r10,2),%ebp
  .byte  197,249,196,197,5                   // vpinsrw       $0x5,%ebp,%xmm0,%xmm0
  .byte  67,15,183,44,72                     // movzwl        (%r8,%r9,2),%ebp
  .byte  197,249,196,197,6                   // vpinsrw       $0x6,%ebp,%xmm0,%xmm0
  .byte  65,15,183,4,64                      // movzwl        (%r8,%rax,2),%eax
  .byte  197,249,196,192,7                   // vpinsrw       $0x7,%eax,%xmm0,%xmm0
  .byte  197,241,239,201                     // vpxor         %xmm1,%xmm1,%xmm1
  .byte  197,249,105,201                     // vpunpckhwd    %xmm1,%xmm0,%xmm1
  .byte  196,226,121,51,192                  // vpmovzxwd     %xmm0,%xmm0
  .byte  196,99,125,24,201,1                 // vinsertf128   $0x1,%xmm1,%ymm0,%ymm9
  .byte  184,0,240,0,0                       // mov           $0xf000,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  197,249,112,192,0                   // vpshufd       $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  196,193,124,84,193                  // vandps        %ymm9,%ymm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,137,136,136,55                  // mov           $0x37888889,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,252,89,193                      // vmulps        %ymm1,%ymm0,%ymm0
  .byte  184,0,15,0,0                        // mov           $0xf00,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  197,249,112,201,0                   // vpshufd       $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  196,193,116,84,201                  // vandps        %ymm9,%ymm1,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  184,137,136,136,57                  // mov           $0x39888889,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,227,121,4,210,0                 // vpermilps     $0x0,%xmm2,%xmm2
  .byte  196,227,109,24,210,1                // vinsertf128   $0x1,%xmm2,%ymm2,%ymm2
  .byte  197,244,89,202                      // vmulps        %ymm2,%ymm1,%ymm1
  .byte  184,240,0,0,0                       // mov           $0xf0,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  197,249,112,210,0                   // vpshufd       $0x0,%xmm2,%xmm2
  .byte  196,227,109,24,210,1                // vinsertf128   $0x1,%xmm2,%ymm2,%ymm2
  .byte  196,193,108,84,209                  // vandps        %ymm9,%ymm2,%ymm2
  .byte  197,124,91,194                      // vcvtdq2ps     %ymm2,%ymm8
  .byte  184,137,136,136,59                  // mov           $0x3b888889,%eax
  .byte  197,249,110,208                     // vmovd         %eax,%xmm2
  .byte  196,227,121,4,210,0                 // vpermilps     $0x0,%xmm2,%xmm2
  .byte  196,227,109,24,210,1                // vinsertf128   $0x1,%xmm2,%ymm2,%ymm2
  .byte  197,188,89,210                      // vmulps        %ymm2,%ymm8,%ymm2
  .byte  184,15,0,0,0                        // mov           $0xf,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  197,249,112,219,0                   // vpshufd       $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  196,193,100,84,217                  // vandps        %ymm9,%ymm3,%ymm3
  .byte  197,124,91,195                      // vcvtdq2ps     %ymm3,%ymm8
  .byte  184,137,136,136,61                  // mov           $0x3d888889,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  197,188,89,219                      // vmulps        %ymm3,%ymm8,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  93                                  // pop           %rbp
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_4444_avx
.globl _sk_store_4444_avx
FUNCTION(_sk_store_4444_avx)
_sk_store_4444_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  184,0,0,112,65                      // mov           $0x41700000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,89,200                       // vmulps        %ymm0,%ymm8,%ymm9
  .byte  196,65,125,91,201                   // vcvtps2dq     %ymm9,%ymm9
  .byte  196,193,41,114,241,12               // vpslld        $0xc,%xmm9,%xmm10
  .byte  196,67,125,25,201,1                 // vextractf128  $0x1,%ymm9,%xmm9
  .byte  196,193,49,114,241,12               // vpslld        $0xc,%xmm9,%xmm9
  .byte  196,67,45,24,201,1                  // vinsertf128   $0x1,%xmm9,%ymm10,%ymm9
  .byte  197,60,89,209                       // vmulps        %ymm1,%ymm8,%ymm10
  .byte  196,65,125,91,210                   // vcvtps2dq     %ymm10,%ymm10
  .byte  196,193,33,114,242,8                // vpslld        $0x8,%xmm10,%xmm11
  .byte  196,67,125,25,210,1                 // vextractf128  $0x1,%ymm10,%xmm10
  .byte  196,193,41,114,242,8                // vpslld        $0x8,%xmm10,%xmm10
  .byte  196,67,37,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm11,%ymm10
  .byte  196,65,45,86,201                    // vorpd         %ymm9,%ymm10,%ymm9
  .byte  197,60,89,210                       // vmulps        %ymm2,%ymm8,%ymm10
  .byte  196,65,125,91,210                   // vcvtps2dq     %ymm10,%ymm10
  .byte  196,193,33,114,242,4                // vpslld        $0x4,%xmm10,%xmm11
  .byte  196,67,125,25,210,1                 // vextractf128  $0x1,%ymm10,%xmm10
  .byte  196,193,41,114,242,4                // vpslld        $0x4,%xmm10,%xmm10
  .byte  196,67,37,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm11,%ymm10
  .byte  197,60,89,195                       // vmulps        %ymm3,%ymm8,%ymm8
  .byte  196,65,125,91,192                   // vcvtps2dq     %ymm8,%ymm8
  .byte  196,65,45,86,192                    // vorpd         %ymm8,%ymm10,%ymm8
  .byte  196,65,53,86,192                    // vorpd         %ymm8,%ymm9,%ymm8
  .byte  196,67,125,25,193,1                 // vextractf128  $0x1,%ymm8,%xmm9
  .byte  196,66,57,43,193                    // vpackusdw     %xmm9,%xmm8,%xmm8
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  117,10                              // jne           3b20 <_sk_store_4444_avx+0xaf>
  .byte  196,65,122,127,4,121                // vmovdqu       %xmm8,(%r9,%rdi,2)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  65,128,224,7                        // and           $0x7,%r8b
  .byte  65,254,200                          // dec           %r8b
  .byte  65,128,248,6                        // cmp           $0x6,%r8b
  .byte  119,236                             // ja            3b1c <_sk_store_4444_avx+0xab>
  .byte  65,15,182,192                       // movzbl        %r8b,%eax
  .byte  76,141,5,69,0,0,0                   // lea           0x45(%rip),%r8        # 3b80 <_sk_store_4444_avx+0x10f>
  .byte  73,99,4,128                         // movslq        (%r8,%rax,4),%rax
  .byte  76,1,192                            // add           %r8,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,67,121,21,68,121,12,6           // vpextrw       $0x6,%xmm8,0xc(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,10,5           // vpextrw       $0x5,%xmm8,0xa(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,8,4            // vpextrw       $0x4,%xmm8,0x8(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,6,3            // vpextrw       $0x3,%xmm8,0x6(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,4,2            // vpextrw       $0x2,%xmm8,0x4(%r9,%rdi,2)
  .byte  196,67,121,21,68,121,2,1            // vpextrw       $0x1,%xmm8,0x2(%r9,%rdi,2)
  .byte  196,67,121,21,4,121,0               // vpextrw       $0x0,%xmm8,(%r9,%rdi,2)
  .byte  235,159                             // jmp           3b1c <_sk_store_4444_avx+0xab>
  .byte  15,31,0                             // nopl          (%rax)
  .byte  244                                 // hlt
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  236                                 // in            (%dx),%al
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,228                             // jmpq          *%rsp
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  220,255                             // fdivr         %st,%st(7)
  .byte  255                                 // (bad)
  .byte  255,212                             // callq         *%rsp
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,204                             // dec           %esp
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,196                             // inc           %esp
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_load_8888_avx
.globl _sk_load_8888_avx
FUNCTION(_sk_load_8888_avx)
_sk_load_8888_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,16                           // mov           (%rax),%r10
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  15,133,147,0,0,0                    // jne           3c3d <_sk_load_8888_avx+0xa1>
  .byte  196,65,124,16,12,186                // vmovups       (%r10,%rdi,4),%ymm9
  .byte  197,124,40,21,104,33,0,0            // vmovaps       0x2168(%rip),%ymm10        # 5d20 <_sk_callback_avx+0x272>
  .byte  196,193,52,84,194                   // vandps        %ymm10,%ymm9,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,99,117,24,193,1                 // vinsertf128   $0x1,%xmm1,%ymm1,%ymm8
  .byte  196,193,124,89,192                  // vmulps        %ymm8,%ymm0,%ymm0
  .byte  196,193,113,114,209,8               // vpsrld        $0x8,%xmm9,%xmm1
  .byte  196,99,125,25,203,1                 // vextractf128  $0x1,%ymm9,%xmm3
  .byte  197,233,114,211,8                   // vpsrld        $0x8,%xmm3,%xmm2
  .byte  196,227,117,24,202,1                // vinsertf128   $0x1,%xmm2,%ymm1,%ymm1
  .byte  196,193,116,84,202                  // vandps        %ymm10,%ymm1,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  196,193,116,89,200                  // vmulps        %ymm8,%ymm1,%ymm1
  .byte  196,193,33,114,209,16               // vpsrld        $0x10,%xmm9,%xmm11
  .byte  197,233,114,211,16                  // vpsrld        $0x10,%xmm3,%xmm2
  .byte  196,227,37,24,210,1                 // vinsertf128   $0x1,%xmm2,%ymm11,%ymm2
  .byte  196,193,108,84,210                  // vandps        %ymm10,%ymm2,%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  196,193,108,89,208                  // vmulps        %ymm8,%ymm2,%ymm2
  .byte  196,193,49,114,209,24               // vpsrld        $0x18,%xmm9,%xmm9
  .byte  197,225,114,211,24                  // vpsrld        $0x18,%xmm3,%xmm3
  .byte  196,227,53,24,219,1                 // vinsertf128   $0x1,%xmm3,%ymm9,%ymm3
  .byte  197,252,91,219                      // vcvtdq2ps     %ymm3,%ymm3
  .byte  196,193,100,89,216                  // vmulps        %ymm8,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  65,128,224,7                        // and           $0x7,%r8b
  .byte  196,65,52,87,201                    // vxorps        %ymm9,%ymm9,%ymm9
  .byte  65,254,200                          // dec           %r8b
  .byte  65,128,248,6                        // cmp           $0x6,%r8b
  .byte  15,135,90,255,255,255               // ja            3bb0 <_sk_load_8888_avx+0x14>
  .byte  69,15,182,192                       // movzbl        %r8b,%r8d
  .byte  76,141,13,139,0,0,0                 // lea           0x8b(%rip),%r9        # 3cec <_sk_load_8888_avx+0x150>
  .byte  75,99,4,129                         // movslq        (%r9,%r8,4),%rax
  .byte  76,1,200                            // add           %r9,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,193,121,110,68,186,24           // vmovd         0x18(%r10,%rdi,4),%xmm0
  .byte  197,249,112,192,68                  // vpshufd       $0x44,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  196,99,117,12,200,64                // vblendps      $0x40,%ymm0,%ymm1,%ymm9
  .byte  196,99,125,25,200,1                 // vextractf128  $0x1,%ymm9,%xmm0
  .byte  196,195,121,34,68,186,20,1          // vpinsrd       $0x1,0x14(%r10,%rdi,4),%xmm0,%xmm0
  .byte  196,99,53,24,200,1                  // vinsertf128   $0x1,%xmm0,%ymm9,%ymm9
  .byte  196,99,125,25,200,1                 // vextractf128  $0x1,%ymm9,%xmm0
  .byte  196,195,121,34,68,186,16,0          // vpinsrd       $0x0,0x10(%r10,%rdi,4),%xmm0,%xmm0
  .byte  196,99,53,24,200,1                  // vinsertf128   $0x1,%xmm0,%ymm9,%ymm9
  .byte  196,195,49,34,68,186,12,3           // vpinsrd       $0x3,0xc(%r10,%rdi,4),%xmm9,%xmm0
  .byte  196,99,53,12,200,15                 // vblendps      $0xf,%ymm0,%ymm9,%ymm9
  .byte  196,195,49,34,68,186,8,2            // vpinsrd       $0x2,0x8(%r10,%rdi,4),%xmm9,%xmm0
  .byte  196,99,53,12,200,15                 // vblendps      $0xf,%ymm0,%ymm9,%ymm9
  .byte  196,195,49,34,68,186,4,1            // vpinsrd       $0x1,0x4(%r10,%rdi,4),%xmm9,%xmm0
  .byte  196,99,53,12,200,15                 // vblendps      $0xf,%ymm0,%ymm9,%ymm9
  .byte  196,195,49,34,4,186,0               // vpinsrd       $0x0,(%r10,%rdi,4),%xmm9,%xmm0
  .byte  196,99,53,12,200,15                 // vblendps      $0xf,%ymm0,%ymm9,%ymm9
  .byte  233,198,254,255,255                 // jmpq          3bb0 <_sk_load_8888_avx+0x14>
  .byte  102,144                             // xchg          %ax,%ax
  .byte  236                                 // in            (%dx),%al
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  222,255                             // fdivrp        %st,%st(7)
  .byte  255                                 // (bad)
  .byte  255,208                             // callq         *%rax
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,194                             // inc           %edx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,174,255,255,255,154             // ljmp          *-0x65000001(%rsi)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  126,255                             // jle           3d05 <_sk_load_8888_avx+0x169>
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_gather_8888_avx
.globl _sk_gather_8888_avx
FUNCTION(_sk_gather_8888_avx)
_sk_gather_8888_avx:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  197,254,91,201                      // vcvttps2dq    %ymm1,%ymm1
  .byte  197,249,110,80,16                   // vmovd         0x10(%rax),%xmm2
  .byte  197,249,112,210,0                   // vpshufd       $0x0,%xmm2,%xmm2
  .byte  196,226,105,64,217                  // vpmulld       %xmm1,%xmm2,%xmm3
  .byte  196,227,125,25,201,1                // vextractf128  $0x1,%ymm1,%xmm1
  .byte  196,226,105,64,201                  // vpmulld       %xmm1,%xmm2,%xmm1
  .byte  197,254,91,192                      // vcvttps2dq    %ymm0,%ymm0
  .byte  196,227,125,25,194,1                // vextractf128  $0x1,%ymm0,%xmm2
  .byte  197,241,254,202                     // vpaddd        %xmm2,%xmm1,%xmm1
  .byte  196,225,249,126,200                 // vmovq         %xmm1,%rax
  .byte  65,137,193                          // mov           %eax,%r9d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  196,195,249,22,202,1                // vpextrq       $0x1,%xmm1,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  197,225,254,192                     // vpaddd        %xmm0,%xmm3,%xmm0
  .byte  196,225,249,126,195                 // vmovq         %xmm0,%rbx
  .byte  65,137,222                          // mov           %ebx,%r14d
  .byte  196,195,249,22,199,1                // vpextrq       $0x1,%xmm0,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  196,129,121,110,4,176               // vmovd         (%r8,%r14,4),%xmm0
  .byte  196,195,121,34,4,152,1              // vpinsrd       $0x1,(%r8,%rbx,4),%xmm0,%xmm0
  .byte  196,131,121,34,4,160,2              // vpinsrd       $0x2,(%r8,%r12,4),%xmm0,%xmm0
  .byte  196,3,121,34,4,184,3                // vpinsrd       $0x3,(%r8,%r15,4),%xmm0,%xmm8
  .byte  196,129,121,110,4,136               // vmovd         (%r8,%r9,4),%xmm0
  .byte  196,195,121,34,4,128,1              // vpinsrd       $0x1,(%r8,%rax,4),%xmm0,%xmm0
  .byte  196,131,121,34,4,152,2              // vpinsrd       $0x2,(%r8,%r11,4),%xmm0,%xmm0
  .byte  196,131,121,34,28,144,3             // vpinsrd       $0x3,(%r8,%r10,4),%xmm0,%xmm3
  .byte  196,227,61,24,195,1                 // vinsertf128   $0x1,%xmm3,%ymm8,%ymm0
  .byte  197,124,40,21,134,31,0,0            // vmovaps       0x1f86(%rip),%ymm10        # 5d40 <_sk_callback_avx+0x292>
  .byte  196,193,124,84,194                  // vandps        %ymm10,%ymm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,99,117,24,201,1                 // vinsertf128   $0x1,%xmm1,%ymm1,%ymm9
  .byte  196,193,124,89,193                  // vmulps        %ymm9,%ymm0,%ymm0
  .byte  196,193,113,114,208,8               // vpsrld        $0x8,%xmm8,%xmm1
  .byte  197,233,114,211,8                   // vpsrld        $0x8,%xmm3,%xmm2
  .byte  196,227,117,24,202,1                // vinsertf128   $0x1,%xmm2,%ymm1,%ymm1
  .byte  196,193,116,84,202                  // vandps        %ymm10,%ymm1,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  196,193,116,89,201                  // vmulps        %ymm9,%ymm1,%ymm1
  .byte  196,193,33,114,208,16               // vpsrld        $0x10,%xmm8,%xmm11
  .byte  197,233,114,211,16                  // vpsrld        $0x10,%xmm3,%xmm2
  .byte  196,227,37,24,210,1                 // vinsertf128   $0x1,%xmm2,%ymm11,%ymm2
  .byte  196,193,108,84,210                  // vandps        %ymm10,%ymm2,%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  196,193,108,89,209                  // vmulps        %ymm9,%ymm2,%ymm2
  .byte  196,193,57,114,208,24               // vpsrld        $0x18,%xmm8,%xmm8
  .byte  197,225,114,211,24                  // vpsrld        $0x18,%xmm3,%xmm3
  .byte  196,227,61,24,219,1                 // vinsertf128   $0x1,%xmm3,%ymm8,%ymm3
  .byte  197,252,91,219                      // vcvtdq2ps     %ymm3,%ymm3
  .byte  196,193,100,89,217                  // vmulps        %ymm9,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_8888_avx
.globl _sk_store_8888_avx
FUNCTION(_sk_store_8888_avx)
_sk_store_8888_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  184,0,0,127,67                      // mov           $0x437f0000,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,89,200                       // vmulps        %ymm0,%ymm8,%ymm9
  .byte  196,65,125,91,201                   // vcvtps2dq     %ymm9,%ymm9
  .byte  197,60,89,209                       // vmulps        %ymm1,%ymm8,%ymm10
  .byte  196,65,125,91,210                   // vcvtps2dq     %ymm10,%ymm10
  .byte  196,193,33,114,242,8                // vpslld        $0x8,%xmm10,%xmm11
  .byte  196,67,125,25,210,1                 // vextractf128  $0x1,%ymm10,%xmm10
  .byte  196,193,41,114,242,8                // vpslld        $0x8,%xmm10,%xmm10
  .byte  196,67,37,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm11,%ymm10
  .byte  196,65,45,86,201                    // vorpd         %ymm9,%ymm10,%ymm9
  .byte  197,60,89,210                       // vmulps        %ymm2,%ymm8,%ymm10
  .byte  196,65,125,91,210                   // vcvtps2dq     %ymm10,%ymm10
  .byte  196,193,33,114,242,16               // vpslld        $0x10,%xmm10,%xmm11
  .byte  196,67,125,25,210,1                 // vextractf128  $0x1,%ymm10,%xmm10
  .byte  196,193,41,114,242,16               // vpslld        $0x10,%xmm10,%xmm10
  .byte  196,67,37,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm11,%ymm10
  .byte  197,60,89,195                       // vmulps        %ymm3,%ymm8,%ymm8
  .byte  196,65,125,91,192                   // vcvtps2dq     %ymm8,%ymm8
  .byte  196,193,33,114,240,24               // vpslld        $0x18,%xmm8,%xmm11
  .byte  196,67,125,25,192,1                 // vextractf128  $0x1,%ymm8,%xmm8
  .byte  196,193,57,114,240,24               // vpslld        $0x18,%xmm8,%xmm8
  .byte  196,67,37,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm11,%ymm8
  .byte  196,65,45,86,192                    // vorpd         %ymm8,%ymm10,%ymm8
  .byte  196,65,53,86,192                    // vorpd         %ymm8,%ymm9,%ymm8
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  117,10                              // jne           3ee4 <_sk_store_8888_avx+0xa4>
  .byte  196,65,124,17,4,185                 // vmovups       %ymm8,(%r9,%rdi,4)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  65,128,224,7                        // and           $0x7,%r8b
  .byte  65,254,200                          // dec           %r8b
  .byte  65,128,248,6                        // cmp           $0x6,%r8b
  .byte  119,236                             // ja            3ee0 <_sk_store_8888_avx+0xa0>
  .byte  65,15,182,192                       // movzbl        %r8b,%eax
  .byte  76,141,5,85,0,0,0                   // lea           0x55(%rip),%r8        # 3f54 <_sk_store_8888_avx+0x114>
  .byte  73,99,4,128                         // movslq        (%r8,%rax,4),%rax
  .byte  76,1,192                            // add           %r8,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,67,125,25,193,1                 // vextractf128  $0x1,%ymm8,%xmm9
  .byte  196,67,121,22,76,185,24,2           // vpextrd       $0x2,%xmm9,0x18(%r9,%rdi,4)
  .byte  196,67,125,25,193,1                 // vextractf128  $0x1,%ymm8,%xmm9
  .byte  196,67,121,22,76,185,20,1           // vpextrd       $0x1,%xmm9,0x14(%r9,%rdi,4)
  .byte  196,67,125,25,193,1                 // vextractf128  $0x1,%ymm8,%xmm9
  .byte  196,65,122,17,76,185,16             // vmovss        %xmm9,0x10(%r9,%rdi,4)
  .byte  196,67,121,22,68,185,12,3           // vpextrd       $0x3,%xmm8,0xc(%r9,%rdi,4)
  .byte  196,67,121,22,68,185,8,2            // vpextrd       $0x2,%xmm8,0x8(%r9,%rdi,4)
  .byte  196,67,121,22,68,185,4,1            // vpextrd       $0x1,%xmm8,0x4(%r9,%rdi,4)
  .byte  196,65,121,126,4,185                // vmovd         %xmm8,(%r9,%rdi,4)
  .byte  235,143                             // jmp           3ee0 <_sk_store_8888_avx+0xa0>
  .byte  15,31,0                             // nopl          (%rax)
  .byte  245                                 // cmc
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  237                                 // in            (%dx),%eax
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,229                             // jmpq          *%rbp
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  221,255                             // (bad)
  .byte  255                                 // (bad)
  .byte  255,208                             // callq         *%rax
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,194                             // inc           %edx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff
  .byte  180,255                             // mov           $0xff,%ah
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_load_f16_avx
.globl _sk_load_f16_avx
FUNCTION(_sk_load_f16_avx)
_sk_load_f16_avx:
  .byte  72,131,236,24                       // sub           $0x18,%rsp
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  197,252,17,124,36,224               // vmovups       %ymm7,-0x20(%rsp)
  .byte  197,252,17,116,36,192               // vmovups       %ymm6,-0x40(%rsp)
  .byte  197,252,17,108,36,160               // vmovups       %ymm5,-0x60(%rsp)
  .byte  197,254,127,100,36,128              // vmovdqu       %ymm4,-0x80(%rsp)
  .byte  15,133,141,2,0,0                    // jne           4227 <_sk_load_f16_avx+0x2b7>
  .byte  197,121,16,4,248                    // vmovupd       (%rax,%rdi,8),%xmm8
  .byte  197,249,16,84,248,16                // vmovupd       0x10(%rax,%rdi,8),%xmm2
  .byte  197,249,16,76,248,32                // vmovupd       0x20(%rax,%rdi,8),%xmm1
  .byte  197,122,111,76,248,48               // vmovdqu       0x30(%rax,%rdi,8),%xmm9
  .byte  197,185,97,194                      // vpunpcklwd    %xmm2,%xmm8,%xmm0
  .byte  197,185,105,210                     // vpunpckhwd    %xmm2,%xmm8,%xmm2
  .byte  196,193,113,97,217                  // vpunpcklwd    %xmm9,%xmm1,%xmm3
  .byte  196,193,113,105,201                 // vpunpckhwd    %xmm9,%xmm1,%xmm1
  .byte  197,121,97,250                      // vpunpcklwd    %xmm2,%xmm0,%xmm15
  .byte  197,121,105,194                     // vpunpckhwd    %xmm2,%xmm0,%xmm8
  .byte  197,225,97,209                      // vpunpcklwd    %xmm1,%xmm3,%xmm2
  .byte  197,97,105,201                      // vpunpckhwd    %xmm1,%xmm3,%xmm9
  .byte  197,129,108,194                     // vpunpcklqdq   %xmm2,%xmm15,%xmm0
  .byte  197,241,239,201                     // vpxor         %xmm1,%xmm1,%xmm1
  .byte  197,249,105,201                     // vpunpckhwd    %xmm1,%xmm0,%xmm1
  .byte  196,226,121,51,192                  // vpmovzxwd     %xmm0,%xmm0
  .byte  196,227,125,24,193,1                // vinsertf128   $0x1,%xmm1,%ymm0,%ymm0
  .byte  196,98,125,24,37,169,28,0,0         // vbroadcastss  0x1ca9(%rip),%ymm12        # 5c9c <_sk_callback_avx+0x1ee>
  .byte  196,193,124,84,204                  // vandps        %ymm12,%ymm0,%ymm1
  .byte  197,252,87,193                      // vxorps        %ymm1,%ymm0,%ymm0
  .byte  196,195,125,25,198,1                // vextractf128  $0x1,%ymm0,%xmm14
  .byte  196,98,121,24,29,149,28,0,0         // vbroadcastss  0x1c95(%rip),%xmm11        # 5ca0 <_sk_callback_avx+0x1f2>
  .byte  196,193,8,87,219                    // vxorps        %xmm11,%xmm14,%xmm3
  .byte  196,98,121,24,45,139,28,0,0         // vbroadcastss  0x1c8b(%rip),%xmm13        # 5ca4 <_sk_callback_avx+0x1f6>
  .byte  197,145,102,219                     // vpcmpgtd      %xmm3,%xmm13,%xmm3
  .byte  196,65,120,87,211                   // vxorps        %xmm11,%xmm0,%xmm10
  .byte  196,65,17,102,210                   // vpcmpgtd      %xmm10,%xmm13,%xmm10
  .byte  196,99,45,24,211,1                  // vinsertf128   $0x1,%xmm3,%ymm10,%ymm10
  .byte  197,225,114,241,16                  // vpslld        $0x10,%xmm1,%xmm3
  .byte  196,227,125,25,201,1                // vextractf128  $0x1,%ymm1,%xmm1
  .byte  197,241,114,241,16                  // vpslld        $0x10,%xmm1,%xmm1
  .byte  196,227,101,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm3,%ymm1
  .byte  197,249,114,240,13                  // vpslld        $0xd,%xmm0,%xmm0
  .byte  196,193,97,114,246,13               // vpslld        $0xd,%xmm14,%xmm3
  .byte  196,227,125,24,195,1                // vinsertf128   $0x1,%xmm3,%ymm0,%ymm0
  .byte  197,252,86,193                      // vorps         %ymm1,%ymm0,%ymm0
  .byte  196,227,125,25,193,1                // vextractf128  $0x1,%ymm0,%xmm1
  .byte  196,226,121,24,29,65,28,0,0         // vbroadcastss  0x1c41(%rip),%xmm3        # 5ca8 <_sk_callback_avx+0x1fa>
  .byte  197,241,254,203                     // vpaddd        %xmm3,%xmm1,%xmm1
  .byte  197,249,254,195                     // vpaddd        %xmm3,%xmm0,%xmm0
  .byte  196,227,125,24,193,1                // vinsertf128   $0x1,%xmm1,%ymm0,%ymm0
  .byte  196,65,12,87,246                    // vxorps        %ymm14,%ymm14,%ymm14
  .byte  196,195,125,74,198,160              // vblendvps     %ymm10,%ymm14,%ymm0,%ymm0
  .byte  197,129,109,202                     // vpunpckhqdq   %xmm2,%xmm15,%xmm1
  .byte  197,217,239,228                     // vpxor         %xmm4,%xmm4,%xmm4
  .byte  197,241,105,212                     // vpunpckhwd    %xmm4,%xmm1,%xmm2
  .byte  196,226,121,51,201                  // vpmovzxwd     %xmm1,%xmm1
  .byte  196,227,117,24,202,1                // vinsertf128   $0x1,%xmm2,%ymm1,%ymm1
  .byte  196,193,116,84,212                  // vandps        %ymm12,%ymm1,%ymm2
  .byte  197,244,87,202                      // vxorps        %ymm2,%ymm1,%ymm1
  .byte  196,195,125,25,202,1                // vextractf128  $0x1,%ymm1,%xmm10
  .byte  196,193,40,87,251                   // vxorps        %xmm11,%xmm10,%xmm7
  .byte  197,145,102,255                     // vpcmpgtd      %xmm7,%xmm13,%xmm7
  .byte  196,193,112,87,243                  // vxorps        %xmm11,%xmm1,%xmm6
  .byte  197,145,102,246                     // vpcmpgtd      %xmm6,%xmm13,%xmm6
  .byte  196,227,77,24,247,1                 // vinsertf128   $0x1,%xmm7,%ymm6,%ymm6
  .byte  197,193,114,242,16                  // vpslld        $0x10,%xmm2,%xmm7
  .byte  196,227,125,25,210,1                // vextractf128  $0x1,%ymm2,%xmm2
  .byte  197,233,114,242,16                  // vpslld        $0x10,%xmm2,%xmm2
  .byte  196,227,69,24,210,1                 // vinsertf128   $0x1,%xmm2,%ymm7,%ymm2
  .byte  197,241,114,241,13                  // vpslld        $0xd,%xmm1,%xmm1
  .byte  196,193,65,114,242,13               // vpslld        $0xd,%xmm10,%xmm7
  .byte  196,227,117,24,207,1                // vinsertf128   $0x1,%xmm7,%ymm1,%ymm1
  .byte  197,244,86,202                      // vorps         %ymm2,%ymm1,%ymm1
  .byte  196,227,125,25,202,1                // vextractf128  $0x1,%ymm1,%xmm2
  .byte  197,233,254,211                     // vpaddd        %xmm3,%xmm2,%xmm2
  .byte  197,241,254,203                     // vpaddd        %xmm3,%xmm1,%xmm1
  .byte  196,227,117,24,202,1                // vinsertf128   $0x1,%xmm2,%ymm1,%ymm1
  .byte  196,195,117,74,206,96               // vblendvps     %ymm6,%ymm14,%ymm1,%ymm1
  .byte  196,193,57,108,209                  // vpunpcklqdq   %xmm9,%xmm8,%xmm2
  .byte  197,233,105,244                     // vpunpckhwd    %xmm4,%xmm2,%xmm6
  .byte  196,65,41,239,210                   // vpxor         %xmm10,%xmm10,%xmm10
  .byte  196,226,121,51,210                  // vpmovzxwd     %xmm2,%xmm2
  .byte  196,227,109,24,214,1                // vinsertf128   $0x1,%xmm6,%ymm2,%ymm2
  .byte  196,193,108,84,244                  // vandps        %ymm12,%ymm2,%ymm6
  .byte  197,236,87,214                      // vxorps        %ymm6,%ymm2,%ymm2
  .byte  196,227,125,25,215,1                // vextractf128  $0x1,%ymm2,%xmm7
  .byte  196,193,64,87,235                   // vxorps        %xmm11,%xmm7,%xmm5
  .byte  197,145,102,237                     // vpcmpgtd      %xmm5,%xmm13,%xmm5
  .byte  196,193,104,87,227                  // vxorps        %xmm11,%xmm2,%xmm4
  .byte  197,145,102,228                     // vpcmpgtd      %xmm4,%xmm13,%xmm4
  .byte  196,227,93,24,229,1                 // vinsertf128   $0x1,%xmm5,%ymm4,%ymm4
  .byte  197,209,114,246,16                  // vpslld        $0x10,%xmm6,%xmm5
  .byte  196,227,125,25,246,1                // vextractf128  $0x1,%ymm6,%xmm6
  .byte  197,201,114,246,16                  // vpslld        $0x10,%xmm6,%xmm6
  .byte  196,227,85,24,238,1                 // vinsertf128   $0x1,%xmm6,%ymm5,%ymm5
  .byte  197,233,114,242,13                  // vpslld        $0xd,%xmm2,%xmm2
  .byte  197,201,114,247,13                  // vpslld        $0xd,%xmm7,%xmm6
  .byte  196,227,109,24,214,1                // vinsertf128   $0x1,%xmm6,%ymm2,%ymm2
  .byte  197,236,86,213                      // vorps         %ymm5,%ymm2,%ymm2
  .byte  196,227,125,25,213,1                // vextractf128  $0x1,%ymm2,%xmm5
  .byte  197,209,254,235                     // vpaddd        %xmm3,%xmm5,%xmm5
  .byte  197,233,254,211                     // vpaddd        %xmm3,%xmm2,%xmm2
  .byte  196,227,109,24,213,1                // vinsertf128   $0x1,%xmm5,%ymm2,%ymm2
  .byte  196,195,109,74,214,64               // vblendvps     %ymm4,%ymm14,%ymm2,%ymm2
  .byte  196,193,57,109,225                  // vpunpckhqdq   %xmm9,%xmm8,%xmm4
  .byte  196,193,89,105,234                  // vpunpckhwd    %xmm10,%xmm4,%xmm5
  .byte  196,226,121,51,228                  // vpmovzxwd     %xmm4,%xmm4
  .byte  196,227,93,24,229,1                 // vinsertf128   $0x1,%xmm5,%ymm4,%ymm4
  .byte  196,193,92,84,236                   // vandps        %ymm12,%ymm4,%ymm5
  .byte  197,220,87,229                      // vxorps        %ymm5,%ymm4,%ymm4
  .byte  196,227,125,25,230,1                // vextractf128  $0x1,%ymm4,%xmm6
  .byte  196,193,72,87,251                   // vxorps        %xmm11,%xmm6,%xmm7
  .byte  197,17,102,199                      // vpcmpgtd      %xmm7,%xmm13,%xmm8
  .byte  196,193,88,87,251                   // vxorps        %xmm11,%xmm4,%xmm7
  .byte  197,145,102,255                     // vpcmpgtd      %xmm7,%xmm13,%xmm7
  .byte  196,195,69,24,248,1                 // vinsertf128   $0x1,%xmm8,%ymm7,%ymm7
  .byte  197,185,114,245,16                  // vpslld        $0x10,%xmm5,%xmm8
  .byte  196,227,125,25,237,1                // vextractf128  $0x1,%ymm5,%xmm5
  .byte  197,209,114,245,16                  // vpslld        $0x10,%xmm5,%xmm5
  .byte  196,227,61,24,237,1                 // vinsertf128   $0x1,%xmm5,%ymm8,%ymm5
  .byte  197,217,114,244,13                  // vpslld        $0xd,%xmm4,%xmm4
  .byte  197,201,114,246,13                  // vpslld        $0xd,%xmm6,%xmm6
  .byte  196,227,93,24,230,1                 // vinsertf128   $0x1,%xmm6,%ymm4,%ymm4
  .byte  197,220,86,229                      // vorps         %ymm5,%ymm4,%ymm4
  .byte  196,227,125,25,229,1                // vextractf128  $0x1,%ymm4,%xmm5
  .byte  197,209,254,235                     // vpaddd        %xmm3,%xmm5,%xmm5
  .byte  197,217,254,219                     // vpaddd        %xmm3,%xmm4,%xmm3
  .byte  196,227,101,24,221,1                // vinsertf128   $0x1,%xmm5,%ymm3,%ymm3
  .byte  196,195,101,74,222,112              // vblendvps     %ymm7,%ymm14,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,16,100,36,128               // vmovups       -0x80(%rsp),%ymm4
  .byte  197,252,16,108,36,160               // vmovups       -0x60(%rsp),%ymm5
  .byte  197,252,16,116,36,192               // vmovups       -0x40(%rsp),%ymm6
  .byte  197,252,16,124,36,224               // vmovups       -0x20(%rsp),%ymm7
  .byte  72,131,196,24                       // add           $0x18,%rsp
  .byte  255,224                             // jmpq          *%rax
  .byte  197,123,16,4,248                    // vmovsd        (%rax,%rdi,8),%xmm8
  .byte  196,65,49,239,201                   // vpxor         %xmm9,%xmm9,%xmm9
  .byte  72,131,249,1                        // cmp           $0x1,%rcx
  .byte  116,79                              // je            4286 <_sk_load_f16_avx+0x316>
  .byte  197,57,22,68,248,8                  // vmovhpd       0x8(%rax,%rdi,8),%xmm8,%xmm8
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  114,67                              // jb            4286 <_sk_load_f16_avx+0x316>
  .byte  197,251,16,84,248,16                // vmovsd        0x10(%rax,%rdi,8),%xmm2
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  116,68                              // je            4293 <_sk_load_f16_avx+0x323>
  .byte  197,233,22,84,248,24                // vmovhpd       0x18(%rax,%rdi,8),%xmm2,%xmm2
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  114,56                              // jb            4293 <_sk_load_f16_avx+0x323>
  .byte  197,251,16,76,248,32                // vmovsd        0x20(%rax,%rdi,8),%xmm1
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  15,132,70,253,255,255               // je            3fb1 <_sk_load_f16_avx+0x41>
  .byte  197,241,22,76,248,40                // vmovhpd       0x28(%rax,%rdi,8),%xmm1,%xmm1
  .byte  72,131,249,7                        // cmp           $0x7,%rcx
  .byte  15,130,54,253,255,255               // jb            3fb1 <_sk_load_f16_avx+0x41>
  .byte  197,122,126,76,248,48               // vmovq         0x30(%rax,%rdi,8),%xmm9
  .byte  233,43,253,255,255                  // jmpq          3fb1 <_sk_load_f16_avx+0x41>
  .byte  197,241,87,201                      // vxorpd        %xmm1,%xmm1,%xmm1
  .byte  197,233,87,210                      // vxorpd        %xmm2,%xmm2,%xmm2
  .byte  233,30,253,255,255                  // jmpq          3fb1 <_sk_load_f16_avx+0x41>
  .byte  197,241,87,201                      // vxorpd        %xmm1,%xmm1,%xmm1
  .byte  233,21,253,255,255                  // jmpq          3fb1 <_sk_load_f16_avx+0x41>

HIDDEN _sk_gather_f16_avx
.globl _sk_gather_f16_avx
FUNCTION(_sk_gather_f16_avx)
_sk_gather_f16_avx:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,131,236,24                       // sub           $0x18,%rsp
  .byte  197,252,17,124,36,224               // vmovups       %ymm7,-0x20(%rsp)
  .byte  197,252,17,116,36,192               // vmovups       %ymm6,-0x40(%rsp)
  .byte  197,252,17,108,36,160               // vmovups       %ymm5,-0x60(%rsp)
  .byte  197,254,127,100,36,128              // vmovdqu       %ymm4,-0x80(%rsp)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  197,254,91,209                      // vcvttps2dq    %ymm1,%ymm2
  .byte  197,249,110,72,16                   // vmovd         0x10(%rax),%xmm1
  .byte  197,249,112,217,0                   // vpshufd       $0x0,%xmm1,%xmm3
  .byte  196,226,97,64,202                   // vpmulld       %xmm2,%xmm3,%xmm1
  .byte  196,227,125,25,210,1                // vextractf128  $0x1,%ymm2,%xmm2
  .byte  196,226,97,64,210                   // vpmulld       %xmm2,%xmm3,%xmm2
  .byte  197,254,91,192                      // vcvttps2dq    %ymm0,%ymm0
  .byte  196,227,125,25,195,1                // vextractf128  $0x1,%ymm0,%xmm3
  .byte  197,233,254,211                     // vpaddd        %xmm3,%xmm2,%xmm2
  .byte  196,227,249,22,208,1                // vpextrq       $0x1,%xmm2,%rax
  .byte  65,137,193                          // mov           %eax,%r9d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  196,193,249,126,210                 // vmovq         %xmm2,%r10
  .byte  69,137,211                          // mov           %r10d,%r11d
  .byte  73,193,234,32                       // shr           $0x20,%r10
  .byte  197,241,254,192                     // vpaddd        %xmm0,%xmm1,%xmm0
  .byte  196,225,249,126,195                 // vmovq         %xmm0,%rbx
  .byte  65,137,222                          // mov           %ebx,%r14d
  .byte  196,195,249,22,199,1                // vpextrq       $0x1,%xmm0,%r15
  .byte  69,137,252                          // mov           %r15d,%r12d
  .byte  73,193,239,32                       // shr           $0x20,%r15
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  196,193,122,126,4,216               // vmovq         (%r8,%rbx,8),%xmm0
  .byte  196,129,122,126,12,240              // vmovq         (%r8,%r14,8),%xmm1
  .byte  197,113,108,200                     // vpunpcklqdq   %xmm0,%xmm1,%xmm9
  .byte  196,129,122,126,12,248              // vmovq         (%r8,%r15,8),%xmm1
  .byte  196,129,122,126,20,224              // vmovq         (%r8,%r12,8),%xmm2
  .byte  197,233,108,201                     // vpunpcklqdq   %xmm1,%xmm2,%xmm1
  .byte  196,129,122,126,20,208              // vmovq         (%r8,%r10,8),%xmm2
  .byte  196,129,122,126,28,216              // vmovq         (%r8,%r11,8),%xmm3
  .byte  197,97,108,210                      // vpunpcklqdq   %xmm2,%xmm3,%xmm10
  .byte  196,65,122,126,4,192                // vmovq         (%r8,%rax,8),%xmm8
  .byte  196,129,122,126,28,200              // vmovq         (%r8,%r9,8),%xmm3
  .byte  196,193,97,108,216                  // vpunpcklqdq   %xmm8,%xmm3,%xmm3
  .byte  197,177,97,193                      // vpunpcklwd    %xmm1,%xmm9,%xmm0
  .byte  197,177,105,201                     // vpunpckhwd    %xmm1,%xmm9,%xmm1
  .byte  197,169,97,211                      // vpunpcklwd    %xmm3,%xmm10,%xmm2
  .byte  197,169,105,219                     // vpunpckhwd    %xmm3,%xmm10,%xmm3
  .byte  197,121,97,249                      // vpunpcklwd    %xmm1,%xmm0,%xmm15
  .byte  197,121,105,193                     // vpunpckhwd    %xmm1,%xmm0,%xmm8
  .byte  197,233,97,203                      // vpunpcklwd    %xmm3,%xmm2,%xmm1
  .byte  197,105,105,203                     // vpunpckhwd    %xmm3,%xmm2,%xmm9
  .byte  197,129,108,193                     // vpunpcklqdq   %xmm1,%xmm15,%xmm0
  .byte  197,233,239,210                     // vpxor         %xmm2,%xmm2,%xmm2
  .byte  197,249,105,210                     // vpunpckhwd    %xmm2,%xmm0,%xmm2
  .byte  196,226,121,51,192                  // vpmovzxwd     %xmm0,%xmm0
  .byte  196,227,125,24,194,1                // vinsertf128   $0x1,%xmm2,%ymm0,%ymm0
  .byte  196,98,125,24,37,5,25,0,0           // vbroadcastss  0x1905(%rip),%ymm12        # 5cac <_sk_callback_avx+0x1fe>
  .byte  196,193,124,84,212                  // vandps        %ymm12,%ymm0,%ymm2
  .byte  197,252,87,194                      // vxorps        %ymm2,%ymm0,%ymm0
  .byte  196,195,125,25,198,1                // vextractf128  $0x1,%ymm0,%xmm14
  .byte  196,98,121,24,29,241,24,0,0         // vbroadcastss  0x18f1(%rip),%xmm11        # 5cb0 <_sk_callback_avx+0x202>
  .byte  196,193,8,87,219                    // vxorps        %xmm11,%xmm14,%xmm3
  .byte  196,98,121,24,45,231,24,0,0         // vbroadcastss  0x18e7(%rip),%xmm13        # 5cb4 <_sk_callback_avx+0x206>
  .byte  197,145,102,219                     // vpcmpgtd      %xmm3,%xmm13,%xmm3
  .byte  196,65,120,87,211                   // vxorps        %xmm11,%xmm0,%xmm10
  .byte  196,65,17,102,210                   // vpcmpgtd      %xmm10,%xmm13,%xmm10
  .byte  196,99,45,24,211,1                  // vinsertf128   $0x1,%xmm3,%ymm10,%ymm10
  .byte  197,225,114,242,16                  // vpslld        $0x10,%xmm2,%xmm3
  .byte  196,227,125,25,210,1                // vextractf128  $0x1,%ymm2,%xmm2
  .byte  197,233,114,242,16                  // vpslld        $0x10,%xmm2,%xmm2
  .byte  196,227,101,24,210,1                // vinsertf128   $0x1,%xmm2,%ymm3,%ymm2
  .byte  197,249,114,240,13                  // vpslld        $0xd,%xmm0,%xmm0
  .byte  196,193,97,114,246,13               // vpslld        $0xd,%xmm14,%xmm3
  .byte  196,227,125,24,195,1                // vinsertf128   $0x1,%xmm3,%ymm0,%ymm0
  .byte  197,252,86,194                      // vorps         %ymm2,%ymm0,%ymm0
  .byte  196,227,125,25,194,1                // vextractf128  $0x1,%ymm0,%xmm2
  .byte  196,226,121,24,29,157,24,0,0        // vbroadcastss  0x189d(%rip),%xmm3        # 5cb8 <_sk_callback_avx+0x20a>
  .byte  197,233,254,211                     // vpaddd        %xmm3,%xmm2,%xmm2
  .byte  197,249,254,195                     // vpaddd        %xmm3,%xmm0,%xmm0
  .byte  196,227,125,24,194,1                // vinsertf128   $0x1,%xmm2,%ymm0,%ymm0
  .byte  196,65,12,87,246                    // vxorps        %ymm14,%ymm14,%ymm14
  .byte  196,195,125,74,198,160              // vblendvps     %ymm10,%ymm14,%ymm0,%ymm0
  .byte  197,129,109,201                     // vpunpckhqdq   %xmm1,%xmm15,%xmm1
  .byte  197,217,239,228                     // vpxor         %xmm4,%xmm4,%xmm4
  .byte  197,241,105,212                     // vpunpckhwd    %xmm4,%xmm1,%xmm2
  .byte  196,226,121,51,201                  // vpmovzxwd     %xmm1,%xmm1
  .byte  196,227,117,24,202,1                // vinsertf128   $0x1,%xmm2,%ymm1,%ymm1
  .byte  196,193,116,84,212                  // vandps        %ymm12,%ymm1,%ymm2
  .byte  197,244,87,202                      // vxorps        %ymm2,%ymm1,%ymm1
  .byte  196,195,125,25,202,1                // vextractf128  $0x1,%ymm1,%xmm10
  .byte  196,193,40,87,251                   // vxorps        %xmm11,%xmm10,%xmm7
  .byte  197,145,102,255                     // vpcmpgtd      %xmm7,%xmm13,%xmm7
  .byte  196,193,112,87,243                  // vxorps        %xmm11,%xmm1,%xmm6
  .byte  197,145,102,246                     // vpcmpgtd      %xmm6,%xmm13,%xmm6
  .byte  196,227,77,24,247,1                 // vinsertf128   $0x1,%xmm7,%ymm6,%ymm6
  .byte  197,193,114,242,16                  // vpslld        $0x10,%xmm2,%xmm7
  .byte  196,227,125,25,210,1                // vextractf128  $0x1,%ymm2,%xmm2
  .byte  197,233,114,242,16                  // vpslld        $0x10,%xmm2,%xmm2
  .byte  196,227,69,24,210,1                 // vinsertf128   $0x1,%xmm2,%ymm7,%ymm2
  .byte  197,241,114,241,13                  // vpslld        $0xd,%xmm1,%xmm1
  .byte  196,193,65,114,242,13               // vpslld        $0xd,%xmm10,%xmm7
  .byte  196,227,117,24,207,1                // vinsertf128   $0x1,%xmm7,%ymm1,%ymm1
  .byte  197,244,86,202                      // vorps         %ymm2,%ymm1,%ymm1
  .byte  196,227,125,25,202,1                // vextractf128  $0x1,%ymm1,%xmm2
  .byte  197,233,254,211                     // vpaddd        %xmm3,%xmm2,%xmm2
  .byte  197,241,254,203                     // vpaddd        %xmm3,%xmm1,%xmm1
  .byte  196,227,117,24,202,1                // vinsertf128   $0x1,%xmm2,%ymm1,%ymm1
  .byte  196,195,117,74,206,96               // vblendvps     %ymm6,%ymm14,%ymm1,%ymm1
  .byte  196,193,57,108,209                  // vpunpcklqdq   %xmm9,%xmm8,%xmm2
  .byte  197,233,105,244                     // vpunpckhwd    %xmm4,%xmm2,%xmm6
  .byte  196,65,41,239,210                   // vpxor         %xmm10,%xmm10,%xmm10
  .byte  196,226,121,51,210                  // vpmovzxwd     %xmm2,%xmm2
  .byte  196,227,109,24,214,1                // vinsertf128   $0x1,%xmm6,%ymm2,%ymm2
  .byte  196,193,108,84,244                  // vandps        %ymm12,%ymm2,%ymm6
  .byte  197,236,87,214                      // vxorps        %ymm6,%ymm2,%ymm2
  .byte  196,227,125,25,215,1                // vextractf128  $0x1,%ymm2,%xmm7
  .byte  196,193,64,87,235                   // vxorps        %xmm11,%xmm7,%xmm5
  .byte  197,145,102,237                     // vpcmpgtd      %xmm5,%xmm13,%xmm5
  .byte  196,193,104,87,227                  // vxorps        %xmm11,%xmm2,%xmm4
  .byte  197,145,102,228                     // vpcmpgtd      %xmm4,%xmm13,%xmm4
  .byte  196,227,93,24,229,1                 // vinsertf128   $0x1,%xmm5,%ymm4,%ymm4
  .byte  197,209,114,246,16                  // vpslld        $0x10,%xmm6,%xmm5
  .byte  196,227,125,25,246,1                // vextractf128  $0x1,%ymm6,%xmm6
  .byte  197,201,114,246,16                  // vpslld        $0x10,%xmm6,%xmm6
  .byte  196,227,85,24,238,1                 // vinsertf128   $0x1,%xmm6,%ymm5,%ymm5
  .byte  197,233,114,242,13                  // vpslld        $0xd,%xmm2,%xmm2
  .byte  197,201,114,247,13                  // vpslld        $0xd,%xmm7,%xmm6
  .byte  196,227,109,24,214,1                // vinsertf128   $0x1,%xmm6,%ymm2,%ymm2
  .byte  197,236,86,213                      // vorps         %ymm5,%ymm2,%ymm2
  .byte  196,227,125,25,213,1                // vextractf128  $0x1,%ymm2,%xmm5
  .byte  197,209,254,235                     // vpaddd        %xmm3,%xmm5,%xmm5
  .byte  197,233,254,211                     // vpaddd        %xmm3,%xmm2,%xmm2
  .byte  196,227,109,24,213,1                // vinsertf128   $0x1,%xmm5,%ymm2,%ymm2
  .byte  196,195,109,74,214,64               // vblendvps     %ymm4,%ymm14,%ymm2,%ymm2
  .byte  196,193,57,109,225                  // vpunpckhqdq   %xmm9,%xmm8,%xmm4
  .byte  196,193,89,105,234                  // vpunpckhwd    %xmm10,%xmm4,%xmm5
  .byte  196,226,121,51,228                  // vpmovzxwd     %xmm4,%xmm4
  .byte  196,227,93,24,229,1                 // vinsertf128   $0x1,%xmm5,%ymm4,%ymm4
  .byte  196,193,92,84,236                   // vandps        %ymm12,%ymm4,%ymm5
  .byte  197,220,87,229                      // vxorps        %ymm5,%ymm4,%ymm4
  .byte  196,227,125,25,230,1                // vextractf128  $0x1,%ymm4,%xmm6
  .byte  196,193,72,87,251                   // vxorps        %xmm11,%xmm6,%xmm7
  .byte  197,17,102,199                      // vpcmpgtd      %xmm7,%xmm13,%xmm8
  .byte  196,193,88,87,251                   // vxorps        %xmm11,%xmm4,%xmm7
  .byte  197,145,102,255                     // vpcmpgtd      %xmm7,%xmm13,%xmm7
  .byte  196,195,69,24,248,1                 // vinsertf128   $0x1,%xmm8,%ymm7,%ymm7
  .byte  197,185,114,245,16                  // vpslld        $0x10,%xmm5,%xmm8
  .byte  196,227,125,25,237,1                // vextractf128  $0x1,%ymm5,%xmm5
  .byte  197,209,114,245,16                  // vpslld        $0x10,%xmm5,%xmm5
  .byte  196,227,61,24,237,1                 // vinsertf128   $0x1,%xmm5,%ymm8,%ymm5
  .byte  197,217,114,244,13                  // vpslld        $0xd,%xmm4,%xmm4
  .byte  197,201,114,246,13                  // vpslld        $0xd,%xmm6,%xmm6
  .byte  196,227,93,24,230,1                 // vinsertf128   $0x1,%xmm6,%ymm4,%ymm4
  .byte  197,220,86,229                      // vorps         %ymm5,%ymm4,%ymm4
  .byte  196,227,125,25,229,1                // vextractf128  $0x1,%ymm4,%xmm5
  .byte  197,209,254,235                     // vpaddd        %xmm3,%xmm5,%xmm5
  .byte  197,217,254,219                     // vpaddd        %xmm3,%xmm4,%xmm3
  .byte  196,227,101,24,221,1                // vinsertf128   $0x1,%xmm5,%ymm3,%ymm3
  .byte  196,195,101,74,222,112              // vblendvps     %ymm7,%ymm14,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,16,100,36,128               // vmovups       -0x80(%rsp),%ymm4
  .byte  197,252,16,108,36,160               // vmovups       -0x60(%rsp),%ymm5
  .byte  197,252,16,116,36,192               // vmovups       -0x40(%rsp),%ymm6
  .byte  197,252,16,124,36,224               // vmovups       -0x20(%rsp),%ymm7
  .byte  72,131,196,24                       // add           $0x18,%rsp
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_f16_avx
.globl _sk_store_f16_avx
FUNCTION(_sk_store_f16_avx)
_sk_store_f16_avx:
  .byte  72,131,236,88                       // sub           $0x58,%rsp
  .byte  197,252,17,124,36,32                // vmovups       %ymm7,0x20(%rsp)
  .byte  197,252,17,52,36                    // vmovups       %ymm6,(%rsp)
  .byte  197,252,17,108,36,224               // vmovups       %ymm5,-0x20(%rsp)
  .byte  197,252,17,100,36,192               // vmovups       %ymm4,-0x40(%rsp)
  .byte  196,98,125,24,13,182,22,0,0         // vbroadcastss  0x16b6(%rip),%ymm9        # 5cbc <_sk_callback_avx+0x20e>
  .byte  196,65,124,84,209                   // vandps        %ymm9,%ymm0,%ymm10
  .byte  197,252,17,68,36,128                // vmovups       %ymm0,-0x80(%rsp)
  .byte  196,65,124,87,218                   // vxorps        %ymm10,%ymm0,%ymm11
  .byte  196,67,125,25,220,1                 // vextractf128  $0x1,%ymm11,%xmm12
  .byte  196,98,121,24,5,155,22,0,0          // vbroadcastss  0x169b(%rip),%xmm8        # 5cc0 <_sk_callback_avx+0x212>
  .byte  196,65,57,102,236                   // vpcmpgtd      %xmm12,%xmm8,%xmm13
  .byte  196,65,57,102,243                   // vpcmpgtd      %xmm11,%xmm8,%xmm14
  .byte  196,67,13,24,237,1                  // vinsertf128   $0x1,%xmm13,%ymm14,%ymm13
  .byte  196,193,9,114,210,16                // vpsrld        $0x10,%xmm10,%xmm14
  .byte  196,67,125,25,210,1                 // vextractf128  $0x1,%ymm10,%xmm10
  .byte  196,193,41,114,210,16               // vpsrld        $0x10,%xmm10,%xmm10
  .byte  196,67,13,24,242,1                  // vinsertf128   $0x1,%xmm10,%ymm14,%ymm14
  .byte  196,193,33,114,211,13               // vpsrld        $0xd,%xmm11,%xmm11
  .byte  196,193,25,114,212,13               // vpsrld        $0xd,%xmm12,%xmm12
  .byte  196,98,125,24,21,98,22,0,0          // vbroadcastss  0x1662(%rip),%ymm10        # 5cc4 <_sk_callback_avx+0x216>
  .byte  196,65,12,86,242                    // vorps         %ymm10,%ymm14,%ymm14
  .byte  196,67,125,25,247,1                 // vextractf128  $0x1,%ymm14,%xmm15
  .byte  196,65,1,254,228                    // vpaddd        %xmm12,%xmm15,%xmm12
  .byte  196,65,9,254,219                    // vpaddd        %xmm11,%xmm14,%xmm11
  .byte  196,67,37,24,228,1                  // vinsertf128   $0x1,%xmm12,%ymm11,%ymm12
  .byte  197,252,87,192                      // vxorps        %ymm0,%ymm0,%ymm0
  .byte  196,99,29,74,224,208                // vblendvps     %ymm13,%ymm0,%ymm12,%ymm12
  .byte  196,65,116,84,233                   // vandps        %ymm9,%ymm1,%ymm13
  .byte  197,252,17,76,36,160                // vmovups       %ymm1,-0x60(%rsp)
  .byte  196,65,116,87,245                   // vxorps        %ymm13,%ymm1,%ymm14
  .byte  196,67,125,25,247,1                 // vextractf128  $0x1,%ymm14,%xmm15
  .byte  196,193,57,102,255                  // vpcmpgtd      %xmm15,%xmm8,%xmm7
  .byte  196,65,57,102,222                   // vpcmpgtd      %xmm14,%xmm8,%xmm11
  .byte  196,227,37,24,255,1                 // vinsertf128   $0x1,%xmm7,%ymm11,%ymm7
  .byte  196,193,33,114,213,16               // vpsrld        $0x10,%xmm13,%xmm11
  .byte  196,99,125,25,238,1                 // vextractf128  $0x1,%ymm13,%xmm6
  .byte  197,201,114,214,16                  // vpsrld        $0x10,%xmm6,%xmm6
  .byte  196,227,37,24,246,1                 // vinsertf128   $0x1,%xmm6,%ymm11,%ymm6
  .byte  196,193,33,114,215,13               // vpsrld        $0xd,%xmm15,%xmm11
  .byte  196,193,76,86,242                   // vorps         %ymm10,%ymm6,%ymm6
  .byte  196,227,125,25,245,1                // vextractf128  $0x1,%ymm6,%xmm5
  .byte  196,193,81,254,235                  // vpaddd        %xmm11,%xmm5,%xmm5
  .byte  196,193,89,114,214,13               // vpsrld        $0xd,%xmm14,%xmm4
  .byte  197,201,254,228                     // vpaddd        %xmm4,%xmm6,%xmm4
  .byte  196,227,93,24,229,1                 // vinsertf128   $0x1,%xmm5,%ymm4,%ymm4
  .byte  196,99,93,74,232,112                // vblendvps     %ymm7,%ymm0,%ymm4,%ymm13
  .byte  196,193,108,84,225                  // vandps        %ymm9,%ymm2,%ymm4
  .byte  197,236,87,236                      // vxorps        %ymm4,%ymm2,%ymm5
  .byte  196,227,125,25,238,1                // vextractf128  $0x1,%ymm5,%xmm6
  .byte  197,185,102,254                     // vpcmpgtd      %xmm6,%xmm8,%xmm7
  .byte  197,57,102,221                      // vpcmpgtd      %xmm5,%xmm8,%xmm11
  .byte  196,227,37,24,255,1                 // vinsertf128   $0x1,%xmm7,%ymm11,%ymm7
  .byte  197,161,114,212,16                  // vpsrld        $0x10,%xmm4,%xmm11
  .byte  196,227,125,25,228,1                // vextractf128  $0x1,%ymm4,%xmm4
  .byte  197,217,114,212,16                  // vpsrld        $0x10,%xmm4,%xmm4
  .byte  196,227,37,24,228,1                 // vinsertf128   $0x1,%xmm4,%ymm11,%ymm4
  .byte  197,201,114,214,13                  // vpsrld        $0xd,%xmm6,%xmm6
  .byte  196,193,92,86,226                   // vorps         %ymm10,%ymm4,%ymm4
  .byte  196,227,125,25,225,1                // vextractf128  $0x1,%ymm4,%xmm1
  .byte  197,241,254,206                     // vpaddd        %xmm6,%xmm1,%xmm1
  .byte  197,209,114,213,13                  // vpsrld        $0xd,%xmm5,%xmm5
  .byte  197,217,254,229                     // vpaddd        %xmm5,%xmm4,%xmm4
  .byte  196,227,93,24,201,1                 // vinsertf128   $0x1,%xmm1,%ymm4,%ymm1
  .byte  196,99,117,74,216,112               // vblendvps     %ymm7,%ymm0,%ymm1,%ymm11
  .byte  196,193,100,84,225                  // vandps        %ymm9,%ymm3,%ymm4
  .byte  197,228,87,236                      // vxorps        %ymm4,%ymm3,%ymm5
  .byte  196,227,125,25,238,1                // vextractf128  $0x1,%ymm5,%xmm6
  .byte  197,185,102,254                     // vpcmpgtd      %xmm6,%xmm8,%xmm7
  .byte  197,57,102,197                      // vpcmpgtd      %xmm5,%xmm8,%xmm8
  .byte  196,227,61,24,255,1                 // vinsertf128   $0x1,%xmm7,%ymm8,%ymm7
  .byte  197,185,114,212,16                  // vpsrld        $0x10,%xmm4,%xmm8
  .byte  196,227,125,25,228,1                // vextractf128  $0x1,%ymm4,%xmm4
  .byte  197,217,114,212,16                  // vpsrld        $0x10,%xmm4,%xmm4
  .byte  196,227,61,24,228,1                 // vinsertf128   $0x1,%xmm4,%ymm8,%ymm4
  .byte  196,193,92,86,226                   // vorps         %ymm10,%ymm4,%ymm4
  .byte  197,201,114,214,13                  // vpsrld        $0xd,%xmm6,%xmm6
  .byte  196,227,125,25,225,1                // vextractf128  $0x1,%ymm4,%xmm1
  .byte  197,241,254,206                     // vpaddd        %xmm6,%xmm1,%xmm1
  .byte  197,209,114,213,13                  // vpsrld        $0xd,%xmm5,%xmm5
  .byte  197,217,254,229                     // vpaddd        %xmm5,%xmm4,%xmm4
  .byte  196,227,93,24,201,1                 // vinsertf128   $0x1,%xmm1,%ymm4,%ymm1
  .byte  196,227,117,74,200,112              // vblendvps     %ymm7,%ymm0,%ymm1,%ymm1
  .byte  196,99,125,25,224,1                 // vextractf128  $0x1,%ymm12,%xmm0
  .byte  196,226,25,43,192                   // vpackusdw     %xmm0,%xmm12,%xmm0
  .byte  196,99,125,25,236,1                 // vextractf128  $0x1,%ymm13,%xmm4
  .byte  196,226,17,43,228                   // vpackusdw     %xmm4,%xmm13,%xmm4
  .byte  196,99,125,25,221,1                 // vextractf128  $0x1,%ymm11,%xmm5
  .byte  196,226,33,43,245                   // vpackusdw     %xmm5,%xmm11,%xmm6
  .byte  196,227,125,25,205,1                // vextractf128  $0x1,%ymm1,%xmm5
  .byte  196,226,113,43,205                  // vpackusdw     %xmm5,%xmm1,%xmm1
  .byte  197,249,97,236                      // vpunpcklwd    %xmm4,%xmm0,%xmm5
  .byte  197,249,105,196                     // vpunpckhwd    %xmm4,%xmm0,%xmm0
  .byte  197,201,97,225                      // vpunpcklwd    %xmm1,%xmm6,%xmm4
  .byte  197,201,105,201                     // vpunpckhwd    %xmm1,%xmm6,%xmm1
  .byte  197,81,98,220                       // vpunpckldq    %xmm4,%xmm5,%xmm11
  .byte  197,81,106,212                      // vpunpckhdq    %xmm4,%xmm5,%xmm10
  .byte  197,121,98,201                      // vpunpckldq    %xmm1,%xmm0,%xmm9
  .byte  197,121,106,193                     // vpunpckhdq    %xmm1,%xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  117,66                              // jne           4840 <_sk_store_f16_avx+0x25e>
  .byte  197,120,17,28,248                   // vmovups       %xmm11,(%rax,%rdi,8)
  .byte  197,120,17,84,248,16                // vmovups       %xmm10,0x10(%rax,%rdi,8)
  .byte  197,120,17,76,248,32                // vmovups       %xmm9,0x20(%rax,%rdi,8)
  .byte  197,122,127,68,248,48               // vmovdqu       %xmm8,0x30(%rax,%rdi,8)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,16,68,36,128                // vmovups       -0x80(%rsp),%ymm0
  .byte  197,252,16,76,36,160                // vmovups       -0x60(%rsp),%ymm1
  .byte  197,252,16,100,36,192               // vmovups       -0x40(%rsp),%ymm4
  .byte  197,252,16,108,36,224               // vmovups       -0x20(%rsp),%ymm5
  .byte  197,252,16,52,36                    // vmovups       (%rsp),%ymm6
  .byte  197,252,16,124,36,32                // vmovups       0x20(%rsp),%ymm7
  .byte  72,131,196,88                       // add           $0x58,%rsp
  .byte  255,224                             // jmpq          *%rax
  .byte  197,121,214,28,248                  // vmovq         %xmm11,(%rax,%rdi,8)
  .byte  72,131,249,1                        // cmp           $0x1,%rcx
  .byte  116,202                             // je            4815 <_sk_store_f16_avx+0x233>
  .byte  197,121,23,92,248,8                 // vmovhpd       %xmm11,0x8(%rax,%rdi,8)
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  114,190                             // jb            4815 <_sk_store_f16_avx+0x233>
  .byte  197,121,214,84,248,16               // vmovq         %xmm10,0x10(%rax,%rdi,8)
  .byte  116,182                             // je            4815 <_sk_store_f16_avx+0x233>
  .byte  197,121,23,84,248,24                // vmovhpd       %xmm10,0x18(%rax,%rdi,8)
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  114,170                             // jb            4815 <_sk_store_f16_avx+0x233>
  .byte  197,121,214,76,248,32               // vmovq         %xmm9,0x20(%rax,%rdi,8)
  .byte  116,162                             // je            4815 <_sk_store_f16_avx+0x233>
  .byte  197,121,23,76,248,40                // vmovhpd       %xmm9,0x28(%rax,%rdi,8)
  .byte  72,131,249,7                        // cmp           $0x7,%rcx
  .byte  114,150                             // jb            4815 <_sk_store_f16_avx+0x233>
  .byte  197,121,214,68,248,48               // vmovq         %xmm8,0x30(%rax,%rdi,8)
  .byte  235,142                             // jmp           4815 <_sk_store_f16_avx+0x233>

HIDDEN _sk_load_u16_be_avx
.globl _sk_load_u16_be_avx
FUNCTION(_sk_load_u16_be_avx)
_sk_load_u16_be_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  72,141,4,189,0,0,0,0                // lea           0x0(,%rdi,4),%rax
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  15,133,5,1,0,0                      // jne           49a2 <_sk_load_u16_be_avx+0x11b>
  .byte  196,65,121,16,4,64                  // vmovupd       (%r8,%rax,2),%xmm8
  .byte  196,193,121,16,84,64,16             // vmovupd       0x10(%r8,%rax,2),%xmm2
  .byte  196,193,121,16,92,64,32             // vmovupd       0x20(%r8,%rax,2),%xmm3
  .byte  196,65,122,111,76,64,48             // vmovdqu       0x30(%r8,%rax,2),%xmm9
  .byte  197,185,97,194                      // vpunpcklwd    %xmm2,%xmm8,%xmm0
  .byte  197,185,105,210                     // vpunpckhwd    %xmm2,%xmm8,%xmm2
  .byte  196,193,97,97,201                   // vpunpcklwd    %xmm9,%xmm3,%xmm1
  .byte  196,193,97,105,217                  // vpunpckhwd    %xmm9,%xmm3,%xmm3
  .byte  197,121,97,210                      // vpunpcklwd    %xmm2,%xmm0,%xmm10
  .byte  197,121,105,194                     // vpunpckhwd    %xmm2,%xmm0,%xmm8
  .byte  197,241,97,211                      // vpunpcklwd    %xmm3,%xmm1,%xmm2
  .byte  197,113,105,203                     // vpunpckhwd    %xmm3,%xmm1,%xmm9
  .byte  184,128,0,128,55                    // mov           $0x37800080,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,99,125,24,224,1                 // vinsertf128   $0x1,%xmm0,%ymm0,%ymm12
  .byte  197,169,108,194                     // vpunpcklqdq   %xmm2,%xmm10,%xmm0
  .byte  197,241,113,240,8                   // vpsllw        $0x8,%xmm0,%xmm1
  .byte  197,249,113,208,8                   // vpsrlw        $0x8,%xmm0,%xmm0
  .byte  197,241,235,192                     // vpor          %xmm0,%xmm1,%xmm0
  .byte  196,65,33,239,219                   // vpxor         %xmm11,%xmm11,%xmm11
  .byte  196,193,121,105,203                 // vpunpckhwd    %xmm11,%xmm0,%xmm1
  .byte  196,226,121,51,192                  // vpmovzxwd     %xmm0,%xmm0
  .byte  196,227,125,24,193,1                // vinsertf128   $0x1,%xmm1,%ymm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  197,156,89,192                      // vmulps        %ymm0,%ymm12,%ymm0
  .byte  197,169,109,202                     // vpunpckhqdq   %xmm2,%xmm10,%xmm1
  .byte  197,233,113,241,8                   // vpsllw        $0x8,%xmm1,%xmm2
  .byte  197,241,113,209,8                   // vpsrlw        $0x8,%xmm1,%xmm1
  .byte  197,233,235,201                     // vpor          %xmm1,%xmm2,%xmm1
  .byte  196,193,113,105,211                 // vpunpckhwd    %xmm11,%xmm1,%xmm2
  .byte  196,226,121,51,201                  // vpmovzxwd     %xmm1,%xmm1
  .byte  196,227,117,24,202,1                // vinsertf128   $0x1,%xmm2,%ymm1,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  197,156,89,201                      // vmulps        %ymm1,%ymm12,%ymm1
  .byte  196,193,57,108,209                  // vpunpcklqdq   %xmm9,%xmm8,%xmm2
  .byte  197,169,113,242,8                   // vpsllw        $0x8,%xmm2,%xmm10
  .byte  197,233,113,210,8                   // vpsrlw        $0x8,%xmm2,%xmm2
  .byte  197,169,235,210                     // vpor          %xmm2,%xmm10,%xmm2
  .byte  196,65,105,105,211                  // vpunpckhwd    %xmm11,%xmm2,%xmm10
  .byte  196,226,121,51,210                  // vpmovzxwd     %xmm2,%xmm2
  .byte  196,195,109,24,210,1                // vinsertf128   $0x1,%xmm10,%ymm2,%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  197,156,89,210                      // vmulps        %ymm2,%ymm12,%ymm2
  .byte  196,193,57,109,217                  // vpunpckhqdq   %xmm9,%xmm8,%xmm3
  .byte  197,185,113,243,8                   // vpsllw        $0x8,%xmm3,%xmm8
  .byte  197,225,113,211,8                   // vpsrlw        $0x8,%xmm3,%xmm3
  .byte  197,185,235,219                     // vpor          %xmm3,%xmm8,%xmm3
  .byte  196,65,97,105,195                   // vpunpckhwd    %xmm11,%xmm3,%xmm8
  .byte  196,226,121,51,219                  // vpmovzxwd     %xmm3,%xmm3
  .byte  196,195,101,24,216,1                // vinsertf128   $0x1,%xmm8,%ymm3,%ymm3
  .byte  197,252,91,219                      // vcvtdq2ps     %ymm3,%ymm3
  .byte  197,156,89,219                      // vmulps        %ymm3,%ymm12,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,65,123,16,4,64                  // vmovsd        (%r8,%rax,2),%xmm8
  .byte  196,65,49,239,201                   // vpxor         %xmm9,%xmm9,%xmm9
  .byte  72,131,249,1                        // cmp           $0x1,%rcx
  .byte  116,85                              // je            4a08 <_sk_load_u16_be_avx+0x181>
  .byte  196,65,57,22,68,64,8                // vmovhpd       0x8(%r8,%rax,2),%xmm8,%xmm8
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  114,72                              // jb            4a08 <_sk_load_u16_be_avx+0x181>
  .byte  196,193,123,16,84,64,16             // vmovsd        0x10(%r8,%rax,2),%xmm2
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  116,72                              // je            4a15 <_sk_load_u16_be_avx+0x18e>
  .byte  196,193,105,22,84,64,24             // vmovhpd       0x18(%r8,%rax,2),%xmm2,%xmm2
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  114,59                              // jb            4a15 <_sk_load_u16_be_avx+0x18e>
  .byte  196,193,123,16,92,64,32             // vmovsd        0x20(%r8,%rax,2),%xmm3
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  15,132,205,254,255,255              // je            48b8 <_sk_load_u16_be_avx+0x31>
  .byte  196,193,97,22,92,64,40              // vmovhpd       0x28(%r8,%rax,2),%xmm3,%xmm3
  .byte  72,131,249,7                        // cmp           $0x7,%rcx
  .byte  15,130,188,254,255,255              // jb            48b8 <_sk_load_u16_be_avx+0x31>
  .byte  196,65,122,126,76,64,48             // vmovq         0x30(%r8,%rax,2),%xmm9
  .byte  233,176,254,255,255                 // jmpq          48b8 <_sk_load_u16_be_avx+0x31>
  .byte  197,225,87,219                      // vxorpd        %xmm3,%xmm3,%xmm3
  .byte  197,233,87,210                      // vxorpd        %xmm2,%xmm2,%xmm2
  .byte  233,163,254,255,255                 // jmpq          48b8 <_sk_load_u16_be_avx+0x31>
  .byte  197,225,87,219                      // vxorpd        %xmm3,%xmm3,%xmm3
  .byte  233,154,254,255,255                 // jmpq          48b8 <_sk_load_u16_be_avx+0x31>

HIDDEN _sk_load_rgb_u16_be_avx
.globl _sk_load_rgb_u16_be_avx
FUNCTION(_sk_load_rgb_u16_be_avx)
_sk_load_rgb_u16_be_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  72,141,4,127                        // lea           (%rdi,%rdi,2),%rax
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  15,133,8,1,0,0                      // jne           4b38 <_sk_load_rgb_u16_be_avx+0x11a>
  .byte  196,193,122,111,4,64                // vmovdqu       (%r8,%rax,2),%xmm0
  .byte  196,193,122,111,84,64,12            // vmovdqu       0xc(%r8,%rax,2),%xmm2
  .byte  196,193,122,111,76,64,24            // vmovdqu       0x18(%r8,%rax,2),%xmm1
  .byte  196,193,122,111,92,64,32            // vmovdqu       0x20(%r8,%rax,2),%xmm3
  .byte  197,225,115,219,4                   // vpsrldq       $0x4,%xmm3,%xmm3
  .byte  197,185,115,216,6                   // vpsrldq       $0x6,%xmm0,%xmm8
  .byte  197,177,115,218,6                   // vpsrldq       $0x6,%xmm2,%xmm9
  .byte  197,161,115,217,6                   // vpsrldq       $0x6,%xmm1,%xmm11
  .byte  197,169,115,219,6                   // vpsrldq       $0x6,%xmm3,%xmm10
  .byte  197,249,97,194                      // vpunpcklwd    %xmm2,%xmm0,%xmm0
  .byte  196,193,57,97,209                   // vpunpcklwd    %xmm9,%xmm8,%xmm2
  .byte  197,241,97,203                      // vpunpcklwd    %xmm3,%xmm1,%xmm1
  .byte  196,193,33,97,218                   // vpunpcklwd    %xmm10,%xmm11,%xmm3
  .byte  197,121,97,194                      // vpunpcklwd    %xmm2,%xmm0,%xmm8
  .byte  197,121,105,202                     // vpunpckhwd    %xmm2,%xmm0,%xmm9
  .byte  197,241,97,211                      // vpunpcklwd    %xmm3,%xmm1,%xmm2
  .byte  197,113,105,219                     // vpunpckhwd    %xmm3,%xmm1,%xmm11
  .byte  184,128,0,128,55                    // mov           $0x37800080,%eax
  .byte  197,249,110,192                     // vmovd         %eax,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,99,125,24,208,1                 // vinsertf128   $0x1,%xmm0,%ymm0,%ymm10
  .byte  197,185,108,194                     // vpunpcklqdq   %xmm2,%xmm8,%xmm0
  .byte  197,241,113,240,8                   // vpsllw        $0x8,%xmm0,%xmm1
  .byte  197,249,113,208,8                   // vpsrlw        $0x8,%xmm0,%xmm0
  .byte  197,241,235,192                     // vpor          %xmm0,%xmm1,%xmm0
  .byte  196,65,25,239,228                   // vpxor         %xmm12,%xmm12,%xmm12
  .byte  196,193,121,105,204                 // vpunpckhwd    %xmm12,%xmm0,%xmm1
  .byte  196,226,121,51,192                  // vpmovzxwd     %xmm0,%xmm0
  .byte  196,227,125,24,193,1                // vinsertf128   $0x1,%xmm1,%ymm0,%ymm0
  .byte  197,252,91,192                      // vcvtdq2ps     %ymm0,%ymm0
  .byte  197,172,89,192                      // vmulps        %ymm0,%ymm10,%ymm0
  .byte  197,185,109,202                     // vpunpckhqdq   %xmm2,%xmm8,%xmm1
  .byte  197,233,113,241,8                   // vpsllw        $0x8,%xmm1,%xmm2
  .byte  197,241,113,209,8                   // vpsrlw        $0x8,%xmm1,%xmm1
  .byte  197,233,235,201                     // vpor          %xmm1,%xmm2,%xmm1
  .byte  196,193,113,105,212                 // vpunpckhwd    %xmm12,%xmm1,%xmm2
  .byte  196,226,121,51,201                  // vpmovzxwd     %xmm1,%xmm1
  .byte  196,227,117,24,202,1                // vinsertf128   $0x1,%xmm2,%ymm1,%ymm1
  .byte  197,252,91,201                      // vcvtdq2ps     %ymm1,%ymm1
  .byte  197,172,89,201                      // vmulps        %ymm1,%ymm10,%ymm1
  .byte  196,193,49,108,211                  // vpunpcklqdq   %xmm11,%xmm9,%xmm2
  .byte  197,225,113,242,8                   // vpsllw        $0x8,%xmm2,%xmm3
  .byte  197,233,113,210,8                   // vpsrlw        $0x8,%xmm2,%xmm2
  .byte  197,225,235,210                     // vpor          %xmm2,%xmm3,%xmm2
  .byte  196,193,105,105,220                 // vpunpckhwd    %xmm12,%xmm2,%xmm3
  .byte  196,226,121,51,210                  // vpmovzxwd     %xmm2,%xmm2
  .byte  196,227,109,24,211,1                // vinsertf128   $0x1,%xmm3,%ymm2,%ymm2
  .byte  197,252,91,210                      // vcvtdq2ps     %ymm2,%ymm2
  .byte  197,172,89,210                      // vmulps        %ymm2,%ymm10,%ymm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,193,121,110,4,64                // vmovd         (%r8,%rax,2),%xmm0
  .byte  196,193,121,196,68,64,4,2           // vpinsrw       $0x2,0x4(%r8,%rax,2),%xmm0,%xmm0
  .byte  72,131,249,1                        // cmp           $0x1,%rcx
  .byte  117,5                               // jne           4b51 <_sk_load_rgb_u16_be_avx+0x133>
  .byte  233,19,255,255,255                  // jmpq          4a64 <_sk_load_rgb_u16_be_avx+0x46>
  .byte  196,193,121,110,76,64,6             // vmovd         0x6(%r8,%rax,2),%xmm1
  .byte  196,65,113,196,68,64,10,2           // vpinsrw       $0x2,0xa(%r8,%rax,2),%xmm1,%xmm8
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  114,26                              // jb            4b80 <_sk_load_rgb_u16_be_avx+0x162>
  .byte  196,193,121,110,76,64,12            // vmovd         0xc(%r8,%rax,2),%xmm1
  .byte  196,193,113,196,84,64,16,2          // vpinsrw       $0x2,0x10(%r8,%rax,2),%xmm1,%xmm2
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  117,10                              // jne           4b85 <_sk_load_rgb_u16_be_avx+0x167>
  .byte  233,228,254,255,255                 // jmpq          4a64 <_sk_load_rgb_u16_be_avx+0x46>
  .byte  233,223,254,255,255                 // jmpq          4a64 <_sk_load_rgb_u16_be_avx+0x46>
  .byte  196,193,121,110,76,64,18            // vmovd         0x12(%r8,%rax,2),%xmm1
  .byte  196,65,113,196,76,64,22,2           // vpinsrw       $0x2,0x16(%r8,%rax,2),%xmm1,%xmm9
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  114,26                              // jb            4bb4 <_sk_load_rgb_u16_be_avx+0x196>
  .byte  196,193,121,110,76,64,24            // vmovd         0x18(%r8,%rax,2),%xmm1
  .byte  196,193,113,196,76,64,28,2          // vpinsrw       $0x2,0x1c(%r8,%rax,2),%xmm1,%xmm1
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  117,10                              // jne           4bb9 <_sk_load_rgb_u16_be_avx+0x19b>
  .byte  233,176,254,255,255                 // jmpq          4a64 <_sk_load_rgb_u16_be_avx+0x46>
  .byte  233,171,254,255,255                 // jmpq          4a64 <_sk_load_rgb_u16_be_avx+0x46>
  .byte  196,193,121,110,92,64,30            // vmovd         0x1e(%r8,%rax,2),%xmm3
  .byte  196,65,97,196,92,64,34,2            // vpinsrw       $0x2,0x22(%r8,%rax,2),%xmm3,%xmm11
  .byte  72,131,249,7                        // cmp           $0x7,%rcx
  .byte  114,20                              // jb            4be2 <_sk_load_rgb_u16_be_avx+0x1c4>
  .byte  196,193,121,110,92,64,36            // vmovd         0x24(%r8,%rax,2),%xmm3
  .byte  196,193,97,196,92,64,40,2           // vpinsrw       $0x2,0x28(%r8,%rax,2),%xmm3,%xmm3
  .byte  233,130,254,255,255                 // jmpq          4a64 <_sk_load_rgb_u16_be_avx+0x46>
  .byte  233,125,254,255,255                 // jmpq          4a64 <_sk_load_rgb_u16_be_avx+0x46>

HIDDEN _sk_store_u16_be_avx
.globl _sk_store_u16_be_avx
FUNCTION(_sk_store_u16_be_avx)
_sk_store_u16_be_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  76,141,12,189,0,0,0,0               // lea           0x0(,%rdi,4),%r9
  .byte  184,0,255,127,71                    // mov           $0x477fff00,%eax
  .byte  197,121,110,192                     // vmovd         %eax,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,89,200                       // vmulps        %ymm0,%ymm8,%ymm9
  .byte  196,65,125,91,201                   // vcvtps2dq     %ymm9,%ymm9
  .byte  196,67,125,25,202,1                 // vextractf128  $0x1,%ymm9,%xmm10
  .byte  196,66,49,43,202                    // vpackusdw     %xmm10,%xmm9,%xmm9
  .byte  196,193,41,113,241,8                // vpsllw        $0x8,%xmm9,%xmm10
  .byte  196,193,49,113,209,8                // vpsrlw        $0x8,%xmm9,%xmm9
  .byte  196,65,41,235,201                   // vpor          %xmm9,%xmm10,%xmm9
  .byte  197,60,89,209                       // vmulps        %ymm1,%ymm8,%ymm10
  .byte  196,65,125,91,210                   // vcvtps2dq     %ymm10,%ymm10
  .byte  196,67,125,25,211,1                 // vextractf128  $0x1,%ymm10,%xmm11
  .byte  196,66,41,43,211                    // vpackusdw     %xmm11,%xmm10,%xmm10
  .byte  196,193,33,113,242,8                // vpsllw        $0x8,%xmm10,%xmm11
  .byte  196,193,41,113,210,8                // vpsrlw        $0x8,%xmm10,%xmm10
  .byte  196,65,33,235,210                   // vpor          %xmm10,%xmm11,%xmm10
  .byte  197,60,89,218                       // vmulps        %ymm2,%ymm8,%ymm11
  .byte  196,65,125,91,219                   // vcvtps2dq     %ymm11,%ymm11
  .byte  196,67,125,25,220,1                 // vextractf128  $0x1,%ymm11,%xmm12
  .byte  196,66,33,43,220                    // vpackusdw     %xmm12,%xmm11,%xmm11
  .byte  196,193,25,113,243,8                // vpsllw        $0x8,%xmm11,%xmm12
  .byte  196,193,33,113,211,8                // vpsrlw        $0x8,%xmm11,%xmm11
  .byte  196,65,25,235,219                   // vpor          %xmm11,%xmm12,%xmm11
  .byte  197,60,89,195                       // vmulps        %ymm3,%ymm8,%ymm8
  .byte  196,65,125,91,192                   // vcvtps2dq     %ymm8,%ymm8
  .byte  196,67,125,25,196,1                 // vextractf128  $0x1,%ymm8,%xmm12
  .byte  196,66,57,43,196                    // vpackusdw     %xmm12,%xmm8,%xmm8
  .byte  196,193,25,113,240,8                // vpsllw        $0x8,%xmm8,%xmm12
  .byte  196,193,57,113,208,8                // vpsrlw        $0x8,%xmm8,%xmm8
  .byte  196,65,25,235,192                   // vpor          %xmm8,%xmm12,%xmm8
  .byte  196,65,49,97,226                    // vpunpcklwd    %xmm10,%xmm9,%xmm12
  .byte  196,65,49,105,234                   // vpunpckhwd    %xmm10,%xmm9,%xmm13
  .byte  196,65,33,97,200                    // vpunpcklwd    %xmm8,%xmm11,%xmm9
  .byte  196,65,33,105,192                   // vpunpckhwd    %xmm8,%xmm11,%xmm8
  .byte  196,65,25,98,217                    // vpunpckldq    %xmm9,%xmm12,%xmm11
  .byte  196,65,25,106,209                   // vpunpckhdq    %xmm9,%xmm12,%xmm10
  .byte  196,65,17,98,200                    // vpunpckldq    %xmm8,%xmm13,%xmm9
  .byte  196,65,17,106,192                   // vpunpckhdq    %xmm8,%xmm13,%xmm8
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  117,31                              // jne           4ce9 <_sk_store_u16_be_avx+0x102>
  .byte  196,1,120,17,28,72                  // vmovups       %xmm11,(%r8,%r9,2)
  .byte  196,1,120,17,84,72,16               // vmovups       %xmm10,0x10(%r8,%r9,2)
  .byte  196,1,120,17,76,72,32               // vmovups       %xmm9,0x20(%r8,%r9,2)
  .byte  196,1,122,127,68,72,48              // vmovdqu       %xmm8,0x30(%r8,%r9,2)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,1,121,214,28,72                 // vmovq         %xmm11,(%r8,%r9,2)
  .byte  72,131,249,1                        // cmp           $0x1,%rcx
  .byte  116,240                             // je            4ce5 <_sk_store_u16_be_avx+0xfe>
  .byte  196,1,121,23,92,72,8                // vmovhpd       %xmm11,0x8(%r8,%r9,2)
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  114,227                             // jb            4ce5 <_sk_store_u16_be_avx+0xfe>
  .byte  196,1,121,214,84,72,16              // vmovq         %xmm10,0x10(%r8,%r9,2)
  .byte  116,218                             // je            4ce5 <_sk_store_u16_be_avx+0xfe>
  .byte  196,1,121,23,84,72,24               // vmovhpd       %xmm10,0x18(%r8,%r9,2)
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  114,205                             // jb            4ce5 <_sk_store_u16_be_avx+0xfe>
  .byte  196,1,121,214,76,72,32              // vmovq         %xmm9,0x20(%r8,%r9,2)
  .byte  116,196                             // je            4ce5 <_sk_store_u16_be_avx+0xfe>
  .byte  196,1,121,23,76,72,40               // vmovhpd       %xmm9,0x28(%r8,%r9,2)
  .byte  72,131,249,7                        // cmp           $0x7,%rcx
  .byte  114,183                             // jb            4ce5 <_sk_store_u16_be_avx+0xfe>
  .byte  196,1,121,214,68,72,48              // vmovq         %xmm8,0x30(%r8,%r9,2)
  .byte  235,174                             // jmp           4ce5 <_sk_store_u16_be_avx+0xfe>

HIDDEN _sk_load_f32_avx
.globl _sk_load_f32_avx
FUNCTION(_sk_load_f32_avx)
_sk_load_f32_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,131,249,7                        // cmp           $0x7,%rcx
  .byte  119,110                             // ja            4dad <_sk_load_f32_avx+0x76>
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  76,141,12,189,0,0,0,0               // lea           0x0(,%rdi,4),%r9
  .byte  76,141,21,135,0,0,0                 // lea           0x87(%rip),%r10        # 4dd8 <_sk_load_f32_avx+0xa1>
  .byte  73,99,4,138                         // movslq        (%r10,%rcx,4),%rax
  .byte  76,1,208                            // add           %r10,%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,3,125,24,68,136,112,1           // vinsertf128   $0x1,0x70(%r8,%r9,4),%ymm0,%ymm8
  .byte  196,131,125,24,92,136,96,1          // vinsertf128   $0x1,0x60(%r8,%r9,4),%ymm0,%ymm3
  .byte  196,131,125,24,76,136,80,1          // vinsertf128   $0x1,0x50(%r8,%r9,4),%ymm0,%ymm1
  .byte  196,131,125,24,84,136,64,1          // vinsertf128   $0x1,0x40(%r8,%r9,4),%ymm0,%ymm2
  .byte  196,129,121,16,68,136,48            // vmovupd       0x30(%r8,%r9,4),%xmm0
  .byte  196,195,125,13,192,12               // vblendpd      $0xc,%ymm8,%ymm0,%ymm0
  .byte  196,1,121,16,68,136,32              // vmovupd       0x20(%r8,%r9,4),%xmm8
  .byte  196,99,61,13,203,12                 // vblendpd      $0xc,%ymm3,%ymm8,%ymm9
  .byte  196,129,121,16,92,136,16            // vmovupd       0x10(%r8,%r9,4),%xmm3
  .byte  196,99,101,13,209,12                // vblendpd      $0xc,%ymm1,%ymm3,%ymm10
  .byte  196,129,121,16,12,136               // vmovupd       (%r8,%r9,4),%xmm1
  .byte  196,227,117,13,202,12               // vblendpd      $0xc,%ymm2,%ymm1,%ymm1
  .byte  196,193,116,20,210                  // vunpcklps     %ymm10,%ymm1,%ymm2
  .byte  196,193,116,21,218                  // vunpckhps     %ymm10,%ymm1,%ymm3
  .byte  197,180,20,200                      // vunpcklps     %ymm0,%ymm9,%ymm1
  .byte  197,52,21,192                       // vunpckhps     %ymm0,%ymm9,%ymm8
  .byte  197,237,20,193                      // vunpcklpd     %ymm1,%ymm2,%ymm0
  .byte  197,237,21,201                      // vunpckhpd     %ymm1,%ymm2,%ymm1
  .byte  196,193,101,20,208                  // vunpcklpd     %ymm8,%ymm3,%ymm2
  .byte  196,193,101,21,216                  // vunpckhpd     %ymm8,%ymm3,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  15,31,0                             // nopl          (%rax)
  .byte  130                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,201                             // dec           %ecx
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  188,255,255,255,175                 // mov           $0xafffffff,%esp
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,162,255,255,255,154             // jmpq          *-0x65000001(%rdx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,146,255,255,255,138             // callq         *-0x75000001(%rdx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // .byte         0xff

HIDDEN _sk_store_f32_avx
.globl _sk_store_f32_avx
FUNCTION(_sk_store_f32_avx)
_sk_store_f32_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  72,141,4,189,0,0,0,0                // lea           0x0(,%rdi,4),%rax
  .byte  197,124,20,193                      // vunpcklps     %ymm1,%ymm0,%ymm8
  .byte  197,124,21,217                      // vunpckhps     %ymm1,%ymm0,%ymm11
  .byte  197,108,20,203                      // vunpcklps     %ymm3,%ymm2,%ymm9
  .byte  197,108,21,227                      // vunpckhps     %ymm3,%ymm2,%ymm12
  .byte  196,65,61,20,209                    // vunpcklpd     %ymm9,%ymm8,%ymm10
  .byte  196,65,61,21,201                    // vunpckhpd     %ymm9,%ymm8,%ymm9
  .byte  196,65,37,20,196                    // vunpcklpd     %ymm12,%ymm11,%ymm8
  .byte  196,65,37,21,220                    // vunpckhpd     %ymm12,%ymm11,%ymm11
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  117,55                              // jne           4e65 <_sk_store_f32_avx+0x6d>
  .byte  196,67,45,24,225,1                  // vinsertf128   $0x1,%xmm9,%ymm10,%ymm12
  .byte  196,67,61,24,235,1                  // vinsertf128   $0x1,%xmm11,%ymm8,%ymm13
  .byte  196,67,45,6,201,49                  // vperm2f128    $0x31,%ymm9,%ymm10,%ymm9
  .byte  196,67,61,6,195,49                  // vperm2f128    $0x31,%ymm11,%ymm8,%ymm8
  .byte  196,65,125,17,36,128                // vmovupd       %ymm12,(%r8,%rax,4)
  .byte  196,65,125,17,108,128,32            // vmovupd       %ymm13,0x20(%r8,%rax,4)
  .byte  196,65,125,17,76,128,64             // vmovupd       %ymm9,0x40(%r8,%rax,4)
  .byte  196,65,125,17,68,128,96             // vmovupd       %ymm8,0x60(%r8,%rax,4)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax
  .byte  196,65,121,17,20,128                // vmovupd       %xmm10,(%r8,%rax,4)
  .byte  72,131,249,1                        // cmp           $0x1,%rcx
  .byte  116,240                             // je            4e61 <_sk_store_f32_avx+0x69>
  .byte  196,65,121,17,76,128,16             // vmovupd       %xmm9,0x10(%r8,%rax,4)
  .byte  72,131,249,3                        // cmp           $0x3,%rcx
  .byte  114,227                             // jb            4e61 <_sk_store_f32_avx+0x69>
  .byte  196,65,121,17,68,128,32             // vmovupd       %xmm8,0x20(%r8,%rax,4)
  .byte  116,218                             // je            4e61 <_sk_store_f32_avx+0x69>
  .byte  196,65,121,17,92,128,48             // vmovupd       %xmm11,0x30(%r8,%rax,4)
  .byte  72,131,249,5                        // cmp           $0x5,%rcx
  .byte  114,205                             // jb            4e61 <_sk_store_f32_avx+0x69>
  .byte  196,67,125,25,84,128,64,1           // vextractf128  $0x1,%ymm10,0x40(%r8,%rax,4)
  .byte  116,195                             // je            4e61 <_sk_store_f32_avx+0x69>
  .byte  196,67,125,25,76,128,80,1           // vextractf128  $0x1,%ymm9,0x50(%r8,%rax,4)
  .byte  72,131,249,7                        // cmp           $0x7,%rcx
  .byte  114,181                             // jb            4e61 <_sk_store_f32_avx+0x69>
  .byte  196,67,125,25,68,128,96,1           // vextractf128  $0x1,%ymm8,0x60(%r8,%rax,4)
  .byte  235,171                             // jmp           4e61 <_sk_store_f32_avx+0x69>

HIDDEN _sk_clamp_x_avx
.globl _sk_clamp_x_avx
FUNCTION(_sk_clamp_x_avx)
_sk_clamp_x_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  197,60,95,200                       // vmaxps        %ymm0,%ymm8,%ymm9
  .byte  196,98,125,24,0                     // vbroadcastss  (%rax),%ymm8
  .byte  196,99,125,25,192,1                 // vextractf128  $0x1,%ymm8,%xmm0
  .byte  196,65,41,118,210                   // vpcmpeqd      %xmm10,%xmm10,%xmm10
  .byte  196,193,121,254,194                 // vpaddd        %xmm10,%xmm0,%xmm0
  .byte  196,65,57,254,194                   // vpaddd        %xmm10,%xmm8,%xmm8
  .byte  196,227,61,24,192,1                 // vinsertf128   $0x1,%xmm0,%ymm8,%ymm0
  .byte  197,180,93,192                      // vminps        %ymm0,%ymm9,%ymm0
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_y_avx
.globl _sk_clamp_y_avx
FUNCTION(_sk_clamp_y_avx)
_sk_clamp_y_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  197,60,95,201                       // vmaxps        %ymm1,%ymm8,%ymm9
  .byte  196,98,125,24,0                     // vbroadcastss  (%rax),%ymm8
  .byte  196,99,125,25,193,1                 // vextractf128  $0x1,%ymm8,%xmm1
  .byte  196,65,41,118,210                   // vpcmpeqd      %xmm10,%xmm10,%xmm10
  .byte  196,193,113,254,202                 // vpaddd        %xmm10,%xmm1,%xmm1
  .byte  196,65,57,254,194                   // vpaddd        %xmm10,%xmm8,%xmm8
  .byte  196,227,61,24,201,1                 // vinsertf128   $0x1,%xmm1,%ymm8,%ymm1
  .byte  197,180,93,201                      // vminps        %ymm1,%ymm9,%ymm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_repeat_x_avx
.globl _sk_repeat_x_avx
FUNCTION(_sk_repeat_x_avx)
_sk_repeat_x_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,0                     // vbroadcastss  (%rax),%ymm8
  .byte  196,65,124,94,200                   // vdivps        %ymm8,%ymm0,%ymm9
  .byte  196,67,125,8,201,1                  // vroundps      $0x1,%ymm9,%ymm9
  .byte  196,65,52,89,200                    // vmulps        %ymm8,%ymm9,%ymm9
  .byte  196,65,124,92,201                   // vsubps        %ymm9,%ymm0,%ymm9
  .byte  196,99,125,25,192,1                 // vextractf128  $0x1,%ymm8,%xmm0
  .byte  196,65,41,118,210                   // vpcmpeqd      %xmm10,%xmm10,%xmm10
  .byte  196,193,121,254,194                 // vpaddd        %xmm10,%xmm0,%xmm0
  .byte  196,65,57,254,194                   // vpaddd        %xmm10,%xmm8,%xmm8
  .byte  196,227,61,24,192,1                 // vinsertf128   $0x1,%xmm0,%ymm8,%ymm0
  .byte  197,180,93,192                      // vminps        %ymm0,%ymm9,%ymm0
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_repeat_y_avx
.globl _sk_repeat_y_avx
FUNCTION(_sk_repeat_y_avx)
_sk_repeat_y_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,0                     // vbroadcastss  (%rax),%ymm8
  .byte  196,65,116,94,200                   // vdivps        %ymm8,%ymm1,%ymm9
  .byte  196,67,125,8,201,1                  // vroundps      $0x1,%ymm9,%ymm9
  .byte  196,65,52,89,200                    // vmulps        %ymm8,%ymm9,%ymm9
  .byte  196,65,116,92,201                   // vsubps        %ymm9,%ymm1,%ymm9
  .byte  196,99,125,25,193,1                 // vextractf128  $0x1,%ymm8,%xmm1
  .byte  196,65,41,118,210                   // vpcmpeqd      %xmm10,%xmm10,%xmm10
  .byte  196,193,113,254,202                 // vpaddd        %xmm10,%xmm1,%xmm1
  .byte  196,65,57,254,194                   // vpaddd        %xmm10,%xmm8,%xmm8
  .byte  196,227,61,24,201,1                 // vinsertf128   $0x1,%xmm1,%ymm8,%ymm1
  .byte  197,180,93,201                      // vminps        %ymm1,%ymm9,%ymm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_mirror_x_avx
.globl _sk_mirror_x_avx
FUNCTION(_sk_mirror_x_avx)
_sk_mirror_x_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,121,110,0                       // vmovd         (%rax),%xmm8
  .byte  196,65,121,112,200,0                // vpshufd       $0x0,%xmm8,%xmm9
  .byte  196,67,53,24,201,1                  // vinsertf128   $0x1,%xmm9,%ymm9,%ymm9
  .byte  196,65,124,92,209                   // vsubps        %ymm9,%ymm0,%ymm10
  .byte  196,193,58,88,192                   // vaddss        %xmm8,%xmm8,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,44,94,192                       // vdivps        %ymm0,%ymm10,%ymm8
  .byte  196,67,125,8,192,1                  // vroundps      $0x1,%ymm8,%ymm8
  .byte  197,188,89,192                      // vmulps        %ymm0,%ymm8,%ymm0
  .byte  197,172,92,192                      // vsubps        %ymm0,%ymm10,%ymm0
  .byte  196,193,124,92,193                  // vsubps        %ymm9,%ymm0,%ymm0
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  197,60,92,192                       // vsubps        %ymm0,%ymm8,%ymm8
  .byte  197,60,84,192                       // vandps        %ymm0,%ymm8,%ymm8
  .byte  196,99,125,25,200,1                 // vextractf128  $0x1,%ymm9,%xmm0
  .byte  196,65,41,118,210                   // vpcmpeqd      %xmm10,%xmm10,%xmm10
  .byte  196,193,121,254,194                 // vpaddd        %xmm10,%xmm0,%xmm0
  .byte  196,65,49,254,202                   // vpaddd        %xmm10,%xmm9,%xmm9
  .byte  196,227,53,24,192,1                 // vinsertf128   $0x1,%xmm0,%ymm9,%ymm0
  .byte  197,188,93,192                      // vminps        %ymm0,%ymm8,%ymm0
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_mirror_y_avx
.globl _sk_mirror_y_avx
FUNCTION(_sk_mirror_y_avx)
_sk_mirror_y_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,121,110,0                       // vmovd         (%rax),%xmm8
  .byte  196,65,121,112,200,0                // vpshufd       $0x0,%xmm8,%xmm9
  .byte  196,67,53,24,201,1                  // vinsertf128   $0x1,%xmm9,%ymm9,%ymm9
  .byte  196,65,116,92,209                   // vsubps        %ymm9,%ymm1,%ymm10
  .byte  196,193,58,88,200                   // vaddss        %xmm8,%xmm8,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,44,94,193                       // vdivps        %ymm1,%ymm10,%ymm8
  .byte  196,67,125,8,192,1                  // vroundps      $0x1,%ymm8,%ymm8
  .byte  197,188,89,201                      // vmulps        %ymm1,%ymm8,%ymm1
  .byte  197,172,92,201                      // vsubps        %ymm1,%ymm10,%ymm1
  .byte  196,193,116,92,201                  // vsubps        %ymm9,%ymm1,%ymm1
  .byte  196,65,60,87,192                    // vxorps        %ymm8,%ymm8,%ymm8
  .byte  197,60,92,193                       // vsubps        %ymm1,%ymm8,%ymm8
  .byte  197,60,84,193                       // vandps        %ymm1,%ymm8,%ymm8
  .byte  196,99,125,25,201,1                 // vextractf128  $0x1,%ymm9,%xmm1
  .byte  196,65,41,118,210                   // vpcmpeqd      %xmm10,%xmm10,%xmm10
  .byte  196,193,113,254,202                 // vpaddd        %xmm10,%xmm1,%xmm1
  .byte  196,65,49,254,202                   // vpaddd        %xmm10,%xmm9,%xmm9
  .byte  196,227,53,24,201,1                 // vinsertf128   $0x1,%xmm1,%ymm9,%ymm1
  .byte  197,188,93,201                      // vminps        %ymm1,%ymm8,%ymm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_luminance_to_alpha_avx
.globl _sk_luminance_to_alpha_avx
FUNCTION(_sk_luminance_to_alpha_avx)
_sk_luminance_to_alpha_avx:
  .byte  184,208,179,89,62                   // mov           $0x3e59b3d0,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  197,228,89,192                      // vmulps        %ymm0,%ymm3,%ymm0
  .byte  184,89,23,55,63                     // mov           $0x3f371759,%eax
  .byte  197,249,110,216                     // vmovd         %eax,%xmm3
  .byte  196,227,121,4,219,0                 // vpermilps     $0x0,%xmm3,%xmm3
  .byte  196,227,101,24,219,1                // vinsertf128   $0x1,%xmm3,%ymm3,%ymm3
  .byte  197,228,89,201                      // vmulps        %ymm1,%ymm3,%ymm1
  .byte  197,252,88,193                      // vaddps        %ymm1,%ymm0,%ymm0
  .byte  184,152,221,147,61                  // mov           $0x3d93dd98,%eax
  .byte  197,249,110,200                     // vmovd         %eax,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,244,89,202                      // vmulps        %ymm2,%ymm1,%ymm1
  .byte  197,252,88,217                      // vaddps        %ymm1,%ymm0,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,252,87,192                      // vxorps        %ymm0,%ymm0,%ymm0
  .byte  197,244,87,201                      // vxorps        %ymm1,%ymm1,%ymm1
  .byte  197,236,87,210                      // vxorps        %ymm2,%ymm2,%ymm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_2x3_avx
.globl _sk_matrix_2x3_avx
FUNCTION(_sk_matrix_2x3_avx)
_sk_matrix_2x3_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,0                     // vbroadcastss  (%rax),%ymm8
  .byte  196,98,125,24,72,8                  // vbroadcastss  0x8(%rax),%ymm9
  .byte  196,98,125,24,80,16                 // vbroadcastss  0x10(%rax),%ymm10
  .byte  197,52,89,201                       // vmulps        %ymm1,%ymm9,%ymm9
  .byte  196,65,52,88,202                    // vaddps        %ymm10,%ymm9,%ymm9
  .byte  197,60,89,192                       // vmulps        %ymm0,%ymm8,%ymm8
  .byte  196,65,60,88,193                    // vaddps        %ymm9,%ymm8,%ymm8
  .byte  196,98,125,24,72,4                  // vbroadcastss  0x4(%rax),%ymm9
  .byte  196,98,125,24,80,12                 // vbroadcastss  0xc(%rax),%ymm10
  .byte  196,98,125,24,88,20                 // vbroadcastss  0x14(%rax),%ymm11
  .byte  197,172,89,201                      // vmulps        %ymm1,%ymm10,%ymm1
  .byte  196,193,116,88,203                  // vaddps        %ymm11,%ymm1,%ymm1
  .byte  197,180,89,192                      // vmulps        %ymm0,%ymm9,%ymm0
  .byte  197,252,88,201                      // vaddps        %ymm1,%ymm0,%ymm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,124,41,192                      // vmovaps       %ymm8,%ymm0
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_3x4_avx
.globl _sk_matrix_3x4_avx
FUNCTION(_sk_matrix_3x4_avx)
_sk_matrix_3x4_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,0                     // vbroadcastss  (%rax),%ymm8
  .byte  196,98,125,24,72,12                 // vbroadcastss  0xc(%rax),%ymm9
  .byte  196,98,125,24,80,24                 // vbroadcastss  0x18(%rax),%ymm10
  .byte  196,98,125,24,88,36                 // vbroadcastss  0x24(%rax),%ymm11
  .byte  197,44,89,210                       // vmulps        %ymm2,%ymm10,%ymm10
  .byte  196,65,44,88,211                    // vaddps        %ymm11,%ymm10,%ymm10
  .byte  197,52,89,201                       // vmulps        %ymm1,%ymm9,%ymm9
  .byte  196,65,52,88,202                    // vaddps        %ymm10,%ymm9,%ymm9
  .byte  197,60,89,192                       // vmulps        %ymm0,%ymm8,%ymm8
  .byte  196,65,60,88,193                    // vaddps        %ymm9,%ymm8,%ymm8
  .byte  196,98,125,24,72,4                  // vbroadcastss  0x4(%rax),%ymm9
  .byte  196,98,125,24,80,16                 // vbroadcastss  0x10(%rax),%ymm10
  .byte  196,98,125,24,88,28                 // vbroadcastss  0x1c(%rax),%ymm11
  .byte  196,98,125,24,96,40                 // vbroadcastss  0x28(%rax),%ymm12
  .byte  197,36,89,218                       // vmulps        %ymm2,%ymm11,%ymm11
  .byte  196,65,36,88,220                    // vaddps        %ymm12,%ymm11,%ymm11
  .byte  197,44,89,209                       // vmulps        %ymm1,%ymm10,%ymm10
  .byte  196,65,44,88,211                    // vaddps        %ymm11,%ymm10,%ymm10
  .byte  197,52,89,200                       // vmulps        %ymm0,%ymm9,%ymm9
  .byte  196,65,52,88,202                    // vaddps        %ymm10,%ymm9,%ymm9
  .byte  196,98,125,24,80,8                  // vbroadcastss  0x8(%rax),%ymm10
  .byte  196,98,125,24,88,20                 // vbroadcastss  0x14(%rax),%ymm11
  .byte  196,98,125,24,96,32                 // vbroadcastss  0x20(%rax),%ymm12
  .byte  196,98,125,24,104,44                // vbroadcastss  0x2c(%rax),%ymm13
  .byte  197,156,89,210                      // vmulps        %ymm2,%ymm12,%ymm2
  .byte  196,193,108,88,213                  // vaddps        %ymm13,%ymm2,%ymm2
  .byte  197,164,89,201                      // vmulps        %ymm1,%ymm11,%ymm1
  .byte  197,244,88,202                      // vaddps        %ymm2,%ymm1,%ymm1
  .byte  197,172,89,192                      // vmulps        %ymm0,%ymm10,%ymm0
  .byte  197,252,88,209                      // vaddps        %ymm1,%ymm0,%ymm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,124,41,192                      // vmovaps       %ymm8,%ymm0
  .byte  197,124,41,201                      // vmovaps       %ymm9,%ymm1
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_4x5_avx
.globl _sk_matrix_4x5_avx
FUNCTION(_sk_matrix_4x5_avx)
_sk_matrix_4x5_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,0                     // vbroadcastss  (%rax),%ymm8
  .byte  196,98,125,24,72,16                 // vbroadcastss  0x10(%rax),%ymm9
  .byte  196,98,125,24,80,32                 // vbroadcastss  0x20(%rax),%ymm10
  .byte  196,98,125,24,88,48                 // vbroadcastss  0x30(%rax),%ymm11
  .byte  196,98,125,24,96,64                 // vbroadcastss  0x40(%rax),%ymm12
  .byte  197,36,89,219                       // vmulps        %ymm3,%ymm11,%ymm11
  .byte  196,65,36,88,220                    // vaddps        %ymm12,%ymm11,%ymm11
  .byte  197,44,89,210                       // vmulps        %ymm2,%ymm10,%ymm10
  .byte  196,65,44,88,211                    // vaddps        %ymm11,%ymm10,%ymm10
  .byte  197,52,89,201                       // vmulps        %ymm1,%ymm9,%ymm9
  .byte  196,65,52,88,202                    // vaddps        %ymm10,%ymm9,%ymm9
  .byte  197,60,89,192                       // vmulps        %ymm0,%ymm8,%ymm8
  .byte  196,65,60,88,193                    // vaddps        %ymm9,%ymm8,%ymm8
  .byte  196,98,125,24,72,4                  // vbroadcastss  0x4(%rax),%ymm9
  .byte  196,98,125,24,80,20                 // vbroadcastss  0x14(%rax),%ymm10
  .byte  196,98,125,24,88,36                 // vbroadcastss  0x24(%rax),%ymm11
  .byte  196,98,125,24,96,52                 // vbroadcastss  0x34(%rax),%ymm12
  .byte  196,98,125,24,104,68                // vbroadcastss  0x44(%rax),%ymm13
  .byte  197,28,89,227                       // vmulps        %ymm3,%ymm12,%ymm12
  .byte  196,65,28,88,229                    // vaddps        %ymm13,%ymm12,%ymm12
  .byte  197,36,89,218                       // vmulps        %ymm2,%ymm11,%ymm11
  .byte  196,65,36,88,220                    // vaddps        %ymm12,%ymm11,%ymm11
  .byte  197,44,89,209                       // vmulps        %ymm1,%ymm10,%ymm10
  .byte  196,65,44,88,211                    // vaddps        %ymm11,%ymm10,%ymm10
  .byte  197,52,89,200                       // vmulps        %ymm0,%ymm9,%ymm9
  .byte  196,65,52,88,202                    // vaddps        %ymm10,%ymm9,%ymm9
  .byte  196,98,125,24,80,8                  // vbroadcastss  0x8(%rax),%ymm10
  .byte  196,98,125,24,88,24                 // vbroadcastss  0x18(%rax),%ymm11
  .byte  196,98,125,24,96,40                 // vbroadcastss  0x28(%rax),%ymm12
  .byte  196,98,125,24,104,56                // vbroadcastss  0x38(%rax),%ymm13
  .byte  196,98,125,24,112,72                // vbroadcastss  0x48(%rax),%ymm14
  .byte  197,20,89,235                       // vmulps        %ymm3,%ymm13,%ymm13
  .byte  196,65,20,88,238                    // vaddps        %ymm14,%ymm13,%ymm13
  .byte  197,28,89,226                       // vmulps        %ymm2,%ymm12,%ymm12
  .byte  196,65,28,88,229                    // vaddps        %ymm13,%ymm12,%ymm12
  .byte  197,36,89,217                       // vmulps        %ymm1,%ymm11,%ymm11
  .byte  196,65,36,88,220                    // vaddps        %ymm12,%ymm11,%ymm11
  .byte  197,44,89,208                       // vmulps        %ymm0,%ymm10,%ymm10
  .byte  196,65,44,88,211                    // vaddps        %ymm11,%ymm10,%ymm10
  .byte  196,98,125,24,88,12                 // vbroadcastss  0xc(%rax),%ymm11
  .byte  196,98,125,24,96,28                 // vbroadcastss  0x1c(%rax),%ymm12
  .byte  196,98,125,24,104,44                // vbroadcastss  0x2c(%rax),%ymm13
  .byte  196,98,125,24,112,60                // vbroadcastss  0x3c(%rax),%ymm14
  .byte  196,98,125,24,120,76                // vbroadcastss  0x4c(%rax),%ymm15
  .byte  197,140,89,219                      // vmulps        %ymm3,%ymm14,%ymm3
  .byte  196,193,100,88,223                  // vaddps        %ymm15,%ymm3,%ymm3
  .byte  197,148,89,210                      // vmulps        %ymm2,%ymm13,%ymm2
  .byte  197,236,88,211                      // vaddps        %ymm3,%ymm2,%ymm2
  .byte  197,156,89,201                      // vmulps        %ymm1,%ymm12,%ymm1
  .byte  197,244,88,202                      // vaddps        %ymm2,%ymm1,%ymm1
  .byte  197,164,89,192                      // vmulps        %ymm0,%ymm11,%ymm0
  .byte  197,252,88,217                      // vaddps        %ymm1,%ymm0,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,124,41,192                      // vmovaps       %ymm8,%ymm0
  .byte  197,124,41,201                      // vmovaps       %ymm9,%ymm1
  .byte  197,124,41,210                      // vmovaps       %ymm10,%ymm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_perspective_avx
.globl _sk_matrix_perspective_avx
FUNCTION(_sk_matrix_perspective_avx)
_sk_matrix_perspective_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,0                     // vbroadcastss  (%rax),%ymm8
  .byte  196,98,125,24,72,4                  // vbroadcastss  0x4(%rax),%ymm9
  .byte  196,98,125,24,80,8                  // vbroadcastss  0x8(%rax),%ymm10
  .byte  197,52,89,201                       // vmulps        %ymm1,%ymm9,%ymm9
  .byte  196,65,52,88,202                    // vaddps        %ymm10,%ymm9,%ymm9
  .byte  197,60,89,192                       // vmulps        %ymm0,%ymm8,%ymm8
  .byte  196,65,60,88,193                    // vaddps        %ymm9,%ymm8,%ymm8
  .byte  196,98,125,24,72,12                 // vbroadcastss  0xc(%rax),%ymm9
  .byte  196,98,125,24,80,16                 // vbroadcastss  0x10(%rax),%ymm10
  .byte  196,98,125,24,88,20                 // vbroadcastss  0x14(%rax),%ymm11
  .byte  197,44,89,209                       // vmulps        %ymm1,%ymm10,%ymm10
  .byte  196,65,44,88,211                    // vaddps        %ymm11,%ymm10,%ymm10
  .byte  197,52,89,200                       // vmulps        %ymm0,%ymm9,%ymm9
  .byte  196,65,52,88,202                    // vaddps        %ymm10,%ymm9,%ymm9
  .byte  196,98,125,24,80,24                 // vbroadcastss  0x18(%rax),%ymm10
  .byte  196,98,125,24,88,28                 // vbroadcastss  0x1c(%rax),%ymm11
  .byte  196,98,125,24,96,32                 // vbroadcastss  0x20(%rax),%ymm12
  .byte  197,164,89,201                      // vmulps        %ymm1,%ymm11,%ymm1
  .byte  196,193,116,88,204                  // vaddps        %ymm12,%ymm1,%ymm1
  .byte  197,172,89,192                      // vmulps        %ymm0,%ymm10,%ymm0
  .byte  197,252,88,193                      // vaddps        %ymm1,%ymm0,%ymm0
  .byte  197,252,83,200                      // vrcpps        %ymm0,%ymm1
  .byte  197,188,89,193                      // vmulps        %ymm1,%ymm8,%ymm0
  .byte  197,180,89,201                      // vmulps        %ymm1,%ymm9,%ymm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_linear_gradient_avx
.globl _sk_linear_gradient_avx
FUNCTION(_sk_linear_gradient_avx)
_sk_linear_gradient_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,98,125,24,64,16                 // vbroadcastss  0x10(%rax),%ymm8
  .byte  196,226,125,24,72,20                // vbroadcastss  0x14(%rax),%ymm1
  .byte  196,226,125,24,80,24                // vbroadcastss  0x18(%rax),%ymm2
  .byte  196,226,125,24,88,28                // vbroadcastss  0x1c(%rax),%ymm3
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  77,133,192                          // test          %r8,%r8
  .byte  15,132,146,0,0,0                    // je            5419 <_sk_linear_gradient_avx+0xb8>
  .byte  72,139,64,8                         // mov           0x8(%rax),%rax
  .byte  72,131,192,32                       // add           $0x20,%rax
  .byte  196,65,28,87,228                    // vxorps        %ymm12,%ymm12,%ymm12
  .byte  196,65,52,87,201                    // vxorps        %ymm9,%ymm9,%ymm9
  .byte  196,65,44,87,210                    // vxorps        %ymm10,%ymm10,%ymm10
  .byte  196,65,36,87,219                    // vxorps        %ymm11,%ymm11,%ymm11
  .byte  196,98,125,24,104,224               // vbroadcastss  -0x20(%rax),%ymm13
  .byte  196,65,124,194,237,1                // vcmpltps      %ymm13,%ymm0,%ymm13
  .byte  196,98,125,24,112,228               // vbroadcastss  -0x1c(%rax),%ymm14
  .byte  196,67,13,74,228,208                // vblendvps     %ymm13,%ymm12,%ymm14,%ymm12
  .byte  196,98,125,24,112,232               // vbroadcastss  -0x18(%rax),%ymm14
  .byte  196,67,13,74,219,208                // vblendvps     %ymm13,%ymm11,%ymm14,%ymm11
  .byte  196,98,125,24,112,236               // vbroadcastss  -0x14(%rax),%ymm14
  .byte  196,67,13,74,210,208                // vblendvps     %ymm13,%ymm10,%ymm14,%ymm10
  .byte  196,98,125,24,112,240               // vbroadcastss  -0x10(%rax),%ymm14
  .byte  196,67,13,74,201,208                // vblendvps     %ymm13,%ymm9,%ymm14,%ymm9
  .byte  196,98,125,24,112,244               // vbroadcastss  -0xc(%rax),%ymm14
  .byte  196,67,13,74,192,208                // vblendvps     %ymm13,%ymm8,%ymm14,%ymm8
  .byte  196,98,125,24,112,248               // vbroadcastss  -0x8(%rax),%ymm14
  .byte  196,227,13,74,201,208               // vblendvps     %ymm13,%ymm1,%ymm14,%ymm1
  .byte  196,98,125,24,112,252               // vbroadcastss  -0x4(%rax),%ymm14
  .byte  196,227,13,74,210,208               // vblendvps     %ymm13,%ymm2,%ymm14,%ymm2
  .byte  196,98,125,24,48                    // vbroadcastss  (%rax),%ymm14
  .byte  196,227,13,74,219,208               // vblendvps     %ymm13,%ymm3,%ymm14,%ymm3
  .byte  72,131,192,36                       // add           $0x24,%rax
  .byte  73,255,200                          // dec           %r8
  .byte  117,140                             // jne           53a3 <_sk_linear_gradient_avx+0x42>
  .byte  235,20                              // jmp           542d <_sk_linear_gradient_avx+0xcc>
  .byte  196,65,36,87,219                    // vxorps        %ymm11,%ymm11,%ymm11
  .byte  196,65,44,87,210                    // vxorps        %ymm10,%ymm10,%ymm10
  .byte  196,65,52,87,201                    // vxorps        %ymm9,%ymm9,%ymm9
  .byte  196,65,28,87,228                    // vxorps        %ymm12,%ymm12,%ymm12
  .byte  197,28,89,224                       // vmulps        %ymm0,%ymm12,%ymm12
  .byte  196,65,60,88,196                    // vaddps        %ymm12,%ymm8,%ymm8
  .byte  197,36,89,216                       // vmulps        %ymm0,%ymm11,%ymm11
  .byte  197,164,88,201                      // vaddps        %ymm1,%ymm11,%ymm1
  .byte  197,44,89,208                       // vmulps        %ymm0,%ymm10,%ymm10
  .byte  197,172,88,210                      // vaddps        %ymm2,%ymm10,%ymm2
  .byte  197,180,89,192                      // vmulps        %ymm0,%ymm9,%ymm0
  .byte  197,252,88,219                      // vaddps        %ymm3,%ymm0,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,124,41,192                      // vmovaps       %ymm8,%ymm0
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_linear_gradient_2stops_avx
.globl _sk_linear_gradient_2stops_avx
FUNCTION(_sk_linear_gradient_2stops_avx)
_sk_linear_gradient_2stops_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  196,226,125,24,8                    // vbroadcastss  (%rax),%ymm1
  .byte  196,226,125,24,80,16                // vbroadcastss  0x10(%rax),%ymm2
  .byte  197,244,89,200                      // vmulps        %ymm0,%ymm1,%ymm1
  .byte  197,116,88,194                      // vaddps        %ymm2,%ymm1,%ymm8
  .byte  196,226,125,24,72,4                 // vbroadcastss  0x4(%rax),%ymm1
  .byte  196,226,125,24,80,20                // vbroadcastss  0x14(%rax),%ymm2
  .byte  197,244,89,200                      // vmulps        %ymm0,%ymm1,%ymm1
  .byte  197,244,88,202                      // vaddps        %ymm2,%ymm1,%ymm1
  .byte  196,226,125,24,80,8                 // vbroadcastss  0x8(%rax),%ymm2
  .byte  196,226,125,24,88,24                // vbroadcastss  0x18(%rax),%ymm3
  .byte  197,236,89,208                      // vmulps        %ymm0,%ymm2,%ymm2
  .byte  197,236,88,211                      // vaddps        %ymm3,%ymm2,%ymm2
  .byte  196,226,125,24,88,12                // vbroadcastss  0xc(%rax),%ymm3
  .byte  196,98,125,24,72,28                 // vbroadcastss  0x1c(%rax),%ymm9
  .byte  197,228,89,192                      // vmulps        %ymm0,%ymm3,%ymm0
  .byte  196,193,124,88,217                  // vaddps        %ymm9,%ymm0,%ymm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,124,41,192                      // vmovaps       %ymm8,%ymm0
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_save_xy_avx
.globl _sk_save_xy_avx
FUNCTION(_sk_save_xy_avx)
_sk_save_xy_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,63                     // mov           $0x3f000000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,88,200                       // vaddps        %ymm0,%ymm8,%ymm9
  .byte  196,67,125,8,209,1                  // vroundps      $0x1,%ymm9,%ymm10
  .byte  196,65,52,92,202                    // vsubps        %ymm10,%ymm9,%ymm9
  .byte  197,60,88,193                       // vaddps        %ymm1,%ymm8,%ymm8
  .byte  196,67,125,8,208,1                  // vroundps      $0x1,%ymm8,%ymm10
  .byte  196,65,60,92,194                    // vsubps        %ymm10,%ymm8,%ymm8
  .byte  197,252,17,0                        // vmovups       %ymm0,(%rax)
  .byte  197,252,17,72,32                    // vmovups       %ymm1,0x20(%rax)
  .byte  197,124,17,72,64                    // vmovups       %ymm9,0x40(%rax)
  .byte  197,124,17,64,96                    // vmovups       %ymm8,0x60(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_accumulate_avx
.globl _sk_accumulate_avx
FUNCTION(_sk_accumulate_avx)
_sk_accumulate_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  197,124,16,128,128,0,0,0            // vmovups       0x80(%rax),%ymm8
  .byte  197,60,89,128,160,0,0,0             // vmulps        0xa0(%rax),%ymm8,%ymm8
  .byte  197,60,89,200                       // vmulps        %ymm0,%ymm8,%ymm9
  .byte  197,180,88,228                      // vaddps        %ymm4,%ymm9,%ymm4
  .byte  197,60,89,201                       // vmulps        %ymm1,%ymm8,%ymm9
  .byte  197,180,88,237                      // vaddps        %ymm5,%ymm9,%ymm5
  .byte  197,60,89,202                       // vmulps        %ymm2,%ymm8,%ymm9
  .byte  197,180,88,246                      // vaddps        %ymm6,%ymm9,%ymm6
  .byte  197,60,89,195                       // vmulps        %ymm3,%ymm8,%ymm8
  .byte  197,188,88,255                      // vaddps        %ymm7,%ymm8,%ymm7
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_nx_avx
.globl _sk_bilinear_nx_avx
FUNCTION(_sk_bilinear_nx_avx)
_sk_bilinear_nx_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,191                    // mov           $0xbf000000,%r8d
  .byte  196,193,121,110,192                 // vmovd         %r8d,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,252,88,0                        // vaddps        (%rax),%ymm0,%ymm0
  .byte  65,184,0,0,128,63                   // mov           $0x3f800000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,64,64                     // vsubps        0x40(%rax),%ymm8,%ymm8
  .byte  197,124,17,128,128,0,0,0            // vmovups       %ymm8,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_px_avx
.globl _sk_bilinear_px_avx
FUNCTION(_sk_bilinear_px_avx)
_sk_bilinear_px_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,63                     // mov           $0x3f000000,%r8d
  .byte  196,193,121,110,192                 // vmovd         %r8d,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,124,16,64,64                    // vmovups       0x40(%rax),%ymm8
  .byte  197,252,88,0                        // vaddps        (%rax),%ymm0,%ymm0
  .byte  197,124,17,128,128,0,0,0            // vmovups       %ymm8,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_ny_avx
.globl _sk_bilinear_ny_avx
FUNCTION(_sk_bilinear_ny_avx)
_sk_bilinear_ny_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,191                    // mov           $0xbf000000,%r8d
  .byte  196,193,121,110,200                 // vmovd         %r8d,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,244,88,72,32                    // vaddps        0x20(%rax),%ymm1,%ymm1
  .byte  65,184,0,0,128,63                   // mov           $0x3f800000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,64,96                     // vsubps        0x60(%rax),%ymm8,%ymm8
  .byte  197,124,17,128,160,0,0,0            // vmovups       %ymm8,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_py_avx
.globl _sk_bilinear_py_avx
FUNCTION(_sk_bilinear_py_avx)
_sk_bilinear_py_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,63                     // mov           $0x3f000000,%r8d
  .byte  196,193,121,110,200                 // vmovd         %r8d,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,124,16,64,96                    // vmovups       0x60(%rax),%ymm8
  .byte  197,244,88,72,32                    // vaddps        0x20(%rax),%ymm1,%ymm1
  .byte  197,124,17,128,160,0,0,0            // vmovups       %ymm8,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n3x_avx
.globl _sk_bicubic_n3x_avx
FUNCTION(_sk_bicubic_n3x_avx)
_sk_bicubic_n3x_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,192,191                  // mov           $0xbfc00000,%r8d
  .byte  196,193,121,110,192                 // vmovd         %r8d,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,252,88,0                        // vaddps        (%rax),%ymm0,%ymm0
  .byte  65,184,0,0,128,63                   // mov           $0x3f800000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,64,64                     // vsubps        0x40(%rax),%ymm8,%ymm8
  .byte  196,65,60,89,200                    // vmulps        %ymm8,%ymm8,%ymm9
  .byte  65,184,114,28,199,62                // mov           $0x3ec71c72,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  65,184,171,170,170,190              // mov           $0xbeaaaaab,%r8d
  .byte  196,65,121,110,216                  // vmovd         %r8d,%xmm11
  .byte  196,67,121,4,219,0                  // vpermilps     $0x0,%xmm11,%xmm11
  .byte  196,67,37,24,219,1                  // vinsertf128   $0x1,%xmm11,%ymm11,%ymm11
  .byte  196,65,44,89,192                    // vmulps        %ymm8,%ymm10,%ymm8
  .byte  196,65,60,88,195                    // vaddps        %ymm11,%ymm8,%ymm8
  .byte  196,65,52,89,192                    // vmulps        %ymm8,%ymm9,%ymm8
  .byte  197,124,17,128,128,0,0,0            // vmovups       %ymm8,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n1x_avx
.globl _sk_bicubic_n1x_avx
FUNCTION(_sk_bicubic_n1x_avx)
_sk_bicubic_n1x_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,191                    // mov           $0xbf000000,%r8d
  .byte  196,193,121,110,192                 // vmovd         %r8d,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,252,88,0                        // vaddps        (%rax),%ymm0,%ymm0
  .byte  65,184,0,0,128,63                   // mov           $0x3f800000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,64,64                     // vsubps        0x40(%rax),%ymm8,%ymm8
  .byte  65,184,85,85,149,191                // mov           $0xbf955555,%r8d
  .byte  196,65,121,110,200                  // vmovd         %r8d,%xmm9
  .byte  196,67,121,4,201,0                  // vpermilps     $0x0,%xmm9,%xmm9
  .byte  196,67,53,24,201,1                  // vinsertf128   $0x1,%xmm9,%ymm9,%ymm9
  .byte  65,184,0,0,192,63                   // mov           $0x3fc00000,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  196,65,52,89,200                    // vmulps        %ymm8,%ymm9,%ymm9
  .byte  196,65,52,88,202                    // vaddps        %ymm10,%ymm9,%ymm9
  .byte  65,184,0,0,0,63                     // mov           $0x3f000000,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  196,65,60,89,201                    // vmulps        %ymm9,%ymm8,%ymm9
  .byte  196,65,44,88,201                    // vaddps        %ymm9,%ymm10,%ymm9
  .byte  65,184,57,142,99,61                 // mov           $0x3d638e39,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  196,65,60,89,193                    // vmulps        %ymm9,%ymm8,%ymm8
  .byte  196,65,44,88,192                    // vaddps        %ymm8,%ymm10,%ymm8
  .byte  197,124,17,128,128,0,0,0            // vmovups       %ymm8,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p1x_avx
.globl _sk_bicubic_p1x_avx
FUNCTION(_sk_bicubic_p1x_avx)
_sk_bicubic_p1x_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,63                     // mov           $0x3f000000,%r8d
  .byte  196,193,121,110,192                 // vmovd         %r8d,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,99,125,24,192,1                 // vinsertf128   $0x1,%xmm0,%ymm0,%ymm8
  .byte  197,188,88,0                        // vaddps        (%rax),%ymm8,%ymm0
  .byte  197,124,16,72,64                    // vmovups       0x40(%rax),%ymm9
  .byte  65,184,85,85,149,191                // mov           $0xbf955555,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  65,184,0,0,192,63                   // mov           $0x3fc00000,%r8d
  .byte  196,65,121,110,216                  // vmovd         %r8d,%xmm11
  .byte  196,67,121,4,219,0                  // vpermilps     $0x0,%xmm11,%xmm11
  .byte  196,67,37,24,219,1                  // vinsertf128   $0x1,%xmm11,%ymm11,%ymm11
  .byte  196,65,52,89,210                    // vmulps        %ymm10,%ymm9,%ymm10
  .byte  196,65,44,88,211                    // vaddps        %ymm11,%ymm10,%ymm10
  .byte  196,65,52,89,210                    // vmulps        %ymm10,%ymm9,%ymm10
  .byte  196,65,60,88,194                    // vaddps        %ymm10,%ymm8,%ymm8
  .byte  65,184,57,142,99,61                 // mov           $0x3d638e39,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  196,65,52,89,192                    // vmulps        %ymm8,%ymm9,%ymm8
  .byte  196,65,44,88,192                    // vaddps        %ymm8,%ymm10,%ymm8
  .byte  197,124,17,128,128,0,0,0            // vmovups       %ymm8,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p3x_avx
.globl _sk_bicubic_p3x_avx
FUNCTION(_sk_bicubic_p3x_avx)
_sk_bicubic_p3x_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,192,63                   // mov           $0x3fc00000,%r8d
  .byte  196,193,121,110,192                 // vmovd         %r8d,%xmm0
  .byte  196,227,121,4,192,0                 // vpermilps     $0x0,%xmm0,%xmm0
  .byte  196,227,125,24,192,1                // vinsertf128   $0x1,%xmm0,%ymm0,%ymm0
  .byte  197,252,88,0                        // vaddps        (%rax),%ymm0,%ymm0
  .byte  197,124,16,64,64                    // vmovups       0x40(%rax),%ymm8
  .byte  196,65,60,89,200                    // vmulps        %ymm8,%ymm8,%ymm9
  .byte  65,184,114,28,199,62                // mov           $0x3ec71c72,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  65,184,171,170,170,190              // mov           $0xbeaaaaab,%r8d
  .byte  196,65,121,110,216                  // vmovd         %r8d,%xmm11
  .byte  196,67,121,4,219,0                  // vpermilps     $0x0,%xmm11,%xmm11
  .byte  196,67,37,24,219,1                  // vinsertf128   $0x1,%xmm11,%ymm11,%ymm11
  .byte  196,65,60,89,194                    // vmulps        %ymm10,%ymm8,%ymm8
  .byte  196,65,60,88,195                    // vaddps        %ymm11,%ymm8,%ymm8
  .byte  196,65,52,89,192                    // vmulps        %ymm8,%ymm9,%ymm8
  .byte  197,124,17,128,128,0,0,0            // vmovups       %ymm8,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n3y_avx
.globl _sk_bicubic_n3y_avx
FUNCTION(_sk_bicubic_n3y_avx)
_sk_bicubic_n3y_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,192,191                  // mov           $0xbfc00000,%r8d
  .byte  196,193,121,110,200                 // vmovd         %r8d,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,244,88,72,32                    // vaddps        0x20(%rax),%ymm1,%ymm1
  .byte  65,184,0,0,128,63                   // mov           $0x3f800000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,64,96                     // vsubps        0x60(%rax),%ymm8,%ymm8
  .byte  196,65,60,89,200                    // vmulps        %ymm8,%ymm8,%ymm9
  .byte  65,184,114,28,199,62                // mov           $0x3ec71c72,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  65,184,171,170,170,190              // mov           $0xbeaaaaab,%r8d
  .byte  196,65,121,110,216                  // vmovd         %r8d,%xmm11
  .byte  196,67,121,4,219,0                  // vpermilps     $0x0,%xmm11,%xmm11
  .byte  196,67,37,24,219,1                  // vinsertf128   $0x1,%xmm11,%ymm11,%ymm11
  .byte  196,65,44,89,192                    // vmulps        %ymm8,%ymm10,%ymm8
  .byte  196,65,60,88,195                    // vaddps        %ymm11,%ymm8,%ymm8
  .byte  196,65,52,89,192                    // vmulps        %ymm8,%ymm9,%ymm8
  .byte  197,124,17,128,160,0,0,0            // vmovups       %ymm8,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n1y_avx
.globl _sk_bicubic_n1y_avx
FUNCTION(_sk_bicubic_n1y_avx)
_sk_bicubic_n1y_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,191                    // mov           $0xbf000000,%r8d
  .byte  196,193,121,110,200                 // vmovd         %r8d,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,244,88,72,32                    // vaddps        0x20(%rax),%ymm1,%ymm1
  .byte  65,184,0,0,128,63                   // mov           $0x3f800000,%r8d
  .byte  196,65,121,110,192                  // vmovd         %r8d,%xmm8
  .byte  196,67,121,4,192,0                  // vpermilps     $0x0,%xmm8,%xmm8
  .byte  196,67,61,24,192,1                  // vinsertf128   $0x1,%xmm8,%ymm8,%ymm8
  .byte  197,60,92,64,96                     // vsubps        0x60(%rax),%ymm8,%ymm8
  .byte  65,184,85,85,149,191                // mov           $0xbf955555,%r8d
  .byte  196,65,121,110,200                  // vmovd         %r8d,%xmm9
  .byte  196,67,121,4,201,0                  // vpermilps     $0x0,%xmm9,%xmm9
  .byte  196,67,53,24,201,1                  // vinsertf128   $0x1,%xmm9,%ymm9,%ymm9
  .byte  65,184,0,0,192,63                   // mov           $0x3fc00000,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  196,65,52,89,200                    // vmulps        %ymm8,%ymm9,%ymm9
  .byte  196,65,52,88,202                    // vaddps        %ymm10,%ymm9,%ymm9
  .byte  65,184,0,0,0,63                     // mov           $0x3f000000,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  196,65,60,89,201                    // vmulps        %ymm9,%ymm8,%ymm9
  .byte  196,65,44,88,201                    // vaddps        %ymm9,%ymm10,%ymm9
  .byte  65,184,57,142,99,61                 // mov           $0x3d638e39,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  196,65,60,89,193                    // vmulps        %ymm9,%ymm8,%ymm8
  .byte  196,65,44,88,192                    // vaddps        %ymm8,%ymm10,%ymm8
  .byte  197,124,17,128,160,0,0,0            // vmovups       %ymm8,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p1y_avx
.globl _sk_bicubic_p1y_avx
FUNCTION(_sk_bicubic_p1y_avx)
_sk_bicubic_p1y_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,0,63                     // mov           $0x3f000000,%r8d
  .byte  196,193,121,110,200                 // vmovd         %r8d,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,99,117,24,193,1                 // vinsertf128   $0x1,%xmm1,%ymm1,%ymm8
  .byte  197,188,88,72,32                    // vaddps        0x20(%rax),%ymm8,%ymm1
  .byte  197,124,16,72,96                    // vmovups       0x60(%rax),%ymm9
  .byte  65,184,85,85,149,191                // mov           $0xbf955555,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  65,184,0,0,192,63                   // mov           $0x3fc00000,%r8d
  .byte  196,65,121,110,216                  // vmovd         %r8d,%xmm11
  .byte  196,67,121,4,219,0                  // vpermilps     $0x0,%xmm11,%xmm11
  .byte  196,67,37,24,219,1                  // vinsertf128   $0x1,%xmm11,%ymm11,%ymm11
  .byte  196,65,52,89,210                    // vmulps        %ymm10,%ymm9,%ymm10
  .byte  196,65,44,88,211                    // vaddps        %ymm11,%ymm10,%ymm10
  .byte  196,65,52,89,210                    // vmulps        %ymm10,%ymm9,%ymm10
  .byte  196,65,60,88,194                    // vaddps        %ymm10,%ymm8,%ymm8
  .byte  65,184,57,142,99,61                 // mov           $0x3d638e39,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  196,65,52,89,192                    // vmulps        %ymm8,%ymm9,%ymm8
  .byte  196,65,44,88,192                    // vaddps        %ymm8,%ymm10,%ymm8
  .byte  197,124,17,128,160,0,0,0            // vmovups       %ymm8,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p3y_avx
.globl _sk_bicubic_p3y_avx
FUNCTION(_sk_bicubic_p3y_avx)
_sk_bicubic_p3y_avx:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,184,0,0,192,63                   // mov           $0x3fc00000,%r8d
  .byte  196,193,121,110,200                 // vmovd         %r8d,%xmm1
  .byte  196,227,121,4,201,0                 // vpermilps     $0x0,%xmm1,%xmm1
  .byte  196,227,117,24,201,1                // vinsertf128   $0x1,%xmm1,%ymm1,%ymm1
  .byte  197,244,88,72,32                    // vaddps        0x20(%rax),%ymm1,%ymm1
  .byte  197,124,16,64,96                    // vmovups       0x60(%rax),%ymm8
  .byte  196,65,60,89,200                    // vmulps        %ymm8,%ymm8,%ymm9
  .byte  65,184,114,28,199,62                // mov           $0x3ec71c72,%r8d
  .byte  196,65,121,110,208                  // vmovd         %r8d,%xmm10
  .byte  196,67,121,4,210,0                  // vpermilps     $0x0,%xmm10,%xmm10
  .byte  196,67,45,24,210,1                  // vinsertf128   $0x1,%xmm10,%ymm10,%ymm10
  .byte  65,184,171,170,170,190              // mov           $0xbeaaaaab,%r8d
  .byte  196,65,121,110,216                  // vmovd         %r8d,%xmm11
  .byte  196,67,121,4,219,0                  // vpermilps     $0x0,%xmm11,%xmm11
  .byte  196,67,37,24,219,1                  // vinsertf128   $0x1,%xmm11,%ymm11,%ymm11
  .byte  196,65,60,89,194                    // vmulps        %ymm10,%ymm8,%ymm8
  .byte  196,65,60,88,195                    // vaddps        %ymm11,%ymm8,%ymm8
  .byte  196,65,52,89,192                    // vmulps        %ymm8,%ymm9,%ymm8
  .byte  197,124,17,128,160,0,0,0            // vmovups       %ymm8,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_callback_avx
.globl _sk_callback_avx
FUNCTION(_sk_callback_avx)
_sk_callback_avx:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,85                               // push          %r13
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,129,236,144,0,0,0                // sub           $0x90,%rsp
  .byte  197,252,17,124,36,96                // vmovups       %ymm7,0x60(%rsp)
  .byte  197,252,17,116,36,64                // vmovups       %ymm6,0x40(%rsp)
  .byte  197,252,17,108,36,32                // vmovups       %ymm5,0x20(%rsp)
  .byte  197,252,17,36,36                    // vmovups       %ymm4,(%rsp)
  .byte  73,137,205                          // mov           %rcx,%r13
  .byte  73,137,214                          // mov           %rdx,%r14
  .byte  73,137,255                          // mov           %rdi,%r15
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,137,195                          // mov           %rax,%rbx
  .byte  73,137,244                          // mov           %rsi,%r12
  .byte  197,252,20,225                      // vunpcklps     %ymm1,%ymm0,%ymm4
  .byte  197,252,21,193                      // vunpckhps     %ymm1,%ymm0,%ymm0
  .byte  197,236,20,203                      // vunpcklps     %ymm3,%ymm2,%ymm1
  .byte  197,236,21,211                      // vunpckhps     %ymm3,%ymm2,%ymm2
  .byte  197,221,20,217                      // vunpcklpd     %ymm1,%ymm4,%ymm3
  .byte  197,221,21,201                      // vunpckhpd     %ymm1,%ymm4,%ymm1
  .byte  197,253,20,226                      // vunpcklpd     %ymm2,%ymm0,%ymm4
  .byte  197,253,21,194                      // vunpckhpd     %ymm2,%ymm0,%ymm0
  .byte  196,227,101,24,209,1                // vinsertf128   $0x1,%xmm1,%ymm3,%ymm2
  .byte  196,227,93,24,232,1                 // vinsertf128   $0x1,%xmm0,%ymm4,%ymm5
  .byte  196,227,101,6,201,49                // vperm2f128    $0x31,%ymm1,%ymm3,%ymm1
  .byte  196,227,93,6,192,49                 // vperm2f128    $0x31,%ymm0,%ymm4,%ymm0
  .byte  197,253,17,83,8                     // vmovupd       %ymm2,0x8(%rbx)
  .byte  197,253,17,107,40                   // vmovupd       %ymm5,0x28(%rbx)
  .byte  197,253,17,75,72                    // vmovupd       %ymm1,0x48(%rbx)
  .byte  197,253,17,67,104                   // vmovupd       %ymm0,0x68(%rbx)
  .byte  77,133,237                          // test          %r13,%r13
  .byte  190,8,0,0,0                         // mov           $0x8,%esi
  .byte  65,15,69,245                        // cmovne        %r13d,%esi
  .byte  72,137,223                          // mov           %rbx,%rdi
  .byte  197,248,119                         // vzeroupper
  .byte  255,19                              // callq         *(%rbx)
  .byte  72,139,131,136,0,0,0                // mov           0x88(%rbx),%rax
  .byte  197,248,16,0                        // vmovups       (%rax),%xmm0
  .byte  197,248,16,72,16                    // vmovups       0x10(%rax),%xmm1
  .byte  197,248,16,80,32                    // vmovups       0x20(%rax),%xmm2
  .byte  197,248,16,88,48                    // vmovups       0x30(%rax),%xmm3
  .byte  196,227,101,24,88,112,1             // vinsertf128   $0x1,0x70(%rax),%ymm3,%ymm3
  .byte  196,227,109,24,80,96,1              // vinsertf128   $0x1,0x60(%rax),%ymm2,%ymm2
  .byte  196,227,117,24,72,80,1              // vinsertf128   $0x1,0x50(%rax),%ymm1,%ymm1
  .byte  196,227,125,24,64,64,1              // vinsertf128   $0x1,0x40(%rax),%ymm0,%ymm0
  .byte  197,252,20,225                      // vunpcklps     %ymm1,%ymm0,%ymm4
  .byte  197,252,21,233                      // vunpckhps     %ymm1,%ymm0,%ymm5
  .byte  197,236,20,203                      // vunpcklps     %ymm3,%ymm2,%ymm1
  .byte  197,236,21,219                      // vunpckhps     %ymm3,%ymm2,%ymm3
  .byte  197,221,20,193                      // vunpcklpd     %ymm1,%ymm4,%ymm0
  .byte  197,221,21,201                      // vunpckhpd     %ymm1,%ymm4,%ymm1
  .byte  197,213,20,211                      // vunpcklpd     %ymm3,%ymm5,%ymm2
  .byte  197,213,21,219                      // vunpckhpd     %ymm3,%ymm5,%ymm3
  .byte  76,137,230                          // mov           %r12,%rsi
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,137,255                          // mov           %r15,%rdi
  .byte  76,137,242                          // mov           %r14,%rdx
  .byte  76,137,233                          // mov           %r13,%rcx
  .byte  197,252,16,36,36                    // vmovups       (%rsp),%ymm4
  .byte  197,252,16,108,36,32                // vmovups       0x20(%rsp),%ymm5
  .byte  197,252,16,116,36,64                // vmovups       0x40(%rsp),%ymm6
  .byte  197,252,16,124,36,96                // vmovups       0x60(%rsp),%ymm7
  .byte  72,129,196,144,0,0,0                // add           $0x90,%rsp
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,93                               // pop           %r13
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  255,224                             // jmpq          *%rax

BALIGN4
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  128,63,0                            // cmpb          $0x0,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,255                              // xor           $0xff,%al
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            5be4 <.literal4+0x10>
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  119,115                             // ja            5c5d <.literal4+0x89>
  .byte  248                                 // clc
  .byte  194,117,191                         // retq          $0xbf75
  .byte  191,63,249,68,180                   // mov           $0xb444f93f,%edi
  .byte  62,163,233,220,63,81,140,242,66,141 // movabs        %eax,%ds:0x8d42f28c513fdce9
  .byte  188,190,63,248,245                  // mov           $0xf5f83fbe,%esp
  .byte  154                                 // (bad)
  .byte  64,254                              // rex           (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,0,0                              // add           %al,(%r8)
  .byte  0,75,0                              // add           %cl,0x0(%rbx)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,255                              // xor           $0xff,%al
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            5c14 <.literal4+0x40>
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  119,115                             // ja            5c8d <.literal4+0xb9>
  .byte  248                                 // clc
  .byte  194,117,191                         // retq          $0xbf75
  .byte  191,63,249,68,180                   // mov           $0xb444f93f,%edi
  .byte  62,163,233,220,63,81,140,242,66,141 // movabs        %eax,%ds:0x8d42f28c513fdce9
  .byte  188,190,63,248,245                  // mov           $0xf5f83fbe,%esp
  .byte  154                                 // (bad)
  .byte  64,254                              // rex           (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,0,0                              // add           %al,(%r8)
  .byte  0,75,0                              // add           %cl,0x0(%rbx)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,255                              // xor           $0xff,%al
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            5c44 <.literal4+0x70>
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  119,115                             // ja            5cbd <.literal4+0xe9>
  .byte  248                                 // clc
  .byte  194,117,191                         // retq          $0xbf75
  .byte  191,63,249,68,180                   // mov           $0xb444f93f,%edi
  .byte  62,163,233,220,63,81,140,242,66,141 // movabs        %eax,%ds:0x8d42f28c513fdce9
  .byte  188,190,63,248,245                  // mov           $0xf5f83fbe,%esp
  .byte  154                                 // (bad)
  .byte  64,254                              // rex           (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,0,0                              // add           %al,(%r8)
  .byte  0,75,0                              // add           %cl,0x0(%rbx)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,255                              // xor           $0xff,%al
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            5c74 <.literal4+0xa0>
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  119,115                             // ja            5ced <_sk_callback_avx+0x23f>
  .byte  248                                 // clc
  .byte  194,117,191                         // retq          $0xbf75
  .byte  191,63,249,68,180                   // mov           $0xb444f93f,%edi
  .byte  62,163,233,220,63,81,140,242,66,141 // movabs        %eax,%ds:0x8d42f28c513fdce9
  .byte  188,190,63,248,245                  // mov           $0xf5f83fbe,%esp
  .byte  154                                 // (bad)
  .byte  64,254                              // rex           (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,0,0                              // add           %al,(%r8)
  .byte  0,75,0                              // add           %cl,0x0(%rbx)
  .byte  128,0,0                             // addb          $0x0,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,128,0,4,0,128                     // add           %al,-0x7ffffc00(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,56                                // add           %bh,(%rax)
  .byte  0,128,0,0,0,0                       // add           %al,0x0(%rax)
  .byte  0,128,0,4,0,128                     // add           %al,-0x7ffffc00(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,56                                // add           %bh,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,128,0,0,128,56                    // add           %al,0x38800000(%rax)
  .byte  0,64,254                            // add           %al,-0x2(%rax)
  .byte  255                                 // .byte         0xff

BALIGN32
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)

BALIGN16
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
BALIGN32

HIDDEN _sk_start_pipeline_sse41
.globl _sk_start_pipeline_sse41
FUNCTION(_sk_start_pipeline_sse41)
_sk_start_pipeline_sse41:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,85                               // push          %r13
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  73,137,207                          // mov           %rcx,%r15
  .byte  73,137,214                          // mov           %rdx,%r14
  .byte  72,137,251                          // mov           %rdi,%rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  73,137,196                          // mov           %rax,%r12
  .byte  73,137,245                          // mov           %rsi,%r13
  .byte  72,141,67,4                         // lea           0x4(%rbx),%rax
  .byte  76,57,248                           // cmp           %r15,%rax
  .byte  118,5                               // jbe           28 <_sk_start_pipeline_sse41+0x28>
  .byte  72,137,216                          // mov           %rbx,%rax
  .byte  235,52                              // jmp           5c <_sk_start_pipeline_sse41+0x5c>
  .byte  15,87,192                           // xorps         %xmm0,%xmm0
  .byte  15,87,201                           // xorps         %xmm1,%xmm1
  .byte  15,87,210                           // xorps         %xmm2,%xmm2
  .byte  15,87,219                           // xorps         %xmm3,%xmm3
  .byte  15,87,228                           // xorps         %xmm4,%xmm4
  .byte  15,87,237                           // xorps         %xmm5,%xmm5
  .byte  15,87,246                           // xorps         %xmm6,%xmm6
  .byte  15,87,255                           // xorps         %xmm7,%xmm7
  .byte  72,137,223                          // mov           %rbx,%rdi
  .byte  76,137,238                          // mov           %r13,%rsi
  .byte  76,137,242                          // mov           %r14,%rdx
  .byte  65,255,212                          // callq         *%r12
  .byte  72,141,67,4                         // lea           0x4(%rbx),%rax
  .byte  72,131,195,8                        // add           $0x8,%rbx
  .byte  76,57,251                           // cmp           %r15,%rbx
  .byte  72,137,195                          // mov           %rax,%rbx
  .byte  118,204                             // jbe           28 <_sk_start_pipeline_sse41+0x28>
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,93                               // pop           %r13
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  195                                 // retq

HIDDEN _sk_just_return_sse41
.globl _sk_just_return_sse41
FUNCTION(_sk_just_return_sse41)
_sk_just_return_sse41:
  .byte  195                                 // retq

HIDDEN _sk_seed_shader_sse41
.globl _sk_seed_shader_sse41
FUNCTION(_sk_seed_shader_sse41)
_sk_seed_shader_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  102,15,110,199                      // movd          %edi,%xmm0
  .byte  102,15,112,192,0                    // pshufd        $0x0,%xmm0,%xmm0
  .byte  15,91,200                           // cvtdq2ps      %xmm0,%xmm1
  .byte  15,40,21,212,62,0,0                 // movaps        0x3ed4(%rip),%xmm2        # 3f50 <_sk_callback_sse41+0xe4>
  .byte  15,88,202                           // addps         %xmm2,%xmm1
  .byte  15,16,2                             // movups        (%rdx),%xmm0
  .byte  15,88,193                           // addps         %xmm1,%xmm0
  .byte  102,15,110,8                        // movd          (%rax),%xmm1
  .byte  102,15,112,201,0                    // pshufd        $0x0,%xmm1,%xmm1
  .byte  15,91,201                           // cvtdq2ps      %xmm1,%xmm1
  .byte  15,88,202                           // addps         %xmm2,%xmm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,40,21,195,62,0,0                 // movaps        0x3ec3(%rip),%xmm2        # 3f60 <_sk_callback_sse41+0xf4>
  .byte  15,87,219                           // xorps         %xmm3,%xmm3
  .byte  15,87,228                           // xorps         %xmm4,%xmm4
  .byte  15,87,237                           // xorps         %xmm5,%xmm5
  .byte  15,87,246                           // xorps         %xmm6,%xmm6
  .byte  15,87,255                           // xorps         %xmm7,%xmm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_constant_color_sse41
.globl _sk_constant_color_sse41
FUNCTION(_sk_constant_color_sse41)
_sk_constant_color_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,15,16,0                         // movss         (%rax),%xmm0
  .byte  243,15,16,72,4                      // movss         0x4(%rax),%xmm1
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  243,15,16,80,8                      // movss         0x8(%rax),%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  243,15,16,88,12                     // movss         0xc(%rax),%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clear_sse41
.globl _sk_clear_sse41
FUNCTION(_sk_clear_sse41)
_sk_clear_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,87,192                           // xorps         %xmm0,%xmm0
  .byte  15,87,201                           // xorps         %xmm1,%xmm1
  .byte  15,87,210                           // xorps         %xmm2,%xmm2
  .byte  15,87,219                           // xorps         %xmm3,%xmm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcatop_sse41
.globl _sk_srcatop_sse41
FUNCTION(_sk_srcatop_sse41)
_sk_srcatop_sse41:
  .byte  15,89,199                           // mulps         %xmm7,%xmm0
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,92,195                        // subps         %xmm3,%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,204                        // mulps         %xmm4,%xmm9
  .byte  65,15,88,193                        // addps         %xmm9,%xmm0
  .byte  15,89,207                           // mulps         %xmm7,%xmm1
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,205                        // mulps         %xmm5,%xmm9
  .byte  65,15,88,201                        // addps         %xmm9,%xmm1
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,206                        // mulps         %xmm6,%xmm9
  .byte  65,15,88,209                        // addps         %xmm9,%xmm2
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  68,15,89,199                        // mulps         %xmm7,%xmm8
  .byte  65,15,88,216                        // addps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstatop_sse41
.globl _sk_dstatop_sse41
FUNCTION(_sk_dstatop_sse41)
_sk_dstatop_sse41:
  .byte  68,15,40,195                        // movaps        %xmm3,%xmm8
  .byte  68,15,89,196                        // mulps         %xmm4,%xmm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,200                   // movd          %eax,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  68,15,92,207                        // subps         %xmm7,%xmm9
  .byte  65,15,89,193                        // mulps         %xmm9,%xmm0
  .byte  65,15,88,192                        // addps         %xmm8,%xmm0
  .byte  68,15,40,195                        // movaps        %xmm3,%xmm8
  .byte  68,15,89,197                        // mulps         %xmm5,%xmm8
  .byte  65,15,89,201                        // mulps         %xmm9,%xmm1
  .byte  65,15,88,200                        // addps         %xmm8,%xmm1
  .byte  68,15,40,195                        // movaps        %xmm3,%xmm8
  .byte  68,15,89,198                        // mulps         %xmm6,%xmm8
  .byte  65,15,89,209                        // mulps         %xmm9,%xmm2
  .byte  65,15,88,208                        // addps         %xmm8,%xmm2
  .byte  68,15,89,203                        // mulps         %xmm3,%xmm9
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  65,15,88,217                        // addps         %xmm9,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcin_sse41
.globl _sk_srcin_sse41
FUNCTION(_sk_srcin_sse41)
_sk_srcin_sse41:
  .byte  15,89,199                           // mulps         %xmm7,%xmm0
  .byte  15,89,207                           // mulps         %xmm7,%xmm1
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstin_sse41
.globl _sk_dstin_sse41
FUNCTION(_sk_dstin_sse41)
_sk_dstin_sse41:
  .byte  15,40,195                           // movaps        %xmm3,%xmm0
  .byte  15,89,196                           // mulps         %xmm4,%xmm0
  .byte  15,40,203                           // movaps        %xmm3,%xmm1
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  15,40,211                           // movaps        %xmm3,%xmm2
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcout_sse41
.globl _sk_srcout_sse41
FUNCTION(_sk_srcout_sse41)
_sk_srcout_sse41:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,92,199                        // subps         %xmm7,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstout_sse41
.globl _sk_dstout_sse41
FUNCTION(_sk_dstout_sse41)
_sk_dstout_sse41:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,92,195                        // subps         %xmm3,%xmm8
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  15,89,196                           // mulps         %xmm4,%xmm0
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  68,15,89,199                        // mulps         %xmm7,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,216                        // movaps        %xmm8,%xmm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcover_sse41
.globl _sk_srcover_sse41
FUNCTION(_sk_srcover_sse41)
_sk_srcover_sse41:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,92,195                        // subps         %xmm3,%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,204                        // mulps         %xmm4,%xmm9
  .byte  65,15,88,193                        // addps         %xmm9,%xmm0
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,205                        // mulps         %xmm5,%xmm9
  .byte  65,15,88,201                        // addps         %xmm9,%xmm1
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,206                        // mulps         %xmm6,%xmm9
  .byte  65,15,88,209                        // addps         %xmm9,%xmm2
  .byte  68,15,89,199                        // mulps         %xmm7,%xmm8
  .byte  65,15,88,216                        // addps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstover_sse41
.globl _sk_dstover_sse41
FUNCTION(_sk_dstover_sse41)
_sk_dstover_sse41:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,92,199                        // subps         %xmm7,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  15,88,214                           // addps         %xmm6,%xmm2
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  15,88,223                           // addps         %xmm7,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_modulate_sse41
.globl _sk_modulate_sse41
FUNCTION(_sk_modulate_sse41)
_sk_modulate_sse41:
  .byte  15,89,196                           // mulps         %xmm4,%xmm0
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_multiply_sse41
.globl _sk_multiply_sse41
FUNCTION(_sk_multiply_sse41)
_sk_multiply_sse41:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,92,207                        // subps         %xmm7,%xmm9
  .byte  69,15,40,209                        // movaps        %xmm9,%xmm10
  .byte  68,15,89,208                        // mulps         %xmm0,%xmm10
  .byte  68,15,92,195                        // subps         %xmm3,%xmm8
  .byte  69,15,40,216                        // movaps        %xmm8,%xmm11
  .byte  68,15,89,220                        // mulps         %xmm4,%xmm11
  .byte  69,15,88,218                        // addps         %xmm10,%xmm11
  .byte  15,89,196                           // mulps         %xmm4,%xmm0
  .byte  65,15,88,195                        // addps         %xmm11,%xmm0
  .byte  69,15,40,209                        // movaps        %xmm9,%xmm10
  .byte  68,15,89,209                        // mulps         %xmm1,%xmm10
  .byte  69,15,40,216                        // movaps        %xmm8,%xmm11
  .byte  68,15,89,221                        // mulps         %xmm5,%xmm11
  .byte  69,15,88,218                        // addps         %xmm10,%xmm11
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  65,15,88,203                        // addps         %xmm11,%xmm1
  .byte  69,15,40,209                        // movaps        %xmm9,%xmm10
  .byte  68,15,89,210                        // mulps         %xmm2,%xmm10
  .byte  69,15,40,216                        // movaps        %xmm8,%xmm11
  .byte  68,15,89,222                        // mulps         %xmm6,%xmm11
  .byte  69,15,88,218                        // addps         %xmm10,%xmm11
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  65,15,88,211                        // addps         %xmm11,%xmm2
  .byte  68,15,89,203                        // mulps         %xmm3,%xmm9
  .byte  68,15,89,199                        // mulps         %xmm7,%xmm8
  .byte  69,15,88,193                        // addps         %xmm9,%xmm8
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  65,15,88,216                        // addps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_plus__sse41
.globl _sk_plus__sse41
FUNCTION(_sk_plus__sse41)
_sk_plus__sse41:
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  15,88,214                           // addps         %xmm6,%xmm2
  .byte  15,88,223                           // addps         %xmm7,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_screen_sse41
.globl _sk_screen_sse41
FUNCTION(_sk_screen_sse41)
_sk_screen_sse41:
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  68,15,88,196                        // addps         %xmm4,%xmm8
  .byte  15,89,196                           // mulps         %xmm4,%xmm0
  .byte  68,15,92,192                        // subps         %xmm0,%xmm8
  .byte  68,15,40,201                        // movaps        %xmm1,%xmm9
  .byte  68,15,88,205                        // addps         %xmm5,%xmm9
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  68,15,92,201                        // subps         %xmm1,%xmm9
  .byte  68,15,40,210                        // movaps        %xmm2,%xmm10
  .byte  68,15,88,214                        // addps         %xmm6,%xmm10
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  68,15,92,210                        // subps         %xmm2,%xmm10
  .byte  68,15,40,219                        // movaps        %xmm3,%xmm11
  .byte  68,15,88,223                        // addps         %xmm7,%xmm11
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  68,15,92,219                        // subps         %xmm3,%xmm11
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  65,15,40,201                        // movaps        %xmm9,%xmm1
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  65,15,40,219                        // movaps        %xmm11,%xmm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_xor__sse41
.globl _sk_xor__sse41
FUNCTION(_sk_xor__sse41)
_sk_xor__sse41:
  .byte  68,15,40,195                        // movaps        %xmm3,%xmm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,92,207                        // subps         %xmm7,%xmm9
  .byte  65,15,89,193                        // mulps         %xmm9,%xmm0
  .byte  65,15,92,216                        // subps         %xmm8,%xmm3
  .byte  68,15,40,211                        // movaps        %xmm3,%xmm10
  .byte  68,15,89,212                        // mulps         %xmm4,%xmm10
  .byte  65,15,88,194                        // addps         %xmm10,%xmm0
  .byte  65,15,89,201                        // mulps         %xmm9,%xmm1
  .byte  68,15,40,211                        // movaps        %xmm3,%xmm10
  .byte  68,15,89,213                        // mulps         %xmm5,%xmm10
  .byte  65,15,88,202                        // addps         %xmm10,%xmm1
  .byte  65,15,89,209                        // mulps         %xmm9,%xmm2
  .byte  68,15,40,211                        // movaps        %xmm3,%xmm10
  .byte  68,15,89,214                        // mulps         %xmm6,%xmm10
  .byte  65,15,88,210                        // addps         %xmm10,%xmm2
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  65,15,88,217                        // addps         %xmm9,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_darken_sse41
.globl _sk_darken_sse41
FUNCTION(_sk_darken_sse41)
_sk_darken_sse41:
  .byte  68,15,40,193                        // movaps        %xmm1,%xmm8
  .byte  68,15,40,200                        // movaps        %xmm0,%xmm9
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  68,15,89,207                        // mulps         %xmm7,%xmm9
  .byte  15,40,203                           // movaps        %xmm3,%xmm1
  .byte  15,89,204                           // mulps         %xmm4,%xmm1
  .byte  68,15,95,201                        // maxps         %xmm1,%xmm9
  .byte  65,15,92,193                        // subps         %xmm9,%xmm0
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  68,15,89,199                        // mulps         %xmm7,%xmm8
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,89,205                        // mulps         %xmm5,%xmm9
  .byte  69,15,95,193                        // maxps         %xmm9,%xmm8
  .byte  65,15,92,200                        // subps         %xmm8,%xmm1
  .byte  68,15,40,194                        // movaps        %xmm2,%xmm8
  .byte  68,15,88,198                        // addps         %xmm6,%xmm8
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,89,206                        // mulps         %xmm6,%xmm9
  .byte  65,15,95,209                        // maxps         %xmm9,%xmm2
  .byte  68,15,92,194                        // subps         %xmm2,%xmm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  15,92,211                           // subps         %xmm3,%xmm2
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  15,88,218                           // addps         %xmm2,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_lighten_sse41
.globl _sk_lighten_sse41
FUNCTION(_sk_lighten_sse41)
_sk_lighten_sse41:
  .byte  68,15,40,193                        // movaps        %xmm1,%xmm8
  .byte  68,15,40,200                        // movaps        %xmm0,%xmm9
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  68,15,89,207                        // mulps         %xmm7,%xmm9
  .byte  15,40,203                           // movaps        %xmm3,%xmm1
  .byte  15,89,204                           // mulps         %xmm4,%xmm1
  .byte  68,15,93,201                        // minps         %xmm1,%xmm9
  .byte  65,15,92,193                        // subps         %xmm9,%xmm0
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  68,15,89,199                        // mulps         %xmm7,%xmm8
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,89,205                        // mulps         %xmm5,%xmm9
  .byte  69,15,93,193                        // minps         %xmm9,%xmm8
  .byte  65,15,92,200                        // subps         %xmm8,%xmm1
  .byte  68,15,40,194                        // movaps        %xmm2,%xmm8
  .byte  68,15,88,198                        // addps         %xmm6,%xmm8
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,89,206                        // mulps         %xmm6,%xmm9
  .byte  65,15,93,209                        // minps         %xmm9,%xmm2
  .byte  68,15,92,194                        // subps         %xmm2,%xmm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  15,92,211                           // subps         %xmm3,%xmm2
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  15,88,218                           // addps         %xmm2,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_difference_sse41
.globl _sk_difference_sse41
FUNCTION(_sk_difference_sse41)
_sk_difference_sse41:
  .byte  68,15,40,193                        // movaps        %xmm1,%xmm8
  .byte  68,15,40,200                        // movaps        %xmm0,%xmm9
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  68,15,89,207                        // mulps         %xmm7,%xmm9
  .byte  15,40,203                           // movaps        %xmm3,%xmm1
  .byte  15,89,204                           // mulps         %xmm4,%xmm1
  .byte  68,15,93,201                        // minps         %xmm1,%xmm9
  .byte  69,15,88,201                        // addps         %xmm9,%xmm9
  .byte  65,15,92,193                        // subps         %xmm9,%xmm0
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  68,15,89,199                        // mulps         %xmm7,%xmm8
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,89,205                        // mulps         %xmm5,%xmm9
  .byte  69,15,93,193                        // minps         %xmm9,%xmm8
  .byte  69,15,88,192                        // addps         %xmm8,%xmm8
  .byte  65,15,92,200                        // subps         %xmm8,%xmm1
  .byte  68,15,40,194                        // movaps        %xmm2,%xmm8
  .byte  68,15,88,198                        // addps         %xmm6,%xmm8
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,89,206                        // mulps         %xmm6,%xmm9
  .byte  65,15,93,209                        // minps         %xmm9,%xmm2
  .byte  15,88,210                           // addps         %xmm2,%xmm2
  .byte  68,15,92,194                        // subps         %xmm2,%xmm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  15,92,211                           // subps         %xmm3,%xmm2
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  15,88,218                           // addps         %xmm2,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_exclusion_sse41
.globl _sk_exclusion_sse41
FUNCTION(_sk_exclusion_sse41)
_sk_exclusion_sse41:
  .byte  68,15,40,193                        // movaps        %xmm1,%xmm8
  .byte  15,40,200                           // movaps        %xmm0,%xmm1
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  15,89,204                           // mulps         %xmm4,%xmm1
  .byte  15,88,201                           // addps         %xmm1,%xmm1
  .byte  15,92,193                           // subps         %xmm1,%xmm0
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  68,15,89,197                        // mulps         %xmm5,%xmm8
  .byte  69,15,88,192                        // addps         %xmm8,%xmm8
  .byte  65,15,92,200                        // subps         %xmm8,%xmm1
  .byte  68,15,40,194                        // movaps        %xmm2,%xmm8
  .byte  68,15,88,198                        // addps         %xmm6,%xmm8
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  15,88,210                           // addps         %xmm2,%xmm2
  .byte  68,15,92,194                        // subps         %xmm2,%xmm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  15,92,211                           // subps         %xmm3,%xmm2
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  15,88,218                           // addps         %xmm2,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_colorburn_sse41
.globl _sk_colorburn_sse41
FUNCTION(_sk_colorburn_sse41)
_sk_colorburn_sse41:
  .byte  68,15,40,200                        // movaps        %xmm0,%xmm9
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,208                   // movd          %eax,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,40,218                        // movaps        %xmm10,%xmm11
  .byte  68,15,92,223                        // subps         %xmm7,%xmm11
  .byte  69,15,40,227                        // movaps        %xmm11,%xmm12
  .byte  69,15,89,225                        // mulps         %xmm9,%xmm12
  .byte  69,15,87,192                        // xorps         %xmm8,%xmm8
  .byte  15,40,199                           // movaps        %xmm7,%xmm0
  .byte  15,92,196                           // subps         %xmm4,%xmm0
  .byte  15,89,195                           // mulps         %xmm3,%xmm0
  .byte  65,15,94,193                        // divps         %xmm9,%xmm0
  .byte  68,15,40,239                        // movaps        %xmm7,%xmm13
  .byte  68,15,93,232                        // minps         %xmm0,%xmm13
  .byte  68,15,40,247                        // movaps        %xmm7,%xmm14
  .byte  69,15,92,245                        // subps         %xmm13,%xmm14
  .byte  65,15,40,193                        // movaps        %xmm9,%xmm0
  .byte  65,15,194,192,0                     // cmpeqps       %xmm8,%xmm0
  .byte  68,15,92,211                        // subps         %xmm3,%xmm10
  .byte  68,15,89,243                        // mulps         %xmm3,%xmm14
  .byte  69,15,88,244                        // addps         %xmm12,%xmm14
  .byte  102,69,15,56,20,241                 // blendvps      %xmm0,%xmm9,%xmm14
  .byte  69,15,40,202                        // movaps        %xmm10,%xmm9
  .byte  68,15,89,204                        // mulps         %xmm4,%xmm9
  .byte  68,15,88,228                        // addps         %xmm4,%xmm12
  .byte  15,40,196                           // movaps        %xmm4,%xmm0
  .byte  15,194,199,0                        // cmpeqps       %xmm7,%xmm0
  .byte  69,15,88,206                        // addps         %xmm14,%xmm9
  .byte  102,69,15,56,20,204                 // blendvps      %xmm0,%xmm12,%xmm9
  .byte  69,15,40,227                        // movaps        %xmm11,%xmm12
  .byte  68,15,89,225                        // mulps         %xmm1,%xmm12
  .byte  15,40,199                           // movaps        %xmm7,%xmm0
  .byte  15,92,197                           // subps         %xmm5,%xmm0
  .byte  15,89,195                           // mulps         %xmm3,%xmm0
  .byte  15,94,193                           // divps         %xmm1,%xmm0
  .byte  68,15,40,239                        // movaps        %xmm7,%xmm13
  .byte  68,15,93,232                        // minps         %xmm0,%xmm13
  .byte  68,15,40,247                        // movaps        %xmm7,%xmm14
  .byte  69,15,92,245                        // subps         %xmm13,%xmm14
  .byte  15,40,193                           // movaps        %xmm1,%xmm0
  .byte  65,15,194,192,0                     // cmpeqps       %xmm8,%xmm0
  .byte  68,15,89,243                        // mulps         %xmm3,%xmm14
  .byte  69,15,88,244                        // addps         %xmm12,%xmm14
  .byte  102,68,15,56,20,241                 // blendvps      %xmm0,%xmm1,%xmm14
  .byte  65,15,40,202                        // movaps        %xmm10,%xmm1
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  68,15,88,229                        // addps         %xmm5,%xmm12
  .byte  65,15,88,206                        // addps         %xmm14,%xmm1
  .byte  15,40,197                           // movaps        %xmm5,%xmm0
  .byte  15,194,199,0                        // cmpeqps       %xmm7,%xmm0
  .byte  102,65,15,56,20,204                 // blendvps      %xmm0,%xmm12,%xmm1
  .byte  15,40,199                           // movaps        %xmm7,%xmm0
  .byte  15,92,198                           // subps         %xmm6,%xmm0
  .byte  15,89,195                           // mulps         %xmm3,%xmm0
  .byte  15,94,194                           // divps         %xmm2,%xmm0
  .byte  68,15,40,231                        // movaps        %xmm7,%xmm12
  .byte  68,15,93,224                        // minps         %xmm0,%xmm12
  .byte  68,15,40,239                        // movaps        %xmm7,%xmm13
  .byte  69,15,92,236                        // subps         %xmm12,%xmm13
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  68,15,194,194,0                     // cmpeqps       %xmm2,%xmm8
  .byte  68,15,89,235                        // mulps         %xmm3,%xmm13
  .byte  69,15,88,235                        // addps         %xmm11,%xmm13
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  102,68,15,56,20,234                 // blendvps      %xmm0,%xmm2,%xmm13
  .byte  68,15,88,222                        // addps         %xmm6,%xmm11
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  65,15,88,213                        // addps         %xmm13,%xmm2
  .byte  15,40,198                           // movaps        %xmm6,%xmm0
  .byte  15,194,199,0                        // cmpeqps       %xmm7,%xmm0
  .byte  102,65,15,56,20,211                 // blendvps      %xmm0,%xmm11,%xmm2
  .byte  68,15,89,215                        // mulps         %xmm7,%xmm10
  .byte  65,15,88,218                        // addps         %xmm10,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,193                        // movaps        %xmm9,%xmm0
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_colordodge_sse41
.globl _sk_colordodge_sse41
FUNCTION(_sk_colordodge_sse41)
_sk_colordodge_sse41:
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,208                   // movd          %eax,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,40,218                        // movaps        %xmm10,%xmm11
  .byte  68,15,92,223                        // subps         %xmm7,%xmm11
  .byte  69,15,40,227                        // movaps        %xmm11,%xmm12
  .byte  69,15,89,224                        // mulps         %xmm8,%xmm12
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,89,204                        // mulps         %xmm4,%xmm9
  .byte  15,40,195                           // movaps        %xmm3,%xmm0
  .byte  65,15,92,192                        // subps         %xmm8,%xmm0
  .byte  68,15,94,200                        // divps         %xmm0,%xmm9
  .byte  68,15,40,239                        // movaps        %xmm7,%xmm13
  .byte  68,15,40,247                        // movaps        %xmm7,%xmm14
  .byte  69,15,93,241                        // minps         %xmm9,%xmm14
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  15,194,195,0                        // cmpeqps       %xmm3,%xmm0
  .byte  68,15,89,243                        // mulps         %xmm3,%xmm14
  .byte  69,15,88,244                        // addps         %xmm12,%xmm14
  .byte  102,69,15,56,20,240                 // blendvps      %xmm0,%xmm8,%xmm14
  .byte  69,15,87,201                        // xorps         %xmm9,%xmm9
  .byte  68,15,92,211                        // subps         %xmm3,%xmm10
  .byte  69,15,40,194                        // movaps        %xmm10,%xmm8
  .byte  68,15,89,196                        // mulps         %xmm4,%xmm8
  .byte  68,15,88,228                        // addps         %xmm4,%xmm12
  .byte  69,15,88,198                        // addps         %xmm14,%xmm8
  .byte  15,40,196                           // movaps        %xmm4,%xmm0
  .byte  65,15,194,193,0                     // cmpeqps       %xmm9,%xmm0
  .byte  102,69,15,56,20,196                 // blendvps      %xmm0,%xmm12,%xmm8
  .byte  68,15,40,227                        // movaps        %xmm3,%xmm12
  .byte  68,15,89,229                        // mulps         %xmm5,%xmm12
  .byte  15,40,195                           // movaps        %xmm3,%xmm0
  .byte  15,92,193                           // subps         %xmm1,%xmm0
  .byte  68,15,94,224                        // divps         %xmm0,%xmm12
  .byte  69,15,40,243                        // movaps        %xmm11,%xmm14
  .byte  68,15,89,241                        // mulps         %xmm1,%xmm14
  .byte  69,15,93,236                        // minps         %xmm12,%xmm13
  .byte  15,40,193                           // movaps        %xmm1,%xmm0
  .byte  15,194,195,0                        // cmpeqps       %xmm3,%xmm0
  .byte  68,15,89,235                        // mulps         %xmm3,%xmm13
  .byte  69,15,88,238                        // addps         %xmm14,%xmm13
  .byte  102,68,15,56,20,233                 // blendvps      %xmm0,%xmm1,%xmm13
  .byte  65,15,40,202                        // movaps        %xmm10,%xmm1
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  68,15,88,245                        // addps         %xmm5,%xmm14
  .byte  65,15,88,205                        // addps         %xmm13,%xmm1
  .byte  15,40,197                           // movaps        %xmm5,%xmm0
  .byte  65,15,194,193,0                     // cmpeqps       %xmm9,%xmm0
  .byte  102,65,15,56,20,206                 // blendvps      %xmm0,%xmm14,%xmm1
  .byte  68,15,40,227                        // movaps        %xmm3,%xmm12
  .byte  68,15,89,230                        // mulps         %xmm6,%xmm12
  .byte  15,40,195                           // movaps        %xmm3,%xmm0
  .byte  15,92,194                           // subps         %xmm2,%xmm0
  .byte  68,15,94,224                        // divps         %xmm0,%xmm12
  .byte  68,15,40,239                        // movaps        %xmm7,%xmm13
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  69,15,93,236                        // minps         %xmm12,%xmm13
  .byte  15,40,194                           // movaps        %xmm2,%xmm0
  .byte  15,194,195,0                        // cmpeqps       %xmm3,%xmm0
  .byte  68,15,89,235                        // mulps         %xmm3,%xmm13
  .byte  69,15,88,235                        // addps         %xmm11,%xmm13
  .byte  102,68,15,56,20,234                 // blendvps      %xmm0,%xmm2,%xmm13
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  65,15,88,213                        // addps         %xmm13,%xmm2
  .byte  68,15,194,206,0                     // cmpeqps       %xmm6,%xmm9
  .byte  68,15,88,222                        // addps         %xmm6,%xmm11
  .byte  65,15,40,193                        // movaps        %xmm9,%xmm0
  .byte  102,65,15,56,20,211                 // blendvps      %xmm0,%xmm11,%xmm2
  .byte  68,15,89,215                        // mulps         %xmm7,%xmm10
  .byte  65,15,88,218                        // addps         %xmm10,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_hardlight_sse41
.globl _sk_hardlight_sse41
FUNCTION(_sk_hardlight_sse41)
_sk_hardlight_sse41:
  .byte  15,41,116,36,232                    // movaps        %xmm6,-0x18(%rsp)
  .byte  68,15,40,229                        // movaps        %xmm5,%xmm12
  .byte  15,40,244                           // movaps        %xmm4,%xmm6
  .byte  15,40,227                           // movaps        %xmm3,%xmm4
  .byte  15,40,234                           // movaps        %xmm2,%xmm5
  .byte  68,15,40,200                        // movaps        %xmm0,%xmm9
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,208                   // movd          %eax,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  15,92,215                           // subps         %xmm7,%xmm2
  .byte  15,40,194                           // movaps        %xmm2,%xmm0
  .byte  65,15,89,193                        // mulps         %xmm9,%xmm0
  .byte  68,15,92,212                        // subps         %xmm4,%xmm10
  .byte  69,15,40,194                        // movaps        %xmm10,%xmm8
  .byte  68,15,89,198                        // mulps         %xmm6,%xmm8
  .byte  68,15,88,192                        // addps         %xmm0,%xmm8
  .byte  68,15,40,252                        // movaps        %xmm4,%xmm15
  .byte  69,15,92,249                        // subps         %xmm9,%xmm15
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  68,15,40,239                        // movaps        %xmm7,%xmm13
  .byte  68,15,40,247                        // movaps        %xmm7,%xmm14
  .byte  15,40,199                           // movaps        %xmm7,%xmm0
  .byte  15,92,198                           // subps         %xmm6,%xmm0
  .byte  65,15,89,199                        // mulps         %xmm15,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  68,15,40,251                        // movaps        %xmm3,%xmm15
  .byte  68,15,92,248                        // subps         %xmm0,%xmm15
  .byte  65,15,40,193                        // movaps        %xmm9,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,194,196,2                        // cmpleps       %xmm4,%xmm0
  .byte  68,15,89,206                        // mulps         %xmm6,%xmm9
  .byte  69,15,88,201                        // addps         %xmm9,%xmm9
  .byte  102,69,15,56,20,249                 // blendvps      %xmm0,%xmm9,%xmm15
  .byte  68,15,40,218                        // movaps        %xmm2,%xmm11
  .byte  68,15,89,217                        // mulps         %xmm1,%xmm11
  .byte  15,40,196                           // movaps        %xmm4,%xmm0
  .byte  15,92,193                           // subps         %xmm1,%xmm0
  .byte  69,15,40,204                        // movaps        %xmm12,%xmm9
  .byte  69,15,92,233                        // subps         %xmm9,%xmm13
  .byte  68,15,89,232                        // mulps         %xmm0,%xmm13
  .byte  69,15,88,237                        // addps         %xmm13,%xmm13
  .byte  68,15,40,227                        // movaps        %xmm3,%xmm12
  .byte  69,15,92,229                        // subps         %xmm13,%xmm12
  .byte  15,40,193                           // movaps        %xmm1,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,194,196,2                        // cmpleps       %xmm4,%xmm0
  .byte  65,15,89,201                        // mulps         %xmm9,%xmm1
  .byte  69,15,40,233                        // movaps        %xmm9,%xmm13
  .byte  15,88,201                           // addps         %xmm1,%xmm1
  .byte  102,68,15,56,20,225                 // blendvps      %xmm0,%xmm1,%xmm12
  .byte  65,15,40,202                        // movaps        %xmm10,%xmm1
  .byte  69,15,40,202                        // movaps        %xmm10,%xmm9
  .byte  68,15,89,215                        // mulps         %xmm7,%xmm10
  .byte  69,15,88,199                        // addps         %xmm15,%xmm8
  .byte  65,15,89,205                        // mulps         %xmm13,%xmm1
  .byte  65,15,88,203                        // addps         %xmm11,%xmm1
  .byte  65,15,88,204                        // addps         %xmm12,%xmm1
  .byte  15,89,213                           // mulps         %xmm5,%xmm2
  .byte  68,15,40,92,36,232                  // movaps        -0x18(%rsp),%xmm11
  .byte  69,15,89,203                        // mulps         %xmm11,%xmm9
  .byte  68,15,88,202                        // addps         %xmm2,%xmm9
  .byte  15,40,197                           // movaps        %xmm5,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,194,196,2                        // cmpleps       %xmm4,%xmm0
  .byte  15,40,212                           // movaps        %xmm4,%xmm2
  .byte  15,92,213                           // subps         %xmm5,%xmm2
  .byte  65,15,89,235                        // mulps         %xmm11,%xmm5
  .byte  15,88,237                           // addps         %xmm5,%xmm5
  .byte  69,15,92,243                        // subps         %xmm11,%xmm14
  .byte  68,15,89,242                        // mulps         %xmm2,%xmm14
  .byte  69,15,88,246                        // addps         %xmm14,%xmm14
  .byte  65,15,92,222                        // subps         %xmm14,%xmm3
  .byte  102,15,56,20,221                    // blendvps      %xmm0,%xmm5,%xmm3
  .byte  68,15,88,203                        // addps         %xmm3,%xmm9
  .byte  65,15,88,226                        // addps         %xmm10,%xmm4
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  65,15,40,209                        // movaps        %xmm9,%xmm2
  .byte  15,40,220                           // movaps        %xmm4,%xmm3
  .byte  15,40,230                           // movaps        %xmm6,%xmm4
  .byte  65,15,40,237                        // movaps        %xmm13,%xmm5
  .byte  65,15,40,243                        // movaps        %xmm11,%xmm6
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_overlay_sse41
.globl _sk_overlay_sse41
FUNCTION(_sk_overlay_sse41)
_sk_overlay_sse41:
  .byte  68,15,40,201                        // movaps        %xmm1,%xmm9
  .byte  68,15,40,240                        // movaps        %xmm0,%xmm14
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,208                   // movd          %eax,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,40,218                        // movaps        %xmm10,%xmm11
  .byte  68,15,92,223                        // subps         %xmm7,%xmm11
  .byte  65,15,40,195                        // movaps        %xmm11,%xmm0
  .byte  65,15,89,198                        // mulps         %xmm14,%xmm0
  .byte  68,15,92,211                        // subps         %xmm3,%xmm10
  .byte  69,15,40,194                        // movaps        %xmm10,%xmm8
  .byte  68,15,89,196                        // mulps         %xmm4,%xmm8
  .byte  68,15,88,192                        // addps         %xmm0,%xmm8
  .byte  68,15,40,235                        // movaps        %xmm3,%xmm13
  .byte  69,15,92,238                        // subps         %xmm14,%xmm13
  .byte  68,15,89,244                        // mulps         %xmm4,%xmm14
  .byte  15,40,207                           // movaps        %xmm7,%xmm1
  .byte  15,92,204                           // subps         %xmm4,%xmm1
  .byte  15,40,196                           // movaps        %xmm4,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,194,199,2                        // cmpleps       %xmm7,%xmm0
  .byte  69,15,88,246                        // addps         %xmm14,%xmm14
  .byte  68,15,40,227                        // movaps        %xmm3,%xmm12
  .byte  68,15,89,231                        // mulps         %xmm7,%xmm12
  .byte  65,15,89,205                        // mulps         %xmm13,%xmm1
  .byte  15,88,201                           // addps         %xmm1,%xmm1
  .byte  69,15,40,236                        // movaps        %xmm12,%xmm13
  .byte  68,15,92,233                        // subps         %xmm1,%xmm13
  .byte  102,69,15,56,20,238                 // blendvps      %xmm0,%xmm14,%xmm13
  .byte  69,15,88,197                        // addps         %xmm13,%xmm8
  .byte  65,15,40,195                        // movaps        %xmm11,%xmm0
  .byte  65,15,89,193                        // mulps         %xmm9,%xmm0
  .byte  65,15,40,202                        // movaps        %xmm10,%xmm1
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  15,88,200                           // addps         %xmm0,%xmm1
  .byte  68,15,40,235                        // movaps        %xmm3,%xmm13
  .byte  69,15,92,233                        // subps         %xmm9,%xmm13
  .byte  68,15,89,205                        // mulps         %xmm5,%xmm9
  .byte  68,15,40,247                        // movaps        %xmm7,%xmm14
  .byte  68,15,92,245                        // subps         %xmm5,%xmm14
  .byte  15,40,197                           // movaps        %xmm5,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,194,199,2                        // cmpleps       %xmm7,%xmm0
  .byte  69,15,88,201                        // addps         %xmm9,%xmm9
  .byte  69,15,89,245                        // mulps         %xmm13,%xmm14
  .byte  69,15,88,246                        // addps         %xmm14,%xmm14
  .byte  69,15,40,236                        // movaps        %xmm12,%xmm13
  .byte  69,15,92,238                        // subps         %xmm14,%xmm13
  .byte  102,69,15,56,20,233                 // blendvps      %xmm0,%xmm9,%xmm13
  .byte  65,15,88,205                        // addps         %xmm13,%xmm1
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  69,15,40,202                        // movaps        %xmm10,%xmm9
  .byte  68,15,89,206                        // mulps         %xmm6,%xmm9
  .byte  69,15,88,203                        // addps         %xmm11,%xmm9
  .byte  68,15,40,219                        // movaps        %xmm3,%xmm11
  .byte  68,15,92,218                        // subps         %xmm2,%xmm11
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  68,15,40,239                        // movaps        %xmm7,%xmm13
  .byte  68,15,92,238                        // subps         %xmm6,%xmm13
  .byte  15,40,198                           // movaps        %xmm6,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,194,199,2                        // cmpleps       %xmm7,%xmm0
  .byte  15,88,210                           // addps         %xmm2,%xmm2
  .byte  69,15,89,235                        // mulps         %xmm11,%xmm13
  .byte  69,15,88,237                        // addps         %xmm13,%xmm13
  .byte  69,15,92,229                        // subps         %xmm13,%xmm12
  .byte  102,68,15,56,20,226                 // blendvps      %xmm0,%xmm2,%xmm12
  .byte  69,15,88,204                        // addps         %xmm12,%xmm9
  .byte  68,15,89,215                        // mulps         %xmm7,%xmm10
  .byte  65,15,88,218                        // addps         %xmm10,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  65,15,40,209                        // movaps        %xmm9,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_softlight_sse41
.globl _sk_softlight_sse41
FUNCTION(_sk_softlight_sse41)
_sk_softlight_sse41:
  .byte  15,41,116,36,216                    // movaps        %xmm6,-0x28(%rsp)
  .byte  15,40,244                           // movaps        %xmm4,%xmm6
  .byte  15,41,84,36,232                     // movaps        %xmm2,-0x18(%rsp)
  .byte  68,15,40,225                        // movaps        %xmm1,%xmm12
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  15,87,228                           // xorps         %xmm4,%xmm4
  .byte  15,194,231,1                        // cmpltps       %xmm7,%xmm4
  .byte  15,40,198                           // movaps        %xmm6,%xmm0
  .byte  15,94,199                           // divps         %xmm7,%xmm0
  .byte  15,84,196                           // andps         %xmm4,%xmm0
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  68,15,40,209                        // movaps        %xmm1,%xmm10
  .byte  68,15,92,208                        // subps         %xmm0,%xmm10
  .byte  68,15,40,240                        // movaps        %xmm0,%xmm14
  .byte  68,15,40,248                        // movaps        %xmm0,%xmm15
  .byte  15,82,208                           // rsqrtps       %xmm0,%xmm2
  .byte  68,15,83,218                        // rcpps         %xmm2,%xmm11
  .byte  68,15,92,216                        // subps         %xmm0,%xmm11
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,40,208                           // movaps        %xmm0,%xmm2
  .byte  15,89,210                           // mulps         %xmm2,%xmm2
  .byte  15,88,208                           // addps         %xmm0,%xmm2
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  69,15,88,201                        // addps         %xmm9,%xmm9
  .byte  68,15,92,241                        // subps         %xmm1,%xmm14
  .byte  68,15,89,242                        // mulps         %xmm2,%xmm14
  .byte  184,0,0,224,64                      // mov           $0x40e00000,%eax
  .byte  102,68,15,110,232                   // movd          %eax,%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  69,15,89,253                        // mulps         %xmm13,%xmm15
  .byte  69,15,88,254                        // addps         %xmm14,%xmm15
  .byte  15,40,198                           // movaps        %xmm6,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,194,199,2                        // cmpleps       %xmm7,%xmm0
  .byte  102,69,15,56,20,223                 // blendvps      %xmm0,%xmm15,%xmm11
  .byte  65,15,40,193                        // movaps        %xmm9,%xmm0
  .byte  15,92,195                           // subps         %xmm3,%xmm0
  .byte  68,15,89,208                        // mulps         %xmm0,%xmm10
  .byte  68,15,88,211                        // addps         %xmm3,%xmm10
  .byte  68,15,89,214                        // mulps         %xmm6,%xmm10
  .byte  15,40,211                           // movaps        %xmm3,%xmm2
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  15,89,199                           // mulps         %xmm7,%xmm0
  .byte  68,15,89,216                        // mulps         %xmm0,%xmm11
  .byte  68,15,88,218                        // addps         %xmm2,%xmm11
  .byte  68,15,194,203,2                     // cmpleps       %xmm3,%xmm9
  .byte  65,15,40,193                        // movaps        %xmm9,%xmm0
  .byte  102,69,15,56,20,218                 // blendvps      %xmm0,%xmm10,%xmm11
  .byte  68,15,40,213                        // movaps        %xmm5,%xmm10
  .byte  68,15,94,215                        // divps         %xmm7,%xmm10
  .byte  68,15,84,212                        // andps         %xmm4,%xmm10
  .byte  68,15,40,201                        // movaps        %xmm1,%xmm9
  .byte  69,15,92,202                        // subps         %xmm10,%xmm9
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  15,88,210                           // addps         %xmm2,%xmm2
  .byte  15,88,210                           // addps         %xmm2,%xmm2
  .byte  15,40,194                           // movaps        %xmm2,%xmm0
  .byte  15,89,192                           // mulps         %xmm0,%xmm0
  .byte  15,88,194                           // addps         %xmm2,%xmm0
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  15,92,209                           // subps         %xmm1,%xmm2
  .byte  15,89,208                           // mulps         %xmm0,%xmm2
  .byte  65,15,82,194                        // rsqrtps       %xmm10,%xmm0
  .byte  68,15,83,240                        // rcpps         %xmm0,%xmm14
  .byte  69,15,92,242                        // subps         %xmm10,%xmm14
  .byte  69,15,89,213                        // mulps         %xmm13,%xmm10
  .byte  68,15,88,210                        // addps         %xmm2,%xmm10
  .byte  15,40,197                           // movaps        %xmm5,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,194,199,2                        // cmpleps       %xmm7,%xmm0
  .byte  102,69,15,56,20,242                 // blendvps      %xmm0,%xmm10,%xmm14
  .byte  65,15,40,196                        // movaps        %xmm12,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,40,208                           // movaps        %xmm0,%xmm2
  .byte  15,92,211                           // subps         %xmm3,%xmm2
  .byte  68,15,89,202                        // mulps         %xmm2,%xmm9
  .byte  68,15,88,203                        // addps         %xmm3,%xmm9
  .byte  15,41,108,36,200                    // movaps        %xmm5,-0x38(%rsp)
  .byte  68,15,89,205                        // mulps         %xmm5,%xmm9
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  68,15,89,242                        // mulps         %xmm2,%xmm14
  .byte  15,40,211                           // movaps        %xmm3,%xmm2
  .byte  15,89,213                           // mulps         %xmm5,%xmm2
  .byte  68,15,88,242                        // addps         %xmm2,%xmm14
  .byte  68,15,40,249                        // movaps        %xmm1,%xmm15
  .byte  15,194,195,2                        // cmpleps       %xmm3,%xmm0
  .byte  102,69,15,56,20,241                 // blendvps      %xmm0,%xmm9,%xmm14
  .byte  68,15,40,209                        // movaps        %xmm1,%xmm10
  .byte  15,40,108,36,216                    // movaps        -0x28(%rsp),%xmm5
  .byte  15,40,197                           // movaps        %xmm5,%xmm0
  .byte  15,94,199                           // divps         %xmm7,%xmm0
  .byte  15,84,196                           // andps         %xmm4,%xmm0
  .byte  15,40,208                           // movaps        %xmm0,%xmm2
  .byte  15,92,209                           // subps         %xmm1,%xmm2
  .byte  15,92,200                           // subps         %xmm0,%xmm1
  .byte  68,15,89,232                        // mulps         %xmm0,%xmm13
  .byte  15,82,224                           // rsqrtps       %xmm0,%xmm4
  .byte  68,15,83,204                        // rcpps         %xmm4,%xmm9
  .byte  68,15,92,200                        // subps         %xmm0,%xmm9
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,40,224                           // movaps        %xmm0,%xmm4
  .byte  15,89,228                           // mulps         %xmm4,%xmm4
  .byte  15,88,224                           // addps         %xmm0,%xmm4
  .byte  15,89,226                           // mulps         %xmm2,%xmm4
  .byte  68,15,88,236                        // addps         %xmm4,%xmm13
  .byte  15,40,197                           // movaps        %xmm5,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,194,199,2                        // cmpleps       %xmm7,%xmm0
  .byte  102,69,15,56,20,205                 // blendvps      %xmm0,%xmm13,%xmm9
  .byte  68,15,40,108,36,232                 // movaps        -0x18(%rsp),%xmm13
  .byte  65,15,40,197                        // movaps        %xmm13,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  15,40,208                           // movaps        %xmm0,%xmm2
  .byte  15,92,211                           // subps         %xmm3,%xmm2
  .byte  15,89,202                           // mulps         %xmm2,%xmm1
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  68,15,89,202                        // mulps         %xmm2,%xmm9
  .byte  15,40,211                           // movaps        %xmm3,%xmm2
  .byte  15,89,213                           // mulps         %xmm5,%xmm2
  .byte  68,15,88,202                        // addps         %xmm2,%xmm9
  .byte  15,88,203                           // addps         %xmm3,%xmm1
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  15,40,213                           // movaps        %xmm5,%xmm2
  .byte  15,194,195,2                        // cmpleps       %xmm3,%xmm0
  .byte  102,68,15,56,20,201                 // blendvps      %xmm0,%xmm1,%xmm9
  .byte  68,15,92,255                        // subps         %xmm7,%xmm15
  .byte  69,15,89,199                        // mulps         %xmm15,%xmm8
  .byte  69,15,89,231                        // mulps         %xmm15,%xmm12
  .byte  69,15,89,253                        // mulps         %xmm13,%xmm15
  .byte  68,15,92,211                        // subps         %xmm3,%xmm10
  .byte  65,15,40,194                        // movaps        %xmm10,%xmm0
  .byte  15,89,198                           // mulps         %xmm6,%xmm0
  .byte  68,15,88,192                        // addps         %xmm0,%xmm8
  .byte  69,15,88,195                        // addps         %xmm11,%xmm8
  .byte  65,15,40,194                        // movaps        %xmm10,%xmm0
  .byte  15,40,108,36,200                    // movaps        -0x38(%rsp),%xmm5
  .byte  15,89,197                           // mulps         %xmm5,%xmm0
  .byte  68,15,88,224                        // addps         %xmm0,%xmm12
  .byte  69,15,88,230                        // addps         %xmm14,%xmm12
  .byte  65,15,40,194                        // movaps        %xmm10,%xmm0
  .byte  15,89,194                           // mulps         %xmm2,%xmm0
  .byte  65,15,88,199                        // addps         %xmm15,%xmm0
  .byte  68,15,88,200                        // addps         %xmm0,%xmm9
  .byte  68,15,89,215                        // mulps         %xmm7,%xmm10
  .byte  65,15,88,218                        // addps         %xmm10,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,40,230                           // movaps        %xmm6,%xmm4
  .byte  15,40,242                           // movaps        %xmm2,%xmm6
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  65,15,40,204                        // movaps        %xmm12,%xmm1
  .byte  65,15,40,209                        // movaps        %xmm9,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_0_sse41
.globl _sk_clamp_0_sse41
FUNCTION(_sk_clamp_0_sse41)
_sk_clamp_0_sse41:
  .byte  69,15,87,192                        // xorps         %xmm8,%xmm8
  .byte  65,15,95,192                        // maxps         %xmm8,%xmm0
  .byte  65,15,95,200                        // maxps         %xmm8,%xmm1
  .byte  65,15,95,208                        // maxps         %xmm8,%xmm2
  .byte  65,15,95,216                        // maxps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_1_sse41
.globl _sk_clamp_1_sse41
FUNCTION(_sk_clamp_1_sse41)
_sk_clamp_1_sse41:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,93,192                        // minps         %xmm8,%xmm0
  .byte  65,15,93,200                        // minps         %xmm8,%xmm1
  .byte  65,15,93,208                        // minps         %xmm8,%xmm2
  .byte  65,15,93,216                        // minps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_a_sse41
.globl _sk_clamp_a_sse41
FUNCTION(_sk_clamp_a_sse41)
_sk_clamp_a_sse41:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,93,216                        // minps         %xmm8,%xmm3
  .byte  15,93,195                           // minps         %xmm3,%xmm0
  .byte  15,93,203                           // minps         %xmm3,%xmm1
  .byte  15,93,211                           // minps         %xmm3,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_set_rgb_sse41
.globl _sk_set_rgb_sse41
FUNCTION(_sk_set_rgb_sse41)
_sk_set_rgb_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,15,16,0                         // movss         (%rax),%xmm0
  .byte  243,15,16,72,4                      // movss         0x4(%rax),%xmm1
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  243,15,16,80,8                      // movss         0x8(%rax),%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_swap_rb_sse41
.globl _sk_swap_rb_sse41
FUNCTION(_sk_swap_rb_sse41)
_sk_swap_rb_sse41:
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,40,194                           // movaps        %xmm2,%xmm0
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_swap_sse41
.globl _sk_swap_sse41
FUNCTION(_sk_swap_sse41)
_sk_swap_sse41:
  .byte  68,15,40,195                        // movaps        %xmm3,%xmm8
  .byte  68,15,40,202                        // movaps        %xmm2,%xmm9
  .byte  68,15,40,209                        // movaps        %xmm1,%xmm10
  .byte  68,15,40,216                        // movaps        %xmm0,%xmm11
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,40,196                           // movaps        %xmm4,%xmm0
  .byte  15,40,205                           // movaps        %xmm5,%xmm1
  .byte  15,40,214                           // movaps        %xmm6,%xmm2
  .byte  15,40,223                           // movaps        %xmm7,%xmm3
  .byte  65,15,40,227                        // movaps        %xmm11,%xmm4
  .byte  65,15,40,234                        // movaps        %xmm10,%xmm5
  .byte  65,15,40,241                        // movaps        %xmm9,%xmm6
  .byte  65,15,40,248                        // movaps        %xmm8,%xmm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_move_src_dst_sse41
.globl _sk_move_src_dst_sse41
FUNCTION(_sk_move_src_dst_sse41)
_sk_move_src_dst_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,40,224                           // movaps        %xmm0,%xmm4
  .byte  15,40,233                           // movaps        %xmm1,%xmm5
  .byte  15,40,242                           // movaps        %xmm2,%xmm6
  .byte  15,40,251                           // movaps        %xmm3,%xmm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_move_dst_src_sse41
.globl _sk_move_dst_src_sse41
FUNCTION(_sk_move_dst_src_sse41)
_sk_move_dst_src_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,40,196                           // movaps        %xmm4,%xmm0
  .byte  15,40,205                           // movaps        %xmm5,%xmm1
  .byte  15,40,214                           // movaps        %xmm6,%xmm2
  .byte  15,40,223                           // movaps        %xmm7,%xmm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_premul_sse41
.globl _sk_premul_sse41
FUNCTION(_sk_premul_sse41)
_sk_premul_sse41:
  .byte  15,89,195                           // mulps         %xmm3,%xmm0
  .byte  15,89,203                           // mulps         %xmm3,%xmm1
  .byte  15,89,211                           // mulps         %xmm3,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_unpremul_sse41
.globl _sk_unpremul_sse41
FUNCTION(_sk_unpremul_sse41)
_sk_unpremul_sse41:
  .byte  69,15,87,192                        // xorps         %xmm8,%xmm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,200                   // movd          %eax,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  68,15,94,203                        // divps         %xmm3,%xmm9
  .byte  68,15,194,195,4                     // cmpneqps      %xmm3,%xmm8
  .byte  69,15,84,193                        // andps         %xmm9,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_from_srgb_sse41
.globl _sk_from_srgb_sse41
FUNCTION(_sk_from_srgb_sse41)
_sk_from_srgb_sse41:
  .byte  184,145,131,158,61                  // mov           $0x3d9e8391,%eax
  .byte  102,68,15,110,216                   // movd          %eax,%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,40,211                        // movaps        %xmm11,%xmm10
  .byte  68,15,89,208                        // mulps         %xmm0,%xmm10
  .byte  68,15,40,240                        // movaps        %xmm0,%xmm14
  .byte  69,15,89,246                        // mulps         %xmm14,%xmm14
  .byte  184,154,153,153,62                  // mov           $0x3e99999a,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  184,92,143,50,63                    // mov           $0x3f328f5c,%eax
  .byte  102,68,15,110,224                   // movd          %eax,%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,200                        // mulps         %xmm0,%xmm9
  .byte  69,15,88,204                        // addps         %xmm12,%xmm9
  .byte  184,10,215,35,59                    // mov           $0x3b23d70a,%eax
  .byte  102,68,15,110,232                   // movd          %eax,%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  69,15,89,206                        // mulps         %xmm14,%xmm9
  .byte  69,15,88,205                        // addps         %xmm13,%xmm9
  .byte  184,174,71,97,61                    // mov           $0x3d6147ae,%eax
  .byte  102,68,15,110,240                   // movd          %eax,%xmm14
  .byte  69,15,198,246,0                     // shufps        $0x0,%xmm14,%xmm14
  .byte  65,15,194,198,1                     // cmpltps       %xmm14,%xmm0
  .byte  102,69,15,56,20,202                 // blendvps      %xmm0,%xmm10,%xmm9
  .byte  69,15,40,251                        // movaps        %xmm11,%xmm15
  .byte  68,15,89,249                        // mulps         %xmm1,%xmm15
  .byte  15,40,193                           // movaps        %xmm1,%xmm0
  .byte  15,89,192                           // mulps         %xmm0,%xmm0
  .byte  69,15,40,208                        // movaps        %xmm8,%xmm10
  .byte  68,15,89,209                        // mulps         %xmm1,%xmm10
  .byte  69,15,88,212                        // addps         %xmm12,%xmm10
  .byte  68,15,89,208                        // mulps         %xmm0,%xmm10
  .byte  69,15,88,213                        // addps         %xmm13,%xmm10
  .byte  65,15,194,206,1                     // cmpltps       %xmm14,%xmm1
  .byte  15,40,193                           // movaps        %xmm1,%xmm0
  .byte  102,69,15,56,20,215                 // blendvps      %xmm0,%xmm15,%xmm10
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  15,40,194                           // movaps        %xmm2,%xmm0
  .byte  15,89,192                           // mulps         %xmm0,%xmm0
  .byte  68,15,89,194                        // mulps         %xmm2,%xmm8
  .byte  69,15,88,196                        // addps         %xmm12,%xmm8
  .byte  68,15,89,192                        // mulps         %xmm0,%xmm8
  .byte  69,15,88,197                        // addps         %xmm13,%xmm8
  .byte  65,15,194,214,1                     // cmpltps       %xmm14,%xmm2
  .byte  15,40,194                           // movaps        %xmm2,%xmm0
  .byte  102,69,15,56,20,195                 // blendvps      %xmm0,%xmm11,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,193                        // movaps        %xmm9,%xmm0
  .byte  65,15,40,202                        // movaps        %xmm10,%xmm1
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_to_srgb_sse41
.globl _sk_to_srgb_sse41
FUNCTION(_sk_to_srgb_sse41)
_sk_to_srgb_sse41:
  .byte  15,41,124,36,232                    // movaps        %xmm7,-0x18(%rsp)
  .byte  15,40,254                           // movaps        %xmm6,%xmm7
  .byte  15,40,245                           // movaps        %xmm5,%xmm6
  .byte  15,40,236                           // movaps        %xmm4,%xmm5
  .byte  15,40,227                           // movaps        %xmm3,%xmm4
  .byte  15,40,218                           // movaps        %xmm2,%xmm3
  .byte  15,40,209                           // movaps        %xmm1,%xmm2
  .byte  68,15,82,192                        // rsqrtps       %xmm0,%xmm8
  .byte  69,15,83,200                        // rcpps         %xmm8,%xmm9
  .byte  69,15,82,248                        // rsqrtps       %xmm8,%xmm15
  .byte  184,41,92,71,65                     // mov           $0x41475c29,%eax
  .byte  102,68,15,110,216                   // movd          %eax,%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,40,211                        // movaps        %xmm11,%xmm10
  .byte  68,15,89,208                        // mulps         %xmm0,%xmm10
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  184,194,135,210,62                  // mov           $0x3ed287c2,%eax
  .byte  102,68,15,110,224                   // movd          %eax,%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  184,206,111,48,63                   // mov           $0x3f306fce,%eax
  .byte  102,68,15,110,232                   // movd          %eax,%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  184,168,87,202,61                   // mov           $0x3dca57a8,%eax
  .byte  53,0,0,0,128                        // xor           $0x80000000,%eax
  .byte  102,68,15,110,240                   // movd          %eax,%xmm14
  .byte  69,15,198,246,0                     // shufps        $0x0,%xmm14,%xmm14
  .byte  69,15,89,205                        // mulps         %xmm13,%xmm9
  .byte  69,15,88,206                        // addps         %xmm14,%xmm9
  .byte  69,15,89,252                        // mulps         %xmm12,%xmm15
  .byte  69,15,88,249                        // addps         %xmm9,%xmm15
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  69,15,93,207                        // minps         %xmm15,%xmm9
  .byte  184,4,231,140,59                    // mov           $0x3b8ce704,%eax
  .byte  102,68,15,110,248                   // movd          %eax,%xmm15
  .byte  69,15,198,255,0                     // shufps        $0x0,%xmm15,%xmm15
  .byte  65,15,194,199,1                     // cmpltps       %xmm15,%xmm0
  .byte  102,69,15,56,20,202                 // blendvps      %xmm0,%xmm10,%xmm9
  .byte  68,15,82,210                        // rsqrtps       %xmm2,%xmm10
  .byte  65,15,83,194                        // rcpps         %xmm10,%xmm0
  .byte  69,15,82,210                        // rsqrtps       %xmm10,%xmm10
  .byte  65,15,89,197                        // mulps         %xmm13,%xmm0
  .byte  65,15,88,198                        // addps         %xmm14,%xmm0
  .byte  69,15,89,212                        // mulps         %xmm12,%xmm10
  .byte  68,15,88,208                        // addps         %xmm0,%xmm10
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  65,15,93,202                        // minps         %xmm10,%xmm1
  .byte  69,15,40,211                        // movaps        %xmm11,%xmm10
  .byte  68,15,89,210                        // mulps         %xmm2,%xmm10
  .byte  65,15,194,215,1                     // cmpltps       %xmm15,%xmm2
  .byte  15,40,194                           // movaps        %xmm2,%xmm0
  .byte  102,65,15,56,20,202                 // blendvps      %xmm0,%xmm10,%xmm1
  .byte  15,82,195                           // rsqrtps       %xmm3,%xmm0
  .byte  15,83,208                           // rcpps         %xmm0,%xmm2
  .byte  65,15,89,213                        // mulps         %xmm13,%xmm2
  .byte  65,15,88,214                        // addps         %xmm14,%xmm2
  .byte  15,82,192                           // rsqrtps       %xmm0,%xmm0
  .byte  65,15,89,196                        // mulps         %xmm12,%xmm0
  .byte  15,88,194                           // addps         %xmm2,%xmm0
  .byte  68,15,93,192                        // minps         %xmm0,%xmm8
  .byte  68,15,89,219                        // mulps         %xmm3,%xmm11
  .byte  65,15,194,223,1                     // cmpltps       %xmm15,%xmm3
  .byte  15,40,195                           // movaps        %xmm3,%xmm0
  .byte  102,69,15,56,20,195                 // blendvps      %xmm0,%xmm11,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,193                        // movaps        %xmm9,%xmm0
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  15,40,220                           // movaps        %xmm4,%xmm3
  .byte  15,40,229                           // movaps        %xmm5,%xmm4
  .byte  15,40,238                           // movaps        %xmm6,%xmm5
  .byte  15,40,247                           // movaps        %xmm7,%xmm6
  .byte  15,40,124,36,232                    // movaps        -0x18(%rsp),%xmm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_rgb_to_hsl_sse41
.globl _sk_rgb_to_hsl_sse41
FUNCTION(_sk_rgb_to_hsl_sse41)
_sk_rgb_to_hsl_sse41:
  .byte  15,41,124,36,232                    // movaps        %xmm7,-0x18(%rsp)
  .byte  15,40,254                           // movaps        %xmm6,%xmm7
  .byte  15,40,245                           // movaps        %xmm5,%xmm6
  .byte  15,40,236                           // movaps        %xmm4,%xmm5
  .byte  15,40,227                           // movaps        %xmm3,%xmm4
  .byte  15,40,218                           // movaps        %xmm2,%xmm3
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,216                   // movd          %eax,%xmm11
  .byte  65,184,171,170,42,62                // mov           $0x3e2aaaab,%r8d
  .byte  65,185,0,0,192,64                   // mov           $0x40c00000,%r9d
  .byte  184,0,0,0,64                        // mov           $0x40000000,%eax
  .byte  185,0,0,128,64                      // mov           $0x40800000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  68,15,40,224                        // movaps        %xmm0,%xmm12
  .byte  68,15,95,225                        // maxps         %xmm1,%xmm12
  .byte  68,15,95,227                        // maxps         %xmm3,%xmm12
  .byte  68,15,40,232                        // movaps        %xmm0,%xmm13
  .byte  68,15,93,233                        // minps         %xmm1,%xmm13
  .byte  68,15,93,235                        // minps         %xmm3,%xmm13
  .byte  69,15,40,204                        // movaps        %xmm12,%xmm9
  .byte  68,15,194,200,0                     // cmpeqps       %xmm0,%xmm9
  .byte  68,15,40,241                        // movaps        %xmm1,%xmm14
  .byte  68,15,92,243                        // subps         %xmm3,%xmm14
  .byte  68,15,40,249                        // movaps        %xmm1,%xmm15
  .byte  68,15,194,251,1                     // cmpltps       %xmm3,%xmm15
  .byte  69,15,40,212                        // movaps        %xmm12,%xmm10
  .byte  68,15,194,209,0                     // cmpeqps       %xmm1,%xmm10
  .byte  15,92,216                           // subps         %xmm0,%xmm3
  .byte  15,92,193                           // subps         %xmm1,%xmm0
  .byte  65,15,40,212                        // movaps        %xmm12,%xmm2
  .byte  65,15,92,213                        // subps         %xmm13,%xmm2
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  68,15,94,218                        // divps         %xmm2,%xmm11
  .byte  65,15,89,195                        // mulps         %xmm11,%xmm0
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,88,192                        // addps         %xmm0,%xmm8
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  65,15,89,219                        // mulps         %xmm11,%xmm3
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  15,88,217                           // addps         %xmm1,%xmm3
  .byte  65,15,40,194                        // movaps        %xmm10,%xmm0
  .byte  102,68,15,56,20,195                 // blendvps      %xmm0,%xmm3,%xmm8
  .byte  69,15,89,243                        // mulps         %xmm11,%xmm14
  .byte  102,65,15,110,217                   // movd          %r9d,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  65,15,84,223                        // andps         %xmm15,%xmm3
  .byte  65,15,88,222                        // addps         %xmm14,%xmm3
  .byte  184,0,0,0,63                        // mov           $0x3f000000,%eax
  .byte  102,68,15,110,208                   // movd          %eax,%xmm10
  .byte  65,15,40,193                        // movaps        %xmm9,%xmm0
  .byte  102,68,15,56,20,195                 // blendvps      %xmm0,%xmm3,%xmm8
  .byte  65,15,40,220                        // movaps        %xmm12,%xmm3
  .byte  65,15,92,204                        // subps         %xmm12,%xmm1
  .byte  69,15,88,229                        // addps         %xmm13,%xmm12
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,40,204                        // movaps        %xmm12,%xmm9
  .byte  69,15,89,202                        // mulps         %xmm10,%xmm9
  .byte  69,15,194,209,1                     // cmpltps       %xmm9,%xmm10
  .byte  65,15,92,205                        // subps         %xmm13,%xmm1
  .byte  65,15,40,194                        // movaps        %xmm10,%xmm0
  .byte  102,68,15,56,20,225                 // blendvps      %xmm0,%xmm1,%xmm12
  .byte  65,15,194,221,4                     // cmpneqps      %xmm13,%xmm3
  .byte  102,65,15,110,192                   // movd          %r8d,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  68,15,84,195                        // andps         %xmm3,%xmm8
  .byte  68,15,89,192                        // mulps         %xmm0,%xmm8
  .byte  65,15,94,212                        // divps         %xmm12,%xmm2
  .byte  15,84,211                           // andps         %xmm3,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  15,40,202                           // movaps        %xmm2,%xmm1
  .byte  65,15,40,209                        // movaps        %xmm9,%xmm2
  .byte  15,40,220                           // movaps        %xmm4,%xmm3
  .byte  15,40,229                           // movaps        %xmm5,%xmm4
  .byte  15,40,238                           // movaps        %xmm6,%xmm5
  .byte  15,40,247                           // movaps        %xmm7,%xmm6
  .byte  15,40,124,36,232                    // movaps        -0x18(%rsp),%xmm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_hsl_to_rgb_sse41
.globl _sk_hsl_to_rgb_sse41
FUNCTION(_sk_hsl_to_rgb_sse41)
_sk_hsl_to_rgb_sse41:
  .byte  72,131,236,24                       // sub           $0x18,%rsp
  .byte  15,41,60,36                         // movaps        %xmm7,(%rsp)
  .byte  15,41,116,36,240                    // movaps        %xmm6,-0x10(%rsp)
  .byte  15,41,108,36,224                    // movaps        %xmm5,-0x20(%rsp)
  .byte  15,41,100,36,208                    // movaps        %xmm4,-0x30(%rsp)
  .byte  15,41,92,36,192                     // movaps        %xmm3,-0x40(%rsp)
  .byte  68,15,40,208                        // movaps        %xmm0,%xmm10
  .byte  184,0,0,0,63                        // mov           $0x3f000000,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  15,41,92,36,128                     // movaps        %xmm3,-0x80(%rsp)
  .byte  15,40,194                           // movaps        %xmm2,%xmm0
  .byte  15,194,195,1                        // cmpltps       %xmm3,%xmm0
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,40,224                        // movaps        %xmm8,%xmm4
  .byte  15,88,225                           // addps         %xmm1,%xmm4
  .byte  15,89,226                           // mulps         %xmm2,%xmm4
  .byte  15,40,217                           // movaps        %xmm1,%xmm3
  .byte  15,40,249                           // movaps        %xmm1,%xmm7
  .byte  15,88,250                           // addps         %xmm2,%xmm7
  .byte  15,89,218                           // mulps         %xmm2,%xmm3
  .byte  15,40,234                           // movaps        %xmm2,%xmm5
  .byte  15,92,251                           // subps         %xmm3,%xmm7
  .byte  102,15,56,20,252                    // blendvps      %xmm0,%xmm4,%xmm7
  .byte  184,0,0,0,64                        // mov           $0x40000000,%eax
  .byte  185,171,170,170,62                  // mov           $0x3eaaaaab,%ecx
  .byte  102,15,110,209                      // movd          %ecx,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  15,41,84,36,176                     // movaps        %xmm2,-0x50(%rsp)
  .byte  65,15,88,210                        // addps         %xmm10,%xmm2
  .byte  185,0,0,0,0                         // mov           $0x0,%ecx
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  15,194,194,1                        // cmpltps       %xmm2,%xmm0
  .byte  15,40,218                           // movaps        %xmm2,%xmm3
  .byte  65,15,92,216                        // subps         %xmm8,%xmm3
  .byte  68,15,40,226                        // movaps        %xmm2,%xmm12
  .byte  102,68,15,56,20,227                 // blendvps      %xmm0,%xmm3,%xmm12
  .byte  102,68,15,110,241                   // movd          %ecx,%xmm14
  .byte  69,15,198,246,0                     // shufps        $0x0,%xmm14,%xmm14
  .byte  15,40,194                           // movaps        %xmm2,%xmm0
  .byte  65,15,194,198,1                     // cmpltps       %xmm14,%xmm0
  .byte  68,15,41,116,36,160                 // movaps        %xmm14,-0x60(%rsp)
  .byte  65,15,40,216                        // movaps        %xmm8,%xmm3
  .byte  15,88,218                           // addps         %xmm2,%xmm3
  .byte  102,68,15,56,20,227                 // blendvps      %xmm0,%xmm3,%xmm12
  .byte  102,68,15,110,200                   // movd          %eax,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  15,40,229                           // movaps        %xmm5,%xmm4
  .byte  15,41,100,36,144                    // movaps        %xmm4,-0x70(%rsp)
  .byte  68,15,89,204                        // mulps         %xmm4,%xmm9
  .byte  68,15,92,207                        // subps         %xmm7,%xmm9
  .byte  184,171,170,42,62                   // mov           $0x3e2aaaab,%eax
  .byte  15,40,199                           // movaps        %xmm7,%xmm0
  .byte  65,15,92,193                        // subps         %xmm9,%xmm0
  .byte  185,0,0,192,64                      // mov           $0x40c00000,%ecx
  .byte  102,15,110,241                      // movd          %ecx,%xmm6
  .byte  15,198,246,0                        // shufps        $0x0,%xmm6,%xmm6
  .byte  15,89,240                           // mulps         %xmm0,%xmm6
  .byte  185,171,170,42,63                   // mov           $0x3f2aaaab,%ecx
  .byte  102,15,110,217                      // movd          %ecx,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  15,40,235                           // movaps        %xmm3,%xmm5
  .byte  65,15,92,236                        // subps         %xmm12,%xmm5
  .byte  69,15,40,236                        // movaps        %xmm12,%xmm13
  .byte  69,15,40,252                        // movaps        %xmm12,%xmm15
  .byte  68,15,194,227,1                     // cmpltps       %xmm3,%xmm12
  .byte  15,89,238                           // mulps         %xmm6,%xmm5
  .byte  65,15,88,233                        // addps         %xmm9,%xmm5
  .byte  69,15,40,217                        // movaps        %xmm9,%xmm11
  .byte  65,15,40,196                        // movaps        %xmm12,%xmm0
  .byte  102,68,15,56,20,221                 // blendvps      %xmm0,%xmm5,%xmm11
  .byte  68,15,194,124,36,128,1              // cmpltps       -0x80(%rsp),%xmm15
  .byte  65,15,40,199                        // movaps        %xmm15,%xmm0
  .byte  102,68,15,56,20,223                 // blendvps      %xmm0,%xmm7,%xmm11
  .byte  102,15,110,232                      // movd          %eax,%xmm5
  .byte  15,198,237,0                        // shufps        $0x0,%xmm5,%xmm5
  .byte  68,15,194,237,1                     // cmpltps       %xmm5,%xmm13
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  65,15,88,209                        // addps         %xmm9,%xmm2
  .byte  65,15,40,197                        // movaps        %xmm13,%xmm0
  .byte  102,68,15,56,20,218                 // blendvps      %xmm0,%xmm2,%xmm11
  .byte  69,15,87,228                        // xorps         %xmm12,%xmm12
  .byte  68,15,194,225,0                     // cmpeqps       %xmm1,%xmm12
  .byte  65,15,40,196                        // movaps        %xmm12,%xmm0
  .byte  102,68,15,56,20,220                 // blendvps      %xmm0,%xmm4,%xmm11
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  65,15,194,194,1                     // cmpltps       %xmm10,%xmm0
  .byte  65,15,40,202                        // movaps        %xmm10,%xmm1
  .byte  65,15,92,200                        // subps         %xmm8,%xmm1
  .byte  69,15,40,234                        // movaps        %xmm10,%xmm13
  .byte  102,68,15,56,20,233                 // blendvps      %xmm0,%xmm1,%xmm13
  .byte  65,15,40,194                        // movaps        %xmm10,%xmm0
  .byte  65,15,194,198,1                     // cmpltps       %xmm14,%xmm0
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  65,15,88,202                        // addps         %xmm10,%xmm1
  .byte  102,68,15,56,20,233                 // blendvps      %xmm0,%xmm1,%xmm13
  .byte  68,15,40,243                        // movaps        %xmm3,%xmm14
  .byte  69,15,92,245                        // subps         %xmm13,%xmm14
  .byte  65,15,40,229                        // movaps        %xmm13,%xmm4
  .byte  69,15,40,253                        // movaps        %xmm13,%xmm15
  .byte  68,15,194,235,1                     // cmpltps       %xmm3,%xmm13
  .byte  68,15,89,246                        // mulps         %xmm6,%xmm14
  .byte  69,15,88,241                        // addps         %xmm9,%xmm14
  .byte  65,15,40,201                        // movaps        %xmm9,%xmm1
  .byte  65,15,40,197                        // movaps        %xmm13,%xmm0
  .byte  102,65,15,56,20,206                 // blendvps      %xmm0,%xmm14,%xmm1
  .byte  68,15,40,116,36,128                 // movaps        -0x80(%rsp),%xmm14
  .byte  69,15,194,254,1                     // cmpltps       %xmm14,%xmm15
  .byte  65,15,40,199                        // movaps        %xmm15,%xmm0
  .byte  102,15,56,20,207                    // blendvps      %xmm0,%xmm7,%xmm1
  .byte  15,194,229,1                        // cmpltps       %xmm5,%xmm4
  .byte  15,40,214                           // movaps        %xmm6,%xmm2
  .byte  65,15,89,210                        // mulps         %xmm10,%xmm2
  .byte  65,15,88,209                        // addps         %xmm9,%xmm2
  .byte  15,40,196                           // movaps        %xmm4,%xmm0
  .byte  102,15,56,20,202                    // blendvps      %xmm0,%xmm2,%xmm1
  .byte  65,15,40,196                        // movaps        %xmm12,%xmm0
  .byte  68,15,40,124,36,144                 // movaps        -0x70(%rsp),%xmm15
  .byte  102,65,15,56,20,207                 // blendvps      %xmm0,%xmm15,%xmm1
  .byte  68,15,92,84,36,176                  // subps         -0x50(%rsp),%xmm10
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  65,15,92,208                        // subps         %xmm8,%xmm2
  .byte  69,15,40,232                        // movaps        %xmm8,%xmm13
  .byte  69,15,194,194,1                     // cmpltps       %xmm10,%xmm8
  .byte  65,15,40,226                        // movaps        %xmm10,%xmm4
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  102,15,56,20,226                    // blendvps      %xmm0,%xmm2,%xmm4
  .byte  65,15,40,194                        // movaps        %xmm10,%xmm0
  .byte  15,194,68,36,160,1                  // cmpltps       -0x60(%rsp),%xmm0
  .byte  69,15,88,234                        // addps         %xmm10,%xmm13
  .byte  102,65,15,56,20,229                 // blendvps      %xmm0,%xmm13,%xmm4
  .byte  68,15,89,214                        // mulps         %xmm6,%xmm10
  .byte  15,40,196                           // movaps        %xmm4,%xmm0
  .byte  15,194,195,1                        // cmpltps       %xmm3,%xmm0
  .byte  15,92,220                           // subps         %xmm4,%xmm3
  .byte  15,89,222                           // mulps         %xmm6,%xmm3
  .byte  69,15,88,209                        // addps         %xmm9,%xmm10
  .byte  65,15,88,217                        // addps         %xmm9,%xmm3
  .byte  102,68,15,56,20,203                 // blendvps      %xmm0,%xmm3,%xmm9
  .byte  15,40,196                           // movaps        %xmm4,%xmm0
  .byte  65,15,194,198,1                     // cmpltps       %xmm14,%xmm0
  .byte  102,68,15,56,20,207                 // blendvps      %xmm0,%xmm7,%xmm9
  .byte  15,40,196                           // movaps        %xmm4,%xmm0
  .byte  15,194,197,1                        // cmpltps       %xmm5,%xmm0
  .byte  102,69,15,56,20,202                 // blendvps      %xmm0,%xmm10,%xmm9
  .byte  65,15,40,196                        // movaps        %xmm12,%xmm0
  .byte  102,69,15,56,20,207                 // blendvps      %xmm0,%xmm15,%xmm9
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,195                        // movaps        %xmm11,%xmm0
  .byte  65,15,40,209                        // movaps        %xmm9,%xmm2
  .byte  15,40,92,36,192                     // movaps        -0x40(%rsp),%xmm3
  .byte  15,40,100,36,208                    // movaps        -0x30(%rsp),%xmm4
  .byte  15,40,108,36,224                    // movaps        -0x20(%rsp),%xmm5
  .byte  15,40,116,36,240                    // movaps        -0x10(%rsp),%xmm6
  .byte  15,40,60,36                         // movaps        (%rsp),%xmm7
  .byte  72,131,196,24                       // add           $0x18,%rsp
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_scale_1_float_sse41
.globl _sk_scale_1_float_sse41
FUNCTION(_sk_scale_1_float_sse41)
_sk_scale_1_float_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,0                      // movss         (%rax),%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_scale_u8_sse41
.globl _sk_scale_u8_sse41
FUNCTION(_sk_scale_u8_sse41)
_sk_scale_u8_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  102,68,15,56,49,4,56                // pmovzxbd      (%rax,%rdi,1),%xmm8
  .byte  69,15,91,192                        // cvtdq2ps      %xmm8,%xmm8
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,68,15,110,200                   // movd          %eax,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  65,15,89,193                        // mulps         %xmm9,%xmm0
  .byte  65,15,89,201                        // mulps         %xmm9,%xmm1
  .byte  65,15,89,209                        // mulps         %xmm9,%xmm2
  .byte  65,15,89,217                        // mulps         %xmm9,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_lerp_1_float_sse41
.globl _sk_lerp_1_float_sse41
FUNCTION(_sk_lerp_1_float_sse41)
_sk_lerp_1_float_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,0                      // movss         (%rax),%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,92,196                           // subps         %xmm4,%xmm0
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  15,92,205                           // subps         %xmm5,%xmm1
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  15,92,214                           // subps         %xmm6,%xmm2
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  15,88,214                           // addps         %xmm6,%xmm2
  .byte  15,92,223                           // subps         %xmm7,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  15,88,223                           // addps         %xmm7,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_lerp_u8_sse41
.globl _sk_lerp_u8_sse41
FUNCTION(_sk_lerp_u8_sse41)
_sk_lerp_u8_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  102,68,15,56,49,4,56                // pmovzxbd      (%rax,%rdi,1),%xmm8
  .byte  69,15,91,192                        // cvtdq2ps      %xmm8,%xmm8
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,68,15,110,200                   // movd          %eax,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  15,92,196                           // subps         %xmm4,%xmm0
  .byte  65,15,89,193                        // mulps         %xmm9,%xmm0
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  15,92,205                           // subps         %xmm5,%xmm1
  .byte  65,15,89,201                        // mulps         %xmm9,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  15,92,214                           // subps         %xmm6,%xmm2
  .byte  65,15,89,209                        // mulps         %xmm9,%xmm2
  .byte  15,88,214                           // addps         %xmm6,%xmm2
  .byte  15,92,223                           // subps         %xmm7,%xmm3
  .byte  65,15,89,217                        // mulps         %xmm9,%xmm3
  .byte  15,88,223                           // addps         %xmm7,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_lerp_565_sse41
.globl _sk_lerp_565_sse41
FUNCTION(_sk_lerp_565_sse41)
_sk_lerp_565_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  102,68,15,56,51,4,120               // pmovzxwd      (%rax,%rdi,2),%xmm8
  .byte  184,0,248,0,0                       // mov           $0xf800,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  102,15,112,219,0                    // pshufd        $0x0,%xmm3,%xmm3
  .byte  102,65,15,219,216                   // pand          %xmm8,%xmm3
  .byte  68,15,91,203                        // cvtdq2ps      %xmm3,%xmm9
  .byte  184,8,33,132,55                     // mov           $0x37842108,%eax
  .byte  102,68,15,110,208                   // movd          %eax,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  184,224,7,0,0                       // mov           $0x7e0,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  102,15,112,219,0                    // pshufd        $0x0,%xmm3,%xmm3
  .byte  102,65,15,219,216                   // pand          %xmm8,%xmm3
  .byte  68,15,91,203                        // cvtdq2ps      %xmm3,%xmm9
  .byte  184,33,8,2,58                       // mov           $0x3a020821,%eax
  .byte  102,68,15,110,216                   // movd          %eax,%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,89,217                        // mulps         %xmm9,%xmm11
  .byte  184,31,0,0,0                        // mov           $0x1f,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  102,15,112,219,0                    // pshufd        $0x0,%xmm3,%xmm3
  .byte  102,65,15,219,216                   // pand          %xmm8,%xmm3
  .byte  68,15,91,195                        // cvtdq2ps      %xmm3,%xmm8
  .byte  184,8,33,4,61                       // mov           $0x3d042108,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  15,92,196                           // subps         %xmm4,%xmm0
  .byte  65,15,89,194                        // mulps         %xmm10,%xmm0
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  15,92,205                           // subps         %xmm5,%xmm1
  .byte  65,15,89,203                        // mulps         %xmm11,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  15,92,214                           // subps         %xmm6,%xmm2
  .byte  15,89,211                           // mulps         %xmm3,%xmm2
  .byte  15,88,214                           // addps         %xmm6,%xmm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_tables_sse41
.globl _sk_load_tables_sse41
FUNCTION(_sk_load_tables_sse41)
_sk_load_tables_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  76,139,72,8                         // mov           0x8(%rax),%r9
  .byte  243,69,15,111,4,184                 // movdqu        (%r8,%rdi,4),%xmm8
  .byte  102,15,111,5,14,42,0,0              // movdqa        0x2a0e(%rip),%xmm0        # 3f70 <_sk_callback_sse41+0x104>
  .byte  102,65,15,219,192                   // pand          %xmm8,%xmm0
  .byte  102,73,15,58,22,192,1               // pextrq        $0x1,%xmm0,%r8
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  68,15,182,209                       // movzbl        %cl,%r10d
  .byte  72,193,233,30                       // shr           $0x1e,%rcx
  .byte  69,15,182,216                       // movzbl        %r8b,%r11d
  .byte  73,193,232,30                       // shr           $0x1e,%r8
  .byte  243,67,15,16,4,145                  // movss         (%r9,%r10,4),%xmm0
  .byte  102,65,15,58,33,4,9,16              // insertps      $0x10,(%r9,%rcx,1),%xmm0
  .byte  102,67,15,58,33,4,153,32            // insertps      $0x20,(%r9,%r11,4),%xmm0
  .byte  243,67,15,16,12,1                   // movss         (%r9,%r8,1),%xmm1
  .byte  102,15,58,33,193,48                 // insertps      $0x30,%xmm1,%xmm0
  .byte  76,139,64,16                        // mov           0x10(%rax),%r8
  .byte  102,65,15,111,200                   // movdqa        %xmm8,%xmm1
  .byte  102,15,56,0,13,201,41,0,0           // pshufb        0x29c9(%rip),%xmm1        # 3f80 <_sk_callback_sse41+0x114>
  .byte  102,73,15,58,22,201,1               // pextrq        $0x1,%xmm1,%r9
  .byte  102,72,15,126,201                   // movq          %xmm1,%rcx
  .byte  68,15,182,209                       // movzbl        %cl,%r10d
  .byte  72,193,233,30                       // shr           $0x1e,%rcx
  .byte  69,15,182,217                       // movzbl        %r9b,%r11d
  .byte  73,193,233,30                       // shr           $0x1e,%r9
  .byte  243,67,15,16,12,144                 // movss         (%r8,%r10,4),%xmm1
  .byte  102,65,15,58,33,12,8,16             // insertps      $0x10,(%r8,%rcx,1),%xmm1
  .byte  243,67,15,16,20,152                 // movss         (%r8,%r11,4),%xmm2
  .byte  102,15,58,33,202,32                 // insertps      $0x20,%xmm2,%xmm1
  .byte  243,67,15,16,20,8                   // movss         (%r8,%r9,1),%xmm2
  .byte  102,15,58,33,202,48                 // insertps      $0x30,%xmm2,%xmm1
  .byte  76,139,64,24                        // mov           0x18(%rax),%r8
  .byte  102,65,15,111,208                   // movdqa        %xmm8,%xmm2
  .byte  102,15,56,0,21,133,41,0,0           // pshufb        0x2985(%rip),%xmm2        # 3f90 <_sk_callback_sse41+0x124>
  .byte  102,72,15,58,22,209,1               // pextrq        $0x1,%xmm2,%rcx
  .byte  102,72,15,126,208                   // movq          %xmm2,%rax
  .byte  68,15,182,200                       // movzbl        %al,%r9d
  .byte  72,193,232,30                       // shr           $0x1e,%rax
  .byte  68,15,182,209                       // movzbl        %cl,%r10d
  .byte  72,193,233,30                       // shr           $0x1e,%rcx
  .byte  243,67,15,16,20,136                 // movss         (%r8,%r9,4),%xmm2
  .byte  102,65,15,58,33,20,0,16             // insertps      $0x10,(%r8,%rax,1),%xmm2
  .byte  243,67,15,16,28,144                 // movss         (%r8,%r10,4),%xmm3
  .byte  102,15,58,33,211,32                 // insertps      $0x20,%xmm3,%xmm2
  .byte  243,65,15,16,28,8                   // movss         (%r8,%rcx,1),%xmm3
  .byte  102,15,58,33,211,48                 // insertps      $0x30,%xmm3,%xmm2
  .byte  102,65,15,114,208,24                // psrld         $0x18,%xmm8
  .byte  69,15,91,192                        // cvtdq2ps      %xmm8,%xmm8
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_tables_u16_be_sse41
.globl _sk_load_tables_u16_be_sse41
FUNCTION(_sk_load_tables_u16_be_sse41)
_sk_load_tables_u16_be_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,8                            // mov           (%rax),%rcx
  .byte  76,139,64,8                         // mov           0x8(%rax),%r8
  .byte  243,15,111,4,249                    // movdqu        (%rcx,%rdi,8),%xmm0
  .byte  243,15,111,76,249,16                // movdqu        0x10(%rcx,%rdi,8),%xmm1
  .byte  102,68,15,111,200                   // movdqa        %xmm0,%xmm9
  .byte  102,68,15,97,201                    // punpcklwd     %xmm1,%xmm9
  .byte  102,15,105,193                      // punpckhwd     %xmm1,%xmm0
  .byte  102,65,15,111,201                   // movdqa        %xmm9,%xmm1
  .byte  102,15,97,200                       // punpcklwd     %xmm0,%xmm1
  .byte  102,68,15,105,200                   // punpckhwd     %xmm0,%xmm9
  .byte  102,68,15,111,5,251,40,0,0          // movdqa        0x28fb(%rip),%xmm8        # 3fa0 <_sk_callback_sse41+0x134>
  .byte  102,15,111,193                      // movdqa        %xmm1,%xmm0
  .byte  102,65,15,219,192                   // pand          %xmm8,%xmm0
  .byte  102,15,56,51,192                    // pmovzxwd      %xmm0,%xmm0
  .byte  102,73,15,58,22,193,1               // pextrq        $0x1,%xmm0,%r9
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  68,15,182,209                       // movzbl        %cl,%r10d
  .byte  72,193,233,30                       // shr           $0x1e,%rcx
  .byte  69,15,182,217                       // movzbl        %r9b,%r11d
  .byte  73,193,233,30                       // shr           $0x1e,%r9
  .byte  243,67,15,16,4,144                  // movss         (%r8,%r10,4),%xmm0
  .byte  102,65,15,58,33,4,8,16              // insertps      $0x10,(%r8,%rcx,1),%xmm0
  .byte  243,67,15,16,20,152                 // movss         (%r8,%r11,4),%xmm2
  .byte  102,15,58,33,194,32                 // insertps      $0x20,%xmm2,%xmm0
  .byte  243,67,15,16,20,8                   // movss         (%r8,%r9,1),%xmm2
  .byte  102,15,58,33,194,48                 // insertps      $0x30,%xmm2,%xmm0
  .byte  76,139,64,16                        // mov           0x10(%rax),%r8
  .byte  102,15,56,0,13,174,40,0,0           // pshufb        0x28ae(%rip),%xmm1        # 3fb0 <_sk_callback_sse41+0x144>
  .byte  102,15,56,51,201                    // pmovzxwd      %xmm1,%xmm1
  .byte  102,73,15,58,22,201,1               // pextrq        $0x1,%xmm1,%r9
  .byte  102,72,15,126,201                   // movq          %xmm1,%rcx
  .byte  68,15,182,209                       // movzbl        %cl,%r10d
  .byte  72,193,233,30                       // shr           $0x1e,%rcx
  .byte  69,15,182,217                       // movzbl        %r9b,%r11d
  .byte  73,193,233,30                       // shr           $0x1e,%r9
  .byte  243,67,15,16,12,144                 // movss         (%r8,%r10,4),%xmm1
  .byte  102,65,15,58,33,12,8,16             // insertps      $0x10,(%r8,%rcx,1),%xmm1
  .byte  243,67,15,16,20,152                 // movss         (%r8,%r11,4),%xmm2
  .byte  102,15,58,33,202,32                 // insertps      $0x20,%xmm2,%xmm1
  .byte  243,67,15,16,20,8                   // movss         (%r8,%r9,1),%xmm2
  .byte  102,15,58,33,202,48                 // insertps      $0x30,%xmm2,%xmm1
  .byte  76,139,64,24                        // mov           0x18(%rax),%r8
  .byte  102,69,15,219,193                   // pand          %xmm9,%xmm8
  .byte  102,65,15,56,51,208                 // pmovzxwd      %xmm8,%xmm2
  .byte  102,72,15,58,22,209,1               // pextrq        $0x1,%xmm2,%rcx
  .byte  102,72,15,126,208                   // movq          %xmm2,%rax
  .byte  68,15,182,200                       // movzbl        %al,%r9d
  .byte  72,193,232,30                       // shr           $0x1e,%rax
  .byte  68,15,182,209                       // movzbl        %cl,%r10d
  .byte  72,193,233,30                       // shr           $0x1e,%rcx
  .byte  243,67,15,16,20,136                 // movss         (%r8,%r9,4),%xmm2
  .byte  102,65,15,58,33,20,0,16             // insertps      $0x10,(%r8,%rax,1),%xmm2
  .byte  243,67,15,16,28,144                 // movss         (%r8,%r10,4),%xmm3
  .byte  102,15,58,33,211,32                 // insertps      $0x20,%xmm3,%xmm2
  .byte  243,65,15,16,28,8                   // movss         (%r8,%rcx,1),%xmm3
  .byte  102,15,58,33,211,48                 // insertps      $0x30,%xmm3,%xmm2
  .byte  184,128,0,128,55                    // mov           $0x37800080,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  102,65,15,112,217,78                // pshufd        $0x4e,%xmm9,%xmm3
  .byte  102,68,15,111,203                   // movdqa        %xmm3,%xmm9
  .byte  102,65,15,113,241,8                 // psllw         $0x8,%xmm9
  .byte  102,15,113,211,8                    // psrlw         $0x8,%xmm3
  .byte  102,65,15,235,217                   // por           %xmm9,%xmm3
  .byte  102,15,56,51,219                    // pmovzxwd      %xmm3,%xmm3
  .byte  15,91,219                           // cvtdq2ps      %xmm3,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_tables_rgb_u16_be_sse41
.globl _sk_load_tables_rgb_u16_be_sse41
FUNCTION(_sk_load_tables_rgb_u16_be_sse41)
_sk_load_tables_rgb_u16_be_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,141,12,127                       // lea           (%rdi,%rdi,2),%r9
  .byte  72,139,8                            // mov           (%rax),%rcx
  .byte  76,139,64,8                         // mov           0x8(%rax),%r8
  .byte  243,66,15,111,20,73                 // movdqu        (%rcx,%r9,2),%xmm2
  .byte  243,66,15,111,68,73,8               // movdqu        0x8(%rcx,%r9,2),%xmm0
  .byte  102,15,115,216,4                    // psrldq        $0x4,%xmm0
  .byte  102,68,15,111,202                   // movdqa        %xmm2,%xmm9
  .byte  102,65,15,115,217,6                 // psrldq        $0x6,%xmm9
  .byte  102,15,97,208                       // punpcklwd     %xmm0,%xmm2
  .byte  102,15,115,216,6                    // psrldq        $0x6,%xmm0
  .byte  102,68,15,97,200                    // punpcklwd     %xmm0,%xmm9
  .byte  102,15,111,202                      // movdqa        %xmm2,%xmm1
  .byte  102,65,15,97,201                    // punpcklwd     %xmm9,%xmm1
  .byte  102,68,15,111,5,162,39,0,0          // movdqa        0x27a2(%rip),%xmm8        # 3fc0 <_sk_callback_sse41+0x154>
  .byte  102,15,111,193                      // movdqa        %xmm1,%xmm0
  .byte  102,65,15,219,192                   // pand          %xmm8,%xmm0
  .byte  102,15,56,51,192                    // pmovzxwd      %xmm0,%xmm0
  .byte  102,73,15,58,22,193,1               // pextrq        $0x1,%xmm0,%r9
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  68,15,182,209                       // movzbl        %cl,%r10d
  .byte  72,193,233,30                       // shr           $0x1e,%rcx
  .byte  69,15,182,217                       // movzbl        %r9b,%r11d
  .byte  73,193,233,30                       // shr           $0x1e,%r9
  .byte  243,67,15,16,4,144                  // movss         (%r8,%r10,4),%xmm0
  .byte  102,65,15,58,33,4,8,16              // insertps      $0x10,(%r8,%rcx,1),%xmm0
  .byte  243,67,15,16,28,152                 // movss         (%r8,%r11,4),%xmm3
  .byte  102,15,58,33,195,32                 // insertps      $0x20,%xmm3,%xmm0
  .byte  243,67,15,16,28,8                   // movss         (%r8,%r9,1),%xmm3
  .byte  102,15,58,33,195,48                 // insertps      $0x30,%xmm3,%xmm0
  .byte  76,139,64,16                        // mov           0x10(%rax),%r8
  .byte  102,15,56,0,13,85,39,0,0            // pshufb        0x2755(%rip),%xmm1        # 3fd0 <_sk_callback_sse41+0x164>
  .byte  102,15,56,51,201                    // pmovzxwd      %xmm1,%xmm1
  .byte  102,73,15,58,22,201,1               // pextrq        $0x1,%xmm1,%r9
  .byte  102,72,15,126,201                   // movq          %xmm1,%rcx
  .byte  68,15,182,209                       // movzbl        %cl,%r10d
  .byte  72,193,233,30                       // shr           $0x1e,%rcx
  .byte  69,15,182,217                       // movzbl        %r9b,%r11d
  .byte  73,193,233,30                       // shr           $0x1e,%r9
  .byte  243,67,15,16,12,144                 // movss         (%r8,%r10,4),%xmm1
  .byte  102,65,15,58,33,12,8,16             // insertps      $0x10,(%r8,%rcx,1),%xmm1
  .byte  243,67,15,16,28,152                 // movss         (%r8,%r11,4),%xmm3
  .byte  102,15,58,33,203,32                 // insertps      $0x20,%xmm3,%xmm1
  .byte  243,67,15,16,28,8                   // movss         (%r8,%r9,1),%xmm3
  .byte  102,15,58,33,203,48                 // insertps      $0x30,%xmm3,%xmm1
  .byte  76,139,64,24                        // mov           0x18(%rax),%r8
  .byte  102,65,15,105,209                   // punpckhwd     %xmm9,%xmm2
  .byte  102,65,15,219,208                   // pand          %xmm8,%xmm2
  .byte  102,15,56,51,210                    // pmovzxwd      %xmm2,%xmm2
  .byte  102,72,15,58,22,209,1               // pextrq        $0x1,%xmm2,%rcx
  .byte  102,72,15,126,208                   // movq          %xmm2,%rax
  .byte  68,15,182,200                       // movzbl        %al,%r9d
  .byte  72,193,232,30                       // shr           $0x1e,%rax
  .byte  68,15,182,209                       // movzbl        %cl,%r10d
  .byte  72,193,233,30                       // shr           $0x1e,%rcx
  .byte  243,67,15,16,20,136                 // movss         (%r8,%r9,4),%xmm2
  .byte  102,65,15,58,33,20,0,16             // insertps      $0x10,(%r8,%rax,1),%xmm2
  .byte  243,67,15,16,28,144                 // movss         (%r8,%r10,4),%xmm3
  .byte  102,15,58,33,211,32                 // insertps      $0x20,%xmm3,%xmm2
  .byte  243,65,15,16,28,8                   // movss         (%r8,%rcx,1),%xmm3
  .byte  102,15,58,33,211,48                 // insertps      $0x30,%xmm3,%xmm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_byte_tables_sse41
.globl _sk_byte_tables_sse41
FUNCTION(_sk_byte_tables_sse41)
_sk_byte_tables_sse41:
  .byte  65,86                               // push          %r14
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,127,67                      // mov           $0x437f0000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  102,15,91,192                       // cvtps2dq      %xmm0,%xmm0
  .byte  102,72,15,58,22,193,1               // pextrq        $0x1,%xmm0,%rcx
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,73,15,126,193                   // movq          %xmm0,%r9
  .byte  69,137,202                          // mov           %r9d,%r10d
  .byte  77,137,203                          // mov           %r9,%r11
  .byte  73,193,235,32                       // shr           $0x20,%r11
  .byte  76,139,48                           // mov           (%rax),%r14
  .byte  76,139,72,8                         // mov           0x8(%rax),%r9
  .byte  102,67,15,58,32,4,22,0              // pinsrb        $0x0,(%r14,%r10,1),%xmm0
  .byte  102,67,15,58,32,4,30,1              // pinsrb        $0x1,(%r14,%r11,1),%xmm0
  .byte  67,15,182,28,6                      // movzbl        (%r14,%r8,1),%ebx
  .byte  102,15,58,32,195,2                  // pinsrb        $0x2,%ebx,%xmm0
  .byte  65,15,182,12,14                     // movzbl        (%r14,%rcx,1),%ecx
  .byte  102,15,58,32,193,3                  // pinsrb        $0x3,%ecx,%xmm0
  .byte  102,15,56,49,192                    // pmovzxbd      %xmm0,%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  185,129,128,128,59                  // mov           $0x3b808081,%ecx
  .byte  102,68,15,110,201                   // movd          %ecx,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  65,15,89,193                        // mulps         %xmm9,%xmm0
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  102,15,91,201                       // cvtps2dq      %xmm1,%xmm1
  .byte  102,72,15,58,22,201,1               // pextrq        $0x1,%xmm1,%rcx
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,72,15,126,203                   // movq          %xmm1,%rbx
  .byte  65,137,218                          // mov           %ebx,%r10d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  102,67,15,58,32,12,17,0             // pinsrb        $0x0,(%r9,%r10,1),%xmm1
  .byte  102,65,15,58,32,12,25,1             // pinsrb        $0x1,(%r9,%rbx,1),%xmm1
  .byte  67,15,182,28,1                      // movzbl        (%r9,%r8,1),%ebx
  .byte  102,15,58,32,203,2                  // pinsrb        $0x2,%ebx,%xmm1
  .byte  65,15,182,12,9                      // movzbl        (%r9,%rcx,1),%ecx
  .byte  102,15,58,32,201,3                  // pinsrb        $0x3,%ecx,%xmm1
  .byte  102,15,56,49,201                    // pmovzxbd      %xmm1,%xmm1
  .byte  15,91,201                           // cvtdq2ps      %xmm1,%xmm1
  .byte  65,15,89,201                        // mulps         %xmm9,%xmm1
  .byte  76,139,72,16                        // mov           0x10(%rax),%r9
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  102,15,91,210                       // cvtps2dq      %xmm2,%xmm2
  .byte  102,72,15,58,22,211,1               // pextrq        $0x1,%xmm2,%rbx
  .byte  65,137,216                          // mov           %ebx,%r8d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  102,72,15,126,209                   // movq          %xmm2,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,67,15,58,32,20,17,0             // pinsrb        $0x0,(%r9,%r10,1),%xmm2
  .byte  102,65,15,58,32,20,9,1              // pinsrb        $0x1,(%r9,%rcx,1),%xmm2
  .byte  67,15,182,12,1                      // movzbl        (%r9,%r8,1),%ecx
  .byte  102,15,58,32,209,2                  // pinsrb        $0x2,%ecx,%xmm2
  .byte  65,15,182,12,25                     // movzbl        (%r9,%rbx,1),%ecx
  .byte  102,15,58,32,209,3                  // pinsrb        $0x3,%ecx,%xmm2
  .byte  102,15,56,49,210                    // pmovzxbd      %xmm2,%xmm2
  .byte  15,91,210                           // cvtdq2ps      %xmm2,%xmm2
  .byte  65,15,89,209                        // mulps         %xmm9,%xmm2
  .byte  72,139,64,24                        // mov           0x18(%rax),%rax
  .byte  68,15,89,195                        // mulps         %xmm3,%xmm8
  .byte  102,65,15,91,216                    // cvtps2dq      %xmm8,%xmm3
  .byte  102,72,15,58,22,217,1               // pextrq        $0x1,%xmm3,%rcx
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,72,15,126,219                   // movq          %xmm3,%rbx
  .byte  65,137,217                          // mov           %ebx,%r9d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  102,66,15,58,32,28,8,0              // pinsrb        $0x0,(%rax,%r9,1),%xmm3
  .byte  102,15,58,32,28,24,1                // pinsrb        $0x1,(%rax,%rbx,1),%xmm3
  .byte  66,15,182,28,0                      // movzbl        (%rax,%r8,1),%ebx
  .byte  102,15,58,32,219,2                  // pinsrb        $0x2,%ebx,%xmm3
  .byte  15,182,4,8                          // movzbl        (%rax,%rcx,1),%eax
  .byte  102,15,58,32,216,3                  // pinsrb        $0x3,%eax,%xmm3
  .byte  102,15,56,49,219                    // pmovzxbd      %xmm3,%xmm3
  .byte  15,91,219                           // cvtdq2ps      %xmm3,%xmm3
  .byte  65,15,89,217                        // mulps         %xmm9,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,94                               // pop           %r14
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_byte_tables_rgb_sse41
.globl _sk_byte_tables_rgb_sse41
FUNCTION(_sk_byte_tables_rgb_sse41)
_sk_byte_tables_rgb_sse41:
  .byte  65,86                               // push          %r14
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  139,72,24                           // mov           0x18(%rax),%ecx
  .byte  255,201                             // dec           %ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  102,69,15,112,192,0                 // pshufd        $0x0,%xmm8,%xmm8
  .byte  69,15,91,192                        // cvtdq2ps      %xmm8,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  102,15,91,192                       // cvtps2dq      %xmm0,%xmm0
  .byte  102,72,15,58,22,193,1               // pextrq        $0x1,%xmm0,%rcx
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,73,15,126,193                   // movq          %xmm0,%r9
  .byte  69,137,202                          // mov           %r9d,%r10d
  .byte  77,137,203                          // mov           %r9,%r11
  .byte  73,193,235,32                       // shr           $0x20,%r11
  .byte  76,139,48                           // mov           (%rax),%r14
  .byte  76,139,72,8                         // mov           0x8(%rax),%r9
  .byte  102,67,15,58,32,4,22,0              // pinsrb        $0x0,(%r14,%r10,1),%xmm0
  .byte  102,67,15,58,32,4,30,1              // pinsrb        $0x1,(%r14,%r11,1),%xmm0
  .byte  67,15,182,28,6                      // movzbl        (%r14,%r8,1),%ebx
  .byte  102,15,58,32,195,2                  // pinsrb        $0x2,%ebx,%xmm0
  .byte  65,15,182,12,14                     // movzbl        (%r14,%rcx,1),%ecx
  .byte  102,15,58,32,193,3                  // pinsrb        $0x3,%ecx,%xmm0
  .byte  102,15,56,49,192                    // pmovzxbd      %xmm0,%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  185,129,128,128,59                  // mov           $0x3b808081,%ecx
  .byte  102,68,15,110,201                   // movd          %ecx,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  65,15,89,193                        // mulps         %xmm9,%xmm0
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  102,15,91,201                       // cvtps2dq      %xmm1,%xmm1
  .byte  102,72,15,58,22,201,1               // pextrq        $0x1,%xmm1,%rcx
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,72,15,126,203                   // movq          %xmm1,%rbx
  .byte  65,137,218                          // mov           %ebx,%r10d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  102,67,15,58,32,12,17,0             // pinsrb        $0x0,(%r9,%r10,1),%xmm1
  .byte  102,65,15,58,32,12,25,1             // pinsrb        $0x1,(%r9,%rbx,1),%xmm1
  .byte  67,15,182,28,1                      // movzbl        (%r9,%r8,1),%ebx
  .byte  102,15,58,32,203,2                  // pinsrb        $0x2,%ebx,%xmm1
  .byte  65,15,182,12,9                      // movzbl        (%r9,%rcx,1),%ecx
  .byte  102,15,58,32,201,3                  // pinsrb        $0x3,%ecx,%xmm1
  .byte  102,15,56,49,201                    // pmovzxbd      %xmm1,%xmm1
  .byte  15,91,201                           // cvtdq2ps      %xmm1,%xmm1
  .byte  65,15,89,201                        // mulps         %xmm9,%xmm1
  .byte  72,139,64,16                        // mov           0x10(%rax),%rax
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  102,15,91,210                       // cvtps2dq      %xmm2,%xmm2
  .byte  102,72,15,58,22,209,1               // pextrq        $0x1,%xmm2,%rcx
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,72,15,126,211                   // movq          %xmm2,%rbx
  .byte  65,137,217                          // mov           %ebx,%r9d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  102,66,15,58,32,20,8,0              // pinsrb        $0x0,(%rax,%r9,1),%xmm2
  .byte  102,15,58,32,20,24,1                // pinsrb        $0x1,(%rax,%rbx,1),%xmm2
  .byte  66,15,182,28,0                      // movzbl        (%rax,%r8,1),%ebx
  .byte  102,15,58,32,211,2                  // pinsrb        $0x2,%ebx,%xmm2
  .byte  15,182,4,8                          // movzbl        (%rax,%rcx,1),%eax
  .byte  102,15,58,32,208,3                  // pinsrb        $0x3,%eax,%xmm2
  .byte  102,15,56,49,210                    // pmovzxbd      %xmm2,%xmm2
  .byte  15,91,210                           // cvtdq2ps      %xmm2,%xmm2
  .byte  65,15,89,209                        // mulps         %xmm9,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,94                               // pop           %r14
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_table_r_sse41
.globl _sk_table_r_sse41
FUNCTION(_sk_table_r_sse41)
_sk_table_r_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  139,64,8                            // mov           0x8(%rax),%eax
  .byte  255,200                             // dec           %eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  102,69,15,112,192,0                 // pshufd        $0x0,%xmm8,%xmm8
  .byte  69,15,91,192                        // cvtdq2ps      %xmm8,%xmm8
  .byte  68,15,89,192                        // mulps         %xmm0,%xmm8
  .byte  102,65,15,91,192                    // cvtps2dq      %xmm8,%xmm0
  .byte  102,72,15,58,22,192,1               // pextrq        $0x1,%xmm0,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  243,67,15,16,4,145                  // movss         (%r9,%r10,4),%xmm0
  .byte  102,65,15,58,33,4,137,16            // insertps      $0x10,(%r9,%rcx,4),%xmm0
  .byte  243,71,15,16,4,129                  // movss         (%r9,%r8,4),%xmm8
  .byte  102,65,15,58,33,192,32              // insertps      $0x20,%xmm8,%xmm0
  .byte  243,69,15,16,4,129                  // movss         (%r9,%rax,4),%xmm8
  .byte  102,65,15,58,33,192,48              // insertps      $0x30,%xmm8,%xmm0
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_table_g_sse41
.globl _sk_table_g_sse41
FUNCTION(_sk_table_g_sse41)
_sk_table_g_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  139,64,8                            // mov           0x8(%rax),%eax
  .byte  255,200                             // dec           %eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  102,69,15,112,192,0                 // pshufd        $0x0,%xmm8,%xmm8
  .byte  69,15,91,192                        // cvtdq2ps      %xmm8,%xmm8
  .byte  68,15,89,193                        // mulps         %xmm1,%xmm8
  .byte  102,65,15,91,200                    // cvtps2dq      %xmm8,%xmm1
  .byte  102,72,15,58,22,200,1               // pextrq        $0x1,%xmm1,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,72,15,126,201                   // movq          %xmm1,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  243,67,15,16,12,145                 // movss         (%r9,%r10,4),%xmm1
  .byte  102,65,15,58,33,12,137,16           // insertps      $0x10,(%r9,%rcx,4),%xmm1
  .byte  243,71,15,16,4,129                  // movss         (%r9,%r8,4),%xmm8
  .byte  102,65,15,58,33,200,32              // insertps      $0x20,%xmm8,%xmm1
  .byte  243,69,15,16,4,129                  // movss         (%r9,%rax,4),%xmm8
  .byte  102,65,15,58,33,200,48              // insertps      $0x30,%xmm8,%xmm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_table_b_sse41
.globl _sk_table_b_sse41
FUNCTION(_sk_table_b_sse41)
_sk_table_b_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  139,64,8                            // mov           0x8(%rax),%eax
  .byte  255,200                             // dec           %eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  102,69,15,112,192,0                 // pshufd        $0x0,%xmm8,%xmm8
  .byte  69,15,91,192                        // cvtdq2ps      %xmm8,%xmm8
  .byte  68,15,89,194                        // mulps         %xmm2,%xmm8
  .byte  102,65,15,91,208                    // cvtps2dq      %xmm8,%xmm2
  .byte  102,72,15,58,22,208,1               // pextrq        $0x1,%xmm2,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,72,15,126,209                   // movq          %xmm2,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  243,67,15,16,20,145                 // movss         (%r9,%r10,4),%xmm2
  .byte  102,65,15,58,33,20,137,16           // insertps      $0x10,(%r9,%rcx,4),%xmm2
  .byte  243,71,15,16,4,129                  // movss         (%r9,%r8,4),%xmm8
  .byte  102,65,15,58,33,208,32              // insertps      $0x20,%xmm8,%xmm2
  .byte  243,69,15,16,4,129                  // movss         (%r9,%rax,4),%xmm8
  .byte  102,65,15,58,33,208,48              // insertps      $0x30,%xmm8,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_table_a_sse41
.globl _sk_table_a_sse41
FUNCTION(_sk_table_a_sse41)
_sk_table_a_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  139,64,8                            // mov           0x8(%rax),%eax
  .byte  255,200                             // dec           %eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  102,69,15,112,192,0                 // pshufd        $0x0,%xmm8,%xmm8
  .byte  69,15,91,192                        // cvtdq2ps      %xmm8,%xmm8
  .byte  68,15,89,195                        // mulps         %xmm3,%xmm8
  .byte  102,65,15,91,216                    // cvtps2dq      %xmm8,%xmm3
  .byte  102,72,15,58,22,216,1               // pextrq        $0x1,%xmm3,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,72,15,126,217                   // movq          %xmm3,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  243,67,15,16,28,145                 // movss         (%r9,%r10,4),%xmm3
  .byte  102,65,15,58,33,28,137,16           // insertps      $0x10,(%r9,%rcx,4),%xmm3
  .byte  243,71,15,16,4,129                  // movss         (%r9,%r8,4),%xmm8
  .byte  102,65,15,58,33,216,32              // insertps      $0x20,%xmm8,%xmm3
  .byte  243,69,15,16,4,129                  // movss         (%r9,%rax,4),%xmm8
  .byte  102,65,15,58,33,216,48              // insertps      $0x30,%xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_parametric_r_sse41
.globl _sk_parametric_r_sse41
FUNCTION(_sk_parametric_r_sse41)
_sk_parametric_r_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,64,16                  // movss         0x10(%rax),%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  243,68,15,16,72,12                  // movss         0xc(%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  68,15,89,200                        // mulps         %xmm0,%xmm9
  .byte  243,68,15,16,80,4                   // movss         0x4(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  68,15,89,208                        // mulps         %xmm0,%xmm10
  .byte  65,15,194,192,2                     // cmpleps       %xmm8,%xmm0
  .byte  243,68,15,16,64,24                  // movss         0x18(%rax),%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,88,200                        // addps         %xmm8,%xmm9
  .byte  243,68,15,16,24                     // movss         (%rax),%xmm11
  .byte  243,68,15,16,64,8                   // movss         0x8(%rax),%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,88,208                        // addps         %xmm8,%xmm10
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,91,194                        // cvtdq2ps      %xmm10,%xmm8
  .byte  68,15,89,5,242,33,0,0               // mulps         0x21f2(%rip),%xmm8        # 3fe0 <_sk_callback_sse41+0x174>
  .byte  68,15,84,21,250,33,0,0              // andps         0x21fa(%rip),%xmm10        # 3ff0 <_sk_callback_sse41+0x184>
  .byte  68,15,86,21,2,34,0,0                // orps          0x2202(%rip),%xmm10        # 4000 <_sk_callback_sse41+0x194>
  .byte  68,15,88,5,10,34,0,0                // addps         0x220a(%rip),%xmm8        # 4010 <_sk_callback_sse41+0x1a4>
  .byte  68,15,40,37,18,34,0,0               // movaps        0x2212(%rip),%xmm12        # 4020 <_sk_callback_sse41+0x1b4>
  .byte  69,15,89,226                        // mulps         %xmm10,%xmm12
  .byte  69,15,92,196                        // subps         %xmm12,%xmm8
  .byte  68,15,88,21,18,34,0,0               // addps         0x2212(%rip),%xmm10        # 4030 <_sk_callback_sse41+0x1c4>
  .byte  68,15,40,37,26,34,0,0               // movaps        0x221a(%rip),%xmm12        # 4040 <_sk_callback_sse41+0x1d4>
  .byte  69,15,94,226                        // divps         %xmm10,%xmm12
  .byte  69,15,92,196                        // subps         %xmm12,%xmm8
  .byte  69,15,89,195                        // mulps         %xmm11,%xmm8
  .byte  102,69,15,58,8,208,1                // roundps       $0x1,%xmm8,%xmm10
  .byte  69,15,40,216                        // movaps        %xmm8,%xmm11
  .byte  69,15,92,218                        // subps         %xmm10,%xmm11
  .byte  68,15,88,5,7,34,0,0                 // addps         0x2207(%rip),%xmm8        # 4050 <_sk_callback_sse41+0x1e4>
  .byte  68,15,40,21,15,34,0,0               // movaps        0x220f(%rip),%xmm10        # 4060 <_sk_callback_sse41+0x1f4>
  .byte  69,15,89,211                        // mulps         %xmm11,%xmm10
  .byte  69,15,92,194                        // subps         %xmm10,%xmm8
  .byte  68,15,40,21,15,34,0,0               // movaps        0x220f(%rip),%xmm10        # 4070 <_sk_callback_sse41+0x204>
  .byte  69,15,92,211                        // subps         %xmm11,%xmm10
  .byte  68,15,40,29,19,34,0,0               // movaps        0x2213(%rip),%xmm11        # 4080 <_sk_callback_sse41+0x214>
  .byte  69,15,94,218                        // divps         %xmm10,%xmm11
  .byte  69,15,88,216                        // addps         %xmm8,%xmm11
  .byte  68,15,89,29,19,34,0,0               // mulps         0x2213(%rip),%xmm11        # 4090 <_sk_callback_sse41+0x224>
  .byte  102,69,15,91,211                    // cvtps2dq      %xmm11,%xmm10
  .byte  243,68,15,16,64,20                  // movss         0x14(%rax),%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,88,194                        // addps         %xmm10,%xmm8
  .byte  102,69,15,56,20,193                 // blendvps      %xmm0,%xmm9,%xmm8
  .byte  15,87,192                           // xorps         %xmm0,%xmm0
  .byte  68,15,95,192                        // maxps         %xmm0,%xmm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  68,15,93,192                        // minps         %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_parametric_g_sse41
.globl _sk_parametric_g_sse41
FUNCTION(_sk_parametric_g_sse41)
_sk_parametric_g_sse41:
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,80,16                  // movss         0x10(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,72,12                  // movss         0xc(%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  68,15,89,201                        // mulps         %xmm1,%xmm9
  .byte  243,68,15,16,88,4                   // movss         0x4(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  68,15,89,217                        // mulps         %xmm1,%xmm11
  .byte  15,40,193                           // movaps        %xmm1,%xmm0
  .byte  65,15,194,194,2                     // cmpleps       %xmm10,%xmm0
  .byte  243,15,16,72,24                     // movss         0x18(%rax),%xmm1
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  68,15,88,201                        // addps         %xmm1,%xmm9
  .byte  243,68,15,16,16                     // movss         (%rax),%xmm10
  .byte  243,15,16,72,8                      // movss         0x8(%rax),%xmm1
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  68,15,88,217                        // addps         %xmm1,%xmm11
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,91,227                        // cvtdq2ps      %xmm11,%xmm12
  .byte  68,15,89,37,130,33,0,0              // mulps         0x2182(%rip),%xmm12        # 40a0 <_sk_callback_sse41+0x234>
  .byte  68,15,84,29,138,33,0,0              // andps         0x218a(%rip),%xmm11        # 40b0 <_sk_callback_sse41+0x244>
  .byte  68,15,86,29,146,33,0,0              // orps          0x2192(%rip),%xmm11        # 40c0 <_sk_callback_sse41+0x254>
  .byte  68,15,88,37,154,33,0,0              // addps         0x219a(%rip),%xmm12        # 40d0 <_sk_callback_sse41+0x264>
  .byte  15,40,13,163,33,0,0                 // movaps        0x21a3(%rip),%xmm1        # 40e0 <_sk_callback_sse41+0x274>
  .byte  65,15,89,203                        // mulps         %xmm11,%xmm1
  .byte  68,15,92,225                        // subps         %xmm1,%xmm12
  .byte  68,15,88,29,163,33,0,0              // addps         0x21a3(%rip),%xmm11        # 40f0 <_sk_callback_sse41+0x284>
  .byte  15,40,13,172,33,0,0                 // movaps        0x21ac(%rip),%xmm1        # 4100 <_sk_callback_sse41+0x294>
  .byte  65,15,94,203                        // divps         %xmm11,%xmm1
  .byte  68,15,92,225                        // subps         %xmm1,%xmm12
  .byte  69,15,89,226                        // mulps         %xmm10,%xmm12
  .byte  102,69,15,58,8,212,1                // roundps       $0x1,%xmm12,%xmm10
  .byte  69,15,40,220                        // movaps        %xmm12,%xmm11
  .byte  69,15,92,218                        // subps         %xmm10,%xmm11
  .byte  68,15,88,37,153,33,0,0              // addps         0x2199(%rip),%xmm12        # 4110 <_sk_callback_sse41+0x2a4>
  .byte  15,40,13,162,33,0,0                 // movaps        0x21a2(%rip),%xmm1        # 4120 <_sk_callback_sse41+0x2b4>
  .byte  65,15,89,203                        // mulps         %xmm11,%xmm1
  .byte  68,15,92,225                        // subps         %xmm1,%xmm12
  .byte  68,15,40,21,162,33,0,0              // movaps        0x21a2(%rip),%xmm10        # 4130 <_sk_callback_sse41+0x2c4>
  .byte  69,15,92,211                        // subps         %xmm11,%xmm10
  .byte  15,40,13,167,33,0,0                 // movaps        0x21a7(%rip),%xmm1        # 4140 <_sk_callback_sse41+0x2d4>
  .byte  65,15,94,202                        // divps         %xmm10,%xmm1
  .byte  65,15,88,204                        // addps         %xmm12,%xmm1
  .byte  15,89,13,168,33,0,0                 // mulps         0x21a8(%rip),%xmm1        # 4150 <_sk_callback_sse41+0x2e4>
  .byte  102,68,15,91,209                    // cvtps2dq      %xmm1,%xmm10
  .byte  243,15,16,72,20                     // movss         0x14(%rax),%xmm1
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  65,15,88,202                        // addps         %xmm10,%xmm1
  .byte  102,65,15,56,20,201                 // blendvps      %xmm0,%xmm9,%xmm1
  .byte  15,87,192                           // xorps         %xmm0,%xmm0
  .byte  15,95,200                           // maxps         %xmm0,%xmm1
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,93,200                           // minps         %xmm0,%xmm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_parametric_b_sse41
.globl _sk_parametric_b_sse41
FUNCTION(_sk_parametric_b_sse41)
_sk_parametric_b_sse41:
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,80,16                  // movss         0x10(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,72,12                  // movss         0xc(%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  68,15,89,202                        // mulps         %xmm2,%xmm9
  .byte  243,68,15,16,88,4                   // movss         0x4(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  15,40,194                           // movaps        %xmm2,%xmm0
  .byte  65,15,194,194,2                     // cmpleps       %xmm10,%xmm0
  .byte  243,15,16,80,24                     // movss         0x18(%rax),%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  68,15,88,202                        // addps         %xmm2,%xmm9
  .byte  243,68,15,16,16                     // movss         (%rax),%xmm10
  .byte  243,15,16,80,8                      // movss         0x8(%rax),%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  68,15,88,218                        // addps         %xmm2,%xmm11
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,91,227                        // cvtdq2ps      %xmm11,%xmm12
  .byte  68,15,89,37,27,33,0,0               // mulps         0x211b(%rip),%xmm12        # 4160 <_sk_callback_sse41+0x2f4>
  .byte  68,15,84,29,35,33,0,0               // andps         0x2123(%rip),%xmm11        # 4170 <_sk_callback_sse41+0x304>
  .byte  68,15,86,29,43,33,0,0               // orps          0x212b(%rip),%xmm11        # 4180 <_sk_callback_sse41+0x314>
  .byte  68,15,88,37,51,33,0,0               // addps         0x2133(%rip),%xmm12        # 4190 <_sk_callback_sse41+0x324>
  .byte  15,40,21,60,33,0,0                  // movaps        0x213c(%rip),%xmm2        # 41a0 <_sk_callback_sse41+0x334>
  .byte  65,15,89,211                        // mulps         %xmm11,%xmm2
  .byte  68,15,92,226                        // subps         %xmm2,%xmm12
  .byte  68,15,88,29,60,33,0,0               // addps         0x213c(%rip),%xmm11        # 41b0 <_sk_callback_sse41+0x344>
  .byte  15,40,21,69,33,0,0                  // movaps        0x2145(%rip),%xmm2        # 41c0 <_sk_callback_sse41+0x354>
  .byte  65,15,94,211                        // divps         %xmm11,%xmm2
  .byte  68,15,92,226                        // subps         %xmm2,%xmm12
  .byte  69,15,89,226                        // mulps         %xmm10,%xmm12
  .byte  102,69,15,58,8,212,1                // roundps       $0x1,%xmm12,%xmm10
  .byte  69,15,40,220                        // movaps        %xmm12,%xmm11
  .byte  69,15,92,218                        // subps         %xmm10,%xmm11
  .byte  68,15,88,37,50,33,0,0               // addps         0x2132(%rip),%xmm12        # 41d0 <_sk_callback_sse41+0x364>
  .byte  15,40,21,59,33,0,0                  // movaps        0x213b(%rip),%xmm2        # 41e0 <_sk_callback_sse41+0x374>
  .byte  65,15,89,211                        // mulps         %xmm11,%xmm2
  .byte  68,15,92,226                        // subps         %xmm2,%xmm12
  .byte  68,15,40,21,59,33,0,0               // movaps        0x213b(%rip),%xmm10        # 41f0 <_sk_callback_sse41+0x384>
  .byte  69,15,92,211                        // subps         %xmm11,%xmm10
  .byte  15,40,21,64,33,0,0                  // movaps        0x2140(%rip),%xmm2        # 4200 <_sk_callback_sse41+0x394>
  .byte  65,15,94,210                        // divps         %xmm10,%xmm2
  .byte  65,15,88,212                        // addps         %xmm12,%xmm2
  .byte  15,89,21,65,33,0,0                  // mulps         0x2141(%rip),%xmm2        # 4210 <_sk_callback_sse41+0x3a4>
  .byte  102,68,15,91,210                    // cvtps2dq      %xmm2,%xmm10
  .byte  243,15,16,80,20                     // movss         0x14(%rax),%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  65,15,88,210                        // addps         %xmm10,%xmm2
  .byte  102,65,15,56,20,209                 // blendvps      %xmm0,%xmm9,%xmm2
  .byte  15,87,192                           // xorps         %xmm0,%xmm0
  .byte  15,95,208                           // maxps         %xmm0,%xmm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,93,208                           // minps         %xmm0,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_parametric_a_sse41
.globl _sk_parametric_a_sse41
FUNCTION(_sk_parametric_a_sse41)
_sk_parametric_a_sse41:
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,80,16                  // movss         0x10(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,72,12                  // movss         0xc(%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  68,15,89,203                        // mulps         %xmm3,%xmm9
  .byte  243,68,15,16,88,4                   // movss         0x4(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  68,15,89,219                        // mulps         %xmm3,%xmm11
  .byte  15,40,195                           // movaps        %xmm3,%xmm0
  .byte  65,15,194,194,2                     // cmpleps       %xmm10,%xmm0
  .byte  243,15,16,88,24                     // movss         0x18(%rax),%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  68,15,88,203                        // addps         %xmm3,%xmm9
  .byte  243,68,15,16,16                     // movss         (%rax),%xmm10
  .byte  243,15,16,88,8                      // movss         0x8(%rax),%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  68,15,88,219                        // addps         %xmm3,%xmm11
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,91,227                        // cvtdq2ps      %xmm11,%xmm12
  .byte  68,15,89,37,180,32,0,0              // mulps         0x20b4(%rip),%xmm12        # 4220 <_sk_callback_sse41+0x3b4>
  .byte  68,15,84,29,188,32,0,0              // andps         0x20bc(%rip),%xmm11        # 4230 <_sk_callback_sse41+0x3c4>
  .byte  68,15,86,29,196,32,0,0              // orps          0x20c4(%rip),%xmm11        # 4240 <_sk_callback_sse41+0x3d4>
  .byte  68,15,88,37,204,32,0,0              // addps         0x20cc(%rip),%xmm12        # 4250 <_sk_callback_sse41+0x3e4>
  .byte  15,40,29,213,32,0,0                 // movaps        0x20d5(%rip),%xmm3        # 4260 <_sk_callback_sse41+0x3f4>
  .byte  65,15,89,219                        // mulps         %xmm11,%xmm3
  .byte  68,15,92,227                        // subps         %xmm3,%xmm12
  .byte  68,15,88,29,213,32,0,0              // addps         0x20d5(%rip),%xmm11        # 4270 <_sk_callback_sse41+0x404>
  .byte  15,40,29,222,32,0,0                 // movaps        0x20de(%rip),%xmm3        # 4280 <_sk_callback_sse41+0x414>
  .byte  65,15,94,219                        // divps         %xmm11,%xmm3
  .byte  68,15,92,227                        // subps         %xmm3,%xmm12
  .byte  69,15,89,226                        // mulps         %xmm10,%xmm12
  .byte  102,69,15,58,8,212,1                // roundps       $0x1,%xmm12,%xmm10
  .byte  69,15,40,220                        // movaps        %xmm12,%xmm11
  .byte  69,15,92,218                        // subps         %xmm10,%xmm11
  .byte  68,15,88,37,203,32,0,0              // addps         0x20cb(%rip),%xmm12        # 4290 <_sk_callback_sse41+0x424>
  .byte  15,40,29,212,32,0,0                 // movaps        0x20d4(%rip),%xmm3        # 42a0 <_sk_callback_sse41+0x434>
  .byte  65,15,89,219                        // mulps         %xmm11,%xmm3
  .byte  68,15,92,227                        // subps         %xmm3,%xmm12
  .byte  68,15,40,21,212,32,0,0              // movaps        0x20d4(%rip),%xmm10        # 42b0 <_sk_callback_sse41+0x444>
  .byte  69,15,92,211                        // subps         %xmm11,%xmm10
  .byte  15,40,29,217,32,0,0                 // movaps        0x20d9(%rip),%xmm3        # 42c0 <_sk_callback_sse41+0x454>
  .byte  65,15,94,218                        // divps         %xmm10,%xmm3
  .byte  65,15,88,220                        // addps         %xmm12,%xmm3
  .byte  15,89,29,218,32,0,0                 // mulps         0x20da(%rip),%xmm3        # 42d0 <_sk_callback_sse41+0x464>
  .byte  102,68,15,91,211                    // cvtps2dq      %xmm3,%xmm10
  .byte  243,15,16,88,20                     // movss         0x14(%rax),%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  65,15,88,218                        // addps         %xmm10,%xmm3
  .byte  102,65,15,56,20,217                 // blendvps      %xmm0,%xmm9,%xmm3
  .byte  15,87,192                           // xorps         %xmm0,%xmm0
  .byte  15,95,216                           // maxps         %xmm0,%xmm3
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,93,216                           // minps         %xmm0,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_lab_to_xyz_sse41
.globl _sk_lab_to_xyz_sse41
FUNCTION(_sk_lab_to_xyz_sse41)
_sk_lab_to_xyz_sse41:
  .byte  68,15,40,193                        // movaps        %xmm1,%xmm8
  .byte  184,0,0,200,66                      // mov           $0x42c80000,%eax
  .byte  102,68,15,110,200                   // movd          %eax,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  68,15,89,200                        // mulps         %xmm0,%xmm9
  .byte  184,0,0,127,67                      // mov           $0x437f0000,%eax
  .byte  102,68,15,110,208                   // movd          %eax,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,194                        // mulps         %xmm10,%xmm8
  .byte  184,0,0,0,67                        // mov           $0x43000000,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  68,15,92,193                        // subps         %xmm1,%xmm8
  .byte  68,15,89,210                        // mulps         %xmm2,%xmm10
  .byte  68,15,92,209                        // subps         %xmm1,%xmm10
  .byte  184,0,0,128,65                      // mov           $0x41800000,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  65,15,88,209                        // addps         %xmm9,%xmm2
  .byte  184,203,61,13,60                    // mov           $0x3c0d3dcb,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  15,89,202                           // mulps         %xmm2,%xmm1
  .byte  184,111,18,3,59                     // mov           $0x3b03126f,%eax
  .byte  102,68,15,110,232                   // movd          %eax,%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  69,15,89,232                        // mulps         %xmm8,%xmm13
  .byte  68,15,88,233                        // addps         %xmm1,%xmm13
  .byte  184,10,215,163,59                   // mov           $0x3ba3d70a,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  65,15,89,194                        // mulps         %xmm10,%xmm0
  .byte  68,15,40,201                        // movaps        %xmm1,%xmm9
  .byte  68,15,92,200                        // subps         %xmm0,%xmm9
  .byte  69,15,40,221                        // movaps        %xmm13,%xmm11
  .byte  69,15,89,219                        // mulps         %xmm11,%xmm11
  .byte  69,15,89,221                        // mulps         %xmm13,%xmm11
  .byte  184,194,24,17,60                    // mov           $0x3c1118c2,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  65,15,194,195,1                     // cmpltps       %xmm11,%xmm0
  .byte  184,203,61,13,62                    // mov           $0x3e0d3dcb,%eax
  .byte  102,68,15,110,208                   // movd          %eax,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,92,234                        // subps         %xmm10,%xmm13
  .byte  184,80,128,3,62                     // mov           $0x3e038050,%eax
  .byte  102,68,15,110,224                   // movd          %eax,%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  69,15,89,236                        // mulps         %xmm12,%xmm13
  .byte  102,69,15,56,20,235                 // blendvps      %xmm0,%xmm11,%xmm13
  .byte  15,40,209                           // movaps        %xmm1,%xmm2
  .byte  15,89,210                           // mulps         %xmm2,%xmm2
  .byte  15,89,209                           // mulps         %xmm1,%xmm2
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  15,194,194,1                        // cmpltps       %xmm2,%xmm0
  .byte  65,15,92,202                        // subps         %xmm10,%xmm1
  .byte  65,15,89,204                        // mulps         %xmm12,%xmm1
  .byte  102,15,56,20,202                    // blendvps      %xmm0,%xmm2,%xmm1
  .byte  65,15,40,209                        // movaps        %xmm9,%xmm2
  .byte  15,89,210                           // mulps         %xmm2,%xmm2
  .byte  65,15,89,209                        // mulps         %xmm9,%xmm2
  .byte  68,15,194,194,1                     // cmpltps       %xmm2,%xmm8
  .byte  69,15,92,202                        // subps         %xmm10,%xmm9
  .byte  69,15,89,204                        // mulps         %xmm12,%xmm9
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  102,68,15,56,20,202                 // blendvps      %xmm0,%xmm2,%xmm9
  .byte  184,31,215,118,63                   // mov           $0x3f76d71f,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  65,15,89,197                        // mulps         %xmm13,%xmm0
  .byte  184,246,64,83,63                    // mov           $0x3f5340f6,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  65,15,89,209                        // mulps         %xmm9,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_a8_sse41
.globl _sk_load_a8_sse41
FUNCTION(_sk_load_a8_sse41)
_sk_load_a8_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  102,15,56,49,4,56                   // pmovzxbd      (%rax,%rdi,1),%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  15,89,216                           // mulps         %xmm0,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,87,192                           // xorps         %xmm0,%xmm0
  .byte  15,87,201                           // xorps         %xmm1,%xmm1
  .byte  15,87,210                           // xorps         %xmm2,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_a8_sse41
.globl _sk_gather_a8_sse41
FUNCTION(_sk_gather_a8_sse41)
_sk_gather_a8_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  243,15,91,201                       // cvttps2dq     %xmm1,%xmm1
  .byte  102,15,110,80,16                    // movd          0x10(%rax),%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,15,56,64,209                    // pmulld        %xmm1,%xmm2
  .byte  243,15,91,192                       // cvttps2dq     %xmm0,%xmm0
  .byte  102,15,254,194                      // paddd         %xmm2,%xmm0
  .byte  102,72,15,58,22,192,1               // pextrq        $0x1,%xmm0,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,67,15,58,32,4,17,0              // pinsrb        $0x0,(%r9,%r10,1),%xmm0
  .byte  102,65,15,58,32,4,9,1               // pinsrb        $0x1,(%r9,%rcx,1),%xmm0
  .byte  67,15,182,12,1                      // movzbl        (%r9,%r8,1),%ecx
  .byte  102,15,58,32,193,2                  // pinsrb        $0x2,%ecx,%xmm0
  .byte  65,15,182,4,1                       // movzbl        (%r9,%rax,1),%eax
  .byte  102,15,58,32,192,3                  // pinsrb        $0x3,%eax,%xmm0
  .byte  102,15,56,49,192                    // pmovzxbd      %xmm0,%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  15,89,216                           // mulps         %xmm0,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,87,192                           // xorps         %xmm0,%xmm0
  .byte  102,15,239,201                      // pxor          %xmm1,%xmm1
  .byte  102,15,239,210                      // pxor          %xmm2,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_a8_sse41
.globl _sk_store_a8_sse41
FUNCTION(_sk_store_a8_sse41)
_sk_store_a8_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  185,0,0,127,67                      // mov           $0x437f0000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,89,195                        // mulps         %xmm3,%xmm8
  .byte  102,69,15,91,192                    // cvtps2dq      %xmm8,%xmm8
  .byte  102,69,15,56,43,192                 // packusdw      %xmm8,%xmm8
  .byte  102,69,15,103,192                   // packuswb      %xmm8,%xmm8
  .byte  102,68,15,126,4,56                  // movd          %xmm8,(%rax,%rdi,1)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_g8_sse41
.globl _sk_load_g8_sse41
FUNCTION(_sk_load_g8_sse41)
_sk_load_g8_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  102,15,56,49,4,56                   // pmovzxbd      (%rax,%rdi,1),%xmm0
  .byte  15,91,200                           // cvtdq2ps      %xmm0,%xmm1
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,40,200                           // movaps        %xmm0,%xmm1
  .byte  15,40,208                           // movaps        %xmm0,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_g8_sse41
.globl _sk_gather_g8_sse41
FUNCTION(_sk_gather_g8_sse41)
_sk_gather_g8_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  243,15,91,201                       // cvttps2dq     %xmm1,%xmm1
  .byte  102,15,110,80,16                    // movd          0x10(%rax),%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,15,56,64,209                    // pmulld        %xmm1,%xmm2
  .byte  243,15,91,192                       // cvttps2dq     %xmm0,%xmm0
  .byte  102,15,254,194                      // paddd         %xmm2,%xmm0
  .byte  102,72,15,58,22,192,1               // pextrq        $0x1,%xmm0,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,67,15,58,32,4,17,0              // pinsrb        $0x0,(%r9,%r10,1),%xmm0
  .byte  102,65,15,58,32,4,9,1               // pinsrb        $0x1,(%r9,%rcx,1),%xmm0
  .byte  67,15,182,12,1                      // movzbl        (%r9,%r8,1),%ecx
  .byte  102,15,58,32,193,2                  // pinsrb        $0x2,%ecx,%xmm0
  .byte  65,15,182,4,1                       // movzbl        (%r9,%rax,1),%eax
  .byte  102,15,58,32,192,3                  // pinsrb        $0x3,%eax,%xmm0
  .byte  102,15,56,49,192                    // pmovzxbd      %xmm0,%xmm0
  .byte  15,91,200                           // cvtdq2ps      %xmm0,%xmm1
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,40,200                           // movaps        %xmm0,%xmm1
  .byte  15,40,208                           // movaps        %xmm0,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_i8_sse41
.globl _sk_gather_i8_sse41
FUNCTION(_sk_gather_i8_sse41)
_sk_gather_i8_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  73,137,192                          // mov           %rax,%r8
  .byte  77,133,192                          // test          %r8,%r8
  .byte  116,5                               // je            252d <_sk_gather_i8_sse41+0xf>
  .byte  76,137,192                          // mov           %r8,%rax
  .byte  235,2                               // jmp           252f <_sk_gather_i8_sse41+0x11>
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,16                           // mov           (%rax),%r10
  .byte  243,15,91,201                       // cvttps2dq     %xmm1,%xmm1
  .byte  102,15,110,80,16                    // movd          0x10(%rax),%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,15,56,64,209                    // pmulld        %xmm1,%xmm2
  .byte  243,15,91,192                       // cvttps2dq     %xmm0,%xmm0
  .byte  102,15,254,194                      // paddd         %xmm2,%xmm0
  .byte  102,72,15,58,22,192,1               // pextrq        $0x1,%xmm0,%rax
  .byte  65,137,193                          // mov           %eax,%r9d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  65,137,203                          // mov           %ecx,%r11d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,67,15,58,32,4,26,0              // pinsrb        $0x0,(%r10,%r11,1),%xmm0
  .byte  102,65,15,58,32,4,10,1              // pinsrb        $0x1,(%r10,%rcx,1),%xmm0
  .byte  102,67,15,58,32,4,10,2              // pinsrb        $0x2,(%r10,%r9,1),%xmm0
  .byte  102,65,15,58,32,4,2,3               // pinsrb        $0x3,(%r10,%rax,1),%xmm0
  .byte  102,15,56,49,192                    // pmovzxbd      %xmm0,%xmm0
  .byte  102,73,15,58,22,193,1               // pextrq        $0x1,%xmm0,%r9
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  73,139,64,8                         // mov           0x8(%r8),%rax
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  72,193,233,30                       // shr           $0x1e,%rcx
  .byte  69,137,202                          // mov           %r9d,%r10d
  .byte  73,193,233,30                       // shr           $0x1e,%r9
  .byte  102,66,15,110,28,128                // movd          (%rax,%r8,4),%xmm3
  .byte  102,15,58,34,28,8,1                 // pinsrd        $0x1,(%rax,%rcx,1),%xmm3
  .byte  102,66,15,58,34,28,144,2            // pinsrd        $0x2,(%rax,%r10,4),%xmm3
  .byte  102,66,15,58,34,28,8,3              // pinsrd        $0x3,(%rax,%r9,1),%xmm3
  .byte  102,15,111,5,17,29,0,0              // movdqa        0x1d11(%rip),%xmm0        # 42e0 <_sk_callback_sse41+0x474>
  .byte  102,15,219,195                      // pand          %xmm3,%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  102,15,111,203                      // movdqa        %xmm3,%xmm1
  .byte  102,15,56,0,13,250,28,0,0           // pshufb        0x1cfa(%rip),%xmm1        # 42f0 <_sk_callback_sse41+0x484>
  .byte  15,91,201                           // cvtdq2ps      %xmm1,%xmm1
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  102,15,111,211                      // movdqa        %xmm3,%xmm2
  .byte  102,15,56,0,21,246,28,0,0           // pshufb        0x1cf6(%rip),%xmm2        # 4300 <_sk_callback_sse41+0x494>
  .byte  15,91,210                           // cvtdq2ps      %xmm2,%xmm2
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  102,15,114,211,24                   // psrld         $0x18,%xmm3
  .byte  15,91,219                           // cvtdq2ps      %xmm3,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_565_sse41
.globl _sk_load_565_sse41
FUNCTION(_sk_load_565_sse41)
_sk_load_565_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  102,15,56,51,20,120                 // pmovzxwd      (%rax,%rdi,2),%xmm2
  .byte  184,0,248,0,0                       // mov           $0xf800,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  102,15,112,192,0                    // pshufd        $0x0,%xmm0,%xmm0
  .byte  102,15,219,194                      // pand          %xmm2,%xmm0
  .byte  15,91,200                           // cvtdq2ps      %xmm0,%xmm1
  .byte  184,8,33,132,55                     // mov           $0x37842108,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  184,224,7,0,0                       // mov           $0x7e0,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  102,15,112,201,0                    // pshufd        $0x0,%xmm1,%xmm1
  .byte  102,15,219,202                      // pand          %xmm2,%xmm1
  .byte  15,91,217                           // cvtdq2ps      %xmm1,%xmm3
  .byte  184,33,8,2,58                       // mov           $0x3a020821,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  15,89,203                           // mulps         %xmm3,%xmm1
  .byte  184,31,0,0,0                        // mov           $0x1f,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  102,15,112,219,0                    // pshufd        $0x0,%xmm3,%xmm3
  .byte  102,15,219,218                      // pand          %xmm2,%xmm3
  .byte  15,91,219                           // cvtdq2ps      %xmm3,%xmm3
  .byte  184,8,33,4,61                       // mov           $0x3d042108,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  15,89,211                           // mulps         %xmm3,%xmm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_565_sse41
.globl _sk_gather_565_sse41
FUNCTION(_sk_gather_565_sse41)
_sk_gather_565_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  243,15,91,201                       // cvttps2dq     %xmm1,%xmm1
  .byte  102,15,110,80,16                    // movd          0x10(%rax),%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,15,56,64,209                    // pmulld        %xmm1,%xmm2
  .byte  243,15,91,192                       // cvttps2dq     %xmm0,%xmm0
  .byte  102,15,254,194                      // paddd         %xmm2,%xmm0
  .byte  102,72,15,58,22,192,1               // pextrq        $0x1,%xmm0,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,67,15,196,4,81,0                // pinsrw        $0x0,(%r9,%r10,2),%xmm0
  .byte  102,65,15,196,4,73,1                // pinsrw        $0x1,(%r9,%rcx,2),%xmm0
  .byte  67,15,183,12,65                     // movzwl        (%r9,%r8,2),%ecx
  .byte  102,15,196,193,2                    // pinsrw        $0x2,%ecx,%xmm0
  .byte  65,15,183,4,65                      // movzwl        (%r9,%rax,2),%eax
  .byte  102,15,196,192,3                    // pinsrw        $0x3,%eax,%xmm0
  .byte  102,15,56,51,208                    // pmovzxwd      %xmm0,%xmm2
  .byte  184,0,248,0,0                       // mov           $0xf800,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  102,15,112,192,0                    // pshufd        $0x0,%xmm0,%xmm0
  .byte  102,15,219,194                      // pand          %xmm2,%xmm0
  .byte  15,91,200                           // cvtdq2ps      %xmm0,%xmm1
  .byte  184,8,33,132,55                     // mov           $0x37842108,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  184,224,7,0,0                       // mov           $0x7e0,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  102,15,112,201,0                    // pshufd        $0x0,%xmm1,%xmm1
  .byte  102,15,219,202                      // pand          %xmm2,%xmm1
  .byte  15,91,217                           // cvtdq2ps      %xmm1,%xmm3
  .byte  184,33,8,2,58                       // mov           $0x3a020821,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  15,89,203                           // mulps         %xmm3,%xmm1
  .byte  184,31,0,0,0                        // mov           $0x1f,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  102,15,112,219,0                    // pshufd        $0x0,%xmm3,%xmm3
  .byte  102,15,219,218                      // pand          %xmm2,%xmm3
  .byte  15,91,219                           // cvtdq2ps      %xmm3,%xmm3
  .byte  184,8,33,4,61                       // mov           $0x3d042108,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  15,89,211                           // mulps         %xmm3,%xmm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_565_sse41
.globl _sk_store_565_sse41
FUNCTION(_sk_store_565_sse41)
_sk_store_565_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  185,0,0,248,65                      // mov           $0x41f80000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,200                        // mulps         %xmm0,%xmm9
  .byte  102,69,15,91,201                    // cvtps2dq      %xmm9,%xmm9
  .byte  102,65,15,114,241,11                // pslld         $0xb,%xmm9
  .byte  185,0,0,124,66                      // mov           $0x427c0000,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  68,15,89,209                        // mulps         %xmm1,%xmm10
  .byte  102,69,15,91,210                    // cvtps2dq      %xmm10,%xmm10
  .byte  102,65,15,114,242,5                 // pslld         $0x5,%xmm10
  .byte  102,69,15,235,209                   // por           %xmm9,%xmm10
  .byte  68,15,89,194                        // mulps         %xmm2,%xmm8
  .byte  102,69,15,91,192                    // cvtps2dq      %xmm8,%xmm8
  .byte  102,69,15,86,194                    // orpd          %xmm10,%xmm8
  .byte  102,69,15,56,43,192                 // packusdw      %xmm8,%xmm8
  .byte  102,68,15,214,4,120                 // movq          %xmm8,(%rax,%rdi,2)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_4444_sse41
.globl _sk_load_4444_sse41
FUNCTION(_sk_load_4444_sse41)
_sk_load_4444_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  102,68,15,56,51,12,120              // pmovzxwd      (%rax,%rdi,2),%xmm9
  .byte  184,0,240,0,0                       // mov           $0xf000,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  102,15,112,192,0                    // pshufd        $0x0,%xmm0,%xmm0
  .byte  102,65,15,219,193                   // pand          %xmm9,%xmm0
  .byte  15,91,200                           // cvtdq2ps      %xmm0,%xmm1
  .byte  184,137,136,136,55                  // mov           $0x37888889,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  184,0,15,0,0                        // mov           $0xf00,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  102,15,112,201,0                    // pshufd        $0x0,%xmm1,%xmm1
  .byte  102,65,15,219,201                   // pand          %xmm9,%xmm1
  .byte  15,91,209                           // cvtdq2ps      %xmm1,%xmm2
  .byte  184,137,136,136,57                  // mov           $0x39888889,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  15,89,202                           // mulps         %xmm2,%xmm1
  .byte  184,240,0,0,0                       // mov           $0xf0,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,65,15,219,209                   // pand          %xmm9,%xmm2
  .byte  68,15,91,194                        // cvtdq2ps      %xmm2,%xmm8
  .byte  184,137,136,136,59                  // mov           $0x3b888889,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  184,15,0,0,0                        // mov           $0xf,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  102,15,112,219,0                    // pshufd        $0x0,%xmm3,%xmm3
  .byte  102,65,15,219,217                   // pand          %xmm9,%xmm3
  .byte  68,15,91,195                        // cvtdq2ps      %xmm3,%xmm8
  .byte  184,137,136,136,61                  // mov           $0x3d888889,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_4444_sse41
.globl _sk_gather_4444_sse41
FUNCTION(_sk_gather_4444_sse41)
_sk_gather_4444_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  243,15,91,201                       // cvttps2dq     %xmm1,%xmm1
  .byte  102,15,110,80,16                    // movd          0x10(%rax),%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,15,56,64,209                    // pmulld        %xmm1,%xmm2
  .byte  243,15,91,192                       // cvttps2dq     %xmm0,%xmm0
  .byte  102,15,254,194                      // paddd         %xmm2,%xmm0
  .byte  102,72,15,58,22,192,1               // pextrq        $0x1,%xmm0,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,67,15,196,4,81,0                // pinsrw        $0x0,(%r9,%r10,2),%xmm0
  .byte  102,65,15,196,4,73,1                // pinsrw        $0x1,(%r9,%rcx,2),%xmm0
  .byte  67,15,183,12,65                     // movzwl        (%r9,%r8,2),%ecx
  .byte  102,15,196,193,2                    // pinsrw        $0x2,%ecx,%xmm0
  .byte  65,15,183,4,65                      // movzwl        (%r9,%rax,2),%eax
  .byte  102,15,196,192,3                    // pinsrw        $0x3,%eax,%xmm0
  .byte  102,68,15,56,51,200                 // pmovzxwd      %xmm0,%xmm9
  .byte  184,0,240,0,0                       // mov           $0xf000,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  102,15,112,192,0                    // pshufd        $0x0,%xmm0,%xmm0
  .byte  102,65,15,219,193                   // pand          %xmm9,%xmm0
  .byte  15,91,200                           // cvtdq2ps      %xmm0,%xmm1
  .byte  184,137,136,136,55                  // mov           $0x37888889,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  184,0,15,0,0                        // mov           $0xf00,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  102,15,112,201,0                    // pshufd        $0x0,%xmm1,%xmm1
  .byte  102,65,15,219,201                   // pand          %xmm9,%xmm1
  .byte  15,91,209                           // cvtdq2ps      %xmm1,%xmm2
  .byte  184,137,136,136,57                  // mov           $0x39888889,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  15,89,202                           // mulps         %xmm2,%xmm1
  .byte  184,240,0,0,0                       // mov           $0xf0,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,65,15,219,209                   // pand          %xmm9,%xmm2
  .byte  68,15,91,194                        // cvtdq2ps      %xmm2,%xmm8
  .byte  184,137,136,136,59                  // mov           $0x3b888889,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  184,15,0,0,0                        // mov           $0xf,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  102,15,112,219,0                    // pshufd        $0x0,%xmm3,%xmm3
  .byte  102,65,15,219,217                   // pand          %xmm9,%xmm3
  .byte  68,15,91,195                        // cvtdq2ps      %xmm3,%xmm8
  .byte  184,137,136,136,61                  // mov           $0x3d888889,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_4444_sse41
.globl _sk_store_4444_sse41
FUNCTION(_sk_store_4444_sse41)
_sk_store_4444_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  185,0,0,112,65                      // mov           $0x41700000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,200                        // mulps         %xmm0,%xmm9
  .byte  102,69,15,91,201                    // cvtps2dq      %xmm9,%xmm9
  .byte  102,65,15,114,241,12                // pslld         $0xc,%xmm9
  .byte  69,15,40,208                        // movaps        %xmm8,%xmm10
  .byte  68,15,89,209                        // mulps         %xmm1,%xmm10
  .byte  102,69,15,91,210                    // cvtps2dq      %xmm10,%xmm10
  .byte  102,65,15,114,242,8                 // pslld         $0x8,%xmm10
  .byte  102,69,15,235,209                   // por           %xmm9,%xmm10
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,202                        // mulps         %xmm2,%xmm9
  .byte  102,69,15,91,201                    // cvtps2dq      %xmm9,%xmm9
  .byte  102,65,15,114,241,4                 // pslld         $0x4,%xmm9
  .byte  68,15,89,195                        // mulps         %xmm3,%xmm8
  .byte  102,69,15,91,192                    // cvtps2dq      %xmm8,%xmm8
  .byte  102,69,15,86,193                    // orpd          %xmm9,%xmm8
  .byte  102,69,15,86,194                    // orpd          %xmm10,%xmm8
  .byte  102,69,15,56,43,192                 // packusdw      %xmm8,%xmm8
  .byte  102,68,15,214,4,120                 // movq          %xmm8,(%rax,%rdi,2)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_8888_sse41
.globl _sk_load_8888_sse41
FUNCTION(_sk_load_8888_sse41)
_sk_load_8888_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  15,16,28,184                        // movups        (%rax,%rdi,4),%xmm3
  .byte  15,40,5,232,24,0,0                  // movaps        0x18e8(%rip),%xmm0        # 4310 <_sk_callback_sse41+0x4a4>
  .byte  15,84,195                           // andps         %xmm3,%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  15,40,203                           // movaps        %xmm3,%xmm1
  .byte  102,15,56,0,13,211,24,0,0           // pshufb        0x18d3(%rip),%xmm1        # 4320 <_sk_callback_sse41+0x4b4>
  .byte  15,91,201                           // cvtdq2ps      %xmm1,%xmm1
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  15,40,211                           // movaps        %xmm3,%xmm2
  .byte  102,15,56,0,21,208,24,0,0           // pshufb        0x18d0(%rip),%xmm2        # 4330 <_sk_callback_sse41+0x4c4>
  .byte  15,91,210                           // cvtdq2ps      %xmm2,%xmm2
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  102,15,114,211,24                   // psrld         $0x18,%xmm3
  .byte  15,91,219                           // cvtdq2ps      %xmm3,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_8888_sse41
.globl _sk_gather_8888_sse41
FUNCTION(_sk_gather_8888_sse41)
_sk_gather_8888_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  243,15,91,201                       // cvttps2dq     %xmm1,%xmm1
  .byte  102,15,110,80,16                    // movd          0x10(%rax),%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,15,56,64,209                    // pmulld        %xmm1,%xmm2
  .byte  243,15,91,192                       // cvttps2dq     %xmm0,%xmm0
  .byte  102,15,254,194                      // paddd         %xmm2,%xmm0
  .byte  102,72,15,126,192                   // movq          %xmm0,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,72,15,58,22,193,1               // pextrq        $0x1,%xmm0,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,67,15,110,28,129                // movd          (%r9,%r8,4),%xmm3
  .byte  102,65,15,58,34,28,129,1            // pinsrd        $0x1,(%r9,%rax,4),%xmm3
  .byte  102,67,15,58,34,28,145,2            // pinsrd        $0x2,(%r9,%r10,4),%xmm3
  .byte  102,65,15,58,34,28,137,3            // pinsrd        $0x3,(%r9,%rcx,4),%xmm3
  .byte  102,15,111,5,105,24,0,0             // movdqa        0x1869(%rip),%xmm0        # 4340 <_sk_callback_sse41+0x4d4>
  .byte  102,15,219,195                      // pand          %xmm3,%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  102,15,111,203                      // movdqa        %xmm3,%xmm1
  .byte  102,15,56,0,13,82,24,0,0            // pshufb        0x1852(%rip),%xmm1        # 4350 <_sk_callback_sse41+0x4e4>
  .byte  15,91,201                           // cvtdq2ps      %xmm1,%xmm1
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  102,15,111,211                      // movdqa        %xmm3,%xmm2
  .byte  102,15,56,0,21,78,24,0,0            // pshufb        0x184e(%rip),%xmm2        # 4360 <_sk_callback_sse41+0x4f4>
  .byte  15,91,210                           // cvtdq2ps      %xmm2,%xmm2
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  102,15,114,211,24                   // psrld         $0x18,%xmm3
  .byte  15,91,219                           // cvtdq2ps      %xmm3,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_8888_sse41
.globl _sk_store_8888_sse41
FUNCTION(_sk_store_8888_sse41)
_sk_store_8888_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  185,0,0,127,67                      // mov           $0x437f0000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,200                        // mulps         %xmm0,%xmm9
  .byte  102,69,15,91,201                    // cvtps2dq      %xmm9,%xmm9
  .byte  69,15,40,208                        // movaps        %xmm8,%xmm10
  .byte  68,15,89,209                        // mulps         %xmm1,%xmm10
  .byte  102,69,15,91,210                    // cvtps2dq      %xmm10,%xmm10
  .byte  102,65,15,114,242,8                 // pslld         $0x8,%xmm10
  .byte  102,69,15,235,209                   // por           %xmm9,%xmm10
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,202                        // mulps         %xmm2,%xmm9
  .byte  102,69,15,91,201                    // cvtps2dq      %xmm9,%xmm9
  .byte  102,65,15,114,241,16                // pslld         $0x10,%xmm9
  .byte  68,15,89,195                        // mulps         %xmm3,%xmm8
  .byte  102,69,15,91,192                    // cvtps2dq      %xmm8,%xmm8
  .byte  102,65,15,114,240,24                // pslld         $0x18,%xmm8
  .byte  102,69,15,235,193                   // por           %xmm9,%xmm8
  .byte  102,69,15,235,194                   // por           %xmm10,%xmm8
  .byte  243,68,15,127,4,184                 // movdqu        %xmm8,(%rax,%rdi,4)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_f16_sse41
.globl _sk_load_f16_sse41
FUNCTION(_sk_load_f16_sse41)
_sk_load_f16_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  243,15,111,4,248                    // movdqu        (%rax,%rdi,8),%xmm0
  .byte  243,15,111,76,248,16                // movdqu        0x10(%rax,%rdi,8),%xmm1
  .byte  102,68,15,111,200                   // movdqa        %xmm0,%xmm9
  .byte  102,68,15,97,201                    // punpcklwd     %xmm1,%xmm9
  .byte  102,15,105,193                      // punpckhwd     %xmm1,%xmm0
  .byte  102,69,15,111,217                   // movdqa        %xmm9,%xmm11
  .byte  102,68,15,97,216                    // punpcklwd     %xmm0,%xmm11
  .byte  102,68,15,105,200                   // punpckhwd     %xmm0,%xmm9
  .byte  102,65,15,56,51,203                 // pmovzxwd      %xmm11,%xmm1
  .byte  102,68,15,111,5,156,23,0,0          // movdqa        0x179c(%rip),%xmm8        # 4370 <_sk_callback_sse41+0x504>
  .byte  102,15,111,209                      // movdqa        %xmm1,%xmm2
  .byte  102,65,15,219,208                   // pand          %xmm8,%xmm2
  .byte  102,15,239,202                      // pxor          %xmm2,%xmm1
  .byte  102,15,111,29,151,23,0,0            // movdqa        0x1797(%rip),%xmm3        # 4380 <_sk_callback_sse41+0x514>
  .byte  102,15,114,242,16                   // pslld         $0x10,%xmm2
  .byte  102,15,111,193                      // movdqa        %xmm1,%xmm0
  .byte  102,15,56,63,195                    // pmaxud        %xmm3,%xmm0
  .byte  102,15,118,193                      // pcmpeqd       %xmm1,%xmm0
  .byte  102,15,114,241,13                   // pslld         $0xd,%xmm1
  .byte  102,15,235,202                      // por           %xmm2,%xmm1
  .byte  102,68,15,111,21,131,23,0,0         // movdqa        0x1783(%rip),%xmm10        # 4390 <_sk_callback_sse41+0x524>
  .byte  102,65,15,254,202                   // paddd         %xmm10,%xmm1
  .byte  102,15,219,193                      // pand          %xmm1,%xmm0
  .byte  102,65,15,115,219,8                 // psrldq        $0x8,%xmm11
  .byte  102,69,15,56,51,219                 // pmovzxwd      %xmm11,%xmm11
  .byte  102,65,15,111,211                   // movdqa        %xmm11,%xmm2
  .byte  102,65,15,219,208                   // pand          %xmm8,%xmm2
  .byte  102,68,15,239,218                   // pxor          %xmm2,%xmm11
  .byte  102,15,114,242,16                   // pslld         $0x10,%xmm2
  .byte  102,65,15,111,203                   // movdqa        %xmm11,%xmm1
  .byte  102,15,56,63,203                    // pmaxud        %xmm3,%xmm1
  .byte  102,65,15,118,203                   // pcmpeqd       %xmm11,%xmm1
  .byte  102,65,15,114,243,13                // pslld         $0xd,%xmm11
  .byte  102,68,15,235,218                   // por           %xmm2,%xmm11
  .byte  102,69,15,254,218                   // paddd         %xmm10,%xmm11
  .byte  102,65,15,219,203                   // pand          %xmm11,%xmm1
  .byte  102,69,15,56,51,217                 // pmovzxwd      %xmm9,%xmm11
  .byte  102,69,15,111,227                   // movdqa        %xmm11,%xmm12
  .byte  102,69,15,219,224                   // pand          %xmm8,%xmm12
  .byte  102,69,15,239,220                   // pxor          %xmm12,%xmm11
  .byte  102,65,15,114,244,16                // pslld         $0x10,%xmm12
  .byte  102,65,15,111,211                   // movdqa        %xmm11,%xmm2
  .byte  102,15,56,63,211                    // pmaxud        %xmm3,%xmm2
  .byte  102,65,15,118,211                   // pcmpeqd       %xmm11,%xmm2
  .byte  102,65,15,114,243,13                // pslld         $0xd,%xmm11
  .byte  102,69,15,235,220                   // por           %xmm12,%xmm11
  .byte  102,69,15,254,218                   // paddd         %xmm10,%xmm11
  .byte  102,65,15,219,211                   // pand          %xmm11,%xmm2
  .byte  102,65,15,115,217,8                 // psrldq        $0x8,%xmm9
  .byte  102,69,15,56,51,201                 // pmovzxwd      %xmm9,%xmm9
  .byte  102,69,15,219,193                   // pand          %xmm9,%xmm8
  .byte  102,69,15,239,200                   // pxor          %xmm8,%xmm9
  .byte  102,65,15,114,240,16                // pslld         $0x10,%xmm8
  .byte  102,65,15,56,63,217                 // pmaxud        %xmm9,%xmm3
  .byte  102,65,15,118,217                   // pcmpeqd       %xmm9,%xmm3
  .byte  102,65,15,114,241,13                // pslld         $0xd,%xmm9
  .byte  102,69,15,235,200                   // por           %xmm8,%xmm9
  .byte  102,69,15,254,202                   // paddd         %xmm10,%xmm9
  .byte  102,65,15,219,217                   // pand          %xmm9,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_f16_sse41
.globl _sk_gather_f16_sse41
FUNCTION(_sk_gather_f16_sse41)
_sk_gather_f16_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  243,15,91,201                       // cvttps2dq     %xmm1,%xmm1
  .byte  102,15,110,80,16                    // movd          0x10(%rax),%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,15,56,64,209                    // pmulld        %xmm1,%xmm2
  .byte  243,15,91,192                       // cvttps2dq     %xmm0,%xmm0
  .byte  102,15,254,194                      // paddd         %xmm2,%xmm0
  .byte  102,72,15,126,192                   // movq          %xmm0,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,72,15,58,22,193,1               // pextrq        $0x1,%xmm0,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  243,65,15,126,4,201                 // movq          (%r9,%rcx,8),%xmm0
  .byte  243,67,15,126,12,209                // movq          (%r9,%r10,8),%xmm1
  .byte  102,15,108,200                      // punpcklqdq    %xmm0,%xmm1
  .byte  243,65,15,126,4,193                 // movq          (%r9,%rax,8),%xmm0
  .byte  243,67,15,126,20,193                // movq          (%r9,%r8,8),%xmm2
  .byte  102,15,108,208                      // punpcklqdq    %xmm0,%xmm2
  .byte  102,68,15,111,202                   // movdqa        %xmm2,%xmm9
  .byte  102,68,15,97,201                    // punpcklwd     %xmm1,%xmm9
  .byte  102,15,105,209                      // punpckhwd     %xmm1,%xmm2
  .byte  102,69,15,111,217                   // movdqa        %xmm9,%xmm11
  .byte  102,68,15,97,218                    // punpcklwd     %xmm2,%xmm11
  .byte  102,68,15,105,202                   // punpckhwd     %xmm2,%xmm9
  .byte  102,65,15,56,51,203                 // pmovzxwd      %xmm11,%xmm1
  .byte  102,68,15,111,5,65,22,0,0           // movdqa        0x1641(%rip),%xmm8        # 43a0 <_sk_callback_sse41+0x534>
  .byte  102,15,111,209                      // movdqa        %xmm1,%xmm2
  .byte  102,65,15,219,208                   // pand          %xmm8,%xmm2
  .byte  102,15,239,202                      // pxor          %xmm2,%xmm1
  .byte  102,15,111,29,60,22,0,0             // movdqa        0x163c(%rip),%xmm3        # 43b0 <_sk_callback_sse41+0x544>
  .byte  102,15,114,242,16                   // pslld         $0x10,%xmm2
  .byte  102,15,111,193                      // movdqa        %xmm1,%xmm0
  .byte  102,15,56,63,195                    // pmaxud        %xmm3,%xmm0
  .byte  102,15,118,193                      // pcmpeqd       %xmm1,%xmm0
  .byte  102,15,114,241,13                   // pslld         $0xd,%xmm1
  .byte  102,15,235,202                      // por           %xmm2,%xmm1
  .byte  102,68,15,111,21,40,22,0,0          // movdqa        0x1628(%rip),%xmm10        # 43c0 <_sk_callback_sse41+0x554>
  .byte  102,65,15,254,202                   // paddd         %xmm10,%xmm1
  .byte  102,15,219,193                      // pand          %xmm1,%xmm0
  .byte  102,65,15,115,219,8                 // psrldq        $0x8,%xmm11
  .byte  102,69,15,56,51,219                 // pmovzxwd      %xmm11,%xmm11
  .byte  102,65,15,111,211                   // movdqa        %xmm11,%xmm2
  .byte  102,65,15,219,208                   // pand          %xmm8,%xmm2
  .byte  102,68,15,239,218                   // pxor          %xmm2,%xmm11
  .byte  102,15,114,242,16                   // pslld         $0x10,%xmm2
  .byte  102,65,15,111,203                   // movdqa        %xmm11,%xmm1
  .byte  102,15,56,63,203                    // pmaxud        %xmm3,%xmm1
  .byte  102,65,15,118,203                   // pcmpeqd       %xmm11,%xmm1
  .byte  102,65,15,114,243,13                // pslld         $0xd,%xmm11
  .byte  102,68,15,235,218                   // por           %xmm2,%xmm11
  .byte  102,69,15,254,218                   // paddd         %xmm10,%xmm11
  .byte  102,65,15,219,203                   // pand          %xmm11,%xmm1
  .byte  102,69,15,56,51,217                 // pmovzxwd      %xmm9,%xmm11
  .byte  102,69,15,111,227                   // movdqa        %xmm11,%xmm12
  .byte  102,69,15,219,224                   // pand          %xmm8,%xmm12
  .byte  102,69,15,239,220                   // pxor          %xmm12,%xmm11
  .byte  102,65,15,114,244,16                // pslld         $0x10,%xmm12
  .byte  102,65,15,111,211                   // movdqa        %xmm11,%xmm2
  .byte  102,15,56,63,211                    // pmaxud        %xmm3,%xmm2
  .byte  102,65,15,118,211                   // pcmpeqd       %xmm11,%xmm2
  .byte  102,65,15,114,243,13                // pslld         $0xd,%xmm11
  .byte  102,69,15,235,220                   // por           %xmm12,%xmm11
  .byte  102,69,15,254,218                   // paddd         %xmm10,%xmm11
  .byte  102,65,15,219,211                   // pand          %xmm11,%xmm2
  .byte  102,65,15,115,217,8                 // psrldq        $0x8,%xmm9
  .byte  102,69,15,56,51,201                 // pmovzxwd      %xmm9,%xmm9
  .byte  102,69,15,219,193                   // pand          %xmm9,%xmm8
  .byte  102,69,15,239,200                   // pxor          %xmm8,%xmm9
  .byte  102,65,15,114,240,16                // pslld         $0x10,%xmm8
  .byte  102,65,15,56,63,217                 // pmaxud        %xmm9,%xmm3
  .byte  102,65,15,118,217                   // pcmpeqd       %xmm9,%xmm3
  .byte  102,65,15,114,241,13                // pslld         $0xd,%xmm9
  .byte  102,69,15,235,200                   // por           %xmm8,%xmm9
  .byte  102,69,15,254,202                   // paddd         %xmm10,%xmm9
  .byte  102,65,15,219,217                   // pand          %xmm9,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_f16_sse41
.globl _sk_store_f16_sse41
FUNCTION(_sk_store_f16_sse41)
_sk_store_f16_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  102,68,15,111,21,94,21,0,0          // movdqa        0x155e(%rip),%xmm10        # 43d0 <_sk_callback_sse41+0x564>
  .byte  102,68,15,111,224                   // movdqa        %xmm0,%xmm12
  .byte  102,68,15,111,232                   // movdqa        %xmm0,%xmm13
  .byte  102,69,15,219,234                   // pand          %xmm10,%xmm13
  .byte  102,69,15,239,229                   // pxor          %xmm13,%xmm12
  .byte  102,68,15,111,13,81,21,0,0          // movdqa        0x1551(%rip),%xmm9        # 43e0 <_sk_callback_sse41+0x574>
  .byte  102,65,15,114,213,16                // psrld         $0x10,%xmm13
  .byte  102,69,15,111,193                   // movdqa        %xmm9,%xmm8
  .byte  102,69,15,102,196                   // pcmpgtd       %xmm12,%xmm8
  .byte  102,65,15,114,212,13                // psrld         $0xd,%xmm12
  .byte  102,68,15,111,29,66,21,0,0          // movdqa        0x1542(%rip),%xmm11        # 43f0 <_sk_callback_sse41+0x584>
  .byte  102,69,15,235,235                   // por           %xmm11,%xmm13
  .byte  102,69,15,254,236                   // paddd         %xmm12,%xmm13
  .byte  102,69,15,223,197                   // pandn         %xmm13,%xmm8
  .byte  102,69,15,56,43,192                 // packusdw      %xmm8,%xmm8
  .byte  102,68,15,111,233                   // movdqa        %xmm1,%xmm13
  .byte  102,68,15,111,241                   // movdqa        %xmm1,%xmm14
  .byte  102,69,15,219,242                   // pand          %xmm10,%xmm14
  .byte  102,69,15,239,238                   // pxor          %xmm14,%xmm13
  .byte  102,65,15,114,214,16                // psrld         $0x10,%xmm14
  .byte  102,69,15,111,225                   // movdqa        %xmm9,%xmm12
  .byte  102,69,15,102,229                   // pcmpgtd       %xmm13,%xmm12
  .byte  102,65,15,114,213,13                // psrld         $0xd,%xmm13
  .byte  102,69,15,235,243                   // por           %xmm11,%xmm14
  .byte  102,69,15,254,245                   // paddd         %xmm13,%xmm14
  .byte  102,69,15,223,230                   // pandn         %xmm14,%xmm12
  .byte  102,69,15,56,43,228                 // packusdw      %xmm12,%xmm12
  .byte  102,68,15,111,242                   // movdqa        %xmm2,%xmm14
  .byte  102,68,15,111,250                   // movdqa        %xmm2,%xmm15
  .byte  102,69,15,219,250                   // pand          %xmm10,%xmm15
  .byte  102,69,15,239,247                   // pxor          %xmm15,%xmm14
  .byte  102,65,15,114,215,16                // psrld         $0x10,%xmm15
  .byte  102,69,15,111,233                   // movdqa        %xmm9,%xmm13
  .byte  102,69,15,102,238                   // pcmpgtd       %xmm14,%xmm13
  .byte  102,65,15,114,214,13                // psrld         $0xd,%xmm14
  .byte  102,69,15,235,251                   // por           %xmm11,%xmm15
  .byte  102,69,15,254,254                   // paddd         %xmm14,%xmm15
  .byte  102,69,15,223,239                   // pandn         %xmm15,%xmm13
  .byte  102,69,15,56,43,237                 // packusdw      %xmm13,%xmm13
  .byte  102,68,15,219,211                   // pand          %xmm3,%xmm10
  .byte  102,68,15,111,243                   // movdqa        %xmm3,%xmm14
  .byte  102,69,15,239,242                   // pxor          %xmm10,%xmm14
  .byte  102,65,15,114,210,16                // psrld         $0x10,%xmm10
  .byte  102,69,15,102,206                   // pcmpgtd       %xmm14,%xmm9
  .byte  102,65,15,114,214,13                // psrld         $0xd,%xmm14
  .byte  102,69,15,235,211                   // por           %xmm11,%xmm10
  .byte  102,69,15,254,214                   // paddd         %xmm14,%xmm10
  .byte  102,69,15,223,202                   // pandn         %xmm10,%xmm9
  .byte  102,69,15,56,43,201                 // packusdw      %xmm9,%xmm9
  .byte  102,69,15,97,196                    // punpcklwd     %xmm12,%xmm8
  .byte  102,69,15,97,233                    // punpcklwd     %xmm9,%xmm13
  .byte  102,69,15,111,200                   // movdqa        %xmm8,%xmm9
  .byte  102,69,15,98,205                    // punpckldq     %xmm13,%xmm9
  .byte  243,68,15,127,12,248                // movdqu        %xmm9,(%rax,%rdi,8)
  .byte  102,69,15,106,197                   // punpckhdq     %xmm13,%xmm8
  .byte  243,68,15,127,68,248,16             // movdqu        %xmm8,0x10(%rax,%rdi,8)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_u16_be_sse41
.globl _sk_load_u16_be_sse41
FUNCTION(_sk_load_u16_be_sse41)
_sk_load_u16_be_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  243,15,111,4,248                    // movdqu        (%rax,%rdi,8),%xmm0
  .byte  243,15,111,76,248,16                // movdqu        0x10(%rax,%rdi,8),%xmm1
  .byte  102,15,111,208                      // movdqa        %xmm0,%xmm2
  .byte  102,15,97,209                       // punpcklwd     %xmm1,%xmm2
  .byte  102,15,105,193                      // punpckhwd     %xmm1,%xmm0
  .byte  102,15,111,202                      // movdqa        %xmm2,%xmm1
  .byte  102,15,97,200                       // punpcklwd     %xmm0,%xmm1
  .byte  102,15,105,208                      // punpckhwd     %xmm0,%xmm2
  .byte  184,128,0,128,55                    // mov           $0x37800080,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  102,15,111,193                      // movdqa        %xmm1,%xmm0
  .byte  102,15,113,240,8                    // psllw         $0x8,%xmm0
  .byte  102,15,112,217,78                   // pshufd        $0x4e,%xmm1,%xmm3
  .byte  102,15,113,209,8                    // psrlw         $0x8,%xmm1
  .byte  102,15,235,200                      // por           %xmm0,%xmm1
  .byte  102,15,56,51,193                    // pmovzxwd      %xmm1,%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  102,15,111,203                      // movdqa        %xmm3,%xmm1
  .byte  102,15,113,241,8                    // psllw         $0x8,%xmm1
  .byte  102,15,113,211,8                    // psrlw         $0x8,%xmm3
  .byte  102,15,235,217                      // por           %xmm1,%xmm3
  .byte  102,15,56,51,203                    // pmovzxwd      %xmm3,%xmm1
  .byte  15,91,201                           // cvtdq2ps      %xmm1,%xmm1
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  102,68,15,111,202                   // movdqa        %xmm2,%xmm9
  .byte  102,65,15,113,241,8                 // psllw         $0x8,%xmm9
  .byte  102,15,112,218,78                   // pshufd        $0x4e,%xmm2,%xmm3
  .byte  102,15,113,210,8                    // psrlw         $0x8,%xmm2
  .byte  102,65,15,235,209                   // por           %xmm9,%xmm2
  .byte  102,15,56,51,210                    // pmovzxwd      %xmm2,%xmm2
  .byte  15,91,210                           // cvtdq2ps      %xmm2,%xmm2
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  102,68,15,111,203                   // movdqa        %xmm3,%xmm9
  .byte  102,65,15,113,241,8                 // psllw         $0x8,%xmm9
  .byte  102,15,113,211,8                    // psrlw         $0x8,%xmm3
  .byte  102,65,15,235,217                   // por           %xmm9,%xmm3
  .byte  102,15,56,51,219                    // pmovzxwd      %xmm3,%xmm3
  .byte  15,91,219                           // cvtdq2ps      %xmm3,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_rgb_u16_be_sse41
.globl _sk_load_rgb_u16_be_sse41
FUNCTION(_sk_load_rgb_u16_be_sse41)
_sk_load_rgb_u16_be_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,141,12,127                       // lea           (%rdi,%rdi,2),%rcx
  .byte  243,15,111,20,72                    // movdqu        (%rax,%rcx,2),%xmm2
  .byte  243,15,111,68,72,8                  // movdqu        0x8(%rax,%rcx,2),%xmm0
  .byte  102,15,115,216,4                    // psrldq        $0x4,%xmm0
  .byte  102,15,111,202                      // movdqa        %xmm2,%xmm1
  .byte  102,15,115,217,6                    // psrldq        $0x6,%xmm1
  .byte  102,15,97,208                       // punpcklwd     %xmm0,%xmm2
  .byte  102,15,115,216,6                    // psrldq        $0x6,%xmm0
  .byte  102,15,97,200                       // punpcklwd     %xmm0,%xmm1
  .byte  102,15,111,194                      // movdqa        %xmm2,%xmm0
  .byte  102,15,97,193                       // punpcklwd     %xmm1,%xmm0
  .byte  102,15,112,216,78                   // pshufd        $0x4e,%xmm0,%xmm3
  .byte  102,15,105,209                      // punpckhwd     %xmm1,%xmm2
  .byte  184,128,0,128,55                    // mov           $0x37800080,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  102,15,111,200                      // movdqa        %xmm0,%xmm1
  .byte  102,15,113,241,8                    // psllw         $0x8,%xmm1
  .byte  102,15,113,208,8                    // psrlw         $0x8,%xmm0
  .byte  102,15,235,193                      // por           %xmm1,%xmm0
  .byte  102,15,56,51,192                    // pmovzxwd      %xmm0,%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  102,15,111,203                      // movdqa        %xmm3,%xmm1
  .byte  102,15,113,241,8                    // psllw         $0x8,%xmm1
  .byte  102,15,113,211,8                    // psrlw         $0x8,%xmm3
  .byte  102,15,235,217                      // por           %xmm1,%xmm3
  .byte  102,15,56,51,203                    // pmovzxwd      %xmm3,%xmm1
  .byte  15,91,201                           // cvtdq2ps      %xmm1,%xmm1
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  102,15,111,218                      // movdqa        %xmm2,%xmm3
  .byte  102,15,113,243,8                    // psllw         $0x8,%xmm3
  .byte  102,15,113,210,8                    // psrlw         $0x8,%xmm2
  .byte  102,15,235,211                      // por           %xmm3,%xmm2
  .byte  102,15,56,51,210                    // pmovzxwd      %xmm2,%xmm2
  .byte  15,91,210                           // cvtdq2ps      %xmm2,%xmm2
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_u16_be_sse41
.globl _sk_store_u16_be_sse41
FUNCTION(_sk_store_u16_be_sse41)
_sk_store_u16_be_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  185,0,255,127,71                    // mov           $0x477fff00,%ecx
  .byte  102,68,15,110,201                   // movd          %ecx,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  69,15,40,193                        // movaps        %xmm9,%xmm8
  .byte  68,15,89,192                        // mulps         %xmm0,%xmm8
  .byte  102,69,15,91,192                    // cvtps2dq      %xmm8,%xmm8
  .byte  102,69,15,56,43,192                 // packusdw      %xmm8,%xmm8
  .byte  102,69,15,111,208                   // movdqa        %xmm8,%xmm10
  .byte  102,65,15,113,242,8                 // psllw         $0x8,%xmm10
  .byte  102,65,15,113,208,8                 // psrlw         $0x8,%xmm8
  .byte  102,69,15,235,194                   // por           %xmm10,%xmm8
  .byte  69,15,40,209                        // movaps        %xmm9,%xmm10
  .byte  68,15,89,209                        // mulps         %xmm1,%xmm10
  .byte  102,69,15,91,210                    // cvtps2dq      %xmm10,%xmm10
  .byte  102,69,15,56,43,210                 // packusdw      %xmm10,%xmm10
  .byte  102,69,15,111,218                   // movdqa        %xmm10,%xmm11
  .byte  102,65,15,113,243,8                 // psllw         $0x8,%xmm11
  .byte  102,65,15,113,210,8                 // psrlw         $0x8,%xmm10
  .byte  102,69,15,235,211                   // por           %xmm11,%xmm10
  .byte  69,15,40,217                        // movaps        %xmm9,%xmm11
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  102,69,15,91,219                    // cvtps2dq      %xmm11,%xmm11
  .byte  102,69,15,56,43,219                 // packusdw      %xmm11,%xmm11
  .byte  102,69,15,111,227                   // movdqa        %xmm11,%xmm12
  .byte  102,65,15,113,244,8                 // psllw         $0x8,%xmm12
  .byte  102,65,15,113,211,8                 // psrlw         $0x8,%xmm11
  .byte  102,69,15,235,220                   // por           %xmm12,%xmm11
  .byte  68,15,89,203                        // mulps         %xmm3,%xmm9
  .byte  102,69,15,91,201                    // cvtps2dq      %xmm9,%xmm9
  .byte  102,69,15,56,43,201                 // packusdw      %xmm9,%xmm9
  .byte  102,69,15,111,225                   // movdqa        %xmm9,%xmm12
  .byte  102,65,15,113,244,8                 // psllw         $0x8,%xmm12
  .byte  102,65,15,113,209,8                 // psrlw         $0x8,%xmm9
  .byte  102,69,15,235,204                   // por           %xmm12,%xmm9
  .byte  102,69,15,97,194                    // punpcklwd     %xmm10,%xmm8
  .byte  102,69,15,97,217                    // punpcklwd     %xmm9,%xmm11
  .byte  102,69,15,111,200                   // movdqa        %xmm8,%xmm9
  .byte  102,69,15,98,203                    // punpckldq     %xmm11,%xmm9
  .byte  243,68,15,127,12,248                // movdqu        %xmm9,(%rax,%rdi,8)
  .byte  102,69,15,106,195                   // punpckhdq     %xmm11,%xmm8
  .byte  243,68,15,127,68,248,16             // movdqu        %xmm8,0x10(%rax,%rdi,8)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_f32_sse41
.globl _sk_load_f32_sse41
FUNCTION(_sk_load_f32_sse41)
_sk_load_f32_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,137,249                          // mov           %rdi,%rcx
  .byte  72,193,225,4                        // shl           $0x4,%rcx
  .byte  68,15,16,4,8                        // movups        (%rax,%rcx,1),%xmm8
  .byte  15,16,68,8,16                       // movups        0x10(%rax,%rcx,1),%xmm0
  .byte  15,16,92,8,32                       // movups        0x20(%rax,%rcx,1),%xmm3
  .byte  68,15,16,76,8,48                    // movups        0x30(%rax,%rcx,1),%xmm9
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  15,20,208                           // unpcklps      %xmm0,%xmm2
  .byte  15,40,203                           // movaps        %xmm3,%xmm1
  .byte  65,15,20,201                        // unpcklps      %xmm9,%xmm1
  .byte  68,15,21,192                        // unpckhps      %xmm0,%xmm8
  .byte  65,15,21,217                        // unpckhps      %xmm9,%xmm3
  .byte  15,40,194                           // movaps        %xmm2,%xmm0
  .byte  102,15,20,193                       // unpcklpd      %xmm1,%xmm0
  .byte  15,18,202                           // movhlps       %xmm2,%xmm1
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  102,15,20,211                       // unpcklpd      %xmm3,%xmm2
  .byte  65,15,18,216                        // movhlps       %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_f32_sse41
.globl _sk_store_f32_sse41
FUNCTION(_sk_store_f32_sse41)
_sk_store_f32_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,137,249                          // mov           %rdi,%rcx
  .byte  72,193,225,4                        // shl           $0x4,%rcx
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  68,15,40,200                        // movaps        %xmm0,%xmm9
  .byte  68,15,20,201                        // unpcklps      %xmm1,%xmm9
  .byte  68,15,40,210                        // movaps        %xmm2,%xmm10
  .byte  68,15,40,218                        // movaps        %xmm2,%xmm11
  .byte  68,15,20,219                        // unpcklps      %xmm3,%xmm11
  .byte  68,15,21,193                        // unpckhps      %xmm1,%xmm8
  .byte  68,15,21,211                        // unpckhps      %xmm3,%xmm10
  .byte  69,15,40,225                        // movaps        %xmm9,%xmm12
  .byte  102,69,15,20,227                    // unpcklpd      %xmm11,%xmm12
  .byte  69,15,18,217                        // movhlps       %xmm9,%xmm11
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  102,69,15,20,202                    // unpcklpd      %xmm10,%xmm9
  .byte  69,15,18,208                        // movhlps       %xmm8,%xmm10
  .byte  102,68,15,17,36,8                   // movupd        %xmm12,(%rax,%rcx,1)
  .byte  68,15,17,92,8,16                    // movups        %xmm11,0x10(%rax,%rcx,1)
  .byte  102,68,15,17,76,8,32                // movupd        %xmm9,0x20(%rax,%rcx,1)
  .byte  68,15,17,84,8,48                    // movups        %xmm10,0x30(%rax,%rcx,1)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_x_sse41
.globl _sk_clamp_x_sse41
FUNCTION(_sk_clamp_x_sse41)
_sk_clamp_x_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  69,15,87,192                        // xorps         %xmm8,%xmm8
  .byte  68,15,95,192                        // maxps         %xmm0,%xmm8
  .byte  243,68,15,16,8                      // movss         (%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  102,15,118,192                      // pcmpeqd       %xmm0,%xmm0
  .byte  102,65,15,254,193                   // paddd         %xmm9,%xmm0
  .byte  68,15,93,192                        // minps         %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_y_sse41
.globl _sk_clamp_y_sse41
FUNCTION(_sk_clamp_y_sse41)
_sk_clamp_y_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  69,15,87,192                        // xorps         %xmm8,%xmm8
  .byte  68,15,95,193                        // maxps         %xmm1,%xmm8
  .byte  243,68,15,16,8                      // movss         (%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  102,15,118,201                      // pcmpeqd       %xmm1,%xmm1
  .byte  102,65,15,254,201                   // paddd         %xmm9,%xmm1
  .byte  68,15,93,193                        // minps         %xmm1,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_repeat_x_sse41
.globl _sk_repeat_x_sse41
FUNCTION(_sk_repeat_x_sse41)
_sk_repeat_x_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,0                      // movss         (%rax),%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,40,200                        // movaps        %xmm0,%xmm9
  .byte  69,15,94,200                        // divps         %xmm8,%xmm9
  .byte  102,69,15,58,8,201,1                // roundps       $0x1,%xmm9,%xmm9
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  65,15,92,193                        // subps         %xmm9,%xmm0
  .byte  102,69,15,118,201                   // pcmpeqd       %xmm9,%xmm9
  .byte  102,69,15,254,200                   // paddd         %xmm8,%xmm9
  .byte  65,15,93,193                        // minps         %xmm9,%xmm0
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_repeat_y_sse41
.globl _sk_repeat_y_sse41
FUNCTION(_sk_repeat_y_sse41)
_sk_repeat_y_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,0                      // movss         (%rax),%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,40,201                        // movaps        %xmm1,%xmm9
  .byte  69,15,94,200                        // divps         %xmm8,%xmm9
  .byte  102,69,15,58,8,201,1                // roundps       $0x1,%xmm9,%xmm9
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  65,15,92,201                        // subps         %xmm9,%xmm1
  .byte  102,69,15,118,201                   // pcmpeqd       %xmm9,%xmm9
  .byte  102,69,15,254,200                   // paddd         %xmm8,%xmm9
  .byte  65,15,93,201                        // minps         %xmm9,%xmm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_mirror_x_sse41
.globl _sk_mirror_x_sse41
FUNCTION(_sk_mirror_x_sse41)
_sk_mirror_x_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,0                      // movss         (%rax),%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  65,15,92,193                        // subps         %xmm9,%xmm0
  .byte  243,69,15,88,192                    // addss         %xmm8,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,40,208                        // movaps        %xmm0,%xmm10
  .byte  69,15,94,208                        // divps         %xmm8,%xmm10
  .byte  102,69,15,58,8,210,1                // roundps       $0x1,%xmm10,%xmm10
  .byte  69,15,89,208                        // mulps         %xmm8,%xmm10
  .byte  65,15,92,194                        // subps         %xmm10,%xmm0
  .byte  65,15,92,193                        // subps         %xmm9,%xmm0
  .byte  69,15,87,192                        // xorps         %xmm8,%xmm8
  .byte  68,15,92,192                        // subps         %xmm0,%xmm8
  .byte  65,15,84,192                        // andps         %xmm8,%xmm0
  .byte  102,69,15,118,192                   // pcmpeqd       %xmm8,%xmm8
  .byte  102,69,15,254,193                   // paddd         %xmm9,%xmm8
  .byte  65,15,93,192                        // minps         %xmm8,%xmm0
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_mirror_y_sse41
.globl _sk_mirror_y_sse41
FUNCTION(_sk_mirror_y_sse41)
_sk_mirror_y_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,0                      // movss         (%rax),%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  65,15,92,201                        // subps         %xmm9,%xmm1
  .byte  243,69,15,88,192                    // addss         %xmm8,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,40,209                        // movaps        %xmm1,%xmm10
  .byte  69,15,94,208                        // divps         %xmm8,%xmm10
  .byte  102,69,15,58,8,210,1                // roundps       $0x1,%xmm10,%xmm10
  .byte  69,15,89,208                        // mulps         %xmm8,%xmm10
  .byte  65,15,92,202                        // subps         %xmm10,%xmm1
  .byte  65,15,92,201                        // subps         %xmm9,%xmm1
  .byte  69,15,87,192                        // xorps         %xmm8,%xmm8
  .byte  68,15,92,193                        // subps         %xmm1,%xmm8
  .byte  65,15,84,200                        // andps         %xmm8,%xmm1
  .byte  102,69,15,118,192                   // pcmpeqd       %xmm8,%xmm8
  .byte  102,69,15,254,193                   // paddd         %xmm9,%xmm8
  .byte  65,15,93,200                        // minps         %xmm8,%xmm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_luminance_to_alpha_sse41
.globl _sk_luminance_to_alpha_sse41
FUNCTION(_sk_luminance_to_alpha_sse41)
_sk_luminance_to_alpha_sse41:
  .byte  184,208,179,89,62                   // mov           $0x3e59b3d0,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  15,89,216                           // mulps         %xmm0,%xmm3
  .byte  184,89,23,55,63                     // mov           $0x3f371759,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  15,88,195                           // addps         %xmm3,%xmm0
  .byte  184,152,221,147,61                  // mov           $0x3d93dd98,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  15,89,218                           // mulps         %xmm2,%xmm3
  .byte  15,88,216                           // addps         %xmm0,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,87,192                           // xorps         %xmm0,%xmm0
  .byte  15,87,201                           // xorps         %xmm1,%xmm1
  .byte  15,87,210                           // xorps         %xmm2,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_2x3_sse41
.globl _sk_matrix_2x3_sse41
FUNCTION(_sk_matrix_2x3_sse41)
_sk_matrix_2x3_sse41:
  .byte  68,15,40,201                        // movaps        %xmm1,%xmm9
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,15,16,0                         // movss         (%rax),%xmm0
  .byte  243,15,16,72,4                      // movss         0x4(%rax),%xmm1
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  243,68,15,16,80,8                   // movss         0x8(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,16                  // movss         0x10(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  65,15,88,194                        // addps         %xmm10,%xmm0
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  243,68,15,16,80,12                  // movss         0xc(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,20                  // movss         0x14(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  65,15,88,202                        // addps         %xmm10,%xmm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_3x4_sse41
.globl _sk_matrix_3x4_sse41
FUNCTION(_sk_matrix_3x4_sse41)
_sk_matrix_3x4_sse41:
  .byte  68,15,40,201                        // movaps        %xmm1,%xmm9
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,15,16,0                         // movss         (%rax),%xmm0
  .byte  243,15,16,72,4                      // movss         0x4(%rax),%xmm1
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  243,68,15,16,80,12                  // movss         0xc(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,24                  // movss         0x18(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,36                  // movss         0x24(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  65,15,88,194                        // addps         %xmm10,%xmm0
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  243,68,15,16,80,16                  // movss         0x10(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,28                  // movss         0x1c(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,40                  // movss         0x28(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  65,15,88,202                        // addps         %xmm10,%xmm1
  .byte  243,68,15,16,80,8                   // movss         0x8(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,20                  // movss         0x14(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,32                  // movss         0x20(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  243,68,15,16,104,44                 // movss         0x2c(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  68,15,89,226                        // mulps         %xmm2,%xmm12
  .byte  69,15,88,229                        // addps         %xmm13,%xmm12
  .byte  69,15,89,217                        // mulps         %xmm9,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  69,15,89,208                        // mulps         %xmm8,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_4x5_sse41
.globl _sk_matrix_4x5_sse41
FUNCTION(_sk_matrix_4x5_sse41)
_sk_matrix_4x5_sse41:
  .byte  68,15,40,201                        // movaps        %xmm1,%xmm9
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,15,16,0                         // movss         (%rax),%xmm0
  .byte  243,15,16,72,4                      // movss         0x4(%rax),%xmm1
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  243,68,15,16,80,16                  // movss         0x10(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,32                  // movss         0x20(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,48                  // movss         0x30(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  243,68,15,16,104,64                 // movss         0x40(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  68,15,89,227                        // mulps         %xmm3,%xmm12
  .byte  69,15,88,229                        // addps         %xmm13,%xmm12
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  65,15,88,194                        // addps         %xmm10,%xmm0
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  243,68,15,16,80,20                  // movss         0x14(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,36                  // movss         0x24(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,52                  // movss         0x34(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  243,68,15,16,104,68                 // movss         0x44(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  68,15,89,227                        // mulps         %xmm3,%xmm12
  .byte  69,15,88,229                        // addps         %xmm13,%xmm12
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  65,15,88,202                        // addps         %xmm10,%xmm1
  .byte  243,68,15,16,80,8                   // movss         0x8(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,24                  // movss         0x18(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,40                  // movss         0x28(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  243,68,15,16,104,56                 // movss         0x38(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  243,68,15,16,112,72                 // movss         0x48(%rax),%xmm14
  .byte  69,15,198,246,0                     // shufps        $0x0,%xmm14,%xmm14
  .byte  68,15,89,235                        // mulps         %xmm3,%xmm13
  .byte  69,15,88,238                        // addps         %xmm14,%xmm13
  .byte  68,15,89,226                        // mulps         %xmm2,%xmm12
  .byte  69,15,88,229                        // addps         %xmm13,%xmm12
  .byte  69,15,89,217                        // mulps         %xmm9,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  69,15,89,208                        // mulps         %xmm8,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  243,68,15,16,88,12                  // movss         0xc(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,28                  // movss         0x1c(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  243,68,15,16,104,44                 // movss         0x2c(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  243,68,15,16,112,60                 // movss         0x3c(%rax),%xmm14
  .byte  69,15,198,246,0                     // shufps        $0x0,%xmm14,%xmm14
  .byte  243,68,15,16,120,76                 // movss         0x4c(%rax),%xmm15
  .byte  69,15,198,255,0                     // shufps        $0x0,%xmm15,%xmm15
  .byte  68,15,89,243                        // mulps         %xmm3,%xmm14
  .byte  69,15,88,247                        // addps         %xmm15,%xmm14
  .byte  68,15,89,234                        // mulps         %xmm2,%xmm13
  .byte  69,15,88,238                        // addps         %xmm14,%xmm13
  .byte  69,15,89,225                        // mulps         %xmm9,%xmm12
  .byte  69,15,88,229                        // addps         %xmm13,%xmm12
  .byte  69,15,89,216                        // mulps         %xmm8,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  65,15,40,219                        // movaps        %xmm11,%xmm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_perspective_sse41
.globl _sk_matrix_perspective_sse41
FUNCTION(_sk_matrix_perspective_sse41)
_sk_matrix_perspective_sse41:
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,15,16,0                         // movss         (%rax),%xmm0
  .byte  243,68,15,16,72,4                   // movss         0x4(%rax),%xmm9
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  243,68,15,16,80,8                   // movss         0x8(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  68,15,89,201                        // mulps         %xmm1,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  65,15,88,193                        // addps         %xmm9,%xmm0
  .byte  243,68,15,16,72,12                  // movss         0xc(%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  243,68,15,16,80,16                  // movss         0x10(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,20                  // movss         0x14(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  68,15,89,209                        // mulps         %xmm1,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  243,68,15,16,80,24                  // movss         0x18(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,28                  // movss         0x1c(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,32                  // movss         0x20(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  68,15,89,217                        // mulps         %xmm1,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  69,15,89,208                        // mulps         %xmm8,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  65,15,83,202                        // rcpps         %xmm10,%xmm1
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  68,15,89,201                        // mulps         %xmm1,%xmm9
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,201                        // movaps        %xmm9,%xmm1
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_linear_gradient_sse41
.globl _sk_linear_gradient_sse41
FUNCTION(_sk_linear_gradient_sse41)
_sk_linear_gradient_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,80,16                  // movss         0x10(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,20                  // movss         0x14(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,24                  // movss         0x18(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  243,68,15,16,104,28                 // movss         0x1c(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  72,139,8                            // mov           (%rax),%rcx
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  15,132,254,0,0,0                    // je            38ee <_sk_linear_gradient_sse41+0x138>
  .byte  15,41,100,36,168                    // movaps        %xmm4,-0x58(%rsp)
  .byte  15,41,108,36,184                    // movaps        %xmm5,-0x48(%rsp)
  .byte  15,41,116,36,200                    // movaps        %xmm6,-0x38(%rsp)
  .byte  15,41,124,36,216                    // movaps        %xmm7,-0x28(%rsp)
  .byte  72,139,64,8                         // mov           0x8(%rax),%rax
  .byte  72,131,192,32                       // add           $0x20,%rax
  .byte  69,15,87,201                        // xorps         %xmm9,%xmm9
  .byte  15,87,219                           // xorps         %xmm3,%xmm3
  .byte  15,87,210                           // xorps         %xmm2,%xmm2
  .byte  15,87,201                           // xorps         %xmm1,%xmm1
  .byte  15,40,233                           // movaps        %xmm1,%xmm5
  .byte  15,40,242                           // movaps        %xmm2,%xmm6
  .byte  15,40,251                           // movaps        %xmm3,%xmm7
  .byte  69,15,40,194                        // movaps        %xmm10,%xmm8
  .byte  69,15,40,243                        // movaps        %xmm11,%xmm14
  .byte  69,15,40,252                        // movaps        %xmm12,%xmm15
  .byte  68,15,41,108,36,232                 // movaps        %xmm13,-0x18(%rsp)
  .byte  65,15,40,201                        // movaps        %xmm9,%xmm1
  .byte  243,15,16,80,224                    // movss         -0x20(%rax),%xmm2
  .byte  243,68,15,16,72,228                 // movss         -0x1c(%rax),%xmm9
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  15,40,224                           // movaps        %xmm0,%xmm4
  .byte  15,194,194,1                        // cmpltps       %xmm2,%xmm0
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  102,68,15,56,20,201                 // blendvps      %xmm0,%xmm1,%xmm9
  .byte  243,15,16,72,232                    // movss         -0x18(%rax),%xmm1
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  102,15,56,20,205                    // blendvps      %xmm0,%xmm5,%xmm1
  .byte  243,15,16,80,236                    // movss         -0x14(%rax),%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  102,15,56,20,214                    // blendvps      %xmm0,%xmm6,%xmm2
  .byte  243,15,16,88,240                    // movss         -0x10(%rax),%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  102,15,56,20,223                    // blendvps      %xmm0,%xmm7,%xmm3
  .byte  243,68,15,16,80,244                 // movss         -0xc(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  102,69,15,56,20,208                 // blendvps      %xmm0,%xmm8,%xmm10
  .byte  243,68,15,16,88,248                 // movss         -0x8(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  102,69,15,56,20,222                 // blendvps      %xmm0,%xmm14,%xmm11
  .byte  243,68,15,16,96,252                 // movss         -0x4(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  102,69,15,56,20,231                 // blendvps      %xmm0,%xmm15,%xmm12
  .byte  243,68,15,16,40                     // movss         (%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  102,68,15,56,20,108,36,232          // blendvps      %xmm0,-0x18(%rsp),%xmm13
  .byte  15,40,196                           // movaps        %xmm4,%xmm0
  .byte  72,131,192,36                       // add           $0x24,%rax
  .byte  72,255,201                          // dec           %rcx
  .byte  15,133,65,255,255,255               // jne           3819 <_sk_linear_gradient_sse41+0x63>
  .byte  15,40,124,36,216                    // movaps        -0x28(%rsp),%xmm7
  .byte  15,40,116,36,200                    // movaps        -0x38(%rsp),%xmm6
  .byte  15,40,108,36,184                    // movaps        -0x48(%rsp),%xmm5
  .byte  15,40,100,36,168                    // movaps        -0x58(%rsp),%xmm4
  .byte  235,13                              // jmp           38fb <_sk_linear_gradient_sse41+0x145>
  .byte  15,87,201                           // xorps         %xmm1,%xmm1
  .byte  15,87,210                           // xorps         %xmm2,%xmm2
  .byte  15,87,219                           // xorps         %xmm3,%xmm3
  .byte  69,15,87,201                        // xorps         %xmm9,%xmm9
  .byte  68,15,89,200                        // mulps         %xmm0,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  15,89,200                           // mulps         %xmm0,%xmm1
  .byte  65,15,88,203                        // addps         %xmm11,%xmm1
  .byte  15,89,208                           // mulps         %xmm0,%xmm2
  .byte  65,15,88,212                        // addps         %xmm12,%xmm2
  .byte  15,89,216                           // mulps         %xmm0,%xmm3
  .byte  65,15,88,221                        // addps         %xmm13,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,193                        // movaps        %xmm9,%xmm0
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_linear_gradient_2stops_sse41
.globl _sk_linear_gradient_2stops_sse41
FUNCTION(_sk_linear_gradient_2stops_sse41)
_sk_linear_gradient_2stops_sse41:
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,15,16,0                         // movss         (%rax),%xmm0
  .byte  243,15,16,72,4                      // movss         0x4(%rax),%xmm1
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  243,15,16,80,16                     // movss         0x10(%rax),%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  15,88,194                           // addps         %xmm2,%xmm0
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  243,15,16,80,20                     // movss         0x14(%rax),%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  15,88,202                           // addps         %xmm2,%xmm1
  .byte  243,15,16,80,8                      // movss         0x8(%rax),%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  243,15,16,88,24                     // movss         0x18(%rax),%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  15,88,211                           // addps         %xmm3,%xmm2
  .byte  243,15,16,88,12                     // movss         0xc(%rax),%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  243,68,15,16,72,28                  // movss         0x1c(%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  65,15,88,217                        // addps         %xmm9,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_save_xy_sse41
.globl _sk_save_xy_sse41
FUNCTION(_sk_save_xy_sse41)
_sk_save_xy_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,63                        // mov           $0x3f000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,88,200                        // addps         %xmm0,%xmm9
  .byte  102,69,15,58,8,209,1                // roundps       $0x1,%xmm9,%xmm10
  .byte  69,15,92,202                        // subps         %xmm10,%xmm9
  .byte  68,15,88,193                        // addps         %xmm1,%xmm8
  .byte  102,69,15,58,8,208,1                // roundps       $0x1,%xmm8,%xmm10
  .byte  69,15,92,194                        // subps         %xmm10,%xmm8
  .byte  15,17,0                             // movups        %xmm0,(%rax)
  .byte  15,17,72,32                         // movups        %xmm1,0x20(%rax)
  .byte  68,15,17,72,64                      // movups        %xmm9,0x40(%rax)
  .byte  68,15,17,64,96                      // movups        %xmm8,0x60(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_accumulate_sse41
.globl _sk_accumulate_sse41
FUNCTION(_sk_accumulate_sse41)
_sk_accumulate_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  68,15,16,128,128,0,0,0              // movups        0x80(%rax),%xmm8
  .byte  68,15,16,136,160,0,0,0              // movups        0xa0(%rax),%xmm9
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,40,193                        // movaps        %xmm9,%xmm8
  .byte  68,15,89,192                        // mulps         %xmm0,%xmm8
  .byte  65,15,88,224                        // addps         %xmm8,%xmm4
  .byte  69,15,40,193                        // movaps        %xmm9,%xmm8
  .byte  68,15,89,193                        // mulps         %xmm1,%xmm8
  .byte  65,15,88,232                        // addps         %xmm8,%xmm5
  .byte  69,15,40,193                        // movaps        %xmm9,%xmm8
  .byte  68,15,89,194                        // mulps         %xmm2,%xmm8
  .byte  65,15,88,240                        // addps         %xmm8,%xmm6
  .byte  68,15,89,203                        // mulps         %xmm3,%xmm9
  .byte  65,15,88,249                        // addps         %xmm9,%xmm7
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_nx_sse41
.globl _sk_bilinear_nx_sse41
FUNCTION(_sk_bilinear_nx_sse41)
_sk_bilinear_nx_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,191                       // mov           $0xbf000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,0                             // movups        (%rax),%xmm0
  .byte  68,15,16,72,64                      // movups        0x40(%rax),%xmm9
  .byte  65,15,88,192                        // addps         %xmm8,%xmm0
  .byte  185,0,0,128,63                      // mov           $0x3f800000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,92,193                        // subps         %xmm9,%xmm8
  .byte  68,15,17,128,128,0,0,0              // movups        %xmm8,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_px_sse41
.globl _sk_bilinear_px_sse41
FUNCTION(_sk_bilinear_px_sse41)
_sk_bilinear_px_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,63                        // mov           $0x3f000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,0                             // movups        (%rax),%xmm0
  .byte  68,15,16,72,64                      // movups        0x40(%rax),%xmm9
  .byte  65,15,88,192                        // addps         %xmm8,%xmm0
  .byte  68,15,17,136,128,0,0,0              // movups        %xmm9,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_ny_sse41
.globl _sk_bilinear_ny_sse41
FUNCTION(_sk_bilinear_ny_sse41)
_sk_bilinear_ny_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,191                       // mov           $0xbf000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,72,32                         // movups        0x20(%rax),%xmm1
  .byte  68,15,16,72,96                      // movups        0x60(%rax),%xmm9
  .byte  65,15,88,200                        // addps         %xmm8,%xmm1
  .byte  185,0,0,128,63                      // mov           $0x3f800000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,92,193                        // subps         %xmm9,%xmm8
  .byte  68,15,17,128,160,0,0,0              // movups        %xmm8,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_py_sse41
.globl _sk_bilinear_py_sse41
FUNCTION(_sk_bilinear_py_sse41)
_sk_bilinear_py_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,63                        // mov           $0x3f000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,72,32                         // movups        0x20(%rax),%xmm1
  .byte  68,15,16,72,96                      // movups        0x60(%rax),%xmm9
  .byte  65,15,88,200                        // addps         %xmm8,%xmm1
  .byte  68,15,17,136,160,0,0,0              // movups        %xmm9,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n3x_sse41
.globl _sk_bicubic_n3x_sse41
FUNCTION(_sk_bicubic_n3x_sse41)
_sk_bicubic_n3x_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,192,191                     // mov           $0xbfc00000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,0                             // movups        (%rax),%xmm0
  .byte  68,15,16,72,64                      // movups        0x40(%rax),%xmm9
  .byte  65,15,88,192                        // addps         %xmm8,%xmm0
  .byte  185,0,0,128,63                      // mov           $0x3f800000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,92,193                        // subps         %xmm9,%xmm8
  .byte  185,114,28,199,62                   // mov           $0x3ec71c72,%ecx
  .byte  102,68,15,110,201                   // movd          %ecx,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  185,171,170,170,190                 // mov           $0xbeaaaaab,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,89,192                        // mulps         %xmm8,%xmm8
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  68,15,17,136,128,0,0,0              // movups        %xmm9,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n1x_sse41
.globl _sk_bicubic_n1x_sse41
FUNCTION(_sk_bicubic_n1x_sse41)
_sk_bicubic_n1x_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,191                       // mov           $0xbf000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,0                             // movups        (%rax),%xmm0
  .byte  68,15,16,72,64                      // movups        0x40(%rax),%xmm9
  .byte  65,15,88,192                        // addps         %xmm8,%xmm0
  .byte  185,0,0,128,63                      // mov           $0x3f800000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,92,193                        // subps         %xmm9,%xmm8
  .byte  185,85,85,149,191                   // mov           $0xbf955555,%ecx
  .byte  102,68,15,110,201                   // movd          %ecx,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  185,0,0,192,63                      // mov           $0x3fc00000,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  185,0,0,0,63                        // mov           $0x3f000000,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  185,57,142,99,61                    // mov           $0x3d638e39,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  68,15,17,136,128,0,0,0              // movups        %xmm9,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p1x_sse41
.globl _sk_bicubic_p1x_sse41
FUNCTION(_sk_bicubic_p1x_sse41)
_sk_bicubic_p1x_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,63                        // mov           $0x3f000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,0                             // movups        (%rax),%xmm0
  .byte  68,15,16,72,64                      // movups        0x40(%rax),%xmm9
  .byte  65,15,88,192                        // addps         %xmm8,%xmm0
  .byte  185,85,85,149,191                   // mov           $0xbf955555,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  185,0,0,192,63                      // mov           $0x3fc00000,%ecx
  .byte  102,68,15,110,217                   // movd          %ecx,%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,208                        // addps         %xmm8,%xmm10
  .byte  185,57,142,99,61                    // mov           $0x3d638e39,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,208                        // addps         %xmm8,%xmm10
  .byte  68,15,17,144,128,0,0,0              // movups        %xmm10,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p3x_sse41
.globl _sk_bicubic_p3x_sse41
FUNCTION(_sk_bicubic_p3x_sse41)
_sk_bicubic_p3x_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,192,63                      // mov           $0x3fc00000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,0                             // movups        (%rax),%xmm0
  .byte  68,15,16,72,64                      // movups        0x40(%rax),%xmm9
  .byte  65,15,88,192                        // addps         %xmm8,%xmm0
  .byte  185,114,28,199,62                   // mov           $0x3ec71c72,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,89,193                        // mulps         %xmm9,%xmm8
  .byte  69,15,89,201                        // mulps         %xmm9,%xmm9
  .byte  185,171,170,170,190                 // mov           $0xbeaaaaab,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,88,194                        // addps         %xmm10,%xmm8
  .byte  69,15,89,193                        // mulps         %xmm9,%xmm8
  .byte  68,15,17,128,128,0,0,0              // movups        %xmm8,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n3y_sse41
.globl _sk_bicubic_n3y_sse41
FUNCTION(_sk_bicubic_n3y_sse41)
_sk_bicubic_n3y_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,192,191                     // mov           $0xbfc00000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,72,32                         // movups        0x20(%rax),%xmm1
  .byte  68,15,16,72,96                      // movups        0x60(%rax),%xmm9
  .byte  65,15,88,200                        // addps         %xmm8,%xmm1
  .byte  185,0,0,128,63                      // mov           $0x3f800000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,92,193                        // subps         %xmm9,%xmm8
  .byte  185,114,28,199,62                   // mov           $0x3ec71c72,%ecx
  .byte  102,68,15,110,201                   // movd          %ecx,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  185,171,170,170,190                 // mov           $0xbeaaaaab,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,89,192                        // mulps         %xmm8,%xmm8
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  68,15,17,136,160,0,0,0              // movups        %xmm9,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n1y_sse41
.globl _sk_bicubic_n1y_sse41
FUNCTION(_sk_bicubic_n1y_sse41)
_sk_bicubic_n1y_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,191                       // mov           $0xbf000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,72,32                         // movups        0x20(%rax),%xmm1
  .byte  68,15,16,72,96                      // movups        0x60(%rax),%xmm9
  .byte  65,15,88,200                        // addps         %xmm8,%xmm1
  .byte  185,0,0,128,63                      // mov           $0x3f800000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,92,193                        // subps         %xmm9,%xmm8
  .byte  185,85,85,149,191                   // mov           $0xbf955555,%ecx
  .byte  102,68,15,110,201                   // movd          %ecx,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  185,0,0,192,63                      // mov           $0x3fc00000,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  185,0,0,0,63                        // mov           $0x3f000000,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  185,57,142,99,61                    // mov           $0x3d638e39,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  68,15,17,136,160,0,0,0              // movups        %xmm9,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p1y_sse41
.globl _sk_bicubic_p1y_sse41
FUNCTION(_sk_bicubic_p1y_sse41)
_sk_bicubic_p1y_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,63                        // mov           $0x3f000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,72,32                         // movups        0x20(%rax),%xmm1
  .byte  68,15,16,72,96                      // movups        0x60(%rax),%xmm9
  .byte  65,15,88,200                        // addps         %xmm8,%xmm1
  .byte  185,85,85,149,191                   // mov           $0xbf955555,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  185,0,0,192,63                      // mov           $0x3fc00000,%ecx
  .byte  102,68,15,110,217                   // movd          %ecx,%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,208                        // addps         %xmm8,%xmm10
  .byte  185,57,142,99,61                    // mov           $0x3d638e39,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,208                        // addps         %xmm8,%xmm10
  .byte  68,15,17,144,160,0,0,0              // movups        %xmm10,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p3y_sse41
.globl _sk_bicubic_p3y_sse41
FUNCTION(_sk_bicubic_p3y_sse41)
_sk_bicubic_p3y_sse41:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,192,63                      // mov           $0x3fc00000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,72,32                         // movups        0x20(%rax),%xmm1
  .byte  68,15,16,72,96                      // movups        0x60(%rax),%xmm9
  .byte  65,15,88,200                        // addps         %xmm8,%xmm1
  .byte  185,114,28,199,62                   // mov           $0x3ec71c72,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,89,193                        // mulps         %xmm9,%xmm8
  .byte  69,15,89,201                        // mulps         %xmm9,%xmm9
  .byte  185,171,170,170,190                 // mov           $0xbeaaaaab,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,88,194                        // addps         %xmm10,%xmm8
  .byte  69,15,89,193                        // mulps         %xmm9,%xmm8
  .byte  68,15,17,128,160,0,0,0              // movups        %xmm8,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_callback_sse41
.globl _sk_callback_sse41
FUNCTION(_sk_callback_sse41)
_sk_callback_sse41:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,131,236,72                       // sub           $0x48,%rsp
  .byte  15,41,124,36,48                     // movaps        %xmm7,0x30(%rsp)
  .byte  15,41,116,36,32                     // movaps        %xmm6,0x20(%rsp)
  .byte  15,41,108,36,16                     // movaps        %xmm5,0x10(%rsp)
  .byte  15,41,36,36                         // movaps        %xmm4,(%rsp)
  .byte  73,137,214                          // mov           %rdx,%r14
  .byte  73,137,255                          // mov           %rdi,%r15
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,137,195                          // mov           %rax,%rbx
  .byte  73,137,244                          // mov           %rsi,%r12
  .byte  15,40,224                           // movaps        %xmm0,%xmm4
  .byte  15,20,225                           // unpcklps      %xmm1,%xmm4
  .byte  15,40,234                           // movaps        %xmm2,%xmm5
  .byte  15,20,235                           // unpcklps      %xmm3,%xmm5
  .byte  15,21,193                           // unpckhps      %xmm1,%xmm0
  .byte  15,21,211                           // unpckhps      %xmm3,%xmm2
  .byte  15,40,204                           // movaps        %xmm4,%xmm1
  .byte  102,15,20,205                       // unpcklpd      %xmm5,%xmm1
  .byte  15,18,236                           // movhlps       %xmm4,%xmm5
  .byte  15,40,216                           // movaps        %xmm0,%xmm3
  .byte  102,15,20,218                       // unpcklpd      %xmm2,%xmm3
  .byte  15,18,208                           // movhlps       %xmm0,%xmm2
  .byte  102,15,17,75,8                      // movupd        %xmm1,0x8(%rbx)
  .byte  15,17,107,24                        // movups        %xmm5,0x18(%rbx)
  .byte  102,15,17,91,40                     // movupd        %xmm3,0x28(%rbx)
  .byte  15,17,83,56                         // movups        %xmm2,0x38(%rbx)
  .byte  190,4,0,0,0                         // mov           $0x4,%esi
  .byte  72,137,223                          // mov           %rbx,%rdi
  .byte  255,19                              // callq         *(%rbx)
  .byte  72,139,131,136,0,0,0                // mov           0x88(%rbx),%rax
  .byte  15,16,32                            // movups        (%rax),%xmm4
  .byte  15,16,64,16                         // movups        0x10(%rax),%xmm0
  .byte  15,16,88,32                         // movups        0x20(%rax),%xmm3
  .byte  15,16,80,48                         // movups        0x30(%rax),%xmm2
  .byte  15,40,236                           // movaps        %xmm4,%xmm5
  .byte  15,20,232                           // unpcklps      %xmm0,%xmm5
  .byte  15,40,203                           // movaps        %xmm3,%xmm1
  .byte  15,20,202                           // unpcklps      %xmm2,%xmm1
  .byte  15,21,224                           // unpckhps      %xmm0,%xmm4
  .byte  15,21,218                           // unpckhps      %xmm2,%xmm3
  .byte  15,40,197                           // movaps        %xmm5,%xmm0
  .byte  102,15,20,193                       // unpcklpd      %xmm1,%xmm0
  .byte  15,18,205                           // movhlps       %xmm5,%xmm1
  .byte  15,40,212                           // movaps        %xmm4,%xmm2
  .byte  102,15,20,211                       // unpcklpd      %xmm3,%xmm2
  .byte  15,18,220                           // movhlps       %xmm4,%xmm3
  .byte  76,137,230                          // mov           %r12,%rsi
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,137,255                          // mov           %r15,%rdi
  .byte  76,137,242                          // mov           %r14,%rdx
  .byte  15,40,36,36                         // movaps        (%rsp),%xmm4
  .byte  15,40,108,36,16                     // movaps        0x10(%rsp),%xmm5
  .byte  15,40,116,36,32                     // movaps        0x20(%rsp),%xmm6
  .byte  15,40,124,36,48                     // movaps        0x30(%rsp),%xmm7
  .byte  72,131,196,72                       // add           $0x48,%rsp
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  255,224                             // jmpq          *%rax

BALIGN16
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  128,63,0                            // cmpb          $0x0,(%rdi)
  .byte  0,128,63,0,0,128                    // add           %al,-0x7fffffc1(%rax)
  .byte  63                                  // (bad)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  128,63,255                          // cmpb          $0xff,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,255                               // add           %bh,%bh
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,255                               // add           %bh,%bh
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,255                               // add           %bh,%bh
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,1                                 // add           %al,(%rcx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,5,255,255,255,9                 // incl          0x9ffffff(%rip)        # a003f88 <_sk_callback_sse41+0xa00011c>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,13,255,255,255,2                // decl          0x2ffffff(%rip)        # 3003f90 <_sk_callback_sse41+0x3000124>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,6                               // incl          (%rsi)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,10                              // decl          (%rdx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,14                              // decl          (%rsi)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  8,255                               // or            %bh,%bh
  .byte  10,255                              // or            %bh,%bh
  .byte  12,255                              // or            $0xff,%al
  .byte  14                                  // (bad)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,255                               // add           %bh,%bh
  .byte  0,255                               // add           %bh,%bh
  .byte  0,255                               // add           %bh,%bh
  .byte  0,255                               // add           %bh,%bh
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,8                                 // add           %cl,(%rax)
  .byte  128,10,128                          // orb           $0x80,(%rdx)
  .byte  12,128                              // or            $0x80,%al
  .byte  14                                  // (bad)
  .byte  128,0,0                             // addb          $0x0,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,52,0                              // add           %dh,(%rax,%rax,1)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,0                                // xor           $0x0,%al
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,0                                // xor           $0x0,%al
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,255                              // xor           $0xff,%al
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            3ff4 <.literal16+0xa4>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            3ff8 <.literal16+0xa8>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            3ffc <.literal16+0xac>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            4000 <.literal16+0xb0>
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  119,115                             // ja            4085 <.literal16+0x135>
  .byte  248                                 // clc
  .byte  194,119,115                         // retq          $0x7377
  .byte  248                                 // clc
  .byte  194,119,115                         // retq          $0x7377
  .byte  248                                 // clc
  .byte  194,119,115                         // retq          $0x7377
  .byte  248                                 // clc
  .byte  194,117,191                         // retq          $0xbf75
  .byte  191,63,117,191,191                  // mov           $0xbfbf753f,%edi
  .byte  63                                  // (bad)
  .byte  117,191                             // jne           3fe9 <.literal16+0x99>
  .byte  191,63,117,191,191                  // mov           $0xbfbf753f,%edi
  .byte  63                                  // (bad)
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  163,233,220,63,163,233,220,63,163   // movabs        %eax,0xa33fdce9a33fdce9
  .byte  233,220,63,163,233                  // jmpq          ffffffffe9a3802a <_sk_callback_sse41+0xffffffffe9a341be>
  .byte  220,63                              // fdivrl        (%rdi)
  .byte  81                                  // push          %rcx
  .byte  140,242                             // mov           %?,%edx
  .byte  66,81                               // rex.X         push %rcx
  .byte  140,242                             // mov           %?,%edx
  .byte  66,81                               // rex.X         push %rcx
  .byte  140,242                             // mov           %?,%edx
  .byte  66,81                               // rex.X         push %rcx
  .byte  140,242                             // mov           %?,%edx
  .byte  66,141,188,190,63,141,188,190       // lea           -0x414372c1(%rsi,%r15,4),%edi
  .byte  63                                  // (bad)
  .byte  141,188,190,63,141,188,190          // lea           -0x414372c1(%rsi,%rdi,4),%edi
  .byte  63                                  // (bad)
  .byte  248                                 // clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,248                              // rex           clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,248                              // rex           clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,248                              // rex           clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,254                              // rex           (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,254                              // rex.B         (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,254                              // rex.B         (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,254                              // rex.B         (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,0,0                              // add           %al,(%r8)
  .byte  0,75,0                              // add           %cl,0x0(%rbx)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  75,0,0                              // rex.WXB       add %al,(%r8)
  .byte  0,75,0                              // add           %cl,0x0(%rbx)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  75,0,0                              // rex.WXB       add %al,(%r8)
  .byte  0,52,0                              // add           %dh,(%rax,%rax,1)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,0                                // xor           $0x0,%al
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,0                                // xor           $0x0,%al
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,255                              // xor           $0xff,%al
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            40b4 <.literal16+0x164>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            40b8 <.literal16+0x168>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            40bc <.literal16+0x16c>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            40c0 <.literal16+0x170>
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  119,115                             // ja            4145 <.literal16+0x1f5>
  .byte  248                                 // clc
  .byte  194,119,115                         // retq          $0x7377
  .byte  248                                 // clc
  .byte  194,119,115                         // retq          $0x7377
  .byte  248                                 // clc
  .byte  194,119,115                         // retq          $0x7377
  .byte  248                                 // clc
  .byte  194,117,191                         // retq          $0xbf75
  .byte  191,63,117,191,191                  // mov           $0xbfbf753f,%edi
  .byte  63                                  // (bad)
  .byte  117,191                             // jne           40a9 <.literal16+0x159>
  .byte  191,63,117,191,191                  // mov           $0xbfbf753f,%edi
  .byte  63                                  // (bad)
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  163,233,220,63,163,233,220,63,163   // movabs        %eax,0xa33fdce9a33fdce9
  .byte  233,220,63,163,233                  // jmpq          ffffffffe9a380ea <_sk_callback_sse41+0xffffffffe9a3427e>
  .byte  220,63                              // fdivrl        (%rdi)
  .byte  81                                  // push          %rcx
  .byte  140,242                             // mov           %?,%edx
  .byte  66,81                               // rex.X         push %rcx
  .byte  140,242                             // mov           %?,%edx
  .byte  66,81                               // rex.X         push %rcx
  .byte  140,242                             // mov           %?,%edx
  .byte  66,81                               // rex.X         push %rcx
  .byte  140,242                             // mov           %?,%edx
  .byte  66,141,188,190,63,141,188,190       // lea           -0x414372c1(%rsi,%r15,4),%edi
  .byte  63                                  // (bad)
  .byte  141,188,190,63,141,188,190          // lea           -0x414372c1(%rsi,%rdi,4),%edi
  .byte  63                                  // (bad)
  .byte  248                                 // clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,248                              // rex           clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,248                              // rex           clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,248                              // rex           clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,254                              // rex           (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,254                              // rex.B         (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,254                              // rex.B         (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,254                              // rex.B         (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,0,0                              // add           %al,(%r8)
  .byte  0,75,0                              // add           %cl,0x0(%rbx)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  75,0,0                              // rex.WXB       add %al,(%r8)
  .byte  0,75,0                              // add           %cl,0x0(%rbx)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  75,0,0                              // rex.WXB       add %al,(%r8)
  .byte  0,52,0                              // add           %dh,(%rax,%rax,1)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,0                                // xor           $0x0,%al
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,0                                // xor           $0x0,%al
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,255                              // xor           $0xff,%al
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            4174 <.literal16+0x224>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            4178 <.literal16+0x228>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            417c <.literal16+0x22c>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            4180 <.literal16+0x230>
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  119,115                             // ja            4205 <.literal16+0x2b5>
  .byte  248                                 // clc
  .byte  194,119,115                         // retq          $0x7377
  .byte  248                                 // clc
  .byte  194,119,115                         // retq          $0x7377
  .byte  248                                 // clc
  .byte  194,119,115                         // retq          $0x7377
  .byte  248                                 // clc
  .byte  194,117,191                         // retq          $0xbf75
  .byte  191,63,117,191,191                  // mov           $0xbfbf753f,%edi
  .byte  63                                  // (bad)
  .byte  117,191                             // jne           4169 <.literal16+0x219>
  .byte  191,63,117,191,191                  // mov           $0xbfbf753f,%edi
  .byte  63                                  // (bad)
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  163,233,220,63,163,233,220,63,163   // movabs        %eax,0xa33fdce9a33fdce9
  .byte  233,220,63,163,233                  // jmpq          ffffffffe9a381aa <_sk_callback_sse41+0xffffffffe9a3433e>
  .byte  220,63                              // fdivrl        (%rdi)
  .byte  81                                  // push          %rcx
  .byte  140,242                             // mov           %?,%edx
  .byte  66,81                               // rex.X         push %rcx
  .byte  140,242                             // mov           %?,%edx
  .byte  66,81                               // rex.X         push %rcx
  .byte  140,242                             // mov           %?,%edx
  .byte  66,81                               // rex.X         push %rcx
  .byte  140,242                             // mov           %?,%edx
  .byte  66,141,188,190,63,141,188,190       // lea           -0x414372c1(%rsi,%r15,4),%edi
  .byte  63                                  // (bad)
  .byte  141,188,190,63,141,188,190          // lea           -0x414372c1(%rsi,%rdi,4),%edi
  .byte  63                                  // (bad)
  .byte  248                                 // clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,248                              // rex           clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,248                              // rex           clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,248                              // rex           clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,254                              // rex           (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,254                              // rex.B         (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,254                              // rex.B         (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,254                              // rex.B         (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,0,0                              // add           %al,(%r8)
  .byte  0,75,0                              // add           %cl,0x0(%rbx)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  75,0,0                              // rex.WXB       add %al,(%r8)
  .byte  0,75,0                              // add           %cl,0x0(%rbx)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  75,0,0                              // rex.WXB       add %al,(%r8)
  .byte  0,52,0                              // add           %dh,(%rax,%rax,1)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,0                                // xor           $0x0,%al
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,0                                // xor           $0x0,%al
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,255                              // xor           $0xff,%al
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            4234 <.literal16+0x2e4>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            4238 <.literal16+0x2e8>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            423c <.literal16+0x2ec>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            4240 <.literal16+0x2f0>
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  119,115                             // ja            42c5 <.literal16+0x375>
  .byte  248                                 // clc
  .byte  194,119,115                         // retq          $0x7377
  .byte  248                                 // clc
  .byte  194,119,115                         // retq          $0x7377
  .byte  248                                 // clc
  .byte  194,119,115                         // retq          $0x7377
  .byte  248                                 // clc
  .byte  194,117,191                         // retq          $0xbf75
  .byte  191,63,117,191,191                  // mov           $0xbfbf753f,%edi
  .byte  63                                  // (bad)
  .byte  117,191                             // jne           4229 <.literal16+0x2d9>
  .byte  191,63,117,191,191                  // mov           $0xbfbf753f,%edi
  .byte  63                                  // (bad)
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  163,233,220,63,163,233,220,63,163   // movabs        %eax,0xa33fdce9a33fdce9
  .byte  233,220,63,163,233                  // jmpq          ffffffffe9a3826a <_sk_callback_sse41+0xffffffffe9a343fe>
  .byte  220,63                              // fdivrl        (%rdi)
  .byte  81                                  // push          %rcx
  .byte  140,242                             // mov           %?,%edx
  .byte  66,81                               // rex.X         push %rcx
  .byte  140,242                             // mov           %?,%edx
  .byte  66,81                               // rex.X         push %rcx
  .byte  140,242                             // mov           %?,%edx
  .byte  66,81                               // rex.X         push %rcx
  .byte  140,242                             // mov           %?,%edx
  .byte  66,141,188,190,63,141,188,190       // lea           -0x414372c1(%rsi,%r15,4),%edi
  .byte  63                                  // (bad)
  .byte  141,188,190,63,141,188,190          // lea           -0x414372c1(%rsi,%rdi,4),%edi
  .byte  63                                  // (bad)
  .byte  248                                 // clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,248                              // rex           clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,248                              // rex           clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,248                              // rex           clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,254                              // rex           (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,254                              // rex.B         (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,254                              // rex.B         (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,254                              // rex.B         (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,0,0                              // add           %al,(%r8)
  .byte  0,75,0                              // add           %cl,0x0(%rbx)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  75,0,0                              // rex.WXB       add %al,(%r8)
  .byte  0,75,0                              // add           %cl,0x0(%rbx)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  75,255,0                            // rex.WXB       incq (%r8)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  1,255                               // add           %edi,%edi
  .byte  255                                 // (bad)
  .byte  255,5,255,255,255,9                 // incl          0x9ffffff(%rip)        # a0042f8 <_sk_callback_sse41+0xa00048c>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,13,255,255,255,2                // decl          0x2ffffff(%rip)        # 3004300 <_sk_callback_sse41+0x3000494>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,6                               // incl          (%rsi)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,10                              // decl          (%rdx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,14                              // decl          (%rsi)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  1,255                               // add           %edi,%edi
  .byte  255                                 // (bad)
  .byte  255,5,255,255,255,9                 // incl          0x9ffffff(%rip)        # a004328 <_sk_callback_sse41+0xa0004bc>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,13,255,255,255,2                // decl          0x2ffffff(%rip)        # 3004330 <_sk_callback_sse41+0x30004c4>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,6                               // incl          (%rsi)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,10                              // decl          (%rdx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,14                              // decl          (%rsi)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  1,255                               // add           %edi,%edi
  .byte  255                                 // (bad)
  .byte  255,5,255,255,255,9                 // incl          0x9ffffff(%rip)        # a004358 <_sk_callback_sse41+0xa0004ec>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,13,255,255,255,2                // decl          0x2ffffff(%rip)        # 3004360 <_sk_callback_sse41+0x30004f4>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,6                               // incl          (%rsi)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,10                              // decl          (%rdx)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,14                              // decl          (%rsi)
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  255,0                               // incl          (%rax)
  .byte  128,0,0                             // addb          $0x0,(%rax)
  .byte  0,128,0,0,0,128                     // add           %al,-0x80000000(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,128,0,0,0,4                       // add           %al,0x4000000(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,4,0                               // add           %al,(%rax,%rax,1)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  4,0                                 // add           $0x0,%al
  .byte  0,0                                 // add           %al,(%rax)
  .byte  4,0                                 // add           $0x0,%al
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  56,0                                // cmp           %al,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  56,0                                // cmp           %al,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  56,0                                // cmp           %al,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  56,0                                // cmp           %al,(%rax)
  .byte  128,0,0                             // addb          $0x0,(%rax)
  .byte  0,128,0,0,0,128                     // add           %al,-0x80000000(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,128,0,0,0,4                       // add           %al,0x4000000(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,4,0                               // add           %al,(%rax,%rax,1)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  4,0                                 // add           $0x0,%al
  .byte  0,0                                 // add           %al,(%rax)
  .byte  4,0                                 // add           $0x0,%al
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  56,0                                // cmp           %al,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  56,0                                // cmp           %al,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  56,0                                // cmp           %al,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  56,0                                // cmp           %al,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  128,0,0                             // addb          $0x0,(%rax)
  .byte  0,128,0,0,0,128                     // add           %al,-0x80000000(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,128,0,0,128,56                    // add           %al,0x38800000(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  128,56,0                            // cmpb          $0x0,(%rax)
  .byte  0,128,56,0,0,128                    // add           %al,-0x7fffffc8(%rax)
  .byte  56,0                                // cmp           %al,(%rax)
  .byte  64,254                              // rex           (bad)
  .byte  255,0                               // incl          (%rax)
  .byte  64,254                              // rex           (bad)
  .byte  255,0                               // incl          (%rax)
  .byte  64,254                              // rex           (bad)
  .byte  255,0                               // incl          (%rax)
  .byte  64,254                              // rex           (bad)
  .byte  255                                 // .byte         0xff
BALIGN32

HIDDEN _sk_start_pipeline_sse2
.globl _sk_start_pipeline_sse2
FUNCTION(_sk_start_pipeline_sse2)
_sk_start_pipeline_sse2:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,85                               // push          %r13
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  73,137,207                          // mov           %rcx,%r15
  .byte  73,137,214                          // mov           %rdx,%r14
  .byte  72,137,251                          // mov           %rdi,%rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  73,137,196                          // mov           %rax,%r12
  .byte  73,137,245                          // mov           %rsi,%r13
  .byte  72,141,67,4                         // lea           0x4(%rbx),%rax
  .byte  76,57,248                           // cmp           %r15,%rax
  .byte  118,5                               // jbe           28 <_sk_start_pipeline_sse2+0x28>
  .byte  72,137,216                          // mov           %rbx,%rax
  .byte  235,52                              // jmp           5c <_sk_start_pipeline_sse2+0x5c>
  .byte  15,87,192                           // xorps         %xmm0,%xmm0
  .byte  15,87,201                           // xorps         %xmm1,%xmm1
  .byte  15,87,210                           // xorps         %xmm2,%xmm2
  .byte  15,87,219                           // xorps         %xmm3,%xmm3
  .byte  15,87,228                           // xorps         %xmm4,%xmm4
  .byte  15,87,237                           // xorps         %xmm5,%xmm5
  .byte  15,87,246                           // xorps         %xmm6,%xmm6
  .byte  15,87,255                           // xorps         %xmm7,%xmm7
  .byte  72,137,223                          // mov           %rbx,%rdi
  .byte  76,137,238                          // mov           %r13,%rsi
  .byte  76,137,242                          // mov           %r14,%rdx
  .byte  65,255,212                          // callq         *%r12
  .byte  72,141,67,4                         // lea           0x4(%rbx),%rax
  .byte  72,131,195,8                        // add           $0x8,%rbx
  .byte  76,57,251                           // cmp           %r15,%rbx
  .byte  72,137,195                          // mov           %rax,%rbx
  .byte  118,204                             // jbe           28 <_sk_start_pipeline_sse2+0x28>
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,93                               // pop           %r13
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  195                                 // retq

HIDDEN _sk_just_return_sse2
.globl _sk_just_return_sse2
FUNCTION(_sk_just_return_sse2)
_sk_just_return_sse2:
  .byte  195                                 // retq

HIDDEN _sk_seed_shader_sse2
.globl _sk_seed_shader_sse2
FUNCTION(_sk_seed_shader_sse2)
_sk_seed_shader_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  102,15,110,199                      // movd          %edi,%xmm0
  .byte  102,15,112,192,0                    // pshufd        $0x0,%xmm0,%xmm0
  .byte  15,91,200                           // cvtdq2ps      %xmm0,%xmm1
  .byte  15,40,21,196,66,0,0                 // movaps        0x42c4(%rip),%xmm2        # 4340 <_sk_callback_sse2+0xe2>
  .byte  15,88,202                           // addps         %xmm2,%xmm1
  .byte  15,16,2                             // movups        (%rdx),%xmm0
  .byte  15,88,193                           // addps         %xmm1,%xmm0
  .byte  102,15,110,8                        // movd          (%rax),%xmm1
  .byte  102,15,112,201,0                    // pshufd        $0x0,%xmm1,%xmm1
  .byte  15,91,201                           // cvtdq2ps      %xmm1,%xmm1
  .byte  15,88,202                           // addps         %xmm2,%xmm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,40,21,179,66,0,0                 // movaps        0x42b3(%rip),%xmm2        # 4350 <_sk_callback_sse2+0xf2>
  .byte  15,87,219                           // xorps         %xmm3,%xmm3
  .byte  15,87,228                           // xorps         %xmm4,%xmm4
  .byte  15,87,237                           // xorps         %xmm5,%xmm5
  .byte  15,87,246                           // xorps         %xmm6,%xmm6
  .byte  15,87,255                           // xorps         %xmm7,%xmm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_constant_color_sse2
.globl _sk_constant_color_sse2
FUNCTION(_sk_constant_color_sse2)
_sk_constant_color_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,15,16,0                         // movss         (%rax),%xmm0
  .byte  243,15,16,72,4                      // movss         0x4(%rax),%xmm1
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  243,15,16,80,8                      // movss         0x8(%rax),%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  243,15,16,88,12                     // movss         0xc(%rax),%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clear_sse2
.globl _sk_clear_sse2
FUNCTION(_sk_clear_sse2)
_sk_clear_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,87,192                           // xorps         %xmm0,%xmm0
  .byte  15,87,201                           // xorps         %xmm1,%xmm1
  .byte  15,87,210                           // xorps         %xmm2,%xmm2
  .byte  15,87,219                           // xorps         %xmm3,%xmm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcatop_sse2
.globl _sk_srcatop_sse2
FUNCTION(_sk_srcatop_sse2)
_sk_srcatop_sse2:
  .byte  15,89,199                           // mulps         %xmm7,%xmm0
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,92,195                        // subps         %xmm3,%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,204                        // mulps         %xmm4,%xmm9
  .byte  65,15,88,193                        // addps         %xmm9,%xmm0
  .byte  15,89,207                           // mulps         %xmm7,%xmm1
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,205                        // mulps         %xmm5,%xmm9
  .byte  65,15,88,201                        // addps         %xmm9,%xmm1
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,206                        // mulps         %xmm6,%xmm9
  .byte  65,15,88,209                        // addps         %xmm9,%xmm2
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  68,15,89,199                        // mulps         %xmm7,%xmm8
  .byte  65,15,88,216                        // addps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstatop_sse2
.globl _sk_dstatop_sse2
FUNCTION(_sk_dstatop_sse2)
_sk_dstatop_sse2:
  .byte  68,15,40,195                        // movaps        %xmm3,%xmm8
  .byte  68,15,89,196                        // mulps         %xmm4,%xmm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,200                   // movd          %eax,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  68,15,92,207                        // subps         %xmm7,%xmm9
  .byte  65,15,89,193                        // mulps         %xmm9,%xmm0
  .byte  65,15,88,192                        // addps         %xmm8,%xmm0
  .byte  68,15,40,195                        // movaps        %xmm3,%xmm8
  .byte  68,15,89,197                        // mulps         %xmm5,%xmm8
  .byte  65,15,89,201                        // mulps         %xmm9,%xmm1
  .byte  65,15,88,200                        // addps         %xmm8,%xmm1
  .byte  68,15,40,195                        // movaps        %xmm3,%xmm8
  .byte  68,15,89,198                        // mulps         %xmm6,%xmm8
  .byte  65,15,89,209                        // mulps         %xmm9,%xmm2
  .byte  65,15,88,208                        // addps         %xmm8,%xmm2
  .byte  68,15,89,203                        // mulps         %xmm3,%xmm9
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  65,15,88,217                        // addps         %xmm9,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcin_sse2
.globl _sk_srcin_sse2
FUNCTION(_sk_srcin_sse2)
_sk_srcin_sse2:
  .byte  15,89,199                           // mulps         %xmm7,%xmm0
  .byte  15,89,207                           // mulps         %xmm7,%xmm1
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstin_sse2
.globl _sk_dstin_sse2
FUNCTION(_sk_dstin_sse2)
_sk_dstin_sse2:
  .byte  15,40,195                           // movaps        %xmm3,%xmm0
  .byte  15,89,196                           // mulps         %xmm4,%xmm0
  .byte  15,40,203                           // movaps        %xmm3,%xmm1
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  15,40,211                           // movaps        %xmm3,%xmm2
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcout_sse2
.globl _sk_srcout_sse2
FUNCTION(_sk_srcout_sse2)
_sk_srcout_sse2:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,92,199                        // subps         %xmm7,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstout_sse2
.globl _sk_dstout_sse2
FUNCTION(_sk_dstout_sse2)
_sk_dstout_sse2:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,92,195                        // subps         %xmm3,%xmm8
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  15,89,196                           // mulps         %xmm4,%xmm0
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  68,15,89,199                        // mulps         %xmm7,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,216                        // movaps        %xmm8,%xmm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_srcover_sse2
.globl _sk_srcover_sse2
FUNCTION(_sk_srcover_sse2)
_sk_srcover_sse2:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,92,195                        // subps         %xmm3,%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,204                        // mulps         %xmm4,%xmm9
  .byte  65,15,88,193                        // addps         %xmm9,%xmm0
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,205                        // mulps         %xmm5,%xmm9
  .byte  65,15,88,201                        // addps         %xmm9,%xmm1
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,206                        // mulps         %xmm6,%xmm9
  .byte  65,15,88,209                        // addps         %xmm9,%xmm2
  .byte  68,15,89,199                        // mulps         %xmm7,%xmm8
  .byte  65,15,88,216                        // addps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_dstover_sse2
.globl _sk_dstover_sse2
FUNCTION(_sk_dstover_sse2)
_sk_dstover_sse2:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,92,199                        // subps         %xmm7,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  15,88,214                           // addps         %xmm6,%xmm2
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  15,88,223                           // addps         %xmm7,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_modulate_sse2
.globl _sk_modulate_sse2
FUNCTION(_sk_modulate_sse2)
_sk_modulate_sse2:
  .byte  15,89,196                           // mulps         %xmm4,%xmm0
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_multiply_sse2
.globl _sk_multiply_sse2
FUNCTION(_sk_multiply_sse2)
_sk_multiply_sse2:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,92,207                        // subps         %xmm7,%xmm9
  .byte  69,15,40,209                        // movaps        %xmm9,%xmm10
  .byte  68,15,89,208                        // mulps         %xmm0,%xmm10
  .byte  68,15,92,195                        // subps         %xmm3,%xmm8
  .byte  69,15,40,216                        // movaps        %xmm8,%xmm11
  .byte  68,15,89,220                        // mulps         %xmm4,%xmm11
  .byte  69,15,88,218                        // addps         %xmm10,%xmm11
  .byte  15,89,196                           // mulps         %xmm4,%xmm0
  .byte  65,15,88,195                        // addps         %xmm11,%xmm0
  .byte  69,15,40,209                        // movaps        %xmm9,%xmm10
  .byte  68,15,89,209                        // mulps         %xmm1,%xmm10
  .byte  69,15,40,216                        // movaps        %xmm8,%xmm11
  .byte  68,15,89,221                        // mulps         %xmm5,%xmm11
  .byte  69,15,88,218                        // addps         %xmm10,%xmm11
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  65,15,88,203                        // addps         %xmm11,%xmm1
  .byte  69,15,40,209                        // movaps        %xmm9,%xmm10
  .byte  68,15,89,210                        // mulps         %xmm2,%xmm10
  .byte  69,15,40,216                        // movaps        %xmm8,%xmm11
  .byte  68,15,89,222                        // mulps         %xmm6,%xmm11
  .byte  69,15,88,218                        // addps         %xmm10,%xmm11
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  65,15,88,211                        // addps         %xmm11,%xmm2
  .byte  68,15,89,203                        // mulps         %xmm3,%xmm9
  .byte  68,15,89,199                        // mulps         %xmm7,%xmm8
  .byte  69,15,88,193                        // addps         %xmm9,%xmm8
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  65,15,88,216                        // addps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_plus__sse2
.globl _sk_plus__sse2
FUNCTION(_sk_plus__sse2)
_sk_plus__sse2:
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  15,88,214                           // addps         %xmm6,%xmm2
  .byte  15,88,223                           // addps         %xmm7,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_screen_sse2
.globl _sk_screen_sse2
FUNCTION(_sk_screen_sse2)
_sk_screen_sse2:
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  68,15,88,196                        // addps         %xmm4,%xmm8
  .byte  15,89,196                           // mulps         %xmm4,%xmm0
  .byte  68,15,92,192                        // subps         %xmm0,%xmm8
  .byte  68,15,40,201                        // movaps        %xmm1,%xmm9
  .byte  68,15,88,205                        // addps         %xmm5,%xmm9
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  68,15,92,201                        // subps         %xmm1,%xmm9
  .byte  68,15,40,210                        // movaps        %xmm2,%xmm10
  .byte  68,15,88,214                        // addps         %xmm6,%xmm10
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  68,15,92,210                        // subps         %xmm2,%xmm10
  .byte  68,15,40,219                        // movaps        %xmm3,%xmm11
  .byte  68,15,88,223                        // addps         %xmm7,%xmm11
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  68,15,92,219                        // subps         %xmm3,%xmm11
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  65,15,40,201                        // movaps        %xmm9,%xmm1
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  65,15,40,219                        // movaps        %xmm11,%xmm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_xor__sse2
.globl _sk_xor__sse2
FUNCTION(_sk_xor__sse2)
_sk_xor__sse2:
  .byte  68,15,40,195                        // movaps        %xmm3,%xmm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,92,207                        // subps         %xmm7,%xmm9
  .byte  65,15,89,193                        // mulps         %xmm9,%xmm0
  .byte  65,15,92,216                        // subps         %xmm8,%xmm3
  .byte  68,15,40,211                        // movaps        %xmm3,%xmm10
  .byte  68,15,89,212                        // mulps         %xmm4,%xmm10
  .byte  65,15,88,194                        // addps         %xmm10,%xmm0
  .byte  65,15,89,201                        // mulps         %xmm9,%xmm1
  .byte  68,15,40,211                        // movaps        %xmm3,%xmm10
  .byte  68,15,89,213                        // mulps         %xmm5,%xmm10
  .byte  65,15,88,202                        // addps         %xmm10,%xmm1
  .byte  65,15,89,209                        // mulps         %xmm9,%xmm2
  .byte  68,15,40,211                        // movaps        %xmm3,%xmm10
  .byte  68,15,89,214                        // mulps         %xmm6,%xmm10
  .byte  65,15,88,210                        // addps         %xmm10,%xmm2
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  15,89,223                           // mulps         %xmm7,%xmm3
  .byte  65,15,88,217                        // addps         %xmm9,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_darken_sse2
.globl _sk_darken_sse2
FUNCTION(_sk_darken_sse2)
_sk_darken_sse2:
  .byte  68,15,40,193                        // movaps        %xmm1,%xmm8
  .byte  68,15,40,200                        // movaps        %xmm0,%xmm9
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  68,15,89,207                        // mulps         %xmm7,%xmm9
  .byte  15,40,203                           // movaps        %xmm3,%xmm1
  .byte  15,89,204                           // mulps         %xmm4,%xmm1
  .byte  68,15,95,201                        // maxps         %xmm1,%xmm9
  .byte  65,15,92,193                        // subps         %xmm9,%xmm0
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  68,15,89,199                        // mulps         %xmm7,%xmm8
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,89,205                        // mulps         %xmm5,%xmm9
  .byte  69,15,95,193                        // maxps         %xmm9,%xmm8
  .byte  65,15,92,200                        // subps         %xmm8,%xmm1
  .byte  68,15,40,194                        // movaps        %xmm2,%xmm8
  .byte  68,15,88,198                        // addps         %xmm6,%xmm8
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,89,206                        // mulps         %xmm6,%xmm9
  .byte  65,15,95,209                        // maxps         %xmm9,%xmm2
  .byte  68,15,92,194                        // subps         %xmm2,%xmm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  15,92,211                           // subps         %xmm3,%xmm2
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  15,88,218                           // addps         %xmm2,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_lighten_sse2
.globl _sk_lighten_sse2
FUNCTION(_sk_lighten_sse2)
_sk_lighten_sse2:
  .byte  68,15,40,193                        // movaps        %xmm1,%xmm8
  .byte  68,15,40,200                        // movaps        %xmm0,%xmm9
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  68,15,89,207                        // mulps         %xmm7,%xmm9
  .byte  15,40,203                           // movaps        %xmm3,%xmm1
  .byte  15,89,204                           // mulps         %xmm4,%xmm1
  .byte  68,15,93,201                        // minps         %xmm1,%xmm9
  .byte  65,15,92,193                        // subps         %xmm9,%xmm0
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  68,15,89,199                        // mulps         %xmm7,%xmm8
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,89,205                        // mulps         %xmm5,%xmm9
  .byte  69,15,93,193                        // minps         %xmm9,%xmm8
  .byte  65,15,92,200                        // subps         %xmm8,%xmm1
  .byte  68,15,40,194                        // movaps        %xmm2,%xmm8
  .byte  68,15,88,198                        // addps         %xmm6,%xmm8
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,89,206                        // mulps         %xmm6,%xmm9
  .byte  65,15,93,209                        // minps         %xmm9,%xmm2
  .byte  68,15,92,194                        // subps         %xmm2,%xmm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  15,92,211                           // subps         %xmm3,%xmm2
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  15,88,218                           // addps         %xmm2,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_difference_sse2
.globl _sk_difference_sse2
FUNCTION(_sk_difference_sse2)
_sk_difference_sse2:
  .byte  68,15,40,193                        // movaps        %xmm1,%xmm8
  .byte  68,15,40,200                        // movaps        %xmm0,%xmm9
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  68,15,89,207                        // mulps         %xmm7,%xmm9
  .byte  15,40,203                           // movaps        %xmm3,%xmm1
  .byte  15,89,204                           // mulps         %xmm4,%xmm1
  .byte  68,15,93,201                        // minps         %xmm1,%xmm9
  .byte  69,15,88,201                        // addps         %xmm9,%xmm9
  .byte  65,15,92,193                        // subps         %xmm9,%xmm0
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  68,15,89,199                        // mulps         %xmm7,%xmm8
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,89,205                        // mulps         %xmm5,%xmm9
  .byte  69,15,93,193                        // minps         %xmm9,%xmm8
  .byte  69,15,88,192                        // addps         %xmm8,%xmm8
  .byte  65,15,92,200                        // subps         %xmm8,%xmm1
  .byte  68,15,40,194                        // movaps        %xmm2,%xmm8
  .byte  68,15,88,198                        // addps         %xmm6,%xmm8
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,89,206                        // mulps         %xmm6,%xmm9
  .byte  65,15,93,209                        // minps         %xmm9,%xmm2
  .byte  15,88,210                           // addps         %xmm2,%xmm2
  .byte  68,15,92,194                        // subps         %xmm2,%xmm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  15,92,211                           // subps         %xmm3,%xmm2
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  15,88,218                           // addps         %xmm2,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_exclusion_sse2
.globl _sk_exclusion_sse2
FUNCTION(_sk_exclusion_sse2)
_sk_exclusion_sse2:
  .byte  68,15,40,193                        // movaps        %xmm1,%xmm8
  .byte  15,40,200                           // movaps        %xmm0,%xmm1
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  15,89,204                           // mulps         %xmm4,%xmm1
  .byte  15,88,201                           // addps         %xmm1,%xmm1
  .byte  15,92,193                           // subps         %xmm1,%xmm0
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  68,15,89,197                        // mulps         %xmm5,%xmm8
  .byte  69,15,88,192                        // addps         %xmm8,%xmm8
  .byte  65,15,92,200                        // subps         %xmm8,%xmm1
  .byte  68,15,40,194                        // movaps        %xmm2,%xmm8
  .byte  68,15,88,198                        // addps         %xmm6,%xmm8
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  15,88,210                           // addps         %xmm2,%xmm2
  .byte  68,15,92,194                        // subps         %xmm2,%xmm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  15,92,211                           // subps         %xmm3,%xmm2
  .byte  15,89,215                           // mulps         %xmm7,%xmm2
  .byte  15,88,218                           // addps         %xmm2,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_colorburn_sse2
.globl _sk_colorburn_sse2
FUNCTION(_sk_colorburn_sse2)
_sk_colorburn_sse2:
  .byte  68,15,40,193                        // movaps        %xmm1,%xmm8
  .byte  68,15,40,224                        // movaps        %xmm0,%xmm12
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,200                   // movd          %eax,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  69,15,40,217                        // movaps        %xmm9,%xmm11
  .byte  68,15,92,223                        // subps         %xmm7,%xmm11
  .byte  65,15,40,195                        // movaps        %xmm11,%xmm0
  .byte  65,15,89,196                        // mulps         %xmm12,%xmm0
  .byte  69,15,87,210                        // xorps         %xmm10,%xmm10
  .byte  15,40,207                           // movaps        %xmm7,%xmm1
  .byte  15,92,204                           // subps         %xmm4,%xmm1
  .byte  15,89,203                           // mulps         %xmm3,%xmm1
  .byte  65,15,94,204                        // divps         %xmm12,%xmm1
  .byte  68,15,40,239                        // movaps        %xmm7,%xmm13
  .byte  68,15,93,233                        // minps         %xmm1,%xmm13
  .byte  68,15,40,247                        // movaps        %xmm7,%xmm14
  .byte  69,15,92,245                        // subps         %xmm13,%xmm14
  .byte  65,15,40,204                        // movaps        %xmm12,%xmm1
  .byte  65,15,194,202,0                     // cmpeqps       %xmm10,%xmm1
  .byte  68,15,92,203                        // subps         %xmm3,%xmm9
  .byte  68,15,89,243                        // mulps         %xmm3,%xmm14
  .byte  68,15,88,240                        // addps         %xmm0,%xmm14
  .byte  68,15,84,225                        // andps         %xmm1,%xmm12
  .byte  65,15,85,206                        // andnps        %xmm14,%xmm1
  .byte  69,15,40,233                        // movaps        %xmm9,%xmm13
  .byte  68,15,89,236                        // mulps         %xmm4,%xmm13
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  65,15,86,204                        // orps          %xmm12,%xmm1
  .byte  68,15,40,228                        // movaps        %xmm4,%xmm12
  .byte  68,15,194,231,0                     // cmpeqps       %xmm7,%xmm12
  .byte  65,15,88,205                        // addps         %xmm13,%xmm1
  .byte  65,15,84,196                        // andps         %xmm12,%xmm0
  .byte  68,15,85,225                        // andnps        %xmm1,%xmm12
  .byte  65,15,86,196                        // orps          %xmm12,%xmm0
  .byte  65,15,40,203                        // movaps        %xmm11,%xmm1
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  68,15,40,231                        // movaps        %xmm7,%xmm12
  .byte  68,15,92,229                        // subps         %xmm5,%xmm12
  .byte  68,15,89,227                        // mulps         %xmm3,%xmm12
  .byte  69,15,94,224                        // divps         %xmm8,%xmm12
  .byte  68,15,40,239                        // movaps        %xmm7,%xmm13
  .byte  69,15,93,236                        // minps         %xmm12,%xmm13
  .byte  68,15,40,231                        // movaps        %xmm7,%xmm12
  .byte  69,15,92,229                        // subps         %xmm13,%xmm12
  .byte  69,15,40,232                        // movaps        %xmm8,%xmm13
  .byte  69,15,194,234,0                     // cmpeqps       %xmm10,%xmm13
  .byte  68,15,89,227                        // mulps         %xmm3,%xmm12
  .byte  68,15,88,225                        // addps         %xmm1,%xmm12
  .byte  69,15,84,197                        // andps         %xmm13,%xmm8
  .byte  69,15,85,236                        // andnps        %xmm12,%xmm13
  .byte  69,15,86,232                        // orps          %xmm8,%xmm13
  .byte  69,15,40,193                        // movaps        %xmm9,%xmm8
  .byte  68,15,89,197                        // mulps         %xmm5,%xmm8
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  69,15,88,232                        // addps         %xmm8,%xmm13
  .byte  68,15,40,197                        // movaps        %xmm5,%xmm8
  .byte  68,15,194,199,0                     // cmpeqps       %xmm7,%xmm8
  .byte  65,15,84,200                        // andps         %xmm8,%xmm1
  .byte  69,15,85,197                        // andnps        %xmm13,%xmm8
  .byte  65,15,86,200                        // orps          %xmm8,%xmm1
  .byte  68,15,40,199                        // movaps        %xmm7,%xmm8
  .byte  68,15,92,198                        // subps         %xmm6,%xmm8
  .byte  68,15,89,195                        // mulps         %xmm3,%xmm8
  .byte  68,15,94,194                        // divps         %xmm2,%xmm8
  .byte  68,15,40,231                        // movaps        %xmm7,%xmm12
  .byte  69,15,93,224                        // minps         %xmm8,%xmm12
  .byte  68,15,40,199                        // movaps        %xmm7,%xmm8
  .byte  69,15,92,196                        // subps         %xmm12,%xmm8
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  68,15,194,210,0                     // cmpeqps       %xmm2,%xmm10
  .byte  68,15,89,195                        // mulps         %xmm3,%xmm8
  .byte  69,15,88,195                        // addps         %xmm11,%xmm8
  .byte  65,15,84,210                        // andps         %xmm10,%xmm2
  .byte  69,15,85,208                        // andnps        %xmm8,%xmm10
  .byte  69,15,40,195                        // movaps        %xmm11,%xmm8
  .byte  68,15,88,198                        // addps         %xmm6,%xmm8
  .byte  68,15,86,210                        // orps          %xmm2,%xmm10
  .byte  65,15,40,209                        // movaps        %xmm9,%xmm2
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  68,15,88,210                        // addps         %xmm2,%xmm10
  .byte  15,40,214                           // movaps        %xmm6,%xmm2
  .byte  15,194,215,0                        // cmpeqps       %xmm7,%xmm2
  .byte  68,15,84,194                        // andps         %xmm2,%xmm8
  .byte  65,15,85,210                        // andnps        %xmm10,%xmm2
  .byte  68,15,86,194                        // orps          %xmm2,%xmm8
  .byte  68,15,89,207                        // mulps         %xmm7,%xmm9
  .byte  65,15,88,217                        // addps         %xmm9,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_colordodge_sse2
.globl _sk_colordodge_sse2
FUNCTION(_sk_colordodge_sse2)
_sk_colordodge_sse2:
  .byte  68,15,40,200                        // movaps        %xmm0,%xmm9
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,208                   // movd          %eax,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,40,218                        // movaps        %xmm10,%xmm11
  .byte  68,15,92,223                        // subps         %xmm7,%xmm11
  .byte  65,15,40,195                        // movaps        %xmm11,%xmm0
  .byte  65,15,89,193                        // mulps         %xmm9,%xmm0
  .byte  68,15,40,195                        // movaps        %xmm3,%xmm8
  .byte  68,15,89,196                        // mulps         %xmm4,%xmm8
  .byte  68,15,40,227                        // movaps        %xmm3,%xmm12
  .byte  69,15,92,225                        // subps         %xmm9,%xmm12
  .byte  69,15,94,196                        // divps         %xmm12,%xmm8
  .byte  68,15,40,231                        // movaps        %xmm7,%xmm12
  .byte  68,15,40,239                        // movaps        %xmm7,%xmm13
  .byte  69,15,93,232                        // minps         %xmm8,%xmm13
  .byte  69,15,40,241                        // movaps        %xmm9,%xmm14
  .byte  68,15,194,243,0                     // cmpeqps       %xmm3,%xmm14
  .byte  68,15,89,235                        // mulps         %xmm3,%xmm13
  .byte  68,15,88,232                        // addps         %xmm0,%xmm13
  .byte  69,15,84,206                        // andps         %xmm14,%xmm9
  .byte  69,15,85,245                        // andnps        %xmm13,%xmm14
  .byte  69,15,87,192                        // xorps         %xmm8,%xmm8
  .byte  68,15,92,211                        // subps         %xmm3,%xmm10
  .byte  69,15,86,241                        // orps          %xmm9,%xmm14
  .byte  69,15,40,202                        // movaps        %xmm10,%xmm9
  .byte  68,15,89,204                        // mulps         %xmm4,%xmm9
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  69,15,88,241                        // addps         %xmm9,%xmm14
  .byte  68,15,40,204                        // movaps        %xmm4,%xmm9
  .byte  69,15,194,200,0                     // cmpeqps       %xmm8,%xmm9
  .byte  65,15,84,193                        // andps         %xmm9,%xmm0
  .byte  69,15,85,206                        // andnps        %xmm14,%xmm9
  .byte  65,15,86,193                        // orps          %xmm9,%xmm0
  .byte  68,15,40,235                        // movaps        %xmm3,%xmm13
  .byte  68,15,89,237                        // mulps         %xmm5,%xmm13
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,92,201                        // subps         %xmm1,%xmm9
  .byte  69,15,94,233                        // divps         %xmm9,%xmm13
  .byte  69,15,40,203                        // movaps        %xmm11,%xmm9
  .byte  68,15,89,201                        // mulps         %xmm1,%xmm9
  .byte  69,15,93,229                        // minps         %xmm13,%xmm12
  .byte  68,15,40,233                        // movaps        %xmm1,%xmm13
  .byte  68,15,194,235,0                     // cmpeqps       %xmm3,%xmm13
  .byte  68,15,89,227                        // mulps         %xmm3,%xmm12
  .byte  69,15,88,225                        // addps         %xmm9,%xmm12
  .byte  65,15,84,205                        // andps         %xmm13,%xmm1
  .byte  69,15,85,236                        // andnps        %xmm12,%xmm13
  .byte  68,15,86,233                        // orps          %xmm1,%xmm13
  .byte  65,15,40,202                        // movaps        %xmm10,%xmm1
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  68,15,88,205                        // addps         %xmm5,%xmm9
  .byte  68,15,88,233                        // addps         %xmm1,%xmm13
  .byte  15,40,205                           // movaps        %xmm5,%xmm1
  .byte  65,15,194,200,0                     // cmpeqps       %xmm8,%xmm1
  .byte  68,15,84,201                        // andps         %xmm1,%xmm9
  .byte  65,15,85,205                        // andnps        %xmm13,%xmm1
  .byte  68,15,86,201                        // orps          %xmm1,%xmm9
  .byte  68,15,40,227                        // movaps        %xmm3,%xmm12
  .byte  68,15,89,230                        // mulps         %xmm6,%xmm12
  .byte  15,40,203                           // movaps        %xmm3,%xmm1
  .byte  15,92,202                           // subps         %xmm2,%xmm1
  .byte  68,15,94,225                        // divps         %xmm1,%xmm12
  .byte  68,15,40,239                        // movaps        %xmm7,%xmm13
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  69,15,93,236                        // minps         %xmm12,%xmm13
  .byte  15,40,202                           // movaps        %xmm2,%xmm1
  .byte  15,194,203,0                        // cmpeqps       %xmm3,%xmm1
  .byte  68,15,89,235                        // mulps         %xmm3,%xmm13
  .byte  69,15,88,235                        // addps         %xmm11,%xmm13
  .byte  15,84,209                           // andps         %xmm1,%xmm2
  .byte  65,15,85,205                        // andnps        %xmm13,%xmm1
  .byte  15,86,202                           // orps          %xmm2,%xmm1
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  15,88,202                           // addps         %xmm2,%xmm1
  .byte  68,15,194,198,0                     // cmpeqps       %xmm6,%xmm8
  .byte  68,15,88,222                        // addps         %xmm6,%xmm11
  .byte  69,15,84,216                        // andps         %xmm8,%xmm11
  .byte  68,15,85,193                        // andnps        %xmm1,%xmm8
  .byte  69,15,86,195                        // orps          %xmm11,%xmm8
  .byte  68,15,89,215                        // mulps         %xmm7,%xmm10
  .byte  65,15,88,218                        // addps         %xmm10,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,201                        // movaps        %xmm9,%xmm1
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_hardlight_sse2
.globl _sk_hardlight_sse2
FUNCTION(_sk_hardlight_sse2)
_sk_hardlight_sse2:
  .byte  15,41,116,36,232                    // movaps        %xmm6,-0x18(%rsp)
  .byte  15,40,245                           // movaps        %xmm5,%xmm6
  .byte  15,40,236                           // movaps        %xmm4,%xmm5
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,216                   // movd          %eax,%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,40,211                        // movaps        %xmm11,%xmm10
  .byte  68,15,92,215                        // subps         %xmm7,%xmm10
  .byte  69,15,40,194                        // movaps        %xmm10,%xmm8
  .byte  68,15,89,192                        // mulps         %xmm0,%xmm8
  .byte  68,15,92,219                        // subps         %xmm3,%xmm11
  .byte  69,15,40,203                        // movaps        %xmm11,%xmm9
  .byte  68,15,89,205                        // mulps         %xmm5,%xmm9
  .byte  69,15,88,200                        // addps         %xmm8,%xmm9
  .byte  68,15,40,195                        // movaps        %xmm3,%xmm8
  .byte  68,15,92,192                        // subps         %xmm0,%xmm8
  .byte  15,40,227                           // movaps        %xmm3,%xmm4
  .byte  15,89,231                           // mulps         %xmm7,%xmm4
  .byte  68,15,40,239                        // movaps        %xmm7,%xmm13
  .byte  68,15,40,247                        // movaps        %xmm7,%xmm14
  .byte  68,15,40,255                        // movaps        %xmm7,%xmm15
  .byte  68,15,92,253                        // subps         %xmm5,%xmm15
  .byte  69,15,89,248                        // mulps         %xmm8,%xmm15
  .byte  69,15,88,255                        // addps         %xmm15,%xmm15
  .byte  68,15,40,228                        // movaps        %xmm4,%xmm12
  .byte  69,15,92,231                        // subps         %xmm15,%xmm12
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  69,15,88,192                        // addps         %xmm8,%xmm8
  .byte  68,15,194,195,2                     // cmpleps       %xmm3,%xmm8
  .byte  15,89,197                           // mulps         %xmm5,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  65,15,84,192                        // andps         %xmm8,%xmm0
  .byte  69,15,85,196                        // andnps        %xmm12,%xmm8
  .byte  68,15,86,192                        // orps          %xmm0,%xmm8
  .byte  69,15,40,251                        // movaps        %xmm11,%xmm15
  .byte  69,15,40,227                        // movaps        %xmm11,%xmm12
  .byte  68,15,89,223                        // mulps         %xmm7,%xmm11
  .byte  69,15,88,193                        // addps         %xmm9,%xmm8
  .byte  65,15,40,194                        // movaps        %xmm10,%xmm0
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  68,15,89,254                        // mulps         %xmm6,%xmm15
  .byte  68,15,88,248                        // addps         %xmm0,%xmm15
  .byte  15,40,195                           // movaps        %xmm3,%xmm0
  .byte  15,92,193                           // subps         %xmm1,%xmm0
  .byte  68,15,92,238                        // subps         %xmm6,%xmm13
  .byte  68,15,89,232                        // mulps         %xmm0,%xmm13
  .byte  69,15,88,237                        // addps         %xmm13,%xmm13
  .byte  15,40,196                           // movaps        %xmm4,%xmm0
  .byte  65,15,92,197                        // subps         %xmm13,%xmm0
  .byte  68,15,40,201                        // movaps        %xmm1,%xmm9
  .byte  69,15,88,201                        // addps         %xmm9,%xmm9
  .byte  68,15,194,203,2                     // cmpleps       %xmm3,%xmm9
  .byte  15,89,206                           // mulps         %xmm6,%xmm1
  .byte  15,88,201                           // addps         %xmm1,%xmm1
  .byte  65,15,84,201                        // andps         %xmm9,%xmm1
  .byte  68,15,85,200                        // andnps        %xmm0,%xmm9
  .byte  68,15,86,201                        // orps          %xmm1,%xmm9
  .byte  69,15,88,207                        // addps         %xmm15,%xmm9
  .byte  68,15,89,210                        // mulps         %xmm2,%xmm10
  .byte  68,15,40,108,36,232                 // movaps        -0x18(%rsp),%xmm13
  .byte  69,15,89,229                        // mulps         %xmm13,%xmm12
  .byte  69,15,88,226                        // addps         %xmm10,%xmm12
  .byte  68,15,40,210                        // movaps        %xmm2,%xmm10
  .byte  69,15,88,210                        // addps         %xmm10,%xmm10
  .byte  68,15,194,211,2                     // cmpleps       %xmm3,%xmm10
  .byte  15,40,195                           // movaps        %xmm3,%xmm0
  .byte  15,92,194                           // subps         %xmm2,%xmm0
  .byte  65,15,89,213                        // mulps         %xmm13,%xmm2
  .byte  15,88,210                           // addps         %xmm2,%xmm2
  .byte  69,15,92,245                        // subps         %xmm13,%xmm14
  .byte  68,15,89,240                        // mulps         %xmm0,%xmm14
  .byte  69,15,88,246                        // addps         %xmm14,%xmm14
  .byte  65,15,92,230                        // subps         %xmm14,%xmm4
  .byte  65,15,84,210                        // andps         %xmm10,%xmm2
  .byte  68,15,85,212                        // andnps        %xmm4,%xmm10
  .byte  68,15,86,210                        // orps          %xmm2,%xmm10
  .byte  69,15,88,212                        // addps         %xmm12,%xmm10
  .byte  65,15,88,219                        // addps         %xmm11,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  65,15,40,201                        // movaps        %xmm9,%xmm1
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  15,40,229                           // movaps        %xmm5,%xmm4
  .byte  15,40,238                           // movaps        %xmm6,%xmm5
  .byte  65,15,40,245                        // movaps        %xmm13,%xmm6
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_overlay_sse2
.globl _sk_overlay_sse2
FUNCTION(_sk_overlay_sse2)
_sk_overlay_sse2:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,92,207                        // subps         %xmm7,%xmm9
  .byte  69,15,40,209                        // movaps        %xmm9,%xmm10
  .byte  68,15,89,208                        // mulps         %xmm0,%xmm10
  .byte  68,15,92,195                        // subps         %xmm3,%xmm8
  .byte  69,15,40,216                        // movaps        %xmm8,%xmm11
  .byte  68,15,89,220                        // mulps         %xmm4,%xmm11
  .byte  69,15,88,218                        // addps         %xmm10,%xmm11
  .byte  68,15,40,227                        // movaps        %xmm3,%xmm12
  .byte  68,15,92,224                        // subps         %xmm0,%xmm12
  .byte  15,89,196                           // mulps         %xmm4,%xmm0
  .byte  68,15,40,239                        // movaps        %xmm7,%xmm13
  .byte  68,15,92,236                        // subps         %xmm4,%xmm13
  .byte  68,15,40,244                        // movaps        %xmm4,%xmm14
  .byte  69,15,88,246                        // addps         %xmm14,%xmm14
  .byte  68,15,194,247,2                     // cmpleps       %xmm7,%xmm14
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  68,15,40,211                        // movaps        %xmm3,%xmm10
  .byte  68,15,89,215                        // mulps         %xmm7,%xmm10
  .byte  69,15,89,236                        // mulps         %xmm12,%xmm13
  .byte  69,15,88,237                        // addps         %xmm13,%xmm13
  .byte  69,15,40,226                        // movaps        %xmm10,%xmm12
  .byte  69,15,92,229                        // subps         %xmm13,%xmm12
  .byte  65,15,84,198                        // andps         %xmm14,%xmm0
  .byte  69,15,85,244                        // andnps        %xmm12,%xmm14
  .byte  65,15,86,198                        // orps          %xmm14,%xmm0
  .byte  65,15,88,195                        // addps         %xmm11,%xmm0
  .byte  69,15,40,217                        // movaps        %xmm9,%xmm11
  .byte  68,15,89,217                        // mulps         %xmm1,%xmm11
  .byte  69,15,40,224                        // movaps        %xmm8,%xmm12
  .byte  68,15,89,229                        // mulps         %xmm5,%xmm12
  .byte  69,15,88,227                        // addps         %xmm11,%xmm12
  .byte  68,15,40,219                        // movaps        %xmm3,%xmm11
  .byte  68,15,92,217                        // subps         %xmm1,%xmm11
  .byte  15,89,205                           // mulps         %xmm5,%xmm1
  .byte  68,15,40,239                        // movaps        %xmm7,%xmm13
  .byte  68,15,92,237                        // subps         %xmm5,%xmm13
  .byte  68,15,40,245                        // movaps        %xmm5,%xmm14
  .byte  69,15,88,246                        // addps         %xmm14,%xmm14
  .byte  68,15,194,247,2                     // cmpleps       %xmm7,%xmm14
  .byte  15,88,201                           // addps         %xmm1,%xmm1
  .byte  69,15,89,235                        // mulps         %xmm11,%xmm13
  .byte  69,15,88,237                        // addps         %xmm13,%xmm13
  .byte  69,15,40,218                        // movaps        %xmm10,%xmm11
  .byte  69,15,92,221                        // subps         %xmm13,%xmm11
  .byte  65,15,84,206                        // andps         %xmm14,%xmm1
  .byte  69,15,85,243                        // andnps        %xmm11,%xmm14
  .byte  65,15,86,206                        // orps          %xmm14,%xmm1
  .byte  65,15,88,204                        // addps         %xmm12,%xmm1
  .byte  68,15,89,202                        // mulps         %xmm2,%xmm9
  .byte  69,15,40,216                        // movaps        %xmm8,%xmm11
  .byte  68,15,89,222                        // mulps         %xmm6,%xmm11
  .byte  69,15,88,217                        // addps         %xmm9,%xmm11
  .byte  68,15,40,203                        // movaps        %xmm3,%xmm9
  .byte  68,15,92,202                        // subps         %xmm2,%xmm9
  .byte  15,89,214                           // mulps         %xmm6,%xmm2
  .byte  68,15,40,231                        // movaps        %xmm7,%xmm12
  .byte  68,15,92,230                        // subps         %xmm6,%xmm12
  .byte  68,15,40,238                        // movaps        %xmm6,%xmm13
  .byte  69,15,88,237                        // addps         %xmm13,%xmm13
  .byte  68,15,194,239,2                     // cmpleps       %xmm7,%xmm13
  .byte  15,88,210                           // addps         %xmm2,%xmm2
  .byte  69,15,89,225                        // mulps         %xmm9,%xmm12
  .byte  69,15,88,228                        // addps         %xmm12,%xmm12
  .byte  69,15,92,212                        // subps         %xmm12,%xmm10
  .byte  65,15,84,213                        // andps         %xmm13,%xmm2
  .byte  69,15,85,234                        // andnps        %xmm10,%xmm13
  .byte  65,15,86,213                        // orps          %xmm13,%xmm2
  .byte  65,15,88,211                        // addps         %xmm11,%xmm2
  .byte  68,15,89,199                        // mulps         %xmm7,%xmm8
  .byte  65,15,88,216                        // addps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_softlight_sse2
.globl _sk_softlight_sse2
FUNCTION(_sk_softlight_sse2)
_sk_softlight_sse2:
  .byte  15,41,84,36,232                     // movaps        %xmm2,-0x18(%rsp)
  .byte  15,40,209                           // movaps        %xmm1,%xmm2
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  69,15,87,228                        // xorps         %xmm12,%xmm12
  .byte  68,15,194,231,1                     // cmpltps       %xmm7,%xmm12
  .byte  68,15,40,212                        // movaps        %xmm4,%xmm10
  .byte  68,15,94,215                        // divps         %xmm7,%xmm10
  .byte  69,15,84,212                        // andps         %xmm12,%xmm10
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,200                   // movd          %eax,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  69,15,40,241                        // movaps        %xmm9,%xmm14
  .byte  69,15,92,242                        // subps         %xmm10,%xmm14
  .byte  69,15,40,218                        // movaps        %xmm10,%xmm11
  .byte  69,15,40,234                        // movaps        %xmm10,%xmm13
  .byte  65,15,82,194                        // rsqrtps       %xmm10,%xmm0
  .byte  68,15,83,248                        // rcpps         %xmm0,%xmm15
  .byte  69,15,92,250                        // subps         %xmm10,%xmm15
  .byte  69,15,88,210                        // addps         %xmm10,%xmm10
  .byte  69,15,88,210                        // addps         %xmm10,%xmm10
  .byte  65,15,40,194                        // movaps        %xmm10,%xmm0
  .byte  15,89,192                           // mulps         %xmm0,%xmm0
  .byte  65,15,88,194                        // addps         %xmm10,%xmm0
  .byte  69,15,92,217                        // subps         %xmm9,%xmm11
  .byte  68,15,89,216                        // mulps         %xmm0,%xmm11
  .byte  184,0,0,224,64                      // mov           $0x40e00000,%eax
  .byte  102,68,15,110,208                   // movd          %eax,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,234                        // mulps         %xmm10,%xmm13
  .byte  69,15,88,235                        // addps         %xmm11,%xmm13
  .byte  68,15,40,219                        // movaps        %xmm3,%xmm11
  .byte  15,40,204                           // movaps        %xmm4,%xmm1
  .byte  68,15,89,217                        // mulps         %xmm1,%xmm11
  .byte  15,88,228                           // addps         %xmm4,%xmm4
  .byte  15,88,228                           // addps         %xmm4,%xmm4
  .byte  15,194,231,2                        // cmpleps       %xmm7,%xmm4
  .byte  68,15,84,236                        // andps         %xmm4,%xmm13
  .byte  65,15,85,231                        // andnps        %xmm15,%xmm4
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  15,88,192                           // addps         %xmm0,%xmm0
  .byte  65,15,86,229                        // orps          %xmm13,%xmm4
  .byte  68,15,40,232                        // movaps        %xmm0,%xmm13
  .byte  68,15,92,235                        // subps         %xmm3,%xmm13
  .byte  69,15,89,245                        // mulps         %xmm13,%xmm14
  .byte  68,15,89,239                        // mulps         %xmm7,%xmm13
  .byte  65,15,89,229                        // mulps         %xmm13,%xmm4
  .byte  65,15,88,227                        // addps         %xmm11,%xmm4
  .byte  69,15,40,217                        // movaps        %xmm9,%xmm11
  .byte  68,15,92,219                        // subps         %xmm3,%xmm11
  .byte  69,15,40,251                        // movaps        %xmm11,%xmm15
  .byte  15,41,76,36,216                     // movaps        %xmm1,-0x28(%rsp)
  .byte  68,15,89,249                        // mulps         %xmm1,%xmm15
  .byte  69,15,40,233                        // movaps        %xmm9,%xmm13
  .byte  68,15,92,239                        // subps         %xmm7,%xmm13
  .byte  69,15,89,197                        // mulps         %xmm13,%xmm8
  .byte  69,15,88,199                        // addps         %xmm15,%xmm8
  .byte  68,15,88,243                        // addps         %xmm3,%xmm14
  .byte  68,15,89,241                        // mulps         %xmm1,%xmm14
  .byte  15,194,195,2                        // cmpleps       %xmm3,%xmm0
  .byte  68,15,84,240                        // andps         %xmm0,%xmm14
  .byte  15,85,196                           // andnps        %xmm4,%xmm0
  .byte  65,15,86,198                        // orps          %xmm14,%xmm0
  .byte  65,15,88,192                        // addps         %xmm8,%xmm0
  .byte  15,41,108,36,200                    // movaps        %xmm5,-0x38(%rsp)
  .byte  68,15,40,197                        // movaps        %xmm5,%xmm8
  .byte  68,15,94,199                        // divps         %xmm7,%xmm8
  .byte  69,15,84,196                        // andps         %xmm12,%xmm8
  .byte  69,15,40,240                        // movaps        %xmm8,%xmm14
  .byte  69,15,88,246                        // addps         %xmm14,%xmm14
  .byte  69,15,88,246                        // addps         %xmm14,%xmm14
  .byte  65,15,40,230                        // movaps        %xmm14,%xmm4
  .byte  15,89,228                           // mulps         %xmm4,%xmm4
  .byte  65,15,88,230                        // addps         %xmm14,%xmm4
  .byte  69,15,40,248                        // movaps        %xmm8,%xmm15
  .byte  69,15,92,249                        // subps         %xmm9,%xmm15
  .byte  68,15,89,252                        // mulps         %xmm4,%xmm15
  .byte  69,15,40,241                        // movaps        %xmm9,%xmm14
  .byte  69,15,92,240                        // subps         %xmm8,%xmm14
  .byte  65,15,82,224                        // rsqrtps       %xmm8,%xmm4
  .byte  15,83,228                           // rcpps         %xmm4,%xmm4
  .byte  65,15,92,224                        // subps         %xmm8,%xmm4
  .byte  69,15,89,194                        // mulps         %xmm10,%xmm8
  .byte  69,15,88,199                        // addps         %xmm15,%xmm8
  .byte  68,15,40,253                        // movaps        %xmm5,%xmm15
  .byte  69,15,88,255                        // addps         %xmm15,%xmm15
  .byte  69,15,88,255                        // addps         %xmm15,%xmm15
  .byte  68,15,194,255,2                     // cmpleps       %xmm7,%xmm15
  .byte  69,15,84,199                        // andps         %xmm15,%xmm8
  .byte  68,15,85,252                        // andnps        %xmm4,%xmm15
  .byte  69,15,86,248                        // orps          %xmm8,%xmm15
  .byte  68,15,40,194                        // movaps        %xmm2,%xmm8
  .byte  69,15,88,192                        // addps         %xmm8,%xmm8
  .byte  65,15,40,224                        // movaps        %xmm8,%xmm4
  .byte  15,92,227                           // subps         %xmm3,%xmm4
  .byte  68,15,89,244                        // mulps         %xmm4,%xmm14
  .byte  15,89,231                           // mulps         %xmm7,%xmm4
  .byte  68,15,89,252                        // mulps         %xmm4,%xmm15
  .byte  15,40,227                           // movaps        %xmm3,%xmm4
  .byte  15,89,229                           // mulps         %xmm5,%xmm4
  .byte  68,15,88,252                        // addps         %xmm4,%xmm15
  .byte  65,15,40,227                        // movaps        %xmm11,%xmm4
  .byte  15,89,229                           // mulps         %xmm5,%xmm4
  .byte  65,15,89,213                        // mulps         %xmm13,%xmm2
  .byte  15,88,212                           // addps         %xmm4,%xmm2
  .byte  68,15,88,243                        // addps         %xmm3,%xmm14
  .byte  68,15,89,245                        // mulps         %xmm5,%xmm14
  .byte  68,15,194,195,2                     // cmpleps       %xmm3,%xmm8
  .byte  69,15,84,240                        // andps         %xmm8,%xmm14
  .byte  69,15,85,199                        // andnps        %xmm15,%xmm8
  .byte  69,15,86,198                        // orps          %xmm14,%xmm8
  .byte  68,15,88,194                        // addps         %xmm2,%xmm8
  .byte  68,15,40,246                        // movaps        %xmm6,%xmm14
  .byte  65,15,40,206                        // movaps        %xmm14,%xmm1
  .byte  15,94,207                           // divps         %xmm7,%xmm1
  .byte  65,15,84,204                        // andps         %xmm12,%xmm1
  .byte  15,40,225                           // movaps        %xmm1,%xmm4
  .byte  65,15,92,225                        // subps         %xmm9,%xmm4
  .byte  68,15,92,201                        // subps         %xmm1,%xmm9
  .byte  68,15,89,209                        // mulps         %xmm1,%xmm10
  .byte  15,82,241                           // rsqrtps       %xmm1,%xmm6
  .byte  15,83,246                           // rcpps         %xmm6,%xmm6
  .byte  15,92,241                           // subps         %xmm1,%xmm6
  .byte  15,88,201                           // addps         %xmm1,%xmm1
  .byte  15,88,201                           // addps         %xmm1,%xmm1
  .byte  15,40,233                           // movaps        %xmm1,%xmm5
  .byte  15,89,237                           // mulps         %xmm5,%xmm5
  .byte  15,88,233                           // addps         %xmm1,%xmm5
  .byte  15,89,236                           // mulps         %xmm4,%xmm5
  .byte  68,15,88,213                        // addps         %xmm5,%xmm10
  .byte  65,15,40,238                        // movaps        %xmm14,%xmm5
  .byte  15,40,205                           // movaps        %xmm5,%xmm1
  .byte  15,88,201                           // addps         %xmm1,%xmm1
  .byte  15,88,201                           // addps         %xmm1,%xmm1
  .byte  15,194,207,2                        // cmpleps       %xmm7,%xmm1
  .byte  68,15,84,209                        // andps         %xmm1,%xmm10
  .byte  15,85,206                           // andnps        %xmm6,%xmm1
  .byte  15,40,84,36,232                     // movaps        -0x18(%rsp),%xmm2
  .byte  68,15,89,234                        // mulps         %xmm2,%xmm13
  .byte  15,88,210                           // addps         %xmm2,%xmm2
  .byte  65,15,86,202                        // orps          %xmm10,%xmm1
  .byte  15,40,226                           // movaps        %xmm2,%xmm4
  .byte  15,92,227                           // subps         %xmm3,%xmm4
  .byte  68,15,89,204                        // mulps         %xmm4,%xmm9
  .byte  15,89,231                           // mulps         %xmm7,%xmm4
  .byte  15,89,204                           // mulps         %xmm4,%xmm1
  .byte  15,40,227                           // movaps        %xmm3,%xmm4
  .byte  15,89,229                           // mulps         %xmm5,%xmm4
  .byte  15,88,204                           // addps         %xmm4,%xmm1
  .byte  65,15,40,227                        // movaps        %xmm11,%xmm4
  .byte  15,89,229                           // mulps         %xmm5,%xmm4
  .byte  65,15,88,229                        // addps         %xmm13,%xmm4
  .byte  68,15,88,203                        // addps         %xmm3,%xmm9
  .byte  68,15,89,205                        // mulps         %xmm5,%xmm9
  .byte  15,40,245                           // movaps        %xmm5,%xmm6
  .byte  15,194,211,2                        // cmpleps       %xmm3,%xmm2
  .byte  68,15,84,202                        // andps         %xmm2,%xmm9
  .byte  15,85,209                           // andnps        %xmm1,%xmm2
  .byte  65,15,86,209                        // orps          %xmm9,%xmm2
  .byte  15,88,212                           // addps         %xmm4,%xmm2
  .byte  68,15,89,223                        // mulps         %xmm7,%xmm11
  .byte  65,15,88,219                        // addps         %xmm11,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,40,100,36,216                    // movaps        -0x28(%rsp),%xmm4
  .byte  15,40,108,36,200                    // movaps        -0x38(%rsp),%xmm5
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_0_sse2
.globl _sk_clamp_0_sse2
FUNCTION(_sk_clamp_0_sse2)
_sk_clamp_0_sse2:
  .byte  69,15,87,192                        // xorps         %xmm8,%xmm8
  .byte  65,15,95,192                        // maxps         %xmm8,%xmm0
  .byte  65,15,95,200                        // maxps         %xmm8,%xmm1
  .byte  65,15,95,208                        // maxps         %xmm8,%xmm2
  .byte  65,15,95,216                        // maxps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_1_sse2
.globl _sk_clamp_1_sse2
FUNCTION(_sk_clamp_1_sse2)
_sk_clamp_1_sse2:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,93,192                        // minps         %xmm8,%xmm0
  .byte  65,15,93,200                        // minps         %xmm8,%xmm1
  .byte  65,15,93,208                        // minps         %xmm8,%xmm2
  .byte  65,15,93,216                        // minps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_a_sse2
.globl _sk_clamp_a_sse2
FUNCTION(_sk_clamp_a_sse2)
_sk_clamp_a_sse2:
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,93,216                        // minps         %xmm8,%xmm3
  .byte  15,93,195                           // minps         %xmm3,%xmm0
  .byte  15,93,203                           // minps         %xmm3,%xmm1
  .byte  15,93,211                           // minps         %xmm3,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_set_rgb_sse2
.globl _sk_set_rgb_sse2
FUNCTION(_sk_set_rgb_sse2)
_sk_set_rgb_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,15,16,0                         // movss         (%rax),%xmm0
  .byte  243,15,16,72,4                      // movss         0x4(%rax),%xmm1
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  243,15,16,80,8                      // movss         0x8(%rax),%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_swap_rb_sse2
.globl _sk_swap_rb_sse2
FUNCTION(_sk_swap_rb_sse2)
_sk_swap_rb_sse2:
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,40,194                           // movaps        %xmm2,%xmm0
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_swap_sse2
.globl _sk_swap_sse2
FUNCTION(_sk_swap_sse2)
_sk_swap_sse2:
  .byte  68,15,40,195                        // movaps        %xmm3,%xmm8
  .byte  68,15,40,202                        // movaps        %xmm2,%xmm9
  .byte  68,15,40,209                        // movaps        %xmm1,%xmm10
  .byte  68,15,40,216                        // movaps        %xmm0,%xmm11
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,40,196                           // movaps        %xmm4,%xmm0
  .byte  15,40,205                           // movaps        %xmm5,%xmm1
  .byte  15,40,214                           // movaps        %xmm6,%xmm2
  .byte  15,40,223                           // movaps        %xmm7,%xmm3
  .byte  65,15,40,227                        // movaps        %xmm11,%xmm4
  .byte  65,15,40,234                        // movaps        %xmm10,%xmm5
  .byte  65,15,40,241                        // movaps        %xmm9,%xmm6
  .byte  65,15,40,248                        // movaps        %xmm8,%xmm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_move_src_dst_sse2
.globl _sk_move_src_dst_sse2
FUNCTION(_sk_move_src_dst_sse2)
_sk_move_src_dst_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,40,224                           // movaps        %xmm0,%xmm4
  .byte  15,40,233                           // movaps        %xmm1,%xmm5
  .byte  15,40,242                           // movaps        %xmm2,%xmm6
  .byte  15,40,251                           // movaps        %xmm3,%xmm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_move_dst_src_sse2
.globl _sk_move_dst_src_sse2
FUNCTION(_sk_move_dst_src_sse2)
_sk_move_dst_src_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,40,196                           // movaps        %xmm4,%xmm0
  .byte  15,40,205                           // movaps        %xmm5,%xmm1
  .byte  15,40,214                           // movaps        %xmm6,%xmm2
  .byte  15,40,223                           // movaps        %xmm7,%xmm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_premul_sse2
.globl _sk_premul_sse2
FUNCTION(_sk_premul_sse2)
_sk_premul_sse2:
  .byte  15,89,195                           // mulps         %xmm3,%xmm0
  .byte  15,89,203                           // mulps         %xmm3,%xmm1
  .byte  15,89,211                           // mulps         %xmm3,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_unpremul_sse2
.globl _sk_unpremul_sse2
FUNCTION(_sk_unpremul_sse2)
_sk_unpremul_sse2:
  .byte  69,15,87,192                        // xorps         %xmm8,%xmm8
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,200                   // movd          %eax,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  68,15,94,203                        // divps         %xmm3,%xmm9
  .byte  68,15,194,195,4                     // cmpneqps      %xmm3,%xmm8
  .byte  69,15,84,193                        // andps         %xmm9,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_from_srgb_sse2
.globl _sk_from_srgb_sse2
FUNCTION(_sk_from_srgb_sse2)
_sk_from_srgb_sse2:
  .byte  184,145,131,158,61                  // mov           $0x3d9e8391,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,40,232                        // movaps        %xmm8,%xmm13
  .byte  68,15,89,232                        // mulps         %xmm0,%xmm13
  .byte  68,15,40,224                        // movaps        %xmm0,%xmm12
  .byte  69,15,89,228                        // mulps         %xmm12,%xmm12
  .byte  184,154,153,153,62                  // mov           $0x3e99999a,%eax
  .byte  102,68,15,110,200                   // movd          %eax,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  184,92,143,50,63                    // mov           $0x3f328f5c,%eax
  .byte  102,68,15,110,208                   // movd          %eax,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,40,241                        // movaps        %xmm9,%xmm14
  .byte  68,15,89,240                        // mulps         %xmm0,%xmm14
  .byte  69,15,88,242                        // addps         %xmm10,%xmm14
  .byte  184,10,215,35,59                    // mov           $0x3b23d70a,%eax
  .byte  102,68,15,110,216                   // movd          %eax,%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,89,244                        // mulps         %xmm12,%xmm14
  .byte  69,15,88,243                        // addps         %xmm11,%xmm14
  .byte  184,174,71,97,61                    // mov           $0x3d6147ae,%eax
  .byte  102,68,15,110,224                   // movd          %eax,%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  65,15,194,196,1                     // cmpltps       %xmm12,%xmm0
  .byte  68,15,84,232                        // andps         %xmm0,%xmm13
  .byte  65,15,85,198                        // andnps        %xmm14,%xmm0
  .byte  65,15,86,197                        // orps          %xmm13,%xmm0
  .byte  69,15,40,232                        // movaps        %xmm8,%xmm13
  .byte  68,15,89,233                        // mulps         %xmm1,%xmm13
  .byte  68,15,40,241                        // movaps        %xmm1,%xmm14
  .byte  69,15,89,246                        // mulps         %xmm14,%xmm14
  .byte  69,15,40,249                        // movaps        %xmm9,%xmm15
  .byte  68,15,89,249                        // mulps         %xmm1,%xmm15
  .byte  69,15,88,250                        // addps         %xmm10,%xmm15
  .byte  69,15,89,254                        // mulps         %xmm14,%xmm15
  .byte  69,15,88,251                        // addps         %xmm11,%xmm15
  .byte  65,15,194,204,1                     // cmpltps       %xmm12,%xmm1
  .byte  68,15,84,233                        // andps         %xmm1,%xmm13
  .byte  65,15,85,207                        // andnps        %xmm15,%xmm1
  .byte  65,15,86,205                        // orps          %xmm13,%xmm1
  .byte  68,15,89,194                        // mulps         %xmm2,%xmm8
  .byte  68,15,40,234                        // movaps        %xmm2,%xmm13
  .byte  69,15,89,237                        // mulps         %xmm13,%xmm13
  .byte  68,15,89,202                        // mulps         %xmm2,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  69,15,89,205                        // mulps         %xmm13,%xmm9
  .byte  69,15,88,203                        // addps         %xmm11,%xmm9
  .byte  65,15,194,212,1                     // cmpltps       %xmm12,%xmm2
  .byte  68,15,84,194                        // andps         %xmm2,%xmm8
  .byte  65,15,85,209                        // andnps        %xmm9,%xmm2
  .byte  65,15,86,208                        // orps          %xmm8,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_to_srgb_sse2
.globl _sk_to_srgb_sse2
FUNCTION(_sk_to_srgb_sse2)
_sk_to_srgb_sse2:
  .byte  68,15,82,192                        // rsqrtps       %xmm0,%xmm8
  .byte  69,15,83,248                        // rcpps         %xmm8,%xmm15
  .byte  69,15,82,232                        // rsqrtps       %xmm8,%xmm13
  .byte  184,41,92,71,65                     // mov           $0x41475c29,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,40,240                        // movaps        %xmm8,%xmm14
  .byte  68,15,89,240                        // mulps         %xmm0,%xmm14
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,200                   // movd          %eax,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  184,194,135,210,62                  // mov           $0x3ed287c2,%eax
  .byte  102,68,15,110,208                   // movd          %eax,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  184,206,111,48,63                   // mov           $0x3f306fce,%eax
  .byte  102,68,15,110,216                   // movd          %eax,%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  184,168,87,202,61                   // mov           $0x3dca57a8,%eax
  .byte  53,0,0,0,128                        // xor           $0x80000000,%eax
  .byte  102,68,15,110,224                   // movd          %eax,%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  69,15,89,251                        // mulps         %xmm11,%xmm15
  .byte  69,15,88,252                        // addps         %xmm12,%xmm15
  .byte  69,15,89,234                        // mulps         %xmm10,%xmm13
  .byte  69,15,88,239                        // addps         %xmm15,%xmm13
  .byte  69,15,40,249                        // movaps        %xmm9,%xmm15
  .byte  69,15,93,253                        // minps         %xmm13,%xmm15
  .byte  184,4,231,140,59                    // mov           $0x3b8ce704,%eax
  .byte  102,68,15,110,232                   // movd          %eax,%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  65,15,194,197,1                     // cmpltps       %xmm13,%xmm0
  .byte  68,15,84,240                        // andps         %xmm0,%xmm14
  .byte  65,15,85,199                        // andnps        %xmm15,%xmm0
  .byte  65,15,86,198                        // orps          %xmm14,%xmm0
  .byte  68,15,82,241                        // rsqrtps       %xmm1,%xmm14
  .byte  69,15,83,254                        // rcpps         %xmm14,%xmm15
  .byte  69,15,82,246                        // rsqrtps       %xmm14,%xmm14
  .byte  69,15,89,251                        // mulps         %xmm11,%xmm15
  .byte  69,15,88,252                        // addps         %xmm12,%xmm15
  .byte  69,15,89,242                        // mulps         %xmm10,%xmm14
  .byte  69,15,88,247                        // addps         %xmm15,%xmm14
  .byte  69,15,40,249                        // movaps        %xmm9,%xmm15
  .byte  69,15,93,254                        // minps         %xmm14,%xmm15
  .byte  69,15,40,240                        // movaps        %xmm8,%xmm14
  .byte  68,15,89,241                        // mulps         %xmm1,%xmm14
  .byte  65,15,194,205,1                     // cmpltps       %xmm13,%xmm1
  .byte  68,15,84,241                        // andps         %xmm1,%xmm14
  .byte  65,15,85,207                        // andnps        %xmm15,%xmm1
  .byte  65,15,86,206                        // orps          %xmm14,%xmm1
  .byte  68,15,82,242                        // rsqrtps       %xmm2,%xmm14
  .byte  69,15,83,254                        // rcpps         %xmm14,%xmm15
  .byte  69,15,89,251                        // mulps         %xmm11,%xmm15
  .byte  69,15,88,252                        // addps         %xmm12,%xmm15
  .byte  69,15,82,222                        // rsqrtps       %xmm14,%xmm11
  .byte  69,15,89,218                        // mulps         %xmm10,%xmm11
  .byte  69,15,88,223                        // addps         %xmm15,%xmm11
  .byte  69,15,93,203                        // minps         %xmm11,%xmm9
  .byte  68,15,89,194                        // mulps         %xmm2,%xmm8
  .byte  65,15,194,213,1                     // cmpltps       %xmm13,%xmm2
  .byte  68,15,84,194                        // andps         %xmm2,%xmm8
  .byte  65,15,85,209                        // andnps        %xmm9,%xmm2
  .byte  65,15,86,208                        // orps          %xmm8,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_rgb_to_hsl_sse2
.globl _sk_rgb_to_hsl_sse2
FUNCTION(_sk_rgb_to_hsl_sse2)
_sk_rgb_to_hsl_sse2:
  .byte  68,15,40,201                        // movaps        %xmm1,%xmm9
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  69,15,40,208                        // movaps        %xmm8,%xmm10
  .byte  69,15,95,209                        // maxps         %xmm9,%xmm10
  .byte  68,15,95,210                        // maxps         %xmm2,%xmm10
  .byte  69,15,40,216                        // movaps        %xmm8,%xmm11
  .byte  69,15,93,217                        // minps         %xmm9,%xmm11
  .byte  68,15,93,218                        // minps         %xmm2,%xmm11
  .byte  65,15,40,202                        // movaps        %xmm10,%xmm1
  .byte  65,15,92,203                        // subps         %xmm11,%xmm1
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,224                   // movd          %eax,%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  68,15,94,225                        // divps         %xmm1,%xmm12
  .byte  65,184,171,170,42,62                // mov           $0x3e2aaaab,%r8d
  .byte  65,15,40,194                        // movaps        %xmm10,%xmm0
  .byte  65,15,194,192,0                     // cmpeqps       %xmm8,%xmm0
  .byte  69,15,40,241                        // movaps        %xmm9,%xmm14
  .byte  68,15,194,242,1                     // cmpltps       %xmm2,%xmm14
  .byte  185,0,0,192,64                      // mov           $0x40c00000,%ecx
  .byte  102,68,15,110,233                   // movd          %ecx,%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  69,15,84,238                        // andps         %xmm14,%xmm13
  .byte  69,15,40,241                        // movaps        %xmm9,%xmm14
  .byte  68,15,92,242                        // subps         %xmm2,%xmm14
  .byte  69,15,89,244                        // mulps         %xmm12,%xmm14
  .byte  69,15,88,238                        // addps         %xmm14,%xmm13
  .byte  69,15,40,242                        // movaps        %xmm10,%xmm14
  .byte  69,15,194,241,0                     // cmpeqps       %xmm9,%xmm14
  .byte  65,15,92,208                        // subps         %xmm8,%xmm2
  .byte  69,15,92,193                        // subps         %xmm9,%xmm8
  .byte  65,15,89,212                        // mulps         %xmm12,%xmm2
  .byte  185,0,0,0,64                        // mov           $0x40000000,%ecx
  .byte  69,15,89,196                        // mulps         %xmm12,%xmm8
  .byte  184,0,0,128,64                      // mov           $0x40800000,%eax
  .byte  102,68,15,110,200                   // movd          %eax,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  69,15,88,200                        // addps         %xmm8,%xmm9
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,88,208                        // addps         %xmm8,%xmm2
  .byte  65,15,84,214                        // andps         %xmm14,%xmm2
  .byte  69,15,85,241                        // andnps        %xmm9,%xmm14
  .byte  68,15,86,242                        // orps          %xmm2,%xmm14
  .byte  68,15,84,232                        // andps         %xmm0,%xmm13
  .byte  65,15,85,198                        // andnps        %xmm14,%xmm0
  .byte  102,65,15,110,208                   // movd          %r8d,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  65,15,86,197                        // orps          %xmm13,%xmm0
  .byte  69,15,40,202                        // movaps        %xmm10,%xmm9
  .byte  69,15,194,203,4                     // cmpneqps      %xmm11,%xmm9
  .byte  65,15,84,193                        // andps         %xmm9,%xmm0
  .byte  15,89,194                           // mulps         %xmm2,%xmm0
  .byte  69,15,92,194                        // subps         %xmm10,%xmm8
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  184,0,0,0,63                        // mov           $0x3f000000,%eax
  .byte  102,68,15,110,224                   // movd          %eax,%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  69,15,92,195                        // subps         %xmm11,%xmm8
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  65,15,89,212                        // mulps         %xmm12,%xmm2
  .byte  68,15,194,226,1                     // cmpltps       %xmm2,%xmm12
  .byte  69,15,84,196                        // andps         %xmm12,%xmm8
  .byte  69,15,85,226                        // andnps        %xmm10,%xmm12
  .byte  69,15,86,224                        // orps          %xmm8,%xmm12
  .byte  65,15,94,204                        // divps         %xmm12,%xmm1
  .byte  65,15,84,201                        // andps         %xmm9,%xmm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_hsl_to_rgb_sse2
.globl _sk_hsl_to_rgb_sse2
FUNCTION(_sk_hsl_to_rgb_sse2)
_sk_hsl_to_rgb_sse2:
  .byte  15,41,124,36,232                    // movaps        %xmm7,-0x18(%rsp)
  .byte  15,41,116,36,216                    // movaps        %xmm6,-0x28(%rsp)
  .byte  15,41,108,36,200                    // movaps        %xmm5,-0x38(%rsp)
  .byte  15,41,100,36,184                    // movaps        %xmm4,-0x48(%rsp)
  .byte  15,41,92,36,168                     // movaps        %xmm3,-0x58(%rsp)
  .byte  68,15,40,210                        // movaps        %xmm2,%xmm10
  .byte  15,40,209                           // movaps        %xmm1,%xmm2
  .byte  15,40,240                           // movaps        %xmm0,%xmm6
  .byte  184,0,0,0,63                        // mov           $0x3f000000,%eax
  .byte  102,68,15,110,240                   // movd          %eax,%xmm14
  .byte  69,15,198,246,0                     // shufps        $0x0,%xmm14,%xmm14
  .byte  69,15,40,202                        // movaps        %xmm10,%xmm9
  .byte  69,15,194,206,1                     // cmpltps       %xmm14,%xmm9
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,224                   // movd          %eax,%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  65,15,40,196                        // movaps        %xmm12,%xmm0
  .byte  15,88,194                           // addps         %xmm2,%xmm0
  .byte  65,15,89,194                        // mulps         %xmm10,%xmm0
  .byte  15,40,218                           // movaps        %xmm2,%xmm3
  .byte  69,15,87,219                        // xorps         %xmm11,%xmm11
  .byte  68,15,194,218,0                     // cmpeqps       %xmm2,%xmm11
  .byte  65,15,88,210                        // addps         %xmm10,%xmm2
  .byte  65,15,89,218                        // mulps         %xmm10,%xmm3
  .byte  15,92,211                           // subps         %xmm3,%xmm2
  .byte  65,15,84,193                        // andps         %xmm9,%xmm0
  .byte  68,15,85,202                        // andnps        %xmm2,%xmm9
  .byte  68,15,86,200                        // orps          %xmm0,%xmm9
  .byte  184,0,0,0,64                        // mov           $0x40000000,%eax
  .byte  185,171,170,170,62                  // mov           $0x3eaaaaab,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,41,68,36,152                  // movaps        %xmm8,-0x68(%rsp)
  .byte  68,15,88,198                        // addps         %xmm6,%xmm8
  .byte  185,0,0,0,0                         // mov           $0x0,%ecx
  .byte  102,15,110,233                      // movd          %ecx,%xmm5
  .byte  15,198,237,0                        // shufps        $0x0,%xmm5,%xmm5
  .byte  65,15,40,196                        // movaps        %xmm12,%xmm0
  .byte  65,15,194,192,1                     // cmpltps       %xmm8,%xmm0
  .byte  65,15,40,216                        // movaps        %xmm8,%xmm3
  .byte  65,15,92,220                        // subps         %xmm12,%xmm3
  .byte  15,84,216                           // andps         %xmm0,%xmm3
  .byte  65,15,85,192                        // andnps        %xmm8,%xmm0
  .byte  15,86,195                           // orps          %xmm3,%xmm0
  .byte  65,15,40,216                        // movaps        %xmm8,%xmm3
  .byte  15,194,221,1                        // cmpltps       %xmm5,%xmm3
  .byte  65,15,40,212                        // movaps        %xmm12,%xmm2
  .byte  65,15,88,208                        // addps         %xmm8,%xmm2
  .byte  15,84,211                           // andps         %xmm3,%xmm2
  .byte  15,85,216                           // andnps        %xmm0,%xmm3
  .byte  15,86,218                           // orps          %xmm2,%xmm3
  .byte  102,68,15,110,232                   // movd          %eax,%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  69,15,89,234                        // mulps         %xmm10,%xmm13
  .byte  69,15,92,233                        // subps         %xmm9,%xmm13
  .byte  184,171,170,42,62                   // mov           $0x3e2aaaab,%eax
  .byte  65,15,40,193                        // movaps        %xmm9,%xmm0
  .byte  65,15,92,197                        // subps         %xmm13,%xmm0
  .byte  185,0,0,192,64                      // mov           $0x40c00000,%ecx
  .byte  102,68,15,110,249                   // movd          %ecx,%xmm15
  .byte  69,15,198,255,0                     // shufps        $0x0,%xmm15,%xmm15
  .byte  68,15,89,248                        // mulps         %xmm0,%xmm15
  .byte  185,171,170,42,63                   // mov           $0x3f2aaaab,%ecx
  .byte  102,15,110,225                      // movd          %ecx,%xmm4
  .byte  15,198,228,0                        // shufps        $0x0,%xmm4,%xmm4
  .byte  15,40,212                           // movaps        %xmm4,%xmm2
  .byte  15,92,211                           // subps         %xmm3,%xmm2
  .byte  15,40,203                           // movaps        %xmm3,%xmm1
  .byte  15,40,195                           // movaps        %xmm3,%xmm0
  .byte  15,194,220,1                        // cmpltps       %xmm4,%xmm3
  .byte  65,15,89,215                        // mulps         %xmm15,%xmm2
  .byte  65,15,88,213                        // addps         %xmm13,%xmm2
  .byte  15,84,211                           // andps         %xmm3,%xmm2
  .byte  65,15,85,221                        // andnps        %xmm13,%xmm3
  .byte  15,86,218                           // orps          %xmm2,%xmm3
  .byte  65,15,194,198,1                     // cmpltps       %xmm14,%xmm0
  .byte  65,15,40,209                        // movaps        %xmm9,%xmm2
  .byte  15,84,208                           // andps         %xmm0,%xmm2
  .byte  15,85,195                           // andnps        %xmm3,%xmm0
  .byte  15,86,194                           // orps          %xmm2,%xmm0
  .byte  102,15,110,248                      // movd          %eax,%xmm7
  .byte  15,198,255,0                        // shufps        $0x0,%xmm7,%xmm7
  .byte  15,194,207,1                        // cmpltps       %xmm7,%xmm1
  .byte  69,15,89,199                        // mulps         %xmm15,%xmm8
  .byte  69,15,88,197                        // addps         %xmm13,%xmm8
  .byte  68,15,84,193                        // andps         %xmm1,%xmm8
  .byte  15,85,200                           // andnps        %xmm0,%xmm1
  .byte  65,15,86,200                        // orps          %xmm8,%xmm1
  .byte  69,15,40,195                        // movaps        %xmm11,%xmm8
  .byte  68,15,85,193                        // andnps        %xmm1,%xmm8
  .byte  65,15,40,196                        // movaps        %xmm12,%xmm0
  .byte  15,194,198,1                        // cmpltps       %xmm6,%xmm0
  .byte  15,40,206                           // movaps        %xmm6,%xmm1
  .byte  65,15,92,204                        // subps         %xmm12,%xmm1
  .byte  15,84,200                           // andps         %xmm0,%xmm1
  .byte  15,85,198                           // andnps        %xmm6,%xmm0
  .byte  15,86,193                           // orps          %xmm1,%xmm0
  .byte  15,40,206                           // movaps        %xmm6,%xmm1
  .byte  15,194,205,1                        // cmpltps       %xmm5,%xmm1
  .byte  65,15,40,212                        // movaps        %xmm12,%xmm2
  .byte  15,88,214                           // addps         %xmm6,%xmm2
  .byte  15,84,209                           // andps         %xmm1,%xmm2
  .byte  15,85,200                           // andnps        %xmm0,%xmm1
  .byte  15,86,202                           // orps          %xmm2,%xmm1
  .byte  15,40,196                           // movaps        %xmm4,%xmm0
  .byte  15,92,193                           // subps         %xmm1,%xmm0
  .byte  15,40,217                           // movaps        %xmm1,%xmm3
  .byte  15,40,209                           // movaps        %xmm1,%xmm2
  .byte  15,194,204,1                        // cmpltps       %xmm4,%xmm1
  .byte  65,15,89,199                        // mulps         %xmm15,%xmm0
  .byte  65,15,88,197                        // addps         %xmm13,%xmm0
  .byte  15,84,193                           // andps         %xmm1,%xmm0
  .byte  65,15,85,205                        // andnps        %xmm13,%xmm1
  .byte  15,86,200                           // orps          %xmm0,%xmm1
  .byte  65,15,194,214,1                     // cmpltps       %xmm14,%xmm2
  .byte  65,15,40,193                        // movaps        %xmm9,%xmm0
  .byte  15,84,194                           // andps         %xmm2,%xmm0
  .byte  15,85,209                           // andnps        %xmm1,%xmm2
  .byte  15,86,208                           // orps          %xmm0,%xmm2
  .byte  15,194,223,1                        // cmpltps       %xmm7,%xmm3
  .byte  65,15,40,199                        // movaps        %xmm15,%xmm0
  .byte  15,89,198                           // mulps         %xmm6,%xmm0
  .byte  65,15,88,197                        // addps         %xmm13,%xmm0
  .byte  15,84,195                           // andps         %xmm3,%xmm0
  .byte  15,85,218                           // andnps        %xmm2,%xmm3
  .byte  15,86,216                           // orps          %xmm0,%xmm3
  .byte  65,15,40,203                        // movaps        %xmm11,%xmm1
  .byte  15,85,203                           // andnps        %xmm3,%xmm1
  .byte  15,92,116,36,152                    // subps         -0x68(%rsp),%xmm6
  .byte  15,40,198                           // movaps        %xmm6,%xmm0
  .byte  15,194,197,1                        // cmpltps       %xmm5,%xmm0
  .byte  15,40,214                           // movaps        %xmm6,%xmm2
  .byte  65,15,92,212                        // subps         %xmm12,%xmm2
  .byte  65,15,40,220                        // movaps        %xmm12,%xmm3
  .byte  68,15,194,230,1                     // cmpltps       %xmm6,%xmm12
  .byte  65,15,84,212                        // andps         %xmm12,%xmm2
  .byte  68,15,85,230                        // andnps        %xmm6,%xmm12
  .byte  68,15,86,226                        // orps          %xmm2,%xmm12
  .byte  15,88,222                           // addps         %xmm6,%xmm3
  .byte  15,84,216                           // andps         %xmm0,%xmm3
  .byte  65,15,85,196                        // andnps        %xmm12,%xmm0
  .byte  15,86,195                           // orps          %xmm3,%xmm0
  .byte  15,40,232                           // movaps        %xmm0,%xmm5
  .byte  15,194,239,1                        // cmpltps       %xmm7,%xmm5
  .byte  15,40,208                           // movaps        %xmm0,%xmm2
  .byte  15,194,212,1                        // cmpltps       %xmm4,%xmm2
  .byte  15,92,224                           // subps         %xmm0,%xmm4
  .byte  65,15,194,198,1                     // cmpltps       %xmm14,%xmm0
  .byte  65,15,89,247                        // mulps         %xmm15,%xmm6
  .byte  65,15,89,231                        // mulps         %xmm15,%xmm4
  .byte  65,15,88,245                        // addps         %xmm13,%xmm6
  .byte  65,15,88,229                        // addps         %xmm13,%xmm4
  .byte  15,84,226                           // andps         %xmm2,%xmm4
  .byte  65,15,85,213                        // andnps        %xmm13,%xmm2
  .byte  15,86,212                           // orps          %xmm4,%xmm2
  .byte  68,15,84,200                        // andps         %xmm0,%xmm9
  .byte  15,85,194                           // andnps        %xmm2,%xmm0
  .byte  65,15,86,193                        // orps          %xmm9,%xmm0
  .byte  15,84,245                           // andps         %xmm5,%xmm6
  .byte  15,85,232                           // andnps        %xmm0,%xmm5
  .byte  15,86,238                           // orps          %xmm6,%xmm5
  .byte  69,15,84,211                        // andps         %xmm11,%xmm10
  .byte  68,15,85,221                        // andnps        %xmm5,%xmm11
  .byte  69,15,86,194                        // orps          %xmm10,%xmm8
  .byte  65,15,86,202                        // orps          %xmm10,%xmm1
  .byte  69,15,86,211                        // orps          %xmm11,%xmm10
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  15,40,92,36,168                     // movaps        -0x58(%rsp),%xmm3
  .byte  15,40,100,36,184                    // movaps        -0x48(%rsp),%xmm4
  .byte  15,40,108,36,200                    // movaps        -0x38(%rsp),%xmm5
  .byte  15,40,116,36,216                    // movaps        -0x28(%rsp),%xmm6
  .byte  15,40,124,36,232                    // movaps        -0x18(%rsp),%xmm7
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_scale_1_float_sse2
.globl _sk_scale_1_float_sse2
FUNCTION(_sk_scale_1_float_sse2)
_sk_scale_1_float_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,0                      // movss         (%rax),%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_scale_u8_sse2
.globl _sk_scale_u8_sse2
FUNCTION(_sk_scale_u8_sse2)
_sk_scale_u8_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  102,68,15,110,4,56                  // movd          (%rax,%rdi,1),%xmm8
  .byte  102,69,15,239,201                   // pxor          %xmm9,%xmm9
  .byte  102,69,15,96,193                    // punpcklbw     %xmm9,%xmm8
  .byte  102,69,15,97,193                    // punpcklwd     %xmm9,%xmm8
  .byte  69,15,91,192                        // cvtdq2ps      %xmm8,%xmm8
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,68,15,110,200                   // movd          %eax,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  65,15,89,193                        // mulps         %xmm9,%xmm0
  .byte  65,15,89,201                        // mulps         %xmm9,%xmm1
  .byte  65,15,89,209                        // mulps         %xmm9,%xmm2
  .byte  65,15,89,217                        // mulps         %xmm9,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_lerp_1_float_sse2
.globl _sk_lerp_1_float_sse2
FUNCTION(_sk_lerp_1_float_sse2)
_sk_lerp_1_float_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,0                      // movss         (%rax),%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,92,196                           // subps         %xmm4,%xmm0
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  15,92,205                           // subps         %xmm5,%xmm1
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  15,92,214                           // subps         %xmm6,%xmm2
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  15,88,214                           // addps         %xmm6,%xmm2
  .byte  15,92,223                           // subps         %xmm7,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  15,88,223                           // addps         %xmm7,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_lerp_u8_sse2
.globl _sk_lerp_u8_sse2
FUNCTION(_sk_lerp_u8_sse2)
_sk_lerp_u8_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  102,68,15,110,4,56                  // movd          (%rax,%rdi,1),%xmm8
  .byte  102,69,15,239,201                   // pxor          %xmm9,%xmm9
  .byte  102,69,15,96,193                    // punpcklbw     %xmm9,%xmm8
  .byte  102,69,15,97,193                    // punpcklwd     %xmm9,%xmm8
  .byte  69,15,91,192                        // cvtdq2ps      %xmm8,%xmm8
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,68,15,110,200                   // movd          %eax,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  15,92,196                           // subps         %xmm4,%xmm0
  .byte  65,15,89,193                        // mulps         %xmm9,%xmm0
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  15,92,205                           // subps         %xmm5,%xmm1
  .byte  65,15,89,201                        // mulps         %xmm9,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  15,92,214                           // subps         %xmm6,%xmm2
  .byte  65,15,89,209                        // mulps         %xmm9,%xmm2
  .byte  15,88,214                           // addps         %xmm6,%xmm2
  .byte  15,92,223                           // subps         %xmm7,%xmm3
  .byte  65,15,89,217                        // mulps         %xmm9,%xmm3
  .byte  15,88,223                           // addps         %xmm7,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_lerp_565_sse2
.globl _sk_lerp_565_sse2
FUNCTION(_sk_lerp_565_sse2)
_sk_lerp_565_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  243,68,15,126,4,120                 // movq          (%rax,%rdi,2),%xmm8
  .byte  102,15,239,219                      // pxor          %xmm3,%xmm3
  .byte  102,68,15,97,195                    // punpcklwd     %xmm3,%xmm8
  .byte  184,0,248,0,0                       // mov           $0xf800,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  102,15,112,219,0                    // pshufd        $0x0,%xmm3,%xmm3
  .byte  102,65,15,219,216                   // pand          %xmm8,%xmm3
  .byte  68,15,91,203                        // cvtdq2ps      %xmm3,%xmm9
  .byte  184,8,33,132,55                     // mov           $0x37842108,%eax
  .byte  102,68,15,110,208                   // movd          %eax,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  184,224,7,0,0                       // mov           $0x7e0,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  102,15,112,219,0                    // pshufd        $0x0,%xmm3,%xmm3
  .byte  102,65,15,219,216                   // pand          %xmm8,%xmm3
  .byte  68,15,91,203                        // cvtdq2ps      %xmm3,%xmm9
  .byte  184,33,8,2,58                       // mov           $0x3a020821,%eax
  .byte  102,68,15,110,216                   // movd          %eax,%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,89,217                        // mulps         %xmm9,%xmm11
  .byte  184,31,0,0,0                        // mov           $0x1f,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  102,15,112,219,0                    // pshufd        $0x0,%xmm3,%xmm3
  .byte  102,65,15,219,216                   // pand          %xmm8,%xmm3
  .byte  68,15,91,195                        // cvtdq2ps      %xmm3,%xmm8
  .byte  184,8,33,4,61                       // mov           $0x3d042108,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  15,92,196                           // subps         %xmm4,%xmm0
  .byte  65,15,89,194                        // mulps         %xmm10,%xmm0
  .byte  15,88,196                           // addps         %xmm4,%xmm0
  .byte  15,92,205                           // subps         %xmm5,%xmm1
  .byte  65,15,89,203                        // mulps         %xmm11,%xmm1
  .byte  15,88,205                           // addps         %xmm5,%xmm1
  .byte  15,92,214                           // subps         %xmm6,%xmm2
  .byte  15,89,211                           // mulps         %xmm3,%xmm2
  .byte  15,88,214                           // addps         %xmm6,%xmm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_tables_sse2
.globl _sk_load_tables_sse2
FUNCTION(_sk_load_tables_sse2)
_sk_load_tables_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,0                            // mov           (%rax),%r8
  .byte  76,139,72,8                         // mov           0x8(%rax),%r9
  .byte  243,69,15,111,12,184                // movdqu        (%r8,%rdi,4),%xmm9
  .byte  102,68,15,111,5,129,45,0,0          // movdqa        0x2d81(%rip),%xmm8        # 4360 <_sk_callback_sse2+0x102>
  .byte  102,65,15,111,193                   // movdqa        %xmm9,%xmm0
  .byte  102,65,15,219,192                   // pand          %xmm8,%xmm0
  .byte  102,15,112,200,78                   // pshufd        $0x4e,%xmm0,%xmm1
  .byte  102,73,15,126,200                   // movq          %xmm1,%r8
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  68,15,182,209                       // movzbl        %cl,%r10d
  .byte  72,193,233,30                       // shr           $0x1e,%rcx
  .byte  69,15,182,216                       // movzbl        %r8b,%r11d
  .byte  73,193,232,30                       // shr           $0x1e,%r8
  .byte  243,65,15,16,12,9                   // movss         (%r9,%rcx,1),%xmm1
  .byte  243,67,15,16,4,1                    // movss         (%r9,%r8,1),%xmm0
  .byte  15,20,200                           // unpcklps      %xmm0,%xmm1
  .byte  243,67,15,16,4,145                  // movss         (%r9,%r10,4),%xmm0
  .byte  243,67,15,16,20,153                 // movss         (%r9,%r11,4),%xmm2
  .byte  15,20,194                           // unpcklps      %xmm2,%xmm0
  .byte  15,20,193                           // unpcklps      %xmm1,%xmm0
  .byte  76,139,64,16                        // mov           0x10(%rax),%r8
  .byte  102,65,15,111,201                   // movdqa        %xmm9,%xmm1
  .byte  102,15,114,209,8                    // psrld         $0x8,%xmm1
  .byte  102,65,15,219,200                   // pand          %xmm8,%xmm1
  .byte  102,15,112,209,78                   // pshufd        $0x4e,%xmm1,%xmm2
  .byte  102,73,15,126,209                   // movq          %xmm2,%r9
  .byte  102,72,15,126,201                   // movq          %xmm1,%rcx
  .byte  68,15,182,209                       // movzbl        %cl,%r10d
  .byte  72,193,233,30                       // shr           $0x1e,%rcx
  .byte  69,15,182,217                       // movzbl        %r9b,%r11d
  .byte  73,193,233,30                       // shr           $0x1e,%r9
  .byte  243,65,15,16,20,8                   // movss         (%r8,%rcx,1),%xmm2
  .byte  243,67,15,16,12,8                   // movss         (%r8,%r9,1),%xmm1
  .byte  15,20,209                           // unpcklps      %xmm1,%xmm2
  .byte  243,67,15,16,12,144                 // movss         (%r8,%r10,4),%xmm1
  .byte  243,67,15,16,28,152                 // movss         (%r8,%r11,4),%xmm3
  .byte  15,20,203                           // unpcklps      %xmm3,%xmm1
  .byte  15,20,202                           // unpcklps      %xmm2,%xmm1
  .byte  76,139,64,24                        // mov           0x18(%rax),%r8
  .byte  102,65,15,111,209                   // movdqa        %xmm9,%xmm2
  .byte  102,15,114,210,16                   // psrld         $0x10,%xmm2
  .byte  102,65,15,219,208                   // pand          %xmm8,%xmm2
  .byte  102,15,112,218,78                   // pshufd        $0x4e,%xmm2,%xmm3
  .byte  102,72,15,126,217                   // movq          %xmm3,%rcx
  .byte  102,72,15,126,208                   // movq          %xmm2,%rax
  .byte  68,15,182,200                       // movzbl        %al,%r9d
  .byte  72,193,232,30                       // shr           $0x1e,%rax
  .byte  68,15,182,209                       // movzbl        %cl,%r10d
  .byte  72,193,233,30                       // shr           $0x1e,%rcx
  .byte  243,69,15,16,4,0                    // movss         (%r8,%rax,1),%xmm8
  .byte  243,65,15,16,20,8                   // movss         (%r8,%rcx,1),%xmm2
  .byte  68,15,20,194                        // unpcklps      %xmm2,%xmm8
  .byte  243,67,15,16,20,136                 // movss         (%r8,%r9,4),%xmm2
  .byte  243,67,15,16,28,144                 // movss         (%r8,%r10,4),%xmm3
  .byte  15,20,211                           // unpcklps      %xmm3,%xmm2
  .byte  65,15,20,208                        // unpcklps      %xmm8,%xmm2
  .byte  102,65,15,114,209,24                // psrld         $0x18,%xmm9
  .byte  69,15,91,193                        // cvtdq2ps      %xmm9,%xmm8
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_tables_u16_be_sse2
.globl _sk_load_tables_u16_be_sse2
FUNCTION(_sk_load_tables_u16_be_sse2)
_sk_load_tables_u16_be_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,8                            // mov           (%rax),%rcx
  .byte  76,139,64,8                         // mov           0x8(%rax),%r8
  .byte  243,15,111,4,249                    // movdqu        (%rcx,%rdi,8),%xmm0
  .byte  243,15,111,76,249,16                // movdqu        0x10(%rcx,%rdi,8),%xmm1
  .byte  102,68,15,111,200                   // movdqa        %xmm0,%xmm9
  .byte  102,68,15,97,201                    // punpcklwd     %xmm1,%xmm9
  .byte  102,15,105,193                      // punpckhwd     %xmm1,%xmm0
  .byte  102,65,15,111,201                   // movdqa        %xmm9,%xmm1
  .byte  102,15,97,200                       // punpcklwd     %xmm0,%xmm1
  .byte  102,68,15,105,200                   // punpckhwd     %xmm0,%xmm9
  .byte  102,68,15,111,21,71,44,0,0          // movdqa        0x2c47(%rip),%xmm10        # 4370 <_sk_callback_sse2+0x112>
  .byte  102,15,111,193                      // movdqa        %xmm1,%xmm0
  .byte  102,65,15,219,194                   // pand          %xmm10,%xmm0
  .byte  102,69,15,239,192                   // pxor          %xmm8,%xmm8
  .byte  102,65,15,97,192                    // punpcklwd     %xmm8,%xmm0
  .byte  102,15,112,216,78                   // pshufd        $0x4e,%xmm0,%xmm3
  .byte  102,72,15,126,217                   // movq          %xmm3,%rcx
  .byte  68,15,182,201                       // movzbl        %cl,%r9d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,73,15,126,194                   // movq          %xmm0,%r10
  .byte  69,15,182,218                       // movzbl        %r10b,%r11d
  .byte  73,193,234,30                       // shr           $0x1e,%r10
  .byte  243,67,15,16,28,16                  // movss         (%r8,%r10,1),%xmm3
  .byte  243,65,15,16,4,136                  // movss         (%r8,%rcx,4),%xmm0
  .byte  15,20,216                           // unpcklps      %xmm0,%xmm3
  .byte  243,67,15,16,4,152                  // movss         (%r8,%r11,4),%xmm0
  .byte  243,67,15,16,20,136                 // movss         (%r8,%r9,4),%xmm2
  .byte  15,20,194                           // unpcklps      %xmm2,%xmm0
  .byte  15,20,195                           // unpcklps      %xmm3,%xmm0
  .byte  76,139,80,16                        // mov           0x10(%rax),%r10
  .byte  102,15,115,217,8                    // psrldq        $0x8,%xmm1
  .byte  102,65,15,219,202                   // pand          %xmm10,%xmm1
  .byte  102,65,15,97,200                    // punpcklwd     %xmm8,%xmm1
  .byte  102,15,112,209,78                   // pshufd        $0x4e,%xmm1,%xmm2
  .byte  102,73,15,126,208                   // movq          %xmm2,%r8
  .byte  69,15,182,200                       // movzbl        %r8b,%r9d
  .byte  73,193,232,32                       // shr           $0x20,%r8
  .byte  102,72,15,126,201                   // movq          %xmm1,%rcx
  .byte  68,15,182,217                       // movzbl        %cl,%r11d
  .byte  72,193,233,30                       // shr           $0x1e,%rcx
  .byte  243,65,15,16,20,10                  // movss         (%r10,%rcx,1),%xmm2
  .byte  243,67,15,16,12,130                 // movss         (%r10,%r8,4),%xmm1
  .byte  15,20,209                           // unpcklps      %xmm1,%xmm2
  .byte  243,67,15,16,12,154                 // movss         (%r10,%r11,4),%xmm1
  .byte  243,67,15,16,28,138                 // movss         (%r10,%r9,4),%xmm3
  .byte  15,20,203                           // unpcklps      %xmm3,%xmm1
  .byte  15,20,202                           // unpcklps      %xmm2,%xmm1
  .byte  76,139,72,24                        // mov           0x18(%rax),%r9
  .byte  102,69,15,219,209                   // pand          %xmm9,%xmm10
  .byte  102,69,15,97,208                    // punpcklwd     %xmm8,%xmm10
  .byte  102,65,15,112,210,78                // pshufd        $0x4e,%xmm10,%xmm2
  .byte  102,72,15,126,209                   // movq          %xmm2,%rcx
  .byte  68,15,182,193                       // movzbl        %cl,%r8d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,76,15,126,208                   // movq          %xmm10,%rax
  .byte  68,15,182,208                       // movzbl        %al,%r10d
  .byte  72,193,232,30                       // shr           $0x1e,%rax
  .byte  243,69,15,16,20,1                   // movss         (%r9,%rax,1),%xmm10
  .byte  243,65,15,16,20,137                 // movss         (%r9,%rcx,4),%xmm2
  .byte  68,15,20,210                        // unpcklps      %xmm2,%xmm10
  .byte  243,67,15,16,20,145                 // movss         (%r9,%r10,4),%xmm2
  .byte  243,67,15,16,28,129                 // movss         (%r9,%r8,4),%xmm3
  .byte  15,20,211                           // unpcklps      %xmm3,%xmm2
  .byte  65,15,20,210                        // unpcklps      %xmm10,%xmm2
  .byte  184,128,0,128,55                    // mov           $0x37800080,%eax
  .byte  102,68,15,110,208                   // movd          %eax,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  102,65,15,112,217,78                // pshufd        $0x4e,%xmm9,%xmm3
  .byte  102,68,15,111,203                   // movdqa        %xmm3,%xmm9
  .byte  102,65,15,113,241,8                 // psllw         $0x8,%xmm9
  .byte  102,15,113,211,8                    // psrlw         $0x8,%xmm3
  .byte  102,65,15,235,217                   // por           %xmm9,%xmm3
  .byte  102,65,15,97,216                    // punpcklwd     %xmm8,%xmm3
  .byte  15,91,219                           // cvtdq2ps      %xmm3,%xmm3
  .byte  65,15,89,218                        // mulps         %xmm10,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_tables_rgb_u16_be_sse2
.globl _sk_load_tables_rgb_u16_be_sse2
FUNCTION(_sk_load_tables_rgb_u16_be_sse2)
_sk_load_tables_rgb_u16_be_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,141,12,127                       // lea           (%rdi,%rdi,2),%r9
  .byte  72,139,8                            // mov           (%rax),%rcx
  .byte  76,139,64,8                         // mov           0x8(%rax),%r8
  .byte  243,70,15,111,28,73                 // movdqu        (%rcx,%r9,2),%xmm11
  .byte  243,66,15,111,68,73,8               // movdqu        0x8(%rcx,%r9,2),%xmm0
  .byte  102,15,115,216,4                    // psrldq        $0x4,%xmm0
  .byte  102,69,15,111,211                   // movdqa        %xmm11,%xmm10
  .byte  102,65,15,115,218,6                 // psrldq        $0x6,%xmm10
  .byte  102,68,15,97,216                    // punpcklwd     %xmm0,%xmm11
  .byte  102,15,115,216,6                    // psrldq        $0x6,%xmm0
  .byte  102,68,15,97,208                    // punpcklwd     %xmm0,%xmm10
  .byte  102,65,15,111,195                   // movdqa        %xmm11,%xmm0
  .byte  102,65,15,97,194                    // punpcklwd     %xmm10,%xmm0
  .byte  102,68,15,111,5,218,42,0,0          // movdqa        0x2ada(%rip),%xmm8        # 4380 <_sk_callback_sse2+0x122>
  .byte  102,15,112,200,78                   // pshufd        $0x4e,%xmm0,%xmm1
  .byte  102,65,15,219,192                   // pand          %xmm8,%xmm0
  .byte  102,69,15,239,201                   // pxor          %xmm9,%xmm9
  .byte  102,65,15,97,193                    // punpcklwd     %xmm9,%xmm0
  .byte  102,15,112,216,78                   // pshufd        $0x4e,%xmm0,%xmm3
  .byte  102,72,15,126,217                   // movq          %xmm3,%rcx
  .byte  68,15,182,201                       // movzbl        %cl,%r9d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,73,15,126,194                   // movq          %xmm0,%r10
  .byte  69,15,182,218                       // movzbl        %r10b,%r11d
  .byte  73,193,234,30                       // shr           $0x1e,%r10
  .byte  243,67,15,16,28,16                  // movss         (%r8,%r10,1),%xmm3
  .byte  243,65,15,16,4,136                  // movss         (%r8,%rcx,4),%xmm0
  .byte  15,20,216                           // unpcklps      %xmm0,%xmm3
  .byte  243,67,15,16,4,152                  // movss         (%r8,%r11,4),%xmm0
  .byte  243,67,15,16,20,136                 // movss         (%r8,%r9,4),%xmm2
  .byte  15,20,194                           // unpcklps      %xmm2,%xmm0
  .byte  15,20,195                           // unpcklps      %xmm3,%xmm0
  .byte  76,139,80,16                        // mov           0x10(%rax),%r10
  .byte  102,65,15,219,200                   // pand          %xmm8,%xmm1
  .byte  102,65,15,97,201                    // punpcklwd     %xmm9,%xmm1
  .byte  102,15,112,209,78                   // pshufd        $0x4e,%xmm1,%xmm2
  .byte  102,73,15,126,208                   // movq          %xmm2,%r8
  .byte  69,15,182,200                       // movzbl        %r8b,%r9d
  .byte  73,193,232,32                       // shr           $0x20,%r8
  .byte  102,72,15,126,201                   // movq          %xmm1,%rcx
  .byte  68,15,182,217                       // movzbl        %cl,%r11d
  .byte  72,193,233,30                       // shr           $0x1e,%rcx
  .byte  243,65,15,16,20,10                  // movss         (%r10,%rcx,1),%xmm2
  .byte  243,67,15,16,12,130                 // movss         (%r10,%r8,4),%xmm1
  .byte  15,20,209                           // unpcklps      %xmm1,%xmm2
  .byte  243,67,15,16,12,154                 // movss         (%r10,%r11,4),%xmm1
  .byte  243,67,15,16,28,138                 // movss         (%r10,%r9,4),%xmm3
  .byte  15,20,203                           // unpcklps      %xmm3,%xmm1
  .byte  15,20,202                           // unpcklps      %xmm2,%xmm1
  .byte  76,139,72,24                        // mov           0x18(%rax),%r9
  .byte  102,69,15,105,218                   // punpckhwd     %xmm10,%xmm11
  .byte  102,69,15,219,216                   // pand          %xmm8,%xmm11
  .byte  102,69,15,97,217                    // punpcklwd     %xmm9,%xmm11
  .byte  102,65,15,112,211,78                // pshufd        $0x4e,%xmm11,%xmm2
  .byte  102,72,15,126,209                   // movq          %xmm2,%rcx
  .byte  68,15,182,193                       // movzbl        %cl,%r8d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,76,15,126,216                   // movq          %xmm11,%rax
  .byte  68,15,182,208                       // movzbl        %al,%r10d
  .byte  72,193,232,30                       // shr           $0x1e,%rax
  .byte  243,69,15,16,4,1                    // movss         (%r9,%rax,1),%xmm8
  .byte  243,65,15,16,20,137                 // movss         (%r9,%rcx,4),%xmm2
  .byte  68,15,20,194                        // unpcklps      %xmm2,%xmm8
  .byte  243,67,15,16,20,145                 // movss         (%r9,%r10,4),%xmm2
  .byte  243,67,15,16,28,129                 // movss         (%r9,%r8,4),%xmm3
  .byte  15,20,211                           // unpcklps      %xmm3,%xmm2
  .byte  65,15,20,208                        // unpcklps      %xmm8,%xmm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_byte_tables_sse2
.globl _sk_byte_tables_sse2
FUNCTION(_sk_byte_tables_sse2)
_sk_byte_tables_sse2:
  .byte  65,86                               // push          %r14
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,127,67                      // mov           $0x437f0000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  102,15,91,192                       // cvtps2dq      %xmm0,%xmm0
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,15,112,192,78                   // pshufd        $0x4e,%xmm0,%xmm0
  .byte  102,73,15,126,193                   // movq          %xmm0,%r9
  .byte  69,137,202                          // mov           %r9d,%r10d
  .byte  77,137,203                          // mov           %r9,%r11
  .byte  73,193,235,32                       // shr           $0x20,%r11
  .byte  76,139,48                           // mov           (%rax),%r14
  .byte  76,139,72,8                         // mov           0x8(%rax),%r9
  .byte  71,15,182,20,22                     // movzbl        (%r14,%r10,1),%r10d
  .byte  67,15,182,28,30                     // movzbl        (%r14,%r11,1),%ebx
  .byte  193,227,8                           // shl           $0x8,%ebx
  .byte  68,9,211                            // or            %r10d,%ebx
  .byte  71,15,182,4,6                       // movzbl        (%r14,%r8,1),%r8d
  .byte  65,15,182,12,14                     // movzbl        (%r14,%rcx,1),%ecx
  .byte  193,225,8                           // shl           $0x8,%ecx
  .byte  68,9,193                            // or            %r8d,%ecx
  .byte  102,15,196,193,0                    // pinsrw        $0x0,%ecx,%xmm0
  .byte  102,15,196,195,1                    // pinsrw        $0x1,%ebx,%xmm0
  .byte  102,69,15,239,201                   // pxor          %xmm9,%xmm9
  .byte  102,65,15,96,193                    // punpcklbw     %xmm9,%xmm0
  .byte  102,65,15,97,193                    // punpcklwd     %xmm9,%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  185,129,128,128,59                  // mov           $0x3b808081,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  65,15,89,194                        // mulps         %xmm10,%xmm0
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  102,15,91,201                       // cvtps2dq      %xmm1,%xmm1
  .byte  102,72,15,126,201                   // movq          %xmm1,%rcx
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,15,112,201,78                   // pshufd        $0x4e,%xmm1,%xmm1
  .byte  102,72,15,126,203                   // movq          %xmm1,%rbx
  .byte  65,137,218                          // mov           %ebx,%r10d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  71,15,182,20,17                     // movzbl        (%r9,%r10,1),%r10d
  .byte  65,15,182,28,25                     // movzbl        (%r9,%rbx,1),%ebx
  .byte  193,227,8                           // shl           $0x8,%ebx
  .byte  68,9,211                            // or            %r10d,%ebx
  .byte  71,15,182,4,1                       // movzbl        (%r9,%r8,1),%r8d
  .byte  65,15,182,12,9                      // movzbl        (%r9,%rcx,1),%ecx
  .byte  193,225,8                           // shl           $0x8,%ecx
  .byte  68,9,193                            // or            %r8d,%ecx
  .byte  102,15,196,201,0                    // pinsrw        $0x0,%ecx,%xmm1
  .byte  102,15,196,203,1                    // pinsrw        $0x1,%ebx,%xmm1
  .byte  102,65,15,96,201                    // punpcklbw     %xmm9,%xmm1
  .byte  102,65,15,97,201                    // punpcklwd     %xmm9,%xmm1
  .byte  15,91,201                           // cvtdq2ps      %xmm1,%xmm1
  .byte  65,15,89,202                        // mulps         %xmm10,%xmm1
  .byte  76,139,72,16                        // mov           0x10(%rax),%r9
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  102,15,91,210                       // cvtps2dq      %xmm2,%xmm2
  .byte  102,72,15,126,211                   // movq          %xmm2,%rbx
  .byte  65,137,216                          // mov           %ebx,%r8d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  102,15,112,210,78                   // pshufd        $0x4e,%xmm2,%xmm2
  .byte  102,72,15,126,209                   // movq          %xmm2,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  71,15,182,20,17                     // movzbl        (%r9,%r10,1),%r10d
  .byte  65,15,182,12,9                      // movzbl        (%r9,%rcx,1),%ecx
  .byte  193,225,8                           // shl           $0x8,%ecx
  .byte  68,9,209                            // or            %r10d,%ecx
  .byte  71,15,182,4,1                       // movzbl        (%r9,%r8,1),%r8d
  .byte  65,15,182,28,25                     // movzbl        (%r9,%rbx,1),%ebx
  .byte  193,227,8                           // shl           $0x8,%ebx
  .byte  68,9,195                            // or            %r8d,%ebx
  .byte  102,15,196,211,0                    // pinsrw        $0x0,%ebx,%xmm2
  .byte  102,15,196,209,1                    // pinsrw        $0x1,%ecx,%xmm2
  .byte  102,65,15,96,209                    // punpcklbw     %xmm9,%xmm2
  .byte  102,65,15,97,209                    // punpcklwd     %xmm9,%xmm2
  .byte  15,91,210                           // cvtdq2ps      %xmm2,%xmm2
  .byte  65,15,89,210                        // mulps         %xmm10,%xmm2
  .byte  72,139,64,24                        // mov           0x18(%rax),%rax
  .byte  68,15,89,195                        // mulps         %xmm3,%xmm8
  .byte  102,65,15,91,216                    // cvtps2dq      %xmm8,%xmm3
  .byte  102,72,15,126,217                   // movq          %xmm3,%rcx
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,15,112,219,78                   // pshufd        $0x4e,%xmm3,%xmm3
  .byte  102,72,15,126,219                   // movq          %xmm3,%rbx
  .byte  65,137,217                          // mov           %ebx,%r9d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  70,15,182,12,8                      // movzbl        (%rax,%r9,1),%r9d
  .byte  15,182,28,24                        // movzbl        (%rax,%rbx,1),%ebx
  .byte  193,227,8                           // shl           $0x8,%ebx
  .byte  68,9,203                            // or            %r9d,%ebx
  .byte  70,15,182,4,0                       // movzbl        (%rax,%r8,1),%r8d
  .byte  15,182,4,8                          // movzbl        (%rax,%rcx,1),%eax
  .byte  193,224,8                           // shl           $0x8,%eax
  .byte  68,9,192                            // or            %r8d,%eax
  .byte  102,15,196,216,0                    // pinsrw        $0x0,%eax,%xmm3
  .byte  102,15,196,219,1                    // pinsrw        $0x1,%ebx,%xmm3
  .byte  102,65,15,96,217                    // punpcklbw     %xmm9,%xmm3
  .byte  102,65,15,97,217                    // punpcklwd     %xmm9,%xmm3
  .byte  15,91,219                           // cvtdq2ps      %xmm3,%xmm3
  .byte  65,15,89,218                        // mulps         %xmm10,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,94                               // pop           %r14
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_byte_tables_rgb_sse2
.globl _sk_byte_tables_rgb_sse2
FUNCTION(_sk_byte_tables_rgb_sse2)
_sk_byte_tables_rgb_sse2:
  .byte  65,86                               // push          %r14
  .byte  83                                  // push          %rbx
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  139,72,24                           // mov           0x18(%rax),%ecx
  .byte  255,201                             // dec           %ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  102,69,15,112,192,0                 // pshufd        $0x0,%xmm8,%xmm8
  .byte  69,15,91,192                        // cvtdq2ps      %xmm8,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  102,15,91,192                       // cvtps2dq      %xmm0,%xmm0
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,15,112,192,78                   // pshufd        $0x4e,%xmm0,%xmm0
  .byte  102,73,15,126,193                   // movq          %xmm0,%r9
  .byte  69,137,202                          // mov           %r9d,%r10d
  .byte  77,137,203                          // mov           %r9,%r11
  .byte  73,193,235,32                       // shr           $0x20,%r11
  .byte  76,139,48                           // mov           (%rax),%r14
  .byte  76,139,72,8                         // mov           0x8(%rax),%r9
  .byte  71,15,182,20,22                     // movzbl        (%r14,%r10,1),%r10d
  .byte  67,15,182,28,30                     // movzbl        (%r14,%r11,1),%ebx
  .byte  193,227,8                           // shl           $0x8,%ebx
  .byte  68,9,211                            // or            %r10d,%ebx
  .byte  71,15,182,4,6                       // movzbl        (%r14,%r8,1),%r8d
  .byte  65,15,182,12,14                     // movzbl        (%r14,%rcx,1),%ecx
  .byte  193,225,8                           // shl           $0x8,%ecx
  .byte  68,9,193                            // or            %r8d,%ecx
  .byte  102,15,196,193,0                    // pinsrw        $0x0,%ecx,%xmm0
  .byte  102,15,196,195,1                    // pinsrw        $0x1,%ebx,%xmm0
  .byte  102,69,15,239,201                   // pxor          %xmm9,%xmm9
  .byte  102,65,15,96,193                    // punpcklbw     %xmm9,%xmm0
  .byte  102,65,15,97,193                    // punpcklwd     %xmm9,%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  185,129,128,128,59                  // mov           $0x3b808081,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  65,15,89,194                        // mulps         %xmm10,%xmm0
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  102,15,91,201                       // cvtps2dq      %xmm1,%xmm1
  .byte  102,72,15,126,201                   // movq          %xmm1,%rcx
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,15,112,201,78                   // pshufd        $0x4e,%xmm1,%xmm1
  .byte  102,72,15,126,203                   // movq          %xmm1,%rbx
  .byte  65,137,218                          // mov           %ebx,%r10d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  71,15,182,20,17                     // movzbl        (%r9,%r10,1),%r10d
  .byte  65,15,182,28,25                     // movzbl        (%r9,%rbx,1),%ebx
  .byte  193,227,8                           // shl           $0x8,%ebx
  .byte  68,9,211                            // or            %r10d,%ebx
  .byte  71,15,182,4,1                       // movzbl        (%r9,%r8,1),%r8d
  .byte  65,15,182,12,9                      // movzbl        (%r9,%rcx,1),%ecx
  .byte  193,225,8                           // shl           $0x8,%ecx
  .byte  68,9,193                            // or            %r8d,%ecx
  .byte  102,15,196,201,0                    // pinsrw        $0x0,%ecx,%xmm1
  .byte  102,15,196,203,1                    // pinsrw        $0x1,%ebx,%xmm1
  .byte  102,65,15,96,201                    // punpcklbw     %xmm9,%xmm1
  .byte  102,65,15,97,201                    // punpcklwd     %xmm9,%xmm1
  .byte  15,91,201                           // cvtdq2ps      %xmm1,%xmm1
  .byte  65,15,89,202                        // mulps         %xmm10,%xmm1
  .byte  72,139,64,16                        // mov           0x10(%rax),%rax
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  102,15,91,210                       // cvtps2dq      %xmm2,%xmm2
  .byte  102,72,15,126,209                   // movq          %xmm2,%rcx
  .byte  65,137,200                          // mov           %ecx,%r8d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,15,112,210,78                   // pshufd        $0x4e,%xmm2,%xmm2
  .byte  102,72,15,126,211                   // movq          %xmm2,%rbx
  .byte  65,137,217                          // mov           %ebx,%r9d
  .byte  72,193,235,32                       // shr           $0x20,%rbx
  .byte  70,15,182,12,8                      // movzbl        (%rax,%r9,1),%r9d
  .byte  15,182,28,24                        // movzbl        (%rax,%rbx,1),%ebx
  .byte  193,227,8                           // shl           $0x8,%ebx
  .byte  68,9,203                            // or            %r9d,%ebx
  .byte  70,15,182,4,0                       // movzbl        (%rax,%r8,1),%r8d
  .byte  15,182,4,8                          // movzbl        (%rax,%rcx,1),%eax
  .byte  193,224,8                           // shl           $0x8,%eax
  .byte  68,9,192                            // or            %r8d,%eax
  .byte  102,15,196,208,0                    // pinsrw        $0x0,%eax,%xmm2
  .byte  102,15,196,211,1                    // pinsrw        $0x1,%ebx,%xmm2
  .byte  102,65,15,96,209                    // punpcklbw     %xmm9,%xmm2
  .byte  102,65,15,97,209                    // punpcklwd     %xmm9,%xmm2
  .byte  15,91,210                           // cvtdq2ps      %xmm2,%xmm2
  .byte  65,15,89,210                        // mulps         %xmm10,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  91                                  // pop           %rbx
  .byte  65,94                               // pop           %r14
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_table_r_sse2
.globl _sk_table_r_sse2
FUNCTION(_sk_table_r_sse2)
_sk_table_r_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  139,64,8                            // mov           0x8(%rax),%eax
  .byte  255,200                             // dec           %eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  102,69,15,112,192,0                 // pshufd        $0x0,%xmm8,%xmm8
  .byte  69,15,91,192                        // cvtdq2ps      %xmm8,%xmm8
  .byte  68,15,89,192                        // mulps         %xmm0,%xmm8
  .byte  102,69,15,91,192                    // cvtps2dq      %xmm8,%xmm8
  .byte  102,65,15,112,192,78                // pshufd        $0x4e,%xmm8,%xmm0
  .byte  102,72,15,126,192                   // movq          %xmm0,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,76,15,126,193                   // movq          %xmm8,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  243,69,15,16,4,137                  // movss         (%r9,%rcx,4),%xmm8
  .byte  243,65,15,16,4,129                  // movss         (%r9,%rax,4),%xmm0
  .byte  68,15,20,192                        // unpcklps      %xmm0,%xmm8
  .byte  243,67,15,16,4,145                  // movss         (%r9,%r10,4),%xmm0
  .byte  243,71,15,16,12,129                 // movss         (%r9,%r8,4),%xmm9
  .byte  65,15,20,193                        // unpcklps      %xmm9,%xmm0
  .byte  65,15,20,192                        // unpcklps      %xmm8,%xmm0
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_table_g_sse2
.globl _sk_table_g_sse2
FUNCTION(_sk_table_g_sse2)
_sk_table_g_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  139,64,8                            // mov           0x8(%rax),%eax
  .byte  255,200                             // dec           %eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  102,69,15,112,192,0                 // pshufd        $0x0,%xmm8,%xmm8
  .byte  69,15,91,192                        // cvtdq2ps      %xmm8,%xmm8
  .byte  68,15,89,193                        // mulps         %xmm1,%xmm8
  .byte  102,69,15,91,192                    // cvtps2dq      %xmm8,%xmm8
  .byte  102,65,15,112,200,78                // pshufd        $0x4e,%xmm8,%xmm1
  .byte  102,72,15,126,200                   // movq          %xmm1,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,76,15,126,193                   // movq          %xmm8,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  243,69,15,16,4,137                  // movss         (%r9,%rcx,4),%xmm8
  .byte  243,65,15,16,12,129                 // movss         (%r9,%rax,4),%xmm1
  .byte  68,15,20,193                        // unpcklps      %xmm1,%xmm8
  .byte  243,67,15,16,12,145                 // movss         (%r9,%r10,4),%xmm1
  .byte  243,71,15,16,12,129                 // movss         (%r9,%r8,4),%xmm9
  .byte  65,15,20,201                        // unpcklps      %xmm9,%xmm1
  .byte  65,15,20,200                        // unpcklps      %xmm8,%xmm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_table_b_sse2
.globl _sk_table_b_sse2
FUNCTION(_sk_table_b_sse2)
_sk_table_b_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  139,64,8                            // mov           0x8(%rax),%eax
  .byte  255,200                             // dec           %eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  102,69,15,112,192,0                 // pshufd        $0x0,%xmm8,%xmm8
  .byte  69,15,91,192                        // cvtdq2ps      %xmm8,%xmm8
  .byte  68,15,89,194                        // mulps         %xmm2,%xmm8
  .byte  102,69,15,91,192                    // cvtps2dq      %xmm8,%xmm8
  .byte  102,65,15,112,208,78                // pshufd        $0x4e,%xmm8,%xmm2
  .byte  102,72,15,126,208                   // movq          %xmm2,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,76,15,126,193                   // movq          %xmm8,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  243,69,15,16,4,137                  // movss         (%r9,%rcx,4),%xmm8
  .byte  243,65,15,16,20,129                 // movss         (%r9,%rax,4),%xmm2
  .byte  68,15,20,194                        // unpcklps      %xmm2,%xmm8
  .byte  243,67,15,16,20,145                 // movss         (%r9,%r10,4),%xmm2
  .byte  243,71,15,16,12,129                 // movss         (%r9,%r8,4),%xmm9
  .byte  65,15,20,209                        // unpcklps      %xmm9,%xmm2
  .byte  65,15,20,208                        // unpcklps      %xmm8,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_table_a_sse2
.globl _sk_table_a_sse2
FUNCTION(_sk_table_a_sse2)
_sk_table_a_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  139,64,8                            // mov           0x8(%rax),%eax
  .byte  255,200                             // dec           %eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  102,69,15,112,192,0                 // pshufd        $0x0,%xmm8,%xmm8
  .byte  69,15,91,192                        // cvtdq2ps      %xmm8,%xmm8
  .byte  68,15,89,195                        // mulps         %xmm3,%xmm8
  .byte  102,69,15,91,192                    // cvtps2dq      %xmm8,%xmm8
  .byte  102,65,15,112,216,78                // pshufd        $0x4e,%xmm8,%xmm3
  .byte  102,72,15,126,216                   // movq          %xmm3,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,76,15,126,193                   // movq          %xmm8,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  243,69,15,16,4,137                  // movss         (%r9,%rcx,4),%xmm8
  .byte  243,65,15,16,28,129                 // movss         (%r9,%rax,4),%xmm3
  .byte  68,15,20,195                        // unpcklps      %xmm3,%xmm8
  .byte  243,67,15,16,28,145                 // movss         (%r9,%r10,4),%xmm3
  .byte  243,71,15,16,12,129                 // movss         (%r9,%r8,4),%xmm9
  .byte  65,15,20,217                        // unpcklps      %xmm9,%xmm3
  .byte  65,15,20,216                        // unpcklps      %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_parametric_r_sse2
.globl _sk_parametric_r_sse2
FUNCTION(_sk_parametric_r_sse2)
_sk_parametric_r_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,72,16                  // movss         0x10(%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  243,68,15,16,64,12                  // movss         0xc(%rax),%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,89,192                        // mulps         %xmm0,%xmm8
  .byte  243,68,15,16,80,4                   // movss         0x4(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  68,15,89,208                        // mulps         %xmm0,%xmm10
  .byte  65,15,194,193,2                     // cmpleps       %xmm9,%xmm0
  .byte  243,68,15,16,72,24                  // movss         0x18(%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  69,15,88,193                        // addps         %xmm9,%xmm8
  .byte  243,68,15,16,24                     // movss         (%rax),%xmm11
  .byte  243,68,15,16,72,8                   // movss         0x8(%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  69,15,88,209                        // addps         %xmm9,%xmm10
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,91,202                        // cvtdq2ps      %xmm10,%xmm9
  .byte  68,15,89,13,189,36,0,0              // mulps         0x24bd(%rip),%xmm9        # 4390 <_sk_callback_sse2+0x132>
  .byte  68,15,84,21,197,36,0,0              // andps         0x24c5(%rip),%xmm10        # 43a0 <_sk_callback_sse2+0x142>
  .byte  68,15,86,21,205,36,0,0              // orps          0x24cd(%rip),%xmm10        # 43b0 <_sk_callback_sse2+0x152>
  .byte  68,15,88,13,213,36,0,0              // addps         0x24d5(%rip),%xmm9        # 43c0 <_sk_callback_sse2+0x162>
  .byte  68,15,40,37,221,36,0,0              // movaps        0x24dd(%rip),%xmm12        # 43d0 <_sk_callback_sse2+0x172>
  .byte  69,15,89,226                        // mulps         %xmm10,%xmm12
  .byte  69,15,92,204                        // subps         %xmm12,%xmm9
  .byte  68,15,88,21,221,36,0,0              // addps         0x24dd(%rip),%xmm10        # 43e0 <_sk_callback_sse2+0x182>
  .byte  68,15,40,37,229,36,0,0              // movaps        0x24e5(%rip),%xmm12        # 43f0 <_sk_callback_sse2+0x192>
  .byte  69,15,94,226                        // divps         %xmm10,%xmm12
  .byte  69,15,92,204                        // subps         %xmm12,%xmm9
  .byte  69,15,89,203                        // mulps         %xmm11,%xmm9
  .byte  243,69,15,91,209                    // cvttps2dq     %xmm9,%xmm10
  .byte  69,15,91,218                        // cvtdq2ps      %xmm10,%xmm11
  .byte  69,15,40,225                        // movaps        %xmm9,%xmm12
  .byte  69,15,194,227,1                     // cmpltps       %xmm11,%xmm12
  .byte  68,15,84,37,207,36,0,0              // andps         0x24cf(%rip),%xmm12        # 4400 <_sk_callback_sse2+0x1a2>
  .byte  69,15,87,210                        // xorps         %xmm10,%xmm10
  .byte  69,15,92,220                        // subps         %xmm12,%xmm11
  .byte  69,15,40,225                        // movaps        %xmm9,%xmm12
  .byte  69,15,92,227                        // subps         %xmm11,%xmm12
  .byte  68,15,88,13,199,36,0,0              // addps         0x24c7(%rip),%xmm9        # 4410 <_sk_callback_sse2+0x1b2>
  .byte  68,15,40,29,207,36,0,0              // movaps        0x24cf(%rip),%xmm11        # 4420 <_sk_callback_sse2+0x1c2>
  .byte  69,15,89,220                        // mulps         %xmm12,%xmm11
  .byte  69,15,92,203                        // subps         %xmm11,%xmm9
  .byte  68,15,40,29,207,36,0,0              // movaps        0x24cf(%rip),%xmm11        # 4430 <_sk_callback_sse2+0x1d2>
  .byte  69,15,92,220                        // subps         %xmm12,%xmm11
  .byte  68,15,40,37,211,36,0,0              // movaps        0x24d3(%rip),%xmm12        # 4440 <_sk_callback_sse2+0x1e2>
  .byte  69,15,94,227                        // divps         %xmm11,%xmm12
  .byte  69,15,88,225                        // addps         %xmm9,%xmm12
  .byte  68,15,89,37,211,36,0,0              // mulps         0x24d3(%rip),%xmm12        # 4450 <_sk_callback_sse2+0x1f2>
  .byte  102,69,15,91,204                    // cvtps2dq      %xmm12,%xmm9
  .byte  243,68,15,16,88,20                  // movss         0x14(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,88,217                        // addps         %xmm9,%xmm11
  .byte  68,15,84,192                        // andps         %xmm0,%xmm8
  .byte  65,15,85,195                        // andnps        %xmm11,%xmm0
  .byte  65,15,86,192                        // orps          %xmm8,%xmm0
  .byte  65,15,95,194                        // maxps         %xmm10,%xmm0
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,93,192                        // minps         %xmm8,%xmm0
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_parametric_g_sse2
.globl _sk_parametric_g_sse2
FUNCTION(_sk_parametric_g_sse2)
_sk_parametric_g_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,72,16                  // movss         0x10(%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  243,68,15,16,64,12                  // movss         0xc(%rax),%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,89,193                        // mulps         %xmm1,%xmm8
  .byte  243,68,15,16,80,4                   // movss         0x4(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  68,15,89,209                        // mulps         %xmm1,%xmm10
  .byte  65,15,194,201,2                     // cmpleps       %xmm9,%xmm1
  .byte  243,68,15,16,72,24                  // movss         0x18(%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  69,15,88,193                        // addps         %xmm9,%xmm8
  .byte  243,68,15,16,24                     // movss         (%rax),%xmm11
  .byte  243,68,15,16,72,8                   // movss         0x8(%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  69,15,88,209                        // addps         %xmm9,%xmm10
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,91,202                        // cvtdq2ps      %xmm10,%xmm9
  .byte  68,15,89,13,68,36,0,0               // mulps         0x2444(%rip),%xmm9        # 4460 <_sk_callback_sse2+0x202>
  .byte  68,15,84,21,76,36,0,0               // andps         0x244c(%rip),%xmm10        # 4470 <_sk_callback_sse2+0x212>
  .byte  68,15,86,21,84,36,0,0               // orps          0x2454(%rip),%xmm10        # 4480 <_sk_callback_sse2+0x222>
  .byte  68,15,88,13,92,36,0,0               // addps         0x245c(%rip),%xmm9        # 4490 <_sk_callback_sse2+0x232>
  .byte  68,15,40,37,100,36,0,0              // movaps        0x2464(%rip),%xmm12        # 44a0 <_sk_callback_sse2+0x242>
  .byte  69,15,89,226                        // mulps         %xmm10,%xmm12
  .byte  69,15,92,204                        // subps         %xmm12,%xmm9
  .byte  68,15,88,21,100,36,0,0              // addps         0x2464(%rip),%xmm10        # 44b0 <_sk_callback_sse2+0x252>
  .byte  68,15,40,37,108,36,0,0              // movaps        0x246c(%rip),%xmm12        # 44c0 <_sk_callback_sse2+0x262>
  .byte  69,15,94,226                        // divps         %xmm10,%xmm12
  .byte  69,15,92,204                        // subps         %xmm12,%xmm9
  .byte  69,15,89,203                        // mulps         %xmm11,%xmm9
  .byte  243,69,15,91,209                    // cvttps2dq     %xmm9,%xmm10
  .byte  69,15,91,218                        // cvtdq2ps      %xmm10,%xmm11
  .byte  69,15,40,225                        // movaps        %xmm9,%xmm12
  .byte  69,15,194,227,1                     // cmpltps       %xmm11,%xmm12
  .byte  68,15,84,37,86,36,0,0               // andps         0x2456(%rip),%xmm12        # 44d0 <_sk_callback_sse2+0x272>
  .byte  69,15,87,210                        // xorps         %xmm10,%xmm10
  .byte  69,15,92,220                        // subps         %xmm12,%xmm11
  .byte  69,15,40,225                        // movaps        %xmm9,%xmm12
  .byte  69,15,92,227                        // subps         %xmm11,%xmm12
  .byte  68,15,88,13,78,36,0,0               // addps         0x244e(%rip),%xmm9        # 44e0 <_sk_callback_sse2+0x282>
  .byte  68,15,40,29,86,36,0,0               // movaps        0x2456(%rip),%xmm11        # 44f0 <_sk_callback_sse2+0x292>
  .byte  69,15,89,220                        // mulps         %xmm12,%xmm11
  .byte  69,15,92,203                        // subps         %xmm11,%xmm9
  .byte  68,15,40,29,86,36,0,0               // movaps        0x2456(%rip),%xmm11        # 4500 <_sk_callback_sse2+0x2a2>
  .byte  69,15,92,220                        // subps         %xmm12,%xmm11
  .byte  68,15,40,37,90,36,0,0               // movaps        0x245a(%rip),%xmm12        # 4510 <_sk_callback_sse2+0x2b2>
  .byte  69,15,94,227                        // divps         %xmm11,%xmm12
  .byte  69,15,88,225                        // addps         %xmm9,%xmm12
  .byte  68,15,89,37,90,36,0,0               // mulps         0x245a(%rip),%xmm12        # 4520 <_sk_callback_sse2+0x2c2>
  .byte  102,69,15,91,204                    // cvtps2dq      %xmm12,%xmm9
  .byte  243,68,15,16,88,20                  // movss         0x14(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,88,217                        // addps         %xmm9,%xmm11
  .byte  68,15,84,193                        // andps         %xmm1,%xmm8
  .byte  65,15,85,203                        // andnps        %xmm11,%xmm1
  .byte  65,15,86,200                        // orps          %xmm8,%xmm1
  .byte  65,15,95,202                        // maxps         %xmm10,%xmm1
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,93,200                        // minps         %xmm8,%xmm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_parametric_b_sse2
.globl _sk_parametric_b_sse2
FUNCTION(_sk_parametric_b_sse2)
_sk_parametric_b_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,72,16                  // movss         0x10(%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  243,68,15,16,64,12                  // movss         0xc(%rax),%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,89,194                        // mulps         %xmm2,%xmm8
  .byte  243,68,15,16,80,4                   // movss         0x4(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  68,15,89,210                        // mulps         %xmm2,%xmm10
  .byte  65,15,194,209,2                     // cmpleps       %xmm9,%xmm2
  .byte  243,68,15,16,72,24                  // movss         0x18(%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  69,15,88,193                        // addps         %xmm9,%xmm8
  .byte  243,68,15,16,24                     // movss         (%rax),%xmm11
  .byte  243,68,15,16,72,8                   // movss         0x8(%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  69,15,88,209                        // addps         %xmm9,%xmm10
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,91,202                        // cvtdq2ps      %xmm10,%xmm9
  .byte  68,15,89,13,203,35,0,0              // mulps         0x23cb(%rip),%xmm9        # 4530 <_sk_callback_sse2+0x2d2>
  .byte  68,15,84,21,211,35,0,0              // andps         0x23d3(%rip),%xmm10        # 4540 <_sk_callback_sse2+0x2e2>
  .byte  68,15,86,21,219,35,0,0              // orps          0x23db(%rip),%xmm10        # 4550 <_sk_callback_sse2+0x2f2>
  .byte  68,15,88,13,227,35,0,0              // addps         0x23e3(%rip),%xmm9        # 4560 <_sk_callback_sse2+0x302>
  .byte  68,15,40,37,235,35,0,0              // movaps        0x23eb(%rip),%xmm12        # 4570 <_sk_callback_sse2+0x312>
  .byte  69,15,89,226                        // mulps         %xmm10,%xmm12
  .byte  69,15,92,204                        // subps         %xmm12,%xmm9
  .byte  68,15,88,21,235,35,0,0              // addps         0x23eb(%rip),%xmm10        # 4580 <_sk_callback_sse2+0x322>
  .byte  68,15,40,37,243,35,0,0              // movaps        0x23f3(%rip),%xmm12        # 4590 <_sk_callback_sse2+0x332>
  .byte  69,15,94,226                        // divps         %xmm10,%xmm12
  .byte  69,15,92,204                        // subps         %xmm12,%xmm9
  .byte  69,15,89,203                        // mulps         %xmm11,%xmm9
  .byte  243,69,15,91,209                    // cvttps2dq     %xmm9,%xmm10
  .byte  69,15,91,218                        // cvtdq2ps      %xmm10,%xmm11
  .byte  69,15,40,225                        // movaps        %xmm9,%xmm12
  .byte  69,15,194,227,1                     // cmpltps       %xmm11,%xmm12
  .byte  68,15,84,37,221,35,0,0              // andps         0x23dd(%rip),%xmm12        # 45a0 <_sk_callback_sse2+0x342>
  .byte  69,15,87,210                        // xorps         %xmm10,%xmm10
  .byte  69,15,92,220                        // subps         %xmm12,%xmm11
  .byte  69,15,40,225                        // movaps        %xmm9,%xmm12
  .byte  69,15,92,227                        // subps         %xmm11,%xmm12
  .byte  68,15,88,13,213,35,0,0              // addps         0x23d5(%rip),%xmm9        # 45b0 <_sk_callback_sse2+0x352>
  .byte  68,15,40,29,221,35,0,0              // movaps        0x23dd(%rip),%xmm11        # 45c0 <_sk_callback_sse2+0x362>
  .byte  69,15,89,220                        // mulps         %xmm12,%xmm11
  .byte  69,15,92,203                        // subps         %xmm11,%xmm9
  .byte  68,15,40,29,221,35,0,0              // movaps        0x23dd(%rip),%xmm11        # 45d0 <_sk_callback_sse2+0x372>
  .byte  69,15,92,220                        // subps         %xmm12,%xmm11
  .byte  68,15,40,37,225,35,0,0              // movaps        0x23e1(%rip),%xmm12        # 45e0 <_sk_callback_sse2+0x382>
  .byte  69,15,94,227                        // divps         %xmm11,%xmm12
  .byte  69,15,88,225                        // addps         %xmm9,%xmm12
  .byte  68,15,89,37,225,35,0,0              // mulps         0x23e1(%rip),%xmm12        # 45f0 <_sk_callback_sse2+0x392>
  .byte  102,69,15,91,204                    // cvtps2dq      %xmm12,%xmm9
  .byte  243,68,15,16,88,20                  // movss         0x14(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,88,217                        // addps         %xmm9,%xmm11
  .byte  68,15,84,194                        // andps         %xmm2,%xmm8
  .byte  65,15,85,211                        // andnps        %xmm11,%xmm2
  .byte  65,15,86,208                        // orps          %xmm8,%xmm2
  .byte  65,15,95,210                        // maxps         %xmm10,%xmm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,93,208                        // minps         %xmm8,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_parametric_a_sse2
.globl _sk_parametric_a_sse2
FUNCTION(_sk_parametric_a_sse2)
_sk_parametric_a_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,72,16                  // movss         0x10(%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  243,68,15,16,64,12                  // movss         0xc(%rax),%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,89,195                        // mulps         %xmm3,%xmm8
  .byte  243,68,15,16,80,4                   // movss         0x4(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  68,15,89,211                        // mulps         %xmm3,%xmm10
  .byte  65,15,194,217,2                     // cmpleps       %xmm9,%xmm3
  .byte  243,68,15,16,72,24                  // movss         0x18(%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  69,15,88,193                        // addps         %xmm9,%xmm8
  .byte  243,68,15,16,24                     // movss         (%rax),%xmm11
  .byte  243,68,15,16,72,8                   // movss         0x8(%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  69,15,88,209                        // addps         %xmm9,%xmm10
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,91,202                        // cvtdq2ps      %xmm10,%xmm9
  .byte  68,15,89,13,82,35,0,0               // mulps         0x2352(%rip),%xmm9        # 4600 <_sk_callback_sse2+0x3a2>
  .byte  68,15,84,21,90,35,0,0               // andps         0x235a(%rip),%xmm10        # 4610 <_sk_callback_sse2+0x3b2>
  .byte  68,15,86,21,98,35,0,0               // orps          0x2362(%rip),%xmm10        # 4620 <_sk_callback_sse2+0x3c2>
  .byte  68,15,88,13,106,35,0,0              // addps         0x236a(%rip),%xmm9        # 4630 <_sk_callback_sse2+0x3d2>
  .byte  68,15,40,37,114,35,0,0              // movaps        0x2372(%rip),%xmm12        # 4640 <_sk_callback_sse2+0x3e2>
  .byte  69,15,89,226                        // mulps         %xmm10,%xmm12
  .byte  69,15,92,204                        // subps         %xmm12,%xmm9
  .byte  68,15,88,21,114,35,0,0              // addps         0x2372(%rip),%xmm10        # 4650 <_sk_callback_sse2+0x3f2>
  .byte  68,15,40,37,122,35,0,0              // movaps        0x237a(%rip),%xmm12        # 4660 <_sk_callback_sse2+0x402>
  .byte  69,15,94,226                        // divps         %xmm10,%xmm12
  .byte  69,15,92,204                        // subps         %xmm12,%xmm9
  .byte  69,15,89,203                        // mulps         %xmm11,%xmm9
  .byte  243,69,15,91,209                    // cvttps2dq     %xmm9,%xmm10
  .byte  69,15,91,218                        // cvtdq2ps      %xmm10,%xmm11
  .byte  69,15,40,225                        // movaps        %xmm9,%xmm12
  .byte  69,15,194,227,1                     // cmpltps       %xmm11,%xmm12
  .byte  68,15,84,37,100,35,0,0              // andps         0x2364(%rip),%xmm12        # 4670 <_sk_callback_sse2+0x412>
  .byte  69,15,87,210                        // xorps         %xmm10,%xmm10
  .byte  69,15,92,220                        // subps         %xmm12,%xmm11
  .byte  69,15,40,225                        // movaps        %xmm9,%xmm12
  .byte  69,15,92,227                        // subps         %xmm11,%xmm12
  .byte  68,15,88,13,92,35,0,0               // addps         0x235c(%rip),%xmm9        # 4680 <_sk_callback_sse2+0x422>
  .byte  68,15,40,29,100,35,0,0              // movaps        0x2364(%rip),%xmm11        # 4690 <_sk_callback_sse2+0x432>
  .byte  69,15,89,220                        // mulps         %xmm12,%xmm11
  .byte  69,15,92,203                        // subps         %xmm11,%xmm9
  .byte  68,15,40,29,100,35,0,0              // movaps        0x2364(%rip),%xmm11        # 46a0 <_sk_callback_sse2+0x442>
  .byte  69,15,92,220                        // subps         %xmm12,%xmm11
  .byte  68,15,40,37,104,35,0,0              // movaps        0x2368(%rip),%xmm12        # 46b0 <_sk_callback_sse2+0x452>
  .byte  69,15,94,227                        // divps         %xmm11,%xmm12
  .byte  69,15,88,225                        // addps         %xmm9,%xmm12
  .byte  68,15,89,37,104,35,0,0              // mulps         0x2368(%rip),%xmm12        # 46c0 <_sk_callback_sse2+0x462>
  .byte  102,69,15,91,204                    // cvtps2dq      %xmm12,%xmm9
  .byte  243,68,15,16,88,20                  // movss         0x14(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,88,217                        // addps         %xmm9,%xmm11
  .byte  68,15,84,195                        // andps         %xmm3,%xmm8
  .byte  65,15,85,219                        // andnps        %xmm11,%xmm3
  .byte  65,15,86,216                        // orps          %xmm8,%xmm3
  .byte  65,15,95,218                        // maxps         %xmm10,%xmm3
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,93,216                        // minps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_lab_to_xyz_sse2
.globl _sk_lab_to_xyz_sse2
FUNCTION(_sk_lab_to_xyz_sse2)
_sk_lab_to_xyz_sse2:
  .byte  184,0,0,200,66                      // mov           $0x42c80000,%eax
  .byte  102,68,15,110,200                   // movd          %eax,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  68,15,89,200                        // mulps         %xmm0,%xmm9
  .byte  184,0,0,127,67                      // mov           $0x437f0000,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  184,0,0,0,67                        // mov           $0x43000000,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,92,200                           // subps         %xmm0,%xmm1
  .byte  68,15,89,194                        // mulps         %xmm2,%xmm8
  .byte  68,15,92,192                        // subps         %xmm0,%xmm8
  .byte  184,0,0,128,65                      // mov           $0x41800000,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  65,15,88,209                        // addps         %xmm9,%xmm2
  .byte  184,203,61,13,60                    // mov           $0x3c0d3dcb,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,89,194                           // mulps         %xmm2,%xmm0
  .byte  184,111,18,3,59                     // mov           $0x3b03126f,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  15,89,209                           // mulps         %xmm1,%xmm2
  .byte  15,88,208                           // addps         %xmm0,%xmm2
  .byte  184,10,215,163,59                   // mov           $0x3ba3d70a,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  68,15,40,208                        // movaps        %xmm0,%xmm10
  .byte  68,15,92,209                        // subps         %xmm1,%xmm10
  .byte  15,40,202                           // movaps        %xmm2,%xmm1
  .byte  15,89,201                           // mulps         %xmm1,%xmm1
  .byte  15,89,202                           // mulps         %xmm2,%xmm1
  .byte  184,194,24,17,60                    // mov           $0x3c1118c2,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,194,201,1                     // cmpltps       %xmm1,%xmm9
  .byte  184,203,61,13,62                    // mov           $0x3e0d3dcb,%eax
  .byte  102,68,15,110,216                   // movd          %eax,%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  65,15,92,211                        // subps         %xmm11,%xmm2
  .byte  184,80,128,3,62                     // mov           $0x3e038050,%eax
  .byte  102,68,15,110,224                   // movd          %eax,%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  65,15,89,212                        // mulps         %xmm12,%xmm2
  .byte  65,15,84,201                        // andps         %xmm9,%xmm1
  .byte  68,15,85,202                        // andnps        %xmm2,%xmm9
  .byte  68,15,86,201                        // orps          %xmm1,%xmm9
  .byte  15,40,208                           // movaps        %xmm0,%xmm2
  .byte  15,89,210                           // mulps         %xmm2,%xmm2
  .byte  15,89,208                           // mulps         %xmm0,%xmm2
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  15,194,202,1                        // cmpltps       %xmm2,%xmm1
  .byte  65,15,92,195                        // subps         %xmm11,%xmm0
  .byte  65,15,89,196                        // mulps         %xmm12,%xmm0
  .byte  15,84,209                           // andps         %xmm1,%xmm2
  .byte  15,85,200                           // andnps        %xmm0,%xmm1
  .byte  15,86,202                           // orps          %xmm2,%xmm1
  .byte  65,15,40,194                        // movaps        %xmm10,%xmm0
  .byte  15,89,192                           // mulps         %xmm0,%xmm0
  .byte  65,15,89,194                        // mulps         %xmm10,%xmm0
  .byte  68,15,194,192,1                     // cmpltps       %xmm0,%xmm8
  .byte  69,15,92,211                        // subps         %xmm11,%xmm10
  .byte  69,15,89,212                        // mulps         %xmm12,%xmm10
  .byte  65,15,84,192                        // andps         %xmm8,%xmm0
  .byte  69,15,85,194                        // andnps        %xmm10,%xmm8
  .byte  68,15,86,192                        // orps          %xmm0,%xmm8
  .byte  184,31,215,118,63                   // mov           $0x3f76d71f,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  65,15,89,193                        // mulps         %xmm9,%xmm0
  .byte  184,246,64,83,63                    // mov           $0x3f5340f6,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_a8_sse2
.globl _sk_load_a8_sse2
FUNCTION(_sk_load_a8_sse2)
_sk_load_a8_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  102,15,110,4,56                     // movd          (%rax,%rdi,1),%xmm0
  .byte  102,15,239,201                      // pxor          %xmm1,%xmm1
  .byte  102,15,96,193                       // punpcklbw     %xmm1,%xmm0
  .byte  102,15,97,193                       // punpcklwd     %xmm1,%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  15,89,216                           // mulps         %xmm0,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,87,192                           // xorps         %xmm0,%xmm0
  .byte  102,15,239,201                      // pxor          %xmm1,%xmm1
  .byte  15,87,210                           // xorps         %xmm2,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_a8_sse2
.globl _sk_gather_a8_sse2
FUNCTION(_sk_gather_a8_sse2)
_sk_gather_a8_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  243,15,91,201                       // cvttps2dq     %xmm1,%xmm1
  .byte  102,15,110,80,16                    // movd          0x10(%rax),%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,15,112,217,245                  // pshufd        $0xf5,%xmm1,%xmm3
  .byte  102,15,244,218                      // pmuludq       %xmm2,%xmm3
  .byte  102,15,112,219,232                  // pshufd        $0xe8,%xmm3,%xmm3
  .byte  102,15,244,209                      // pmuludq       %xmm1,%xmm2
  .byte  102,15,112,202,232                  // pshufd        $0xe8,%xmm2,%xmm1
  .byte  102,15,98,203                       // punpckldq     %xmm3,%xmm1
  .byte  243,15,91,192                       // cvttps2dq     %xmm0,%xmm0
  .byte  102,15,254,193                      // paddd         %xmm1,%xmm0
  .byte  102,72,15,126,192                   // movq          %xmm0,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,15,112,192,78                   // pshufd        $0x4e,%xmm0,%xmm0
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  71,15,182,20,17                     // movzbl        (%r9,%r10,1),%r10d
  .byte  65,15,182,12,9                      // movzbl        (%r9,%rcx,1),%ecx
  .byte  193,225,8                           // shl           $0x8,%ecx
  .byte  68,9,209                            // or            %r10d,%ecx
  .byte  71,15,182,4,1                       // movzbl        (%r9,%r8,1),%r8d
  .byte  65,15,182,4,1                       // movzbl        (%r9,%rax,1),%eax
  .byte  193,224,8                           // shl           $0x8,%eax
  .byte  68,9,192                            // or            %r8d,%eax
  .byte  102,15,196,192,0                    // pinsrw        $0x0,%eax,%xmm0
  .byte  102,15,196,193,1                    // pinsrw        $0x1,%ecx,%xmm0
  .byte  102,15,239,201                      // pxor          %xmm1,%xmm1
  .byte  102,15,96,193                       // punpcklbw     %xmm1,%xmm0
  .byte  102,15,97,193                       // punpcklwd     %xmm1,%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  15,89,216                           // mulps         %xmm0,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,87,192                           // xorps         %xmm0,%xmm0
  .byte  102,15,239,201                      // pxor          %xmm1,%xmm1
  .byte  102,15,239,210                      // pxor          %xmm2,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_a8_sse2
.globl _sk_store_a8_sse2
FUNCTION(_sk_store_a8_sse2)
_sk_store_a8_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  185,0,0,127,67                      // mov           $0x437f0000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,89,195                        // mulps         %xmm3,%xmm8
  .byte  102,69,15,91,192                    // cvtps2dq      %xmm8,%xmm8
  .byte  102,65,15,114,240,16                // pslld         $0x10,%xmm8
  .byte  102,65,15,114,224,16                // psrad         $0x10,%xmm8
  .byte  102,69,15,107,192                   // packssdw      %xmm8,%xmm8
  .byte  102,69,15,103,192                   // packuswb      %xmm8,%xmm8
  .byte  102,68,15,126,4,56                  // movd          %xmm8,(%rax,%rdi,1)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_g8_sse2
.globl _sk_load_g8_sse2
FUNCTION(_sk_load_g8_sse2)
_sk_load_g8_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  102,15,110,4,56                     // movd          (%rax,%rdi,1),%xmm0
  .byte  102,15,239,201                      // pxor          %xmm1,%xmm1
  .byte  102,15,96,193                       // punpcklbw     %xmm1,%xmm0
  .byte  102,15,97,193                       // punpcklwd     %xmm1,%xmm0
  .byte  15,91,200                           // cvtdq2ps      %xmm0,%xmm1
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,40,200                           // movaps        %xmm0,%xmm1
  .byte  15,40,208                           // movaps        %xmm0,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_g8_sse2
.globl _sk_gather_g8_sse2
FUNCTION(_sk_gather_g8_sse2)
_sk_gather_g8_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  243,15,91,201                       // cvttps2dq     %xmm1,%xmm1
  .byte  102,15,110,80,16                    // movd          0x10(%rax),%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,15,112,217,245                  // pshufd        $0xf5,%xmm1,%xmm3
  .byte  102,15,244,218                      // pmuludq       %xmm2,%xmm3
  .byte  102,15,112,219,232                  // pshufd        $0xe8,%xmm3,%xmm3
  .byte  102,15,244,209                      // pmuludq       %xmm1,%xmm2
  .byte  102,15,112,202,232                  // pshufd        $0xe8,%xmm2,%xmm1
  .byte  102,15,98,203                       // punpckldq     %xmm3,%xmm1
  .byte  243,15,91,192                       // cvttps2dq     %xmm0,%xmm0
  .byte  102,15,254,193                      // paddd         %xmm1,%xmm0
  .byte  102,72,15,126,192                   // movq          %xmm0,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,15,112,192,78                   // pshufd        $0x4e,%xmm0,%xmm0
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  71,15,182,20,17                     // movzbl        (%r9,%r10,1),%r10d
  .byte  65,15,182,12,9                      // movzbl        (%r9,%rcx,1),%ecx
  .byte  193,225,8                           // shl           $0x8,%ecx
  .byte  68,9,209                            // or            %r10d,%ecx
  .byte  71,15,182,4,1                       // movzbl        (%r9,%r8,1),%r8d
  .byte  65,15,182,4,1                       // movzbl        (%r9,%rax,1),%eax
  .byte  193,224,8                           // shl           $0x8,%eax
  .byte  68,9,192                            // or            %r8d,%eax
  .byte  102,15,196,192,0                    // pinsrw        $0x0,%eax,%xmm0
  .byte  102,15,196,193,1                    // pinsrw        $0x1,%ecx,%xmm0
  .byte  102,15,239,201                      // pxor          %xmm1,%xmm1
  .byte  102,15,96,193                       // punpcklbw     %xmm1,%xmm0
  .byte  102,15,97,193                       // punpcklwd     %xmm1,%xmm0
  .byte  15,91,200                           // cvtdq2ps      %xmm0,%xmm1
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,40,200                           // movaps        %xmm0,%xmm1
  .byte  15,40,208                           // movaps        %xmm0,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_i8_sse2
.globl _sk_gather_i8_sse2
FUNCTION(_sk_gather_i8_sse2)
_sk_gather_i8_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  73,137,192                          // mov           %rax,%r8
  .byte  77,133,192                          // test          %r8,%r8
  .byte  116,5                               // je            26fe <_sk_gather_i8_sse2+0xf>
  .byte  76,137,192                          // mov           %r8,%rax
  .byte  235,2                               // jmp           2700 <_sk_gather_i8_sse2+0x11>
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,16                           // mov           (%rax),%r10
  .byte  243,15,91,201                       // cvttps2dq     %xmm1,%xmm1
  .byte  102,15,110,80,16                    // movd          0x10(%rax),%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,15,112,217,245                  // pshufd        $0xf5,%xmm1,%xmm3
  .byte  102,15,244,218                      // pmuludq       %xmm2,%xmm3
  .byte  102,15,112,219,232                  // pshufd        $0xe8,%xmm3,%xmm3
  .byte  102,15,244,209                      // pmuludq       %xmm1,%xmm2
  .byte  102,15,112,202,232                  // pshufd        $0xe8,%xmm2,%xmm1
  .byte  102,15,98,203                       // punpckldq     %xmm3,%xmm1
  .byte  243,15,91,192                       // cvttps2dq     %xmm0,%xmm0
  .byte  102,15,254,193                      // paddd         %xmm1,%xmm0
  .byte  102,72,15,126,192                   // movq          %xmm0,%rax
  .byte  65,137,193                          // mov           %eax,%r9d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,15,112,192,78                   // pshufd        $0x4e,%xmm0,%xmm0
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  65,137,203                          // mov           %ecx,%r11d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  71,15,182,28,26                     // movzbl        (%r10,%r11,1),%r11d
  .byte  65,15,182,12,10                     // movzbl        (%r10,%rcx,1),%ecx
  .byte  193,225,8                           // shl           $0x8,%ecx
  .byte  68,9,217                            // or            %r11d,%ecx
  .byte  71,15,182,12,10                     // movzbl        (%r10,%r9,1),%r9d
  .byte  65,15,182,4,2                       // movzbl        (%r10,%rax,1),%eax
  .byte  193,224,8                           // shl           $0x8,%eax
  .byte  68,9,200                            // or            %r9d,%eax
  .byte  102,15,196,192,0                    // pinsrw        $0x0,%eax,%xmm0
  .byte  102,15,196,193,1                    // pinsrw        $0x1,%ecx,%xmm0
  .byte  102,15,239,201                      // pxor          %xmm1,%xmm1
  .byte  102,15,96,193                       // punpcklbw     %xmm1,%xmm0
  .byte  102,15,97,193                       // punpcklwd     %xmm1,%xmm0
  .byte  102,15,112,200,78                   // pshufd        $0x4e,%xmm0,%xmm1
  .byte  102,72,15,126,200                   // movq          %xmm1,%rax
  .byte  68,15,182,200                       // movzbl        %al,%r9d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  77,139,64,8                         // mov           0x8(%r8),%r8
  .byte  68,15,182,209                       // movzbl        %cl,%r10d
  .byte  72,193,233,30                       // shr           $0x1e,%rcx
  .byte  102,65,15,110,4,8                   // movd          (%r8,%rcx,1),%xmm0
  .byte  102,65,15,110,12,128                // movd          (%r8,%rax,4),%xmm1
  .byte  102,15,98,193                       // punpckldq     %xmm1,%xmm0
  .byte  102,71,15,110,12,144                // movd          (%r8,%r10,4),%xmm9
  .byte  102,67,15,110,12,136                // movd          (%r8,%r9,4),%xmm1
  .byte  102,68,15,98,201                    // punpckldq     %xmm1,%xmm9
  .byte  102,68,15,98,200                    // punpckldq     %xmm0,%xmm9
  .byte  102,15,111,21,248,30,0,0            // movdqa        0x1ef8(%rip),%xmm2        # 46d0 <_sk_callback_sse2+0x472>
  .byte  102,65,15,111,193                   // movdqa        %xmm9,%xmm0
  .byte  102,15,219,194                      // pand          %xmm2,%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  102,65,15,111,201                   // movdqa        %xmm9,%xmm1
  .byte  102,15,114,209,8                    // psrld         $0x8,%xmm1
  .byte  102,15,219,202                      // pand          %xmm2,%xmm1
  .byte  15,91,201                           // cvtdq2ps      %xmm1,%xmm1
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  102,65,15,111,217                   // movdqa        %xmm9,%xmm3
  .byte  102,15,114,211,16                   // psrld         $0x10,%xmm3
  .byte  102,15,219,218                      // pand          %xmm2,%xmm3
  .byte  15,91,211                           // cvtdq2ps      %xmm3,%xmm2
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  102,65,15,114,209,24                // psrld         $0x18,%xmm9
  .byte  65,15,91,217                        // cvtdq2ps      %xmm9,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_565_sse2
.globl _sk_load_565_sse2
FUNCTION(_sk_load_565_sse2)
_sk_load_565_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  243,15,126,20,120                   // movq          (%rax,%rdi,2),%xmm2
  .byte  102,15,239,192                      // pxor          %xmm0,%xmm0
  .byte  102,15,97,208                       // punpcklwd     %xmm0,%xmm2
  .byte  184,0,248,0,0                       // mov           $0xf800,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  102,15,112,192,0                    // pshufd        $0x0,%xmm0,%xmm0
  .byte  102,15,219,194                      // pand          %xmm2,%xmm0
  .byte  15,91,200                           // cvtdq2ps      %xmm0,%xmm1
  .byte  184,8,33,132,55                     // mov           $0x37842108,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  184,224,7,0,0                       // mov           $0x7e0,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  102,15,112,201,0                    // pshufd        $0x0,%xmm1,%xmm1
  .byte  102,15,219,202                      // pand          %xmm2,%xmm1
  .byte  15,91,217                           // cvtdq2ps      %xmm1,%xmm3
  .byte  184,33,8,2,58                       // mov           $0x3a020821,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  15,89,203                           // mulps         %xmm3,%xmm1
  .byte  184,31,0,0,0                        // mov           $0x1f,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  102,15,112,219,0                    // pshufd        $0x0,%xmm3,%xmm3
  .byte  102,15,219,218                      // pand          %xmm2,%xmm3
  .byte  15,91,219                           // cvtdq2ps      %xmm3,%xmm3
  .byte  184,8,33,4,61                       // mov           $0x3d042108,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  15,89,211                           // mulps         %xmm3,%xmm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_565_sse2
.globl _sk_gather_565_sse2
FUNCTION(_sk_gather_565_sse2)
_sk_gather_565_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  243,15,91,201                       // cvttps2dq     %xmm1,%xmm1
  .byte  102,15,110,80,16                    // movd          0x10(%rax),%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,15,112,217,245                  // pshufd        $0xf5,%xmm1,%xmm3
  .byte  102,15,244,218                      // pmuludq       %xmm2,%xmm3
  .byte  102,15,112,219,232                  // pshufd        $0xe8,%xmm3,%xmm3
  .byte  102,15,244,209                      // pmuludq       %xmm1,%xmm2
  .byte  102,15,112,202,232                  // pshufd        $0xe8,%xmm2,%xmm1
  .byte  102,15,98,203                       // punpckldq     %xmm3,%xmm1
  .byte  243,15,91,192                       // cvttps2dq     %xmm0,%xmm0
  .byte  102,15,254,193                      // paddd         %xmm1,%xmm0
  .byte  102,15,112,200,78                   // pshufd        $0x4e,%xmm0,%xmm1
  .byte  102,72,15,126,200                   // movq          %xmm1,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,67,15,196,20,81,0               // pinsrw        $0x0,(%r9,%r10,2),%xmm2
  .byte  102,65,15,196,20,73,1               // pinsrw        $0x1,(%r9,%rcx,2),%xmm2
  .byte  67,15,183,12,65                     // movzwl        (%r9,%r8,2),%ecx
  .byte  102,15,196,209,2                    // pinsrw        $0x2,%ecx,%xmm2
  .byte  65,15,183,4,65                      // movzwl        (%r9,%rax,2),%eax
  .byte  102,15,196,208,3                    // pinsrw        $0x3,%eax,%xmm2
  .byte  102,15,239,192                      // pxor          %xmm0,%xmm0
  .byte  102,15,97,208                       // punpcklwd     %xmm0,%xmm2
  .byte  184,0,248,0,0                       // mov           $0xf800,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  102,15,112,192,0                    // pshufd        $0x0,%xmm0,%xmm0
  .byte  102,15,219,194                      // pand          %xmm2,%xmm0
  .byte  15,91,200                           // cvtdq2ps      %xmm0,%xmm1
  .byte  184,8,33,132,55                     // mov           $0x37842108,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  184,224,7,0,0                       // mov           $0x7e0,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  102,15,112,201,0                    // pshufd        $0x0,%xmm1,%xmm1
  .byte  102,15,219,202                      // pand          %xmm2,%xmm1
  .byte  15,91,217                           // cvtdq2ps      %xmm1,%xmm3
  .byte  184,33,8,2,58                       // mov           $0x3a020821,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  15,89,203                           // mulps         %xmm3,%xmm1
  .byte  184,31,0,0,0                        // mov           $0x1f,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  102,15,112,219,0                    // pshufd        $0x0,%xmm3,%xmm3
  .byte  102,15,219,218                      // pand          %xmm2,%xmm3
  .byte  15,91,219                           // cvtdq2ps      %xmm3,%xmm3
  .byte  184,8,33,4,61                       // mov           $0x3d042108,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  15,89,211                           // mulps         %xmm3,%xmm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_565_sse2
.globl _sk_store_565_sse2
FUNCTION(_sk_store_565_sse2)
_sk_store_565_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  185,0,0,248,65                      // mov           $0x41f80000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,200                        // mulps         %xmm0,%xmm9
  .byte  102,69,15,91,201                    // cvtps2dq      %xmm9,%xmm9
  .byte  102,65,15,114,241,11                // pslld         $0xb,%xmm9
  .byte  185,0,0,124,66                      // mov           $0x427c0000,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  68,15,89,209                        // mulps         %xmm1,%xmm10
  .byte  102,69,15,91,210                    // cvtps2dq      %xmm10,%xmm10
  .byte  102,65,15,114,242,5                 // pslld         $0x5,%xmm10
  .byte  102,69,15,235,209                   // por           %xmm9,%xmm10
  .byte  68,15,89,194                        // mulps         %xmm2,%xmm8
  .byte  102,69,15,91,192                    // cvtps2dq      %xmm8,%xmm8
  .byte  102,69,15,86,194                    // orpd          %xmm10,%xmm8
  .byte  102,65,15,114,240,16                // pslld         $0x10,%xmm8
  .byte  102,65,15,114,224,16                // psrad         $0x10,%xmm8
  .byte  102,69,15,107,192                   // packssdw      %xmm8,%xmm8
  .byte  102,68,15,214,4,120                 // movq          %xmm8,(%rax,%rdi,2)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_4444_sse2
.globl _sk_load_4444_sse2
FUNCTION(_sk_load_4444_sse2)
_sk_load_4444_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  243,68,15,126,12,120                // movq          (%rax,%rdi,2),%xmm9
  .byte  102,15,239,192                      // pxor          %xmm0,%xmm0
  .byte  102,68,15,97,200                    // punpcklwd     %xmm0,%xmm9
  .byte  184,0,240,0,0                       // mov           $0xf000,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  102,15,112,192,0                    // pshufd        $0x0,%xmm0,%xmm0
  .byte  102,65,15,219,193                   // pand          %xmm9,%xmm0
  .byte  15,91,200                           // cvtdq2ps      %xmm0,%xmm1
  .byte  184,137,136,136,55                  // mov           $0x37888889,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  184,0,15,0,0                        // mov           $0xf00,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  102,15,112,201,0                    // pshufd        $0x0,%xmm1,%xmm1
  .byte  102,65,15,219,201                   // pand          %xmm9,%xmm1
  .byte  15,91,209                           // cvtdq2ps      %xmm1,%xmm2
  .byte  184,137,136,136,57                  // mov           $0x39888889,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  15,89,202                           // mulps         %xmm2,%xmm1
  .byte  184,240,0,0,0                       // mov           $0xf0,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,65,15,219,209                   // pand          %xmm9,%xmm2
  .byte  68,15,91,194                        // cvtdq2ps      %xmm2,%xmm8
  .byte  184,137,136,136,59                  // mov           $0x3b888889,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  184,15,0,0,0                        // mov           $0xf,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  102,15,112,219,0                    // pshufd        $0x0,%xmm3,%xmm3
  .byte  102,65,15,219,217                   // pand          %xmm9,%xmm3
  .byte  68,15,91,195                        // cvtdq2ps      %xmm3,%xmm8
  .byte  184,137,136,136,61                  // mov           $0x3d888889,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_4444_sse2
.globl _sk_gather_4444_sse2
FUNCTION(_sk_gather_4444_sse2)
_sk_gather_4444_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  243,15,91,201                       // cvttps2dq     %xmm1,%xmm1
  .byte  102,15,110,80,16                    // movd          0x10(%rax),%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,15,112,217,245                  // pshufd        $0xf5,%xmm1,%xmm3
  .byte  102,15,244,218                      // pmuludq       %xmm2,%xmm3
  .byte  102,15,112,219,232                  // pshufd        $0xe8,%xmm3,%xmm3
  .byte  102,15,244,209                      // pmuludq       %xmm1,%xmm2
  .byte  102,15,112,202,232                  // pshufd        $0xe8,%xmm2,%xmm1
  .byte  102,15,98,203                       // punpckldq     %xmm3,%xmm1
  .byte  243,15,91,192                       // cvttps2dq     %xmm0,%xmm0
  .byte  102,15,254,193                      // paddd         %xmm1,%xmm0
  .byte  102,15,112,200,78                   // pshufd        $0x4e,%xmm0,%xmm1
  .byte  102,72,15,126,200                   // movq          %xmm1,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,71,15,196,12,81,0               // pinsrw        $0x0,(%r9,%r10,2),%xmm9
  .byte  102,69,15,196,12,73,1               // pinsrw        $0x1,(%r9,%rcx,2),%xmm9
  .byte  67,15,183,12,65                     // movzwl        (%r9,%r8,2),%ecx
  .byte  102,68,15,196,201,2                 // pinsrw        $0x2,%ecx,%xmm9
  .byte  65,15,183,4,65                      // movzwl        (%r9,%rax,2),%eax
  .byte  102,68,15,196,200,3                 // pinsrw        $0x3,%eax,%xmm9
  .byte  102,15,239,192                      // pxor          %xmm0,%xmm0
  .byte  102,68,15,97,200                    // punpcklwd     %xmm0,%xmm9
  .byte  184,0,240,0,0                       // mov           $0xf000,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  102,15,112,192,0                    // pshufd        $0x0,%xmm0,%xmm0
  .byte  102,65,15,219,193                   // pand          %xmm9,%xmm0
  .byte  15,91,200                           // cvtdq2ps      %xmm0,%xmm1
  .byte  184,137,136,136,55                  // mov           $0x37888889,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  184,0,15,0,0                        // mov           $0xf00,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  102,15,112,201,0                    // pshufd        $0x0,%xmm1,%xmm1
  .byte  102,65,15,219,201                   // pand          %xmm9,%xmm1
  .byte  15,91,209                           // cvtdq2ps      %xmm1,%xmm2
  .byte  184,137,136,136,57                  // mov           $0x39888889,%eax
  .byte  102,15,110,200                      // movd          %eax,%xmm1
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  15,89,202                           // mulps         %xmm2,%xmm1
  .byte  184,240,0,0,0                       // mov           $0xf0,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,65,15,219,209                   // pand          %xmm9,%xmm2
  .byte  68,15,91,194                        // cvtdq2ps      %xmm2,%xmm8
  .byte  184,137,136,136,59                  // mov           $0x3b888889,%eax
  .byte  102,15,110,208                      // movd          %eax,%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  184,15,0,0,0                        // mov           $0xf,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  102,15,112,219,0                    // pshufd        $0x0,%xmm3,%xmm3
  .byte  102,65,15,219,217                   // pand          %xmm9,%xmm3
  .byte  68,15,91,195                        // cvtdq2ps      %xmm3,%xmm8
  .byte  184,137,136,136,61                  // mov           $0x3d888889,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_4444_sse2
.globl _sk_store_4444_sse2
FUNCTION(_sk_store_4444_sse2)
_sk_store_4444_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  185,0,0,112,65                      // mov           $0x41700000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,200                        // mulps         %xmm0,%xmm9
  .byte  102,69,15,91,201                    // cvtps2dq      %xmm9,%xmm9
  .byte  102,65,15,114,241,12                // pslld         $0xc,%xmm9
  .byte  69,15,40,208                        // movaps        %xmm8,%xmm10
  .byte  68,15,89,209                        // mulps         %xmm1,%xmm10
  .byte  102,69,15,91,210                    // cvtps2dq      %xmm10,%xmm10
  .byte  102,65,15,114,242,8                 // pslld         $0x8,%xmm10
  .byte  102,69,15,235,209                   // por           %xmm9,%xmm10
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,202                        // mulps         %xmm2,%xmm9
  .byte  102,69,15,91,201                    // cvtps2dq      %xmm9,%xmm9
  .byte  102,65,15,114,241,4                 // pslld         $0x4,%xmm9
  .byte  68,15,89,195                        // mulps         %xmm3,%xmm8
  .byte  102,69,15,91,192                    // cvtps2dq      %xmm8,%xmm8
  .byte  102,69,15,86,193                    // orpd          %xmm9,%xmm8
  .byte  102,69,15,86,194                    // orpd          %xmm10,%xmm8
  .byte  102,65,15,114,240,16                // pslld         $0x10,%xmm8
  .byte  102,65,15,114,224,16                // psrad         $0x10,%xmm8
  .byte  102,69,15,107,192                   // packssdw      %xmm8,%xmm8
  .byte  102,68,15,214,4,120                 // movq          %xmm8,(%rax,%rdi,2)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_8888_sse2
.globl _sk_load_8888_sse2
FUNCTION(_sk_load_8888_sse2)
_sk_load_8888_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  68,15,16,12,184                     // movups        (%rax,%rdi,4),%xmm9
  .byte  15,40,21,70,26,0,0                  // movaps        0x1a46(%rip),%xmm2        # 46e0 <_sk_callback_sse2+0x482>
  .byte  65,15,40,193                        // movaps        %xmm9,%xmm0
  .byte  15,84,194                           // andps         %xmm2,%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  65,15,40,201                        // movaps        %xmm9,%xmm1
  .byte  102,15,114,209,8                    // psrld         $0x8,%xmm1
  .byte  102,15,219,202                      // pand          %xmm2,%xmm1
  .byte  15,91,201                           // cvtdq2ps      %xmm1,%xmm1
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  65,15,40,217                        // movaps        %xmm9,%xmm3
  .byte  102,15,114,211,16                   // psrld         $0x10,%xmm3
  .byte  102,15,219,218                      // pand          %xmm2,%xmm3
  .byte  15,91,211                           // cvtdq2ps      %xmm3,%xmm2
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  102,65,15,114,209,24                // psrld         $0x18,%xmm9
  .byte  65,15,91,217                        // cvtdq2ps      %xmm9,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_8888_sse2
.globl _sk_gather_8888_sse2
FUNCTION(_sk_gather_8888_sse2)
_sk_gather_8888_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  243,15,91,201                       // cvttps2dq     %xmm1,%xmm1
  .byte  102,15,110,80,16                    // movd          0x10(%rax),%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,15,112,217,245                  // pshufd        $0xf5,%xmm1,%xmm3
  .byte  102,15,244,218                      // pmuludq       %xmm2,%xmm3
  .byte  102,15,112,219,232                  // pshufd        $0xe8,%xmm3,%xmm3
  .byte  102,15,244,209                      // pmuludq       %xmm1,%xmm2
  .byte  102,15,112,202,232                  // pshufd        $0xe8,%xmm2,%xmm1
  .byte  102,15,98,203                       // punpckldq     %xmm3,%xmm1
  .byte  243,15,91,192                       // cvttps2dq     %xmm0,%xmm0
  .byte  102,15,254,193                      // paddd         %xmm1,%xmm0
  .byte  102,15,112,200,78                   // pshufd        $0x4e,%xmm0,%xmm1
  .byte  102,72,15,126,200                   // movq          %xmm1,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  102,65,15,110,4,137                 // movd          (%r9,%rcx,4),%xmm0
  .byte  102,65,15,110,12,129                // movd          (%r9,%rax,4),%xmm1
  .byte  102,15,98,193                       // punpckldq     %xmm1,%xmm0
  .byte  102,71,15,110,12,145                // movd          (%r9,%r10,4),%xmm9
  .byte  102,67,15,110,12,129                // movd          (%r9,%r8,4),%xmm1
  .byte  102,68,15,98,201                    // punpckldq     %xmm1,%xmm9
  .byte  102,68,15,98,200                    // punpckldq     %xmm0,%xmm9
  .byte  102,15,111,21,126,25,0,0            // movdqa        0x197e(%rip),%xmm2        # 46f0 <_sk_callback_sse2+0x492>
  .byte  102,65,15,111,193                   // movdqa        %xmm9,%xmm0
  .byte  102,15,219,194                      // pand          %xmm2,%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  184,129,128,128,59                  // mov           $0x3b808081,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  102,65,15,111,201                   // movdqa        %xmm9,%xmm1
  .byte  102,15,114,209,8                    // psrld         $0x8,%xmm1
  .byte  102,15,219,202                      // pand          %xmm2,%xmm1
  .byte  15,91,201                           // cvtdq2ps      %xmm1,%xmm1
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  102,65,15,111,217                   // movdqa        %xmm9,%xmm3
  .byte  102,15,114,211,16                   // psrld         $0x10,%xmm3
  .byte  102,15,219,218                      // pand          %xmm2,%xmm3
  .byte  15,91,211                           // cvtdq2ps      %xmm3,%xmm2
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  102,65,15,114,209,24                // psrld         $0x18,%xmm9
  .byte  65,15,91,217                        // cvtdq2ps      %xmm9,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_8888_sse2
.globl _sk_store_8888_sse2
FUNCTION(_sk_store_8888_sse2)
_sk_store_8888_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  185,0,0,127,67                      // mov           $0x437f0000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,200                        // mulps         %xmm0,%xmm9
  .byte  102,69,15,91,201                    // cvtps2dq      %xmm9,%xmm9
  .byte  69,15,40,208                        // movaps        %xmm8,%xmm10
  .byte  68,15,89,209                        // mulps         %xmm1,%xmm10
  .byte  102,69,15,91,210                    // cvtps2dq      %xmm10,%xmm10
  .byte  102,65,15,114,242,8                 // pslld         $0x8,%xmm10
  .byte  102,69,15,235,209                   // por           %xmm9,%xmm10
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,89,202                        // mulps         %xmm2,%xmm9
  .byte  102,69,15,91,201                    // cvtps2dq      %xmm9,%xmm9
  .byte  102,65,15,114,241,16                // pslld         $0x10,%xmm9
  .byte  68,15,89,195                        // mulps         %xmm3,%xmm8
  .byte  102,69,15,91,192                    // cvtps2dq      %xmm8,%xmm8
  .byte  102,65,15,114,240,24                // pslld         $0x18,%xmm8
  .byte  102,69,15,235,193                   // por           %xmm9,%xmm8
  .byte  102,69,15,235,194                   // por           %xmm10,%xmm8
  .byte  243,68,15,127,4,184                 // movdqu        %xmm8,(%rax,%rdi,4)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_f16_sse2
.globl _sk_load_f16_sse2
FUNCTION(_sk_load_f16_sse2)
_sk_load_f16_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  243,15,111,4,248                    // movdqu        (%rax,%rdi,8),%xmm0
  .byte  243,15,111,76,248,16                // movdqu        0x10(%rax,%rdi,8),%xmm1
  .byte  102,68,15,111,192                   // movdqa        %xmm0,%xmm8
  .byte  102,68,15,97,193                    // punpcklwd     %xmm1,%xmm8
  .byte  102,15,105,193                      // punpckhwd     %xmm1,%xmm0
  .byte  102,69,15,111,240                   // movdqa        %xmm8,%xmm14
  .byte  102,68,15,97,240                    // punpcklwd     %xmm0,%xmm14
  .byte  102,68,15,105,192                   // punpckhwd     %xmm0,%xmm8
  .byte  102,69,15,239,210                   // pxor          %xmm10,%xmm10
  .byte  102,65,15,111,206                   // movdqa        %xmm14,%xmm1
  .byte  102,65,15,97,202                    // punpcklwd     %xmm10,%xmm1
  .byte  102,68,15,111,13,127,24,0,0         // movdqa        0x187f(%rip),%xmm9        # 4700 <_sk_callback_sse2+0x4a2>
  .byte  102,15,111,193                      // movdqa        %xmm1,%xmm0
  .byte  102,65,15,219,193                   // pand          %xmm9,%xmm0
  .byte  102,15,239,200                      // pxor          %xmm0,%xmm1
  .byte  102,15,114,240,16                   // pslld         $0x10,%xmm0
  .byte  102,68,15,111,233                   // movdqa        %xmm1,%xmm13
  .byte  102,65,15,114,245,13                // pslld         $0xd,%xmm13
  .byte  102,68,15,235,232                   // por           %xmm0,%xmm13
  .byte  102,68,15,111,29,100,24,0,0         // movdqa        0x1864(%rip),%xmm11        # 4710 <_sk_callback_sse2+0x4b2>
  .byte  102,69,15,254,235                   // paddd         %xmm11,%xmm13
  .byte  102,68,15,111,37,102,24,0,0         // movdqa        0x1866(%rip),%xmm12        # 4720 <_sk_callback_sse2+0x4c2>
  .byte  102,65,15,239,204                   // pxor          %xmm12,%xmm1
  .byte  102,15,111,29,105,24,0,0            // movdqa        0x1869(%rip),%xmm3        # 4730 <_sk_callback_sse2+0x4d2>
  .byte  102,15,111,195                      // movdqa        %xmm3,%xmm0
  .byte  102,15,102,193                      // pcmpgtd       %xmm1,%xmm0
  .byte  102,65,15,223,197                   // pandn         %xmm13,%xmm0
  .byte  102,65,15,115,222,8                 // psrldq        $0x8,%xmm14
  .byte  102,69,15,97,242                    // punpcklwd     %xmm10,%xmm14
  .byte  102,65,15,111,206                   // movdqa        %xmm14,%xmm1
  .byte  102,65,15,219,201                   // pand          %xmm9,%xmm1
  .byte  102,68,15,239,241                   // pxor          %xmm1,%xmm14
  .byte  102,15,114,241,16                   // pslld         $0x10,%xmm1
  .byte  102,65,15,111,214                   // movdqa        %xmm14,%xmm2
  .byte  102,15,114,242,13                   // pslld         $0xd,%xmm2
  .byte  102,15,235,209                      // por           %xmm1,%xmm2
  .byte  102,65,15,254,211                   // paddd         %xmm11,%xmm2
  .byte  102,69,15,239,244                   // pxor          %xmm12,%xmm14
  .byte  102,15,111,203                      // movdqa        %xmm3,%xmm1
  .byte  102,65,15,102,206                   // pcmpgtd       %xmm14,%xmm1
  .byte  102,15,223,202                      // pandn         %xmm2,%xmm1
  .byte  102,69,15,111,232                   // movdqa        %xmm8,%xmm13
  .byte  102,69,15,97,234                    // punpcklwd     %xmm10,%xmm13
  .byte  102,65,15,111,213                   // movdqa        %xmm13,%xmm2
  .byte  102,65,15,219,209                   // pand          %xmm9,%xmm2
  .byte  102,68,15,239,234                   // pxor          %xmm2,%xmm13
  .byte  102,15,114,242,16                   // pslld         $0x10,%xmm2
  .byte  102,69,15,111,245                   // movdqa        %xmm13,%xmm14
  .byte  102,65,15,114,246,13                // pslld         $0xd,%xmm14
  .byte  102,68,15,235,242                   // por           %xmm2,%xmm14
  .byte  102,69,15,254,243                   // paddd         %xmm11,%xmm14
  .byte  102,69,15,239,236                   // pxor          %xmm12,%xmm13
  .byte  102,15,111,211                      // movdqa        %xmm3,%xmm2
  .byte  102,65,15,102,213                   // pcmpgtd       %xmm13,%xmm2
  .byte  102,65,15,223,214                   // pandn         %xmm14,%xmm2
  .byte  102,65,15,115,216,8                 // psrldq        $0x8,%xmm8
  .byte  102,69,15,97,194                    // punpcklwd     %xmm10,%xmm8
  .byte  102,69,15,219,200                   // pand          %xmm8,%xmm9
  .byte  102,69,15,239,193                   // pxor          %xmm9,%xmm8
  .byte  102,65,15,114,241,16                // pslld         $0x10,%xmm9
  .byte  102,69,15,111,208                   // movdqa        %xmm8,%xmm10
  .byte  102,65,15,114,242,13                // pslld         $0xd,%xmm10
  .byte  102,69,15,235,209                   // por           %xmm9,%xmm10
  .byte  102,69,15,254,211                   // paddd         %xmm11,%xmm10
  .byte  102,69,15,239,196                   // pxor          %xmm12,%xmm8
  .byte  102,65,15,102,216                   // pcmpgtd       %xmm8,%xmm3
  .byte  102,65,15,223,218                   // pandn         %xmm10,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_gather_f16_sse2
.globl _sk_gather_f16_sse2
FUNCTION(_sk_gather_f16_sse2)
_sk_gather_f16_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,139,8                            // mov           (%rax),%r9
  .byte  243,15,91,201                       // cvttps2dq     %xmm1,%xmm1
  .byte  102,15,110,80,16                    // movd          0x10(%rax),%xmm2
  .byte  102,15,112,210,0                    // pshufd        $0x0,%xmm2,%xmm2
  .byte  102,15,112,217,245                  // pshufd        $0xf5,%xmm1,%xmm3
  .byte  102,15,244,218                      // pmuludq       %xmm2,%xmm3
  .byte  102,15,112,219,232                  // pshufd        $0xe8,%xmm3,%xmm3
  .byte  102,15,244,209                      // pmuludq       %xmm1,%xmm2
  .byte  102,15,112,202,232                  // pshufd        $0xe8,%xmm2,%xmm1
  .byte  102,15,98,203                       // punpckldq     %xmm3,%xmm1
  .byte  243,15,91,192                       // cvttps2dq     %xmm0,%xmm0
  .byte  102,15,254,193                      // paddd         %xmm1,%xmm0
  .byte  102,15,112,200,78                   // pshufd        $0x4e,%xmm0,%xmm1
  .byte  102,72,15,126,200                   // movq          %xmm1,%rax
  .byte  65,137,192                          // mov           %eax,%r8d
  .byte  72,193,232,32                       // shr           $0x20,%rax
  .byte  102,72,15,126,193                   // movq          %xmm0,%rcx
  .byte  65,137,202                          // mov           %ecx,%r10d
  .byte  72,193,233,32                       // shr           $0x20,%rcx
  .byte  243,65,15,126,4,201                 // movq          (%r9,%rcx,8),%xmm0
  .byte  243,67,15,126,12,209                // movq          (%r9,%r10,8),%xmm1
  .byte  102,15,108,200                      // punpcklqdq    %xmm0,%xmm1
  .byte  243,65,15,126,4,193                 // movq          (%r9,%rax,8),%xmm0
  .byte  243,67,15,126,20,193                // movq          (%r9,%r8,8),%xmm2
  .byte  102,15,108,208                      // punpcklqdq    %xmm0,%xmm2
  .byte  102,68,15,111,193                   // movdqa        %xmm1,%xmm8
  .byte  102,68,15,97,194                    // punpcklwd     %xmm2,%xmm8
  .byte  102,15,105,202                      // punpckhwd     %xmm2,%xmm1
  .byte  102,69,15,111,240                   // movdqa        %xmm8,%xmm14
  .byte  102,68,15,97,241                    // punpcklwd     %xmm1,%xmm14
  .byte  102,68,15,105,193                   // punpckhwd     %xmm1,%xmm8
  .byte  102,69,15,239,210                   // pxor          %xmm10,%xmm10
  .byte  102,65,15,111,206                   // movdqa        %xmm14,%xmm1
  .byte  102,65,15,97,202                    // punpcklwd     %xmm10,%xmm1
  .byte  102,68,15,111,13,247,22,0,0         // movdqa        0x16f7(%rip),%xmm9        # 4740 <_sk_callback_sse2+0x4e2>
  .byte  102,15,111,193                      // movdqa        %xmm1,%xmm0
  .byte  102,65,15,219,193                   // pand          %xmm9,%xmm0
  .byte  102,15,239,200                      // pxor          %xmm0,%xmm1
  .byte  102,15,114,240,16                   // pslld         $0x10,%xmm0
  .byte  102,68,15,111,233                   // movdqa        %xmm1,%xmm13
  .byte  102,65,15,114,245,13                // pslld         $0xd,%xmm13
  .byte  102,68,15,235,232                   // por           %xmm0,%xmm13
  .byte  102,68,15,111,29,220,22,0,0         // movdqa        0x16dc(%rip),%xmm11        # 4750 <_sk_callback_sse2+0x4f2>
  .byte  102,69,15,254,235                   // paddd         %xmm11,%xmm13
  .byte  102,68,15,111,37,222,22,0,0         // movdqa        0x16de(%rip),%xmm12        # 4760 <_sk_callback_sse2+0x502>
  .byte  102,65,15,239,204                   // pxor          %xmm12,%xmm1
  .byte  102,15,111,29,225,22,0,0            // movdqa        0x16e1(%rip),%xmm3        # 4770 <_sk_callback_sse2+0x512>
  .byte  102,15,111,195                      // movdqa        %xmm3,%xmm0
  .byte  102,15,102,193                      // pcmpgtd       %xmm1,%xmm0
  .byte  102,65,15,223,197                   // pandn         %xmm13,%xmm0
  .byte  102,65,15,115,222,8                 // psrldq        $0x8,%xmm14
  .byte  102,69,15,97,242                    // punpcklwd     %xmm10,%xmm14
  .byte  102,65,15,111,206                   // movdqa        %xmm14,%xmm1
  .byte  102,65,15,219,201                   // pand          %xmm9,%xmm1
  .byte  102,68,15,239,241                   // pxor          %xmm1,%xmm14
  .byte  102,15,114,241,16                   // pslld         $0x10,%xmm1
  .byte  102,65,15,111,214                   // movdqa        %xmm14,%xmm2
  .byte  102,15,114,242,13                   // pslld         $0xd,%xmm2
  .byte  102,15,235,209                      // por           %xmm1,%xmm2
  .byte  102,65,15,254,211                   // paddd         %xmm11,%xmm2
  .byte  102,69,15,239,244                   // pxor          %xmm12,%xmm14
  .byte  102,15,111,203                      // movdqa        %xmm3,%xmm1
  .byte  102,65,15,102,206                   // pcmpgtd       %xmm14,%xmm1
  .byte  102,15,223,202                      // pandn         %xmm2,%xmm1
  .byte  102,69,15,111,232                   // movdqa        %xmm8,%xmm13
  .byte  102,69,15,97,234                    // punpcklwd     %xmm10,%xmm13
  .byte  102,65,15,111,213                   // movdqa        %xmm13,%xmm2
  .byte  102,65,15,219,209                   // pand          %xmm9,%xmm2
  .byte  102,68,15,239,234                   // pxor          %xmm2,%xmm13
  .byte  102,15,114,242,16                   // pslld         $0x10,%xmm2
  .byte  102,69,15,111,245                   // movdqa        %xmm13,%xmm14
  .byte  102,65,15,114,246,13                // pslld         $0xd,%xmm14
  .byte  102,68,15,235,242                   // por           %xmm2,%xmm14
  .byte  102,69,15,254,243                   // paddd         %xmm11,%xmm14
  .byte  102,69,15,239,236                   // pxor          %xmm12,%xmm13
  .byte  102,15,111,211                      // movdqa        %xmm3,%xmm2
  .byte  102,65,15,102,213                   // pcmpgtd       %xmm13,%xmm2
  .byte  102,65,15,223,214                   // pandn         %xmm14,%xmm2
  .byte  102,65,15,115,216,8                 // psrldq        $0x8,%xmm8
  .byte  102,69,15,97,194                    // punpcklwd     %xmm10,%xmm8
  .byte  102,69,15,219,200                   // pand          %xmm8,%xmm9
  .byte  102,69,15,239,193                   // pxor          %xmm9,%xmm8
  .byte  102,65,15,114,241,16                // pslld         $0x10,%xmm9
  .byte  102,69,15,111,208                   // movdqa        %xmm8,%xmm10
  .byte  102,65,15,114,242,13                // pslld         $0xd,%xmm10
  .byte  102,69,15,235,209                   // por           %xmm9,%xmm10
  .byte  102,69,15,254,211                   // paddd         %xmm11,%xmm10
  .byte  102,69,15,239,196                   // pxor          %xmm12,%xmm8
  .byte  102,65,15,102,216                   // pcmpgtd       %xmm8,%xmm3
  .byte  102,65,15,223,218                   // pandn         %xmm10,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_f16_sse2
.globl _sk_store_f16_sse2
FUNCTION(_sk_store_f16_sse2)
_sk_store_f16_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  102,68,15,111,21,9,22,0,0           // movdqa        0x1609(%rip),%xmm10        # 4780 <_sk_callback_sse2+0x522>
  .byte  102,68,15,111,224                   // movdqa        %xmm0,%xmm12
  .byte  102,68,15,111,232                   // movdqa        %xmm0,%xmm13
  .byte  102,69,15,219,234                   // pand          %xmm10,%xmm13
  .byte  102,69,15,239,229                   // pxor          %xmm13,%xmm12
  .byte  102,68,15,111,13,252,21,0,0         // movdqa        0x15fc(%rip),%xmm9        # 4790 <_sk_callback_sse2+0x532>
  .byte  102,65,15,114,213,16                // psrld         $0x10,%xmm13
  .byte  102,69,15,111,193                   // movdqa        %xmm9,%xmm8
  .byte  102,69,15,102,196                   // pcmpgtd       %xmm12,%xmm8
  .byte  102,65,15,114,212,13                // psrld         $0xd,%xmm12
  .byte  102,68,15,111,29,237,21,0,0         // movdqa        0x15ed(%rip),%xmm11        # 47a0 <_sk_callback_sse2+0x542>
  .byte  102,69,15,235,235                   // por           %xmm11,%xmm13
  .byte  102,69,15,254,236                   // paddd         %xmm12,%xmm13
  .byte  102,65,15,114,245,16                // pslld         $0x10,%xmm13
  .byte  102,65,15,114,229,16                // psrad         $0x10,%xmm13
  .byte  102,69,15,223,197                   // pandn         %xmm13,%xmm8
  .byte  102,69,15,107,192                   // packssdw      %xmm8,%xmm8
  .byte  102,68,15,111,233                   // movdqa        %xmm1,%xmm13
  .byte  102,68,15,111,241                   // movdqa        %xmm1,%xmm14
  .byte  102,69,15,219,242                   // pand          %xmm10,%xmm14
  .byte  102,69,15,239,238                   // pxor          %xmm14,%xmm13
  .byte  102,65,15,114,214,16                // psrld         $0x10,%xmm14
  .byte  102,69,15,111,225                   // movdqa        %xmm9,%xmm12
  .byte  102,69,15,102,229                   // pcmpgtd       %xmm13,%xmm12
  .byte  102,65,15,114,213,13                // psrld         $0xd,%xmm13
  .byte  102,69,15,235,243                   // por           %xmm11,%xmm14
  .byte  102,69,15,254,245                   // paddd         %xmm13,%xmm14
  .byte  102,65,15,114,246,16                // pslld         $0x10,%xmm14
  .byte  102,65,15,114,230,16                // psrad         $0x10,%xmm14
  .byte  102,69,15,223,230                   // pandn         %xmm14,%xmm12
  .byte  102,69,15,107,228                   // packssdw      %xmm12,%xmm12
  .byte  102,68,15,111,242                   // movdqa        %xmm2,%xmm14
  .byte  102,68,15,111,250                   // movdqa        %xmm2,%xmm15
  .byte  102,69,15,219,250                   // pand          %xmm10,%xmm15
  .byte  102,69,15,239,247                   // pxor          %xmm15,%xmm14
  .byte  102,65,15,114,215,16                // psrld         $0x10,%xmm15
  .byte  102,69,15,111,233                   // movdqa        %xmm9,%xmm13
  .byte  102,69,15,102,238                   // pcmpgtd       %xmm14,%xmm13
  .byte  102,65,15,114,214,13                // psrld         $0xd,%xmm14
  .byte  102,69,15,235,251                   // por           %xmm11,%xmm15
  .byte  102,69,15,254,254                   // paddd         %xmm14,%xmm15
  .byte  102,65,15,114,247,16                // pslld         $0x10,%xmm15
  .byte  102,65,15,114,231,16                // psrad         $0x10,%xmm15
  .byte  102,69,15,223,239                   // pandn         %xmm15,%xmm13
  .byte  102,69,15,107,237                   // packssdw      %xmm13,%xmm13
  .byte  102,68,15,219,211                   // pand          %xmm3,%xmm10
  .byte  102,68,15,111,243                   // movdqa        %xmm3,%xmm14
  .byte  102,69,15,239,242                   // pxor          %xmm10,%xmm14
  .byte  102,65,15,114,210,16                // psrld         $0x10,%xmm10
  .byte  102,69,15,102,206                   // pcmpgtd       %xmm14,%xmm9
  .byte  102,65,15,114,214,13                // psrld         $0xd,%xmm14
  .byte  102,69,15,235,211                   // por           %xmm11,%xmm10
  .byte  102,69,15,254,214                   // paddd         %xmm14,%xmm10
  .byte  102,65,15,114,242,16                // pslld         $0x10,%xmm10
  .byte  102,65,15,114,226,16                // psrad         $0x10,%xmm10
  .byte  102,69,15,223,202                   // pandn         %xmm10,%xmm9
  .byte  102,69,15,107,201                   // packssdw      %xmm9,%xmm9
  .byte  102,69,15,97,196                    // punpcklwd     %xmm12,%xmm8
  .byte  102,69,15,97,233                    // punpcklwd     %xmm9,%xmm13
  .byte  102,69,15,111,200                   // movdqa        %xmm8,%xmm9
  .byte  102,69,15,98,205                    // punpckldq     %xmm13,%xmm9
  .byte  243,68,15,127,12,248                // movdqu        %xmm9,(%rax,%rdi,8)
  .byte  102,69,15,106,197                   // punpckhdq     %xmm13,%xmm8
  .byte  243,68,15,127,68,248,16             // movdqu        %xmm8,0x10(%rax,%rdi,8)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_u16_be_sse2
.globl _sk_load_u16_be_sse2
FUNCTION(_sk_load_u16_be_sse2)
_sk_load_u16_be_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  243,15,111,4,248                    // movdqu        (%rax,%rdi,8),%xmm0
  .byte  243,15,111,76,248,16                // movdqu        0x10(%rax,%rdi,8),%xmm1
  .byte  102,15,111,208                      // movdqa        %xmm0,%xmm2
  .byte  102,15,97,209                       // punpcklwd     %xmm1,%xmm2
  .byte  102,15,105,193                      // punpckhwd     %xmm1,%xmm0
  .byte  102,15,111,202                      // movdqa        %xmm2,%xmm1
  .byte  102,15,97,200                       // punpcklwd     %xmm0,%xmm1
  .byte  102,15,105,208                      // punpckhwd     %xmm0,%xmm2
  .byte  184,128,0,128,55                    // mov           $0x37800080,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  102,15,111,193                      // movdqa        %xmm1,%xmm0
  .byte  102,15,113,240,8                    // psllw         $0x8,%xmm0
  .byte  102,15,112,217,78                   // pshufd        $0x4e,%xmm1,%xmm3
  .byte  102,15,113,209,8                    // psrlw         $0x8,%xmm1
  .byte  102,15,235,200                      // por           %xmm0,%xmm1
  .byte  102,69,15,239,201                   // pxor          %xmm9,%xmm9
  .byte  102,65,15,97,201                    // punpcklwd     %xmm9,%xmm1
  .byte  15,91,193                           // cvtdq2ps      %xmm1,%xmm0
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  102,15,111,203                      // movdqa        %xmm3,%xmm1
  .byte  102,15,113,241,8                    // psllw         $0x8,%xmm1
  .byte  102,15,113,211,8                    // psrlw         $0x8,%xmm3
  .byte  102,15,235,217                      // por           %xmm1,%xmm3
  .byte  102,65,15,97,217                    // punpcklwd     %xmm9,%xmm3
  .byte  15,91,203                           // cvtdq2ps      %xmm3,%xmm1
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  102,68,15,111,210                   // movdqa        %xmm2,%xmm10
  .byte  102,65,15,113,242,8                 // psllw         $0x8,%xmm10
  .byte  102,15,112,218,78                   // pshufd        $0x4e,%xmm2,%xmm3
  .byte  102,15,113,210,8                    // psrlw         $0x8,%xmm2
  .byte  102,65,15,235,210                   // por           %xmm10,%xmm2
  .byte  102,65,15,97,209                    // punpcklwd     %xmm9,%xmm2
  .byte  15,91,210                           // cvtdq2ps      %xmm2,%xmm2
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  102,68,15,111,211                   // movdqa        %xmm3,%xmm10
  .byte  102,65,15,113,242,8                 // psllw         $0x8,%xmm10
  .byte  102,15,113,211,8                    // psrlw         $0x8,%xmm3
  .byte  102,65,15,235,218                   // por           %xmm10,%xmm3
  .byte  102,65,15,97,217                    // punpcklwd     %xmm9,%xmm3
  .byte  15,91,219                           // cvtdq2ps      %xmm3,%xmm3
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_rgb_u16_be_sse2
.globl _sk_load_rgb_u16_be_sse2
FUNCTION(_sk_load_rgb_u16_be_sse2)
_sk_load_rgb_u16_be_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,141,12,127                       // lea           (%rdi,%rdi,2),%rcx
  .byte  243,15,111,20,72                    // movdqu        (%rax,%rcx,2),%xmm2
  .byte  243,15,111,68,72,8                  // movdqu        0x8(%rax,%rcx,2),%xmm0
  .byte  102,15,115,216,4                    // psrldq        $0x4,%xmm0
  .byte  102,15,111,202                      // movdqa        %xmm2,%xmm1
  .byte  102,15,115,217,6                    // psrldq        $0x6,%xmm1
  .byte  102,15,97,208                       // punpcklwd     %xmm0,%xmm2
  .byte  102,15,115,216,6                    // psrldq        $0x6,%xmm0
  .byte  102,15,97,200                       // punpcklwd     %xmm0,%xmm1
  .byte  102,15,111,194                      // movdqa        %xmm2,%xmm0
  .byte  102,15,97,193                       // punpcklwd     %xmm1,%xmm0
  .byte  102,15,112,216,78                   // pshufd        $0x4e,%xmm0,%xmm3
  .byte  102,15,105,209                      // punpckhwd     %xmm1,%xmm2
  .byte  184,128,0,128,55                    // mov           $0x37800080,%eax
  .byte  102,68,15,110,192                   // movd          %eax,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  102,15,111,200                      // movdqa        %xmm0,%xmm1
  .byte  102,15,113,241,8                    // psllw         $0x8,%xmm1
  .byte  102,15,113,208,8                    // psrlw         $0x8,%xmm0
  .byte  102,15,235,193                      // por           %xmm1,%xmm0
  .byte  102,69,15,239,201                   // pxor          %xmm9,%xmm9
  .byte  102,65,15,97,193                    // punpcklwd     %xmm9,%xmm0
  .byte  15,91,192                           // cvtdq2ps      %xmm0,%xmm0
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  102,15,111,203                      // movdqa        %xmm3,%xmm1
  .byte  102,15,113,241,8                    // psllw         $0x8,%xmm1
  .byte  102,15,113,211,8                    // psrlw         $0x8,%xmm3
  .byte  102,15,235,217                      // por           %xmm1,%xmm3
  .byte  102,65,15,97,217                    // punpcklwd     %xmm9,%xmm3
  .byte  15,91,203                           // cvtdq2ps      %xmm3,%xmm1
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  102,15,111,218                      // movdqa        %xmm2,%xmm3
  .byte  102,15,113,243,8                    // psllw         $0x8,%xmm3
  .byte  102,15,113,210,8                    // psrlw         $0x8,%xmm2
  .byte  102,15,235,211                      // por           %xmm3,%xmm2
  .byte  102,65,15,97,209                    // punpcklwd     %xmm9,%xmm2
  .byte  15,91,210                           // cvtdq2ps      %xmm2,%xmm2
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  184,0,0,128,63                      // mov           $0x3f800000,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_u16_be_sse2
.globl _sk_store_u16_be_sse2
FUNCTION(_sk_store_u16_be_sse2)
_sk_store_u16_be_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  185,0,255,127,71                    // mov           $0x477fff00,%ecx
  .byte  102,68,15,110,201                   // movd          %ecx,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  69,15,40,193                        // movaps        %xmm9,%xmm8
  .byte  68,15,89,192                        // mulps         %xmm0,%xmm8
  .byte  102,69,15,91,192                    // cvtps2dq      %xmm8,%xmm8
  .byte  102,65,15,114,240,16                // pslld         $0x10,%xmm8
  .byte  102,65,15,114,224,16                // psrad         $0x10,%xmm8
  .byte  102,69,15,107,192                   // packssdw      %xmm8,%xmm8
  .byte  102,69,15,111,208                   // movdqa        %xmm8,%xmm10
  .byte  102,65,15,113,242,8                 // psllw         $0x8,%xmm10
  .byte  102,65,15,113,208,8                 // psrlw         $0x8,%xmm8
  .byte  102,69,15,235,194                   // por           %xmm10,%xmm8
  .byte  69,15,40,209                        // movaps        %xmm9,%xmm10
  .byte  68,15,89,209                        // mulps         %xmm1,%xmm10
  .byte  102,69,15,91,210                    // cvtps2dq      %xmm10,%xmm10
  .byte  102,65,15,114,242,16                // pslld         $0x10,%xmm10
  .byte  102,65,15,114,226,16                // psrad         $0x10,%xmm10
  .byte  102,69,15,107,210                   // packssdw      %xmm10,%xmm10
  .byte  102,69,15,111,218                   // movdqa        %xmm10,%xmm11
  .byte  102,65,15,113,243,8                 // psllw         $0x8,%xmm11
  .byte  102,65,15,113,210,8                 // psrlw         $0x8,%xmm10
  .byte  102,69,15,235,211                   // por           %xmm11,%xmm10
  .byte  69,15,40,217                        // movaps        %xmm9,%xmm11
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  102,69,15,91,219                    // cvtps2dq      %xmm11,%xmm11
  .byte  102,65,15,114,243,16                // pslld         $0x10,%xmm11
  .byte  102,65,15,114,227,16                // psrad         $0x10,%xmm11
  .byte  102,69,15,107,219                   // packssdw      %xmm11,%xmm11
  .byte  102,69,15,111,227                   // movdqa        %xmm11,%xmm12
  .byte  102,65,15,113,244,8                 // psllw         $0x8,%xmm12
  .byte  102,65,15,113,211,8                 // psrlw         $0x8,%xmm11
  .byte  102,69,15,235,220                   // por           %xmm12,%xmm11
  .byte  68,15,89,203                        // mulps         %xmm3,%xmm9
  .byte  102,69,15,91,201                    // cvtps2dq      %xmm9,%xmm9
  .byte  102,65,15,114,241,16                // pslld         $0x10,%xmm9
  .byte  102,65,15,114,225,16                // psrad         $0x10,%xmm9
  .byte  102,69,15,107,201                   // packssdw      %xmm9,%xmm9
  .byte  102,69,15,111,225                   // movdqa        %xmm9,%xmm12
  .byte  102,65,15,113,244,8                 // psllw         $0x8,%xmm12
  .byte  102,65,15,113,209,8                 // psrlw         $0x8,%xmm9
  .byte  102,69,15,235,204                   // por           %xmm12,%xmm9
  .byte  102,69,15,97,194                    // punpcklwd     %xmm10,%xmm8
  .byte  102,69,15,97,217                    // punpcklwd     %xmm9,%xmm11
  .byte  102,69,15,111,200                   // movdqa        %xmm8,%xmm9
  .byte  102,69,15,98,203                    // punpckldq     %xmm11,%xmm9
  .byte  243,68,15,127,12,248                // movdqu        %xmm9,(%rax,%rdi,8)
  .byte  102,69,15,106,195                   // punpckhdq     %xmm11,%xmm8
  .byte  243,68,15,127,68,248,16             // movdqu        %xmm8,0x10(%rax,%rdi,8)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_load_f32_sse2
.globl _sk_load_f32_sse2
FUNCTION(_sk_load_f32_sse2)
_sk_load_f32_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,137,249                          // mov           %rdi,%rcx
  .byte  72,193,225,4                        // shl           $0x4,%rcx
  .byte  68,15,16,4,8                        // movups        (%rax,%rcx,1),%xmm8
  .byte  15,16,68,8,16                       // movups        0x10(%rax,%rcx,1),%xmm0
  .byte  15,16,92,8,32                       // movups        0x20(%rax,%rcx,1),%xmm3
  .byte  68,15,16,76,8,48                    // movups        0x30(%rax,%rcx,1),%xmm9
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  15,20,208                           // unpcklps      %xmm0,%xmm2
  .byte  15,40,203                           // movaps        %xmm3,%xmm1
  .byte  65,15,20,201                        // unpcklps      %xmm9,%xmm1
  .byte  68,15,21,192                        // unpckhps      %xmm0,%xmm8
  .byte  65,15,21,217                        // unpckhps      %xmm9,%xmm3
  .byte  15,40,194                           // movaps        %xmm2,%xmm0
  .byte  102,15,20,193                       // unpcklpd      %xmm1,%xmm0
  .byte  15,18,202                           // movhlps       %xmm2,%xmm1
  .byte  65,15,40,208                        // movaps        %xmm8,%xmm2
  .byte  102,15,20,211                       // unpcklpd      %xmm3,%xmm2
  .byte  65,15,18,216                        // movhlps       %xmm8,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_store_f32_sse2
.globl _sk_store_f32_sse2
FUNCTION(_sk_store_f32_sse2)
_sk_store_f32_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,139,0                            // mov           (%rax),%rax
  .byte  72,137,249                          // mov           %rdi,%rcx
  .byte  72,193,225,4                        // shl           $0x4,%rcx
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  68,15,40,200                        // movaps        %xmm0,%xmm9
  .byte  68,15,20,201                        // unpcklps      %xmm1,%xmm9
  .byte  68,15,40,210                        // movaps        %xmm2,%xmm10
  .byte  68,15,40,218                        // movaps        %xmm2,%xmm11
  .byte  68,15,20,219                        // unpcklps      %xmm3,%xmm11
  .byte  68,15,21,193                        // unpckhps      %xmm1,%xmm8
  .byte  68,15,21,211                        // unpckhps      %xmm3,%xmm10
  .byte  69,15,40,225                        // movaps        %xmm9,%xmm12
  .byte  102,69,15,20,227                    // unpcklpd      %xmm11,%xmm12
  .byte  69,15,18,217                        // movhlps       %xmm9,%xmm11
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  102,69,15,20,202                    // unpcklpd      %xmm10,%xmm9
  .byte  69,15,18,208                        // movhlps       %xmm8,%xmm10
  .byte  102,68,15,17,36,8                   // movupd        %xmm12,(%rax,%rcx,1)
  .byte  68,15,17,92,8,16                    // movups        %xmm11,0x10(%rax,%rcx,1)
  .byte  102,68,15,17,76,8,32                // movupd        %xmm9,0x20(%rax,%rcx,1)
  .byte  68,15,17,84,8,48                    // movups        %xmm10,0x30(%rax,%rcx,1)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_x_sse2
.globl _sk_clamp_x_sse2
FUNCTION(_sk_clamp_x_sse2)
_sk_clamp_x_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  69,15,87,192                        // xorps         %xmm8,%xmm8
  .byte  68,15,95,192                        // maxps         %xmm0,%xmm8
  .byte  243,68,15,16,8                      // movss         (%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  102,15,118,192                      // pcmpeqd       %xmm0,%xmm0
  .byte  102,65,15,254,193                   // paddd         %xmm9,%xmm0
  .byte  68,15,93,192                        // minps         %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_clamp_y_sse2
.globl _sk_clamp_y_sse2
FUNCTION(_sk_clamp_y_sse2)
_sk_clamp_y_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  69,15,87,192                        // xorps         %xmm8,%xmm8
  .byte  68,15,95,193                        // maxps         %xmm1,%xmm8
  .byte  243,68,15,16,8                      // movss         (%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  102,15,118,201                      // pcmpeqd       %xmm1,%xmm1
  .byte  102,65,15,254,201                   // paddd         %xmm9,%xmm1
  .byte  68,15,93,193                        // minps         %xmm1,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,200                        // movaps        %xmm8,%xmm1
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_repeat_x_sse2
.globl _sk_repeat_x_sse2
FUNCTION(_sk_repeat_x_sse2)
_sk_repeat_x_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,0                      // movss         (%rax),%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,40,200                        // movaps        %xmm0,%xmm9
  .byte  69,15,94,200                        // divps         %xmm8,%xmm9
  .byte  243,69,15,91,209                    // cvttps2dq     %xmm9,%xmm10
  .byte  69,15,91,210                        // cvtdq2ps      %xmm10,%xmm10
  .byte  69,15,194,202,1                     // cmpltps       %xmm10,%xmm9
  .byte  68,15,84,13,30,17,0,0               // andps         0x111e(%rip),%xmm9        # 47b0 <_sk_callback_sse2+0x552>
  .byte  69,15,92,209                        // subps         %xmm9,%xmm10
  .byte  69,15,89,208                        // mulps         %xmm8,%xmm10
  .byte  65,15,92,194                        // subps         %xmm10,%xmm0
  .byte  102,69,15,118,201                   // pcmpeqd       %xmm9,%xmm9
  .byte  102,69,15,254,200                   // paddd         %xmm8,%xmm9
  .byte  65,15,93,193                        // minps         %xmm9,%xmm0
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_repeat_y_sse2
.globl _sk_repeat_y_sse2
FUNCTION(_sk_repeat_y_sse2)
_sk_repeat_y_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,0                      // movss         (%rax),%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,40,201                        // movaps        %xmm1,%xmm9
  .byte  69,15,94,200                        // divps         %xmm8,%xmm9
  .byte  243,69,15,91,209                    // cvttps2dq     %xmm9,%xmm10
  .byte  69,15,91,210                        // cvtdq2ps      %xmm10,%xmm10
  .byte  69,15,194,202,1                     // cmpltps       %xmm10,%xmm9
  .byte  68,15,84,13,230,16,0,0              // andps         0x10e6(%rip),%xmm9        # 47c0 <_sk_callback_sse2+0x562>
  .byte  69,15,92,209                        // subps         %xmm9,%xmm10
  .byte  69,15,89,208                        // mulps         %xmm8,%xmm10
  .byte  65,15,92,202                        // subps         %xmm10,%xmm1
  .byte  102,69,15,118,201                   // pcmpeqd       %xmm9,%xmm9
  .byte  102,69,15,254,200                   // paddd         %xmm8,%xmm9
  .byte  65,15,93,201                        // minps         %xmm9,%xmm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_mirror_x_sse2
.globl _sk_mirror_x_sse2
FUNCTION(_sk_mirror_x_sse2)
_sk_mirror_x_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,0                      // movss         (%rax),%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  65,15,92,193                        // subps         %xmm9,%xmm0
  .byte  243,69,15,88,192                    // addss         %xmm8,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,40,208                        // movaps        %xmm0,%xmm10
  .byte  69,15,94,208                        // divps         %xmm8,%xmm10
  .byte  243,69,15,91,218                    // cvttps2dq     %xmm10,%xmm11
  .byte  69,15,91,219                        // cvtdq2ps      %xmm11,%xmm11
  .byte  69,15,194,211,1                     // cmpltps       %xmm11,%xmm10
  .byte  68,15,84,21,156,16,0,0              // andps         0x109c(%rip),%xmm10        # 47d0 <_sk_callback_sse2+0x572>
  .byte  69,15,87,228                        // xorps         %xmm12,%xmm12
  .byte  69,15,92,218                        // subps         %xmm10,%xmm11
  .byte  69,15,89,216                        // mulps         %xmm8,%xmm11
  .byte  65,15,92,195                        // subps         %xmm11,%xmm0
  .byte  65,15,92,193                        // subps         %xmm9,%xmm0
  .byte  68,15,92,224                        // subps         %xmm0,%xmm12
  .byte  65,15,84,196                        // andps         %xmm12,%xmm0
  .byte  102,69,15,118,192                   // pcmpeqd       %xmm8,%xmm8
  .byte  102,69,15,254,193                   // paddd         %xmm9,%xmm8
  .byte  65,15,93,192                        // minps         %xmm8,%xmm0
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_mirror_y_sse2
.globl _sk_mirror_y_sse2
FUNCTION(_sk_mirror_y_sse2)
_sk_mirror_y_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,0                      // movss         (%rax),%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  65,15,92,201                        // subps         %xmm9,%xmm1
  .byte  243,69,15,88,192                    // addss         %xmm8,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  68,15,40,209                        // movaps        %xmm1,%xmm10
  .byte  69,15,94,208                        // divps         %xmm8,%xmm10
  .byte  243,69,15,91,218                    // cvttps2dq     %xmm10,%xmm11
  .byte  69,15,91,219                        // cvtdq2ps      %xmm11,%xmm11
  .byte  69,15,194,211,1                     // cmpltps       %xmm11,%xmm10
  .byte  68,15,84,21,66,16,0,0               // andps         0x1042(%rip),%xmm10        # 47e0 <_sk_callback_sse2+0x582>
  .byte  69,15,87,228                        // xorps         %xmm12,%xmm12
  .byte  69,15,92,218                        // subps         %xmm10,%xmm11
  .byte  69,15,89,216                        // mulps         %xmm8,%xmm11
  .byte  65,15,92,203                        // subps         %xmm11,%xmm1
  .byte  65,15,92,201                        // subps         %xmm9,%xmm1
  .byte  68,15,92,225                        // subps         %xmm1,%xmm12
  .byte  65,15,84,204                        // andps         %xmm12,%xmm1
  .byte  102,69,15,118,192                   // pcmpeqd       %xmm8,%xmm8
  .byte  102,69,15,254,193                   // paddd         %xmm9,%xmm8
  .byte  65,15,93,200                        // minps         %xmm8,%xmm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_luminance_to_alpha_sse2
.globl _sk_luminance_to_alpha_sse2
FUNCTION(_sk_luminance_to_alpha_sse2)
_sk_luminance_to_alpha_sse2:
  .byte  184,208,179,89,62                   // mov           $0x3e59b3d0,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  15,89,216                           // mulps         %xmm0,%xmm3
  .byte  184,89,23,55,63                     // mov           $0x3f371759,%eax
  .byte  102,15,110,192                      // movd          %eax,%xmm0
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  15,88,195                           // addps         %xmm3,%xmm0
  .byte  184,152,221,147,61                  // mov           $0x3d93dd98,%eax
  .byte  102,15,110,216                      // movd          %eax,%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  15,89,218                           // mulps         %xmm2,%xmm3
  .byte  15,88,216                           // addps         %xmm0,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  15,87,192                           // xorps         %xmm0,%xmm0
  .byte  15,87,201                           // xorps         %xmm1,%xmm1
  .byte  15,87,210                           // xorps         %xmm2,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_2x3_sse2
.globl _sk_matrix_2x3_sse2
FUNCTION(_sk_matrix_2x3_sse2)
_sk_matrix_2x3_sse2:
  .byte  68,15,40,201                        // movaps        %xmm1,%xmm9
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,15,16,0                         // movss         (%rax),%xmm0
  .byte  243,15,16,72,4                      // movss         0x4(%rax),%xmm1
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  243,68,15,16,80,8                   // movss         0x8(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,16                  // movss         0x10(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  65,15,88,194                        // addps         %xmm10,%xmm0
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  243,68,15,16,80,12                  // movss         0xc(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,20                  // movss         0x14(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  65,15,88,202                        // addps         %xmm10,%xmm1
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_3x4_sse2
.globl _sk_matrix_3x4_sse2
FUNCTION(_sk_matrix_3x4_sse2)
_sk_matrix_3x4_sse2:
  .byte  68,15,40,201                        // movaps        %xmm1,%xmm9
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,15,16,0                         // movss         (%rax),%xmm0
  .byte  243,15,16,72,4                      // movss         0x4(%rax),%xmm1
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  243,68,15,16,80,12                  // movss         0xc(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,24                  // movss         0x18(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,36                  // movss         0x24(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  65,15,88,194                        // addps         %xmm10,%xmm0
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  243,68,15,16,80,16                  // movss         0x10(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,28                  // movss         0x1c(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,40                  // movss         0x28(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  65,15,88,202                        // addps         %xmm10,%xmm1
  .byte  243,68,15,16,80,8                   // movss         0x8(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,20                  // movss         0x14(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,32                  // movss         0x20(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  243,68,15,16,104,44                 // movss         0x2c(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  68,15,89,226                        // mulps         %xmm2,%xmm12
  .byte  69,15,88,229                        // addps         %xmm13,%xmm12
  .byte  69,15,89,217                        // mulps         %xmm9,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  69,15,89,208                        // mulps         %xmm8,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_4x5_sse2
.globl _sk_matrix_4x5_sse2
FUNCTION(_sk_matrix_4x5_sse2)
_sk_matrix_4x5_sse2:
  .byte  68,15,40,201                        // movaps        %xmm1,%xmm9
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,15,16,0                         // movss         (%rax),%xmm0
  .byte  243,15,16,72,4                      // movss         0x4(%rax),%xmm1
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  243,68,15,16,80,16                  // movss         0x10(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,32                  // movss         0x20(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,48                  // movss         0x30(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  243,68,15,16,104,64                 // movss         0x40(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  68,15,89,227                        // mulps         %xmm3,%xmm12
  .byte  69,15,88,229                        // addps         %xmm13,%xmm12
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  65,15,88,194                        // addps         %xmm10,%xmm0
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  243,68,15,16,80,20                  // movss         0x14(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,36                  // movss         0x24(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,52                  // movss         0x34(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  243,68,15,16,104,68                 // movss         0x44(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  68,15,89,227                        // mulps         %xmm3,%xmm12
  .byte  69,15,88,229                        // addps         %xmm13,%xmm12
  .byte  68,15,89,218                        // mulps         %xmm2,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  65,15,88,202                        // addps         %xmm10,%xmm1
  .byte  243,68,15,16,80,8                   // movss         0x8(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,24                  // movss         0x18(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,40                  // movss         0x28(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  243,68,15,16,104,56                 // movss         0x38(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  243,68,15,16,112,72                 // movss         0x48(%rax),%xmm14
  .byte  69,15,198,246,0                     // shufps        $0x0,%xmm14,%xmm14
  .byte  68,15,89,235                        // mulps         %xmm3,%xmm13
  .byte  69,15,88,238                        // addps         %xmm14,%xmm13
  .byte  68,15,89,226                        // mulps         %xmm2,%xmm12
  .byte  69,15,88,229                        // addps         %xmm13,%xmm12
  .byte  69,15,89,217                        // mulps         %xmm9,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  69,15,89,208                        // mulps         %xmm8,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  243,68,15,16,88,12                  // movss         0xc(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,28                  // movss         0x1c(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  243,68,15,16,104,44                 // movss         0x2c(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  243,68,15,16,112,60                 // movss         0x3c(%rax),%xmm14
  .byte  69,15,198,246,0                     // shufps        $0x0,%xmm14,%xmm14
  .byte  243,68,15,16,120,76                 // movss         0x4c(%rax),%xmm15
  .byte  69,15,198,255,0                     // shufps        $0x0,%xmm15,%xmm15
  .byte  68,15,89,243                        // mulps         %xmm3,%xmm14
  .byte  69,15,88,247                        // addps         %xmm15,%xmm14
  .byte  68,15,89,234                        // mulps         %xmm2,%xmm13
  .byte  69,15,88,238                        // addps         %xmm14,%xmm13
  .byte  69,15,89,225                        // mulps         %xmm9,%xmm12
  .byte  69,15,88,229                        // addps         %xmm13,%xmm12
  .byte  69,15,89,216                        // mulps         %xmm8,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,210                        // movaps        %xmm10,%xmm2
  .byte  65,15,40,219                        // movaps        %xmm11,%xmm3
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_matrix_perspective_sse2
.globl _sk_matrix_perspective_sse2
FUNCTION(_sk_matrix_perspective_sse2)
_sk_matrix_perspective_sse2:
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,15,16,0                         // movss         (%rax),%xmm0
  .byte  243,68,15,16,72,4                   // movss         0x4(%rax),%xmm9
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  243,68,15,16,80,8                   // movss         0x8(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  68,15,89,201                        // mulps         %xmm1,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  65,15,88,193                        // addps         %xmm9,%xmm0
  .byte  243,68,15,16,72,12                  // movss         0xc(%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  243,68,15,16,80,16                  // movss         0x10(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,20                  // movss         0x14(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  68,15,89,209                        // mulps         %xmm1,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  243,68,15,16,80,24                  // movss         0x18(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,28                  // movss         0x1c(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,32                  // movss         0x20(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  68,15,89,217                        // mulps         %xmm1,%xmm11
  .byte  69,15,88,220                        // addps         %xmm12,%xmm11
  .byte  69,15,89,208                        // mulps         %xmm8,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  65,15,83,202                        // rcpps         %xmm10,%xmm1
  .byte  15,89,193                           // mulps         %xmm1,%xmm0
  .byte  68,15,89,201                        // mulps         %xmm1,%xmm9
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,201                        // movaps        %xmm9,%xmm1
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_linear_gradient_sse2
.globl _sk_linear_gradient_sse2
FUNCTION(_sk_linear_gradient_sse2)
_sk_linear_gradient_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,68,15,16,72,16                  // movss         0x10(%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  243,68,15,16,80,20                  // movss         0x14(%rax),%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  243,68,15,16,88,24                  // movss         0x18(%rax),%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  243,68,15,16,96,28                  // movss         0x1c(%rax),%xmm12
  .byte  69,15,198,228,0                     // shufps        $0x0,%xmm12,%xmm12
  .byte  72,139,8                            // mov           (%rax),%rcx
  .byte  72,133,201                          // test          %rcx,%rcx
  .byte  15,132,15,1,0,0                     // je            3cb2 <_sk_linear_gradient_sse2+0x149>
  .byte  72,139,64,8                         // mov           0x8(%rax),%rax
  .byte  72,131,192,32                       // add           $0x20,%rax
  .byte  69,15,87,192                        // xorps         %xmm8,%xmm8
  .byte  15,87,219                           // xorps         %xmm3,%xmm3
  .byte  15,87,210                           // xorps         %xmm2,%xmm2
  .byte  15,87,201                           // xorps         %xmm1,%xmm1
  .byte  243,68,15,16,112,224                // movss         -0x20(%rax),%xmm14
  .byte  243,68,15,16,104,228                // movss         -0x1c(%rax),%xmm13
  .byte  69,15,198,246,0                     // shufps        $0x0,%xmm14,%xmm14
  .byte  69,15,40,252                        // movaps        %xmm12,%xmm15
  .byte  68,15,40,224                        // movaps        %xmm0,%xmm12
  .byte  69,15,194,230,1                     // cmpltps       %xmm14,%xmm12
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  69,15,40,244                        // movaps        %xmm12,%xmm14
  .byte  69,15,85,245                        // andnps        %xmm13,%xmm14
  .byte  69,15,84,196                        // andps         %xmm12,%xmm8
  .byte  69,15,86,198                        // orps          %xmm14,%xmm8
  .byte  243,68,15,16,104,232                // movss         -0x18(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  69,15,40,244                        // movaps        %xmm12,%xmm14
  .byte  69,15,85,245                        // andnps        %xmm13,%xmm14
  .byte  65,15,84,204                        // andps         %xmm12,%xmm1
  .byte  65,15,86,206                        // orps          %xmm14,%xmm1
  .byte  243,68,15,16,104,236                // movss         -0x14(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  69,15,40,244                        // movaps        %xmm12,%xmm14
  .byte  69,15,85,245                        // andnps        %xmm13,%xmm14
  .byte  65,15,84,212                        // andps         %xmm12,%xmm2
  .byte  65,15,86,214                        // orps          %xmm14,%xmm2
  .byte  243,68,15,16,104,240                // movss         -0x10(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  69,15,40,244                        // movaps        %xmm12,%xmm14
  .byte  69,15,85,245                        // andnps        %xmm13,%xmm14
  .byte  65,15,84,220                        // andps         %xmm12,%xmm3
  .byte  65,15,86,222                        // orps          %xmm14,%xmm3
  .byte  243,68,15,16,104,244                // movss         -0xc(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  69,15,40,244                        // movaps        %xmm12,%xmm14
  .byte  69,15,85,245                        // andnps        %xmm13,%xmm14
  .byte  69,15,84,204                        // andps         %xmm12,%xmm9
  .byte  69,15,86,206                        // orps          %xmm14,%xmm9
  .byte  243,68,15,16,104,248                // movss         -0x8(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  69,15,40,244                        // movaps        %xmm12,%xmm14
  .byte  69,15,85,245                        // andnps        %xmm13,%xmm14
  .byte  69,15,84,212                        // andps         %xmm12,%xmm10
  .byte  69,15,86,214                        // orps          %xmm14,%xmm10
  .byte  243,68,15,16,104,252                // movss         -0x4(%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  69,15,40,244                        // movaps        %xmm12,%xmm14
  .byte  69,15,85,245                        // andnps        %xmm13,%xmm14
  .byte  69,15,84,220                        // andps         %xmm12,%xmm11
  .byte  69,15,86,222                        // orps          %xmm14,%xmm11
  .byte  243,68,15,16,40                     // movss         (%rax),%xmm13
  .byte  69,15,198,237,0                     // shufps        $0x0,%xmm13,%xmm13
  .byte  69,15,84,252                        // andps         %xmm12,%xmm15
  .byte  69,15,85,229                        // andnps        %xmm13,%xmm12
  .byte  69,15,86,231                        // orps          %xmm15,%xmm12
  .byte  72,131,192,36                       // add           $0x24,%rax
  .byte  72,255,201                          // dec           %rcx
  .byte  15,133,8,255,255,255                // jne           3bb8 <_sk_linear_gradient_sse2+0x4f>
  .byte  235,13                              // jmp           3cbf <_sk_linear_gradient_sse2+0x156>
  .byte  15,87,201                           // xorps         %xmm1,%xmm1
  .byte  15,87,210                           // xorps         %xmm2,%xmm2
  .byte  15,87,219                           // xorps         %xmm3,%xmm3
  .byte  69,15,87,192                        // xorps         %xmm8,%xmm8
  .byte  68,15,89,192                        // mulps         %xmm0,%xmm8
  .byte  69,15,88,193                        // addps         %xmm9,%xmm8
  .byte  15,89,200                           // mulps         %xmm0,%xmm1
  .byte  65,15,88,202                        // addps         %xmm10,%xmm1
  .byte  15,89,208                           // mulps         %xmm0,%xmm2
  .byte  65,15,88,211                        // addps         %xmm11,%xmm2
  .byte  15,89,216                           // mulps         %xmm0,%xmm3
  .byte  65,15,88,220                        // addps         %xmm12,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  65,15,40,192                        // movaps        %xmm8,%xmm0
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_linear_gradient_2stops_sse2
.globl _sk_linear_gradient_2stops_sse2
FUNCTION(_sk_linear_gradient_2stops_sse2)
_sk_linear_gradient_2stops_sse2:
  .byte  68,15,40,192                        // movaps        %xmm0,%xmm8
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  243,15,16,0                         // movss         (%rax),%xmm0
  .byte  243,15,16,72,4                      // movss         0x4(%rax),%xmm1
  .byte  15,198,192,0                        // shufps        $0x0,%xmm0,%xmm0
  .byte  243,15,16,80,16                     // movss         0x10(%rax),%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  65,15,89,192                        // mulps         %xmm8,%xmm0
  .byte  15,88,194                           // addps         %xmm2,%xmm0
  .byte  15,198,201,0                        // shufps        $0x0,%xmm1,%xmm1
  .byte  243,15,16,80,20                     // movss         0x14(%rax),%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  65,15,89,200                        // mulps         %xmm8,%xmm1
  .byte  15,88,202                           // addps         %xmm2,%xmm1
  .byte  243,15,16,80,8                      // movss         0x8(%rax),%xmm2
  .byte  15,198,210,0                        // shufps        $0x0,%xmm2,%xmm2
  .byte  243,15,16,88,24                     // movss         0x18(%rax),%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  65,15,89,208                        // mulps         %xmm8,%xmm2
  .byte  15,88,211                           // addps         %xmm3,%xmm2
  .byte  243,15,16,88,12                     // movss         0xc(%rax),%xmm3
  .byte  15,198,219,0                        // shufps        $0x0,%xmm3,%xmm3
  .byte  243,68,15,16,72,28                  // movss         0x1c(%rax),%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  65,15,89,216                        // mulps         %xmm8,%xmm3
  .byte  65,15,88,217                        // addps         %xmm9,%xmm3
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_save_xy_sse2
.globl _sk_save_xy_sse2
FUNCTION(_sk_save_xy_sse2)
_sk_save_xy_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,63                        // mov           $0x3f000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,40,200                        // movaps        %xmm8,%xmm9
  .byte  68,15,88,200                        // addps         %xmm0,%xmm9
  .byte  243,69,15,91,209                    // cvttps2dq     %xmm9,%xmm10
  .byte  69,15,91,210                        // cvtdq2ps      %xmm10,%xmm10
  .byte  69,15,40,217                        // movaps        %xmm9,%xmm11
  .byte  69,15,194,218,1                     // cmpltps       %xmm10,%xmm11
  .byte  68,15,40,37,105,10,0,0              // movaps        0xa69(%rip),%xmm12        # 47f0 <_sk_callback_sse2+0x592>
  .byte  69,15,84,220                        // andps         %xmm12,%xmm11
  .byte  69,15,92,211                        // subps         %xmm11,%xmm10
  .byte  69,15,92,202                        // subps         %xmm10,%xmm9
  .byte  68,15,88,193                        // addps         %xmm1,%xmm8
  .byte  243,69,15,91,208                    // cvttps2dq     %xmm8,%xmm10
  .byte  69,15,91,210                        // cvtdq2ps      %xmm10,%xmm10
  .byte  69,15,40,216                        // movaps        %xmm8,%xmm11
  .byte  69,15,194,218,1                     // cmpltps       %xmm10,%xmm11
  .byte  69,15,84,220                        // andps         %xmm12,%xmm11
  .byte  69,15,92,211                        // subps         %xmm11,%xmm10
  .byte  69,15,92,194                        // subps         %xmm10,%xmm8
  .byte  15,17,0                             // movups        %xmm0,(%rax)
  .byte  15,17,72,32                         // movups        %xmm1,0x20(%rax)
  .byte  68,15,17,72,64                      // movups        %xmm9,0x40(%rax)
  .byte  68,15,17,64,96                      // movups        %xmm8,0x60(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_accumulate_sse2
.globl _sk_accumulate_sse2
FUNCTION(_sk_accumulate_sse2)
_sk_accumulate_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  68,15,16,128,128,0,0,0              // movups        0x80(%rax),%xmm8
  .byte  68,15,16,136,160,0,0,0              // movups        0xa0(%rax),%xmm9
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,40,193                        // movaps        %xmm9,%xmm8
  .byte  68,15,89,192                        // mulps         %xmm0,%xmm8
  .byte  65,15,88,224                        // addps         %xmm8,%xmm4
  .byte  69,15,40,193                        // movaps        %xmm9,%xmm8
  .byte  68,15,89,193                        // mulps         %xmm1,%xmm8
  .byte  65,15,88,232                        // addps         %xmm8,%xmm5
  .byte  69,15,40,193                        // movaps        %xmm9,%xmm8
  .byte  68,15,89,194                        // mulps         %xmm2,%xmm8
  .byte  65,15,88,240                        // addps         %xmm8,%xmm6
  .byte  68,15,89,203                        // mulps         %xmm3,%xmm9
  .byte  65,15,88,249                        // addps         %xmm9,%xmm7
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_nx_sse2
.globl _sk_bilinear_nx_sse2
FUNCTION(_sk_bilinear_nx_sse2)
_sk_bilinear_nx_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,191                       // mov           $0xbf000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,0                             // movups        (%rax),%xmm0
  .byte  68,15,16,72,64                      // movups        0x40(%rax),%xmm9
  .byte  65,15,88,192                        // addps         %xmm8,%xmm0
  .byte  185,0,0,128,63                      // mov           $0x3f800000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,92,193                        // subps         %xmm9,%xmm8
  .byte  68,15,17,128,128,0,0,0              // movups        %xmm8,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_px_sse2
.globl _sk_bilinear_px_sse2
FUNCTION(_sk_bilinear_px_sse2)
_sk_bilinear_px_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,63                        // mov           $0x3f000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,0                             // movups        (%rax),%xmm0
  .byte  68,15,16,72,64                      // movups        0x40(%rax),%xmm9
  .byte  65,15,88,192                        // addps         %xmm8,%xmm0
  .byte  68,15,17,136,128,0,0,0              // movups        %xmm9,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_ny_sse2
.globl _sk_bilinear_ny_sse2
FUNCTION(_sk_bilinear_ny_sse2)
_sk_bilinear_ny_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,191                       // mov           $0xbf000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,72,32                         // movups        0x20(%rax),%xmm1
  .byte  68,15,16,72,96                      // movups        0x60(%rax),%xmm9
  .byte  65,15,88,200                        // addps         %xmm8,%xmm1
  .byte  185,0,0,128,63                      // mov           $0x3f800000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,92,193                        // subps         %xmm9,%xmm8
  .byte  68,15,17,128,160,0,0,0              // movups        %xmm8,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bilinear_py_sse2
.globl _sk_bilinear_py_sse2
FUNCTION(_sk_bilinear_py_sse2)
_sk_bilinear_py_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,63                        // mov           $0x3f000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,72,32                         // movups        0x20(%rax),%xmm1
  .byte  68,15,16,72,96                      // movups        0x60(%rax),%xmm9
  .byte  65,15,88,200                        // addps         %xmm8,%xmm1
  .byte  68,15,17,136,160,0,0,0              // movups        %xmm9,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n3x_sse2
.globl _sk_bicubic_n3x_sse2
FUNCTION(_sk_bicubic_n3x_sse2)
_sk_bicubic_n3x_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,192,191                     // mov           $0xbfc00000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,0                             // movups        (%rax),%xmm0
  .byte  68,15,16,72,64                      // movups        0x40(%rax),%xmm9
  .byte  65,15,88,192                        // addps         %xmm8,%xmm0
  .byte  185,0,0,128,63                      // mov           $0x3f800000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,92,193                        // subps         %xmm9,%xmm8
  .byte  185,114,28,199,62                   // mov           $0x3ec71c72,%ecx
  .byte  102,68,15,110,201                   // movd          %ecx,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  185,171,170,170,190                 // mov           $0xbeaaaaab,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,89,192                        // mulps         %xmm8,%xmm8
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  68,15,17,136,128,0,0,0              // movups        %xmm9,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n1x_sse2
.globl _sk_bicubic_n1x_sse2
FUNCTION(_sk_bicubic_n1x_sse2)
_sk_bicubic_n1x_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,191                       // mov           $0xbf000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,0                             // movups        (%rax),%xmm0
  .byte  68,15,16,72,64                      // movups        0x40(%rax),%xmm9
  .byte  65,15,88,192                        // addps         %xmm8,%xmm0
  .byte  185,0,0,128,63                      // mov           $0x3f800000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,92,193                        // subps         %xmm9,%xmm8
  .byte  185,85,85,149,191                   // mov           $0xbf955555,%ecx
  .byte  102,68,15,110,201                   // movd          %ecx,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  185,0,0,192,63                      // mov           $0x3fc00000,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  185,0,0,0,63                        // mov           $0x3f000000,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  185,57,142,99,61                    // mov           $0x3d638e39,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  68,15,17,136,128,0,0,0              // movups        %xmm9,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p1x_sse2
.globl _sk_bicubic_p1x_sse2
FUNCTION(_sk_bicubic_p1x_sse2)
_sk_bicubic_p1x_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,63                        // mov           $0x3f000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,0                             // movups        (%rax),%xmm0
  .byte  68,15,16,72,64                      // movups        0x40(%rax),%xmm9
  .byte  65,15,88,192                        // addps         %xmm8,%xmm0
  .byte  185,85,85,149,191                   // mov           $0xbf955555,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  185,0,0,192,63                      // mov           $0x3fc00000,%ecx
  .byte  102,68,15,110,217                   // movd          %ecx,%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,208                        // addps         %xmm8,%xmm10
  .byte  185,57,142,99,61                    // mov           $0x3d638e39,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,208                        // addps         %xmm8,%xmm10
  .byte  68,15,17,144,128,0,0,0              // movups        %xmm10,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p3x_sse2
.globl _sk_bicubic_p3x_sse2
FUNCTION(_sk_bicubic_p3x_sse2)
_sk_bicubic_p3x_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,192,63                      // mov           $0x3fc00000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,0                             // movups        (%rax),%xmm0
  .byte  68,15,16,72,64                      // movups        0x40(%rax),%xmm9
  .byte  65,15,88,192                        // addps         %xmm8,%xmm0
  .byte  185,114,28,199,62                   // mov           $0x3ec71c72,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,89,193                        // mulps         %xmm9,%xmm8
  .byte  69,15,89,201                        // mulps         %xmm9,%xmm9
  .byte  185,171,170,170,190                 // mov           $0xbeaaaaab,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,88,194                        // addps         %xmm10,%xmm8
  .byte  69,15,89,193                        // mulps         %xmm9,%xmm8
  .byte  68,15,17,128,128,0,0,0              // movups        %xmm8,0x80(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n3y_sse2
.globl _sk_bicubic_n3y_sse2
FUNCTION(_sk_bicubic_n3y_sse2)
_sk_bicubic_n3y_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,192,191                     // mov           $0xbfc00000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,72,32                         // movups        0x20(%rax),%xmm1
  .byte  68,15,16,72,96                      // movups        0x60(%rax),%xmm9
  .byte  65,15,88,200                        // addps         %xmm8,%xmm1
  .byte  185,0,0,128,63                      // mov           $0x3f800000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,92,193                        // subps         %xmm9,%xmm8
  .byte  185,114,28,199,62                   // mov           $0x3ec71c72,%ecx
  .byte  102,68,15,110,201                   // movd          %ecx,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  185,171,170,170,190                 // mov           $0xbeaaaaab,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,89,192                        // mulps         %xmm8,%xmm8
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  68,15,17,136,160,0,0,0              // movups        %xmm9,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_n1y_sse2
.globl _sk_bicubic_n1y_sse2
FUNCTION(_sk_bicubic_n1y_sse2)
_sk_bicubic_n1y_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,191                       // mov           $0xbf000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,72,32                         // movups        0x20(%rax),%xmm1
  .byte  68,15,16,72,96                      // movups        0x60(%rax),%xmm9
  .byte  65,15,88,200                        // addps         %xmm8,%xmm1
  .byte  185,0,0,128,63                      // mov           $0x3f800000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,92,193                        // subps         %xmm9,%xmm8
  .byte  185,85,85,149,191                   // mov           $0xbf955555,%ecx
  .byte  102,68,15,110,201                   // movd          %ecx,%xmm9
  .byte  69,15,198,201,0                     // shufps        $0x0,%xmm9,%xmm9
  .byte  185,0,0,192,63                      // mov           $0x3fc00000,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  185,0,0,0,63                        // mov           $0x3f000000,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  185,57,142,99,61                    // mov           $0x3d638e39,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,89,200                        // mulps         %xmm8,%xmm9
  .byte  69,15,88,202                        // addps         %xmm10,%xmm9
  .byte  68,15,17,136,160,0,0,0              // movups        %xmm9,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p1y_sse2
.globl _sk_bicubic_p1y_sse2
FUNCTION(_sk_bicubic_p1y_sse2)
_sk_bicubic_p1y_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,0,63                        // mov           $0x3f000000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,72,32                         // movups        0x20(%rax),%xmm1
  .byte  68,15,16,72,96                      // movups        0x60(%rax),%xmm9
  .byte  65,15,88,200                        // addps         %xmm8,%xmm1
  .byte  185,85,85,149,191                   // mov           $0xbf955555,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  185,0,0,192,63                      // mov           $0x3fc00000,%ecx
  .byte  102,68,15,110,217                   // movd          %ecx,%xmm11
  .byte  69,15,198,219,0                     // shufps        $0x0,%xmm11,%xmm11
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,211                        // addps         %xmm11,%xmm10
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,208                        // addps         %xmm8,%xmm10
  .byte  185,57,142,99,61                    // mov           $0x3d638e39,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,89,209                        // mulps         %xmm9,%xmm10
  .byte  69,15,88,208                        // addps         %xmm8,%xmm10
  .byte  68,15,17,144,160,0,0,0              // movups        %xmm10,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_bicubic_p3y_sse2
.globl _sk_bicubic_p3y_sse2
FUNCTION(_sk_bicubic_p3y_sse2)
_sk_bicubic_p3y_sse2:
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  185,0,0,192,63                      // mov           $0x3fc00000,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  15,16,72,32                         // movups        0x20(%rax),%xmm1
  .byte  68,15,16,72,96                      // movups        0x60(%rax),%xmm9
  .byte  65,15,88,200                        // addps         %xmm8,%xmm1
  .byte  185,114,28,199,62                   // mov           $0x3ec71c72,%ecx
  .byte  102,68,15,110,193                   // movd          %ecx,%xmm8
  .byte  69,15,198,192,0                     // shufps        $0x0,%xmm8,%xmm8
  .byte  69,15,89,193                        // mulps         %xmm9,%xmm8
  .byte  69,15,89,201                        // mulps         %xmm9,%xmm9
  .byte  185,171,170,170,190                 // mov           $0xbeaaaaab,%ecx
  .byte  102,68,15,110,209                   // movd          %ecx,%xmm10
  .byte  69,15,198,210,0                     // shufps        $0x0,%xmm10,%xmm10
  .byte  69,15,88,194                        // addps         %xmm10,%xmm8
  .byte  69,15,89,193                        // mulps         %xmm9,%xmm8
  .byte  68,15,17,128,160,0,0,0              // movups        %xmm8,0xa0(%rax)
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  255,224                             // jmpq          *%rax

HIDDEN _sk_callback_sse2
.globl _sk_callback_sse2
FUNCTION(_sk_callback_sse2)
_sk_callback_sse2:
  .byte  65,87                               // push          %r15
  .byte  65,86                               // push          %r14
  .byte  65,84                               // push          %r12
  .byte  83                                  // push          %rbx
  .byte  72,131,236,72                       // sub           $0x48,%rsp
  .byte  15,41,124,36,48                     // movaps        %xmm7,0x30(%rsp)
  .byte  15,41,116,36,32                     // movaps        %xmm6,0x20(%rsp)
  .byte  15,41,108,36,16                     // movaps        %xmm5,0x10(%rsp)
  .byte  15,41,36,36                         // movaps        %xmm4,(%rsp)
  .byte  73,137,214                          // mov           %rdx,%r14
  .byte  73,137,255                          // mov           %rdi,%r15
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  72,137,195                          // mov           %rax,%rbx
  .byte  73,137,244                          // mov           %rsi,%r12
  .byte  15,40,224                           // movaps        %xmm0,%xmm4
  .byte  15,20,225                           // unpcklps      %xmm1,%xmm4
  .byte  15,40,234                           // movaps        %xmm2,%xmm5
  .byte  15,20,235                           // unpcklps      %xmm3,%xmm5
  .byte  15,21,193                           // unpckhps      %xmm1,%xmm0
  .byte  15,21,211                           // unpckhps      %xmm3,%xmm2
  .byte  15,40,204                           // movaps        %xmm4,%xmm1
  .byte  102,15,20,205                       // unpcklpd      %xmm5,%xmm1
  .byte  15,18,236                           // movhlps       %xmm4,%xmm5
  .byte  15,40,216                           // movaps        %xmm0,%xmm3
  .byte  102,15,20,218                       // unpcklpd      %xmm2,%xmm3
  .byte  15,18,208                           // movhlps       %xmm0,%xmm2
  .byte  102,15,17,75,8                      // movupd        %xmm1,0x8(%rbx)
  .byte  15,17,107,24                        // movups        %xmm5,0x18(%rbx)
  .byte  102,15,17,91,40                     // movupd        %xmm3,0x28(%rbx)
  .byte  15,17,83,56                         // movups        %xmm2,0x38(%rbx)
  .byte  190,4,0,0,0                         // mov           $0x4,%esi
  .byte  72,137,223                          // mov           %rbx,%rdi
  .byte  255,19                              // callq         *(%rbx)
  .byte  72,139,131,136,0,0,0                // mov           0x88(%rbx),%rax
  .byte  15,16,32                            // movups        (%rax),%xmm4
  .byte  15,16,64,16                         // movups        0x10(%rax),%xmm0
  .byte  15,16,88,32                         // movups        0x20(%rax),%xmm3
  .byte  15,16,80,48                         // movups        0x30(%rax),%xmm2
  .byte  15,40,236                           // movaps        %xmm4,%xmm5
  .byte  15,20,232                           // unpcklps      %xmm0,%xmm5
  .byte  15,40,203                           // movaps        %xmm3,%xmm1
  .byte  15,20,202                           // unpcklps      %xmm2,%xmm1
  .byte  15,21,224                           // unpckhps      %xmm0,%xmm4
  .byte  15,21,218                           // unpckhps      %xmm2,%xmm3
  .byte  15,40,197                           // movaps        %xmm5,%xmm0
  .byte  102,15,20,193                       // unpcklpd      %xmm1,%xmm0
  .byte  15,18,205                           // movhlps       %xmm5,%xmm1
  .byte  15,40,212                           // movaps        %xmm4,%xmm2
  .byte  102,15,20,211                       // unpcklpd      %xmm3,%xmm2
  .byte  15,18,220                           // movhlps       %xmm4,%xmm3
  .byte  76,137,230                          // mov           %r12,%rsi
  .byte  72,173                              // lods          %ds:(%rsi),%rax
  .byte  76,137,255                          // mov           %r15,%rdi
  .byte  76,137,242                          // mov           %r14,%rdx
  .byte  15,40,36,36                         // movaps        (%rsp),%xmm4
  .byte  15,40,108,36,16                     // movaps        0x10(%rsp),%xmm5
  .byte  15,40,116,36,32                     // movaps        0x20(%rsp),%xmm6
  .byte  15,40,124,36,48                     // movaps        0x30(%rsp),%xmm7
  .byte  72,131,196,72                       // add           $0x48,%rsp
  .byte  91                                  // pop           %rbx
  .byte  65,92                               // pop           %r12
  .byte  65,94                               // pop           %r14
  .byte  65,95                               // pop           %r15
  .byte  255,224                             // jmpq          *%rax

BALIGN16
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  128,63,0                            // cmpb          $0x0,(%rdi)
  .byte  0,128,63,0,0,128                    // add           %al,-0x7fffffc1(%rax)
  .byte  63                                  // (bad)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  128,63,255                          // cmpb          $0xff,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,255                               // add           %bh,%bh
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,255                               // add           %bh,%bh
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,255                               // add           %bh,%bh
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,255                               // add           %bh,%bh
  .byte  0,255                               // add           %bh,%bh
  .byte  0,255                               // add           %bh,%bh
  .byte  0,255                               // add           %bh,%bh
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,255                               // add           %bh,%bh
  .byte  0,255                               // add           %bh,%bh
  .byte  0,255                               // add           %bh,%bh
  .byte  0,255                               // add           %bh,%bh
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,0                                // xor           $0x0,%al
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,0                                // xor           $0x0,%al
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,0                                // xor           $0x0,%al
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,255                              // xor           $0xff,%al
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            43a4 <.literal16+0x64>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            43a8 <.literal16+0x68>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            43ac <.literal16+0x6c>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            43b0 <.literal16+0x70>
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  119,115                             // ja            4435 <.literal16+0xf5>
  .byte  248                                 // clc
  .byte  194,119,115                         // retq          $0x7377
  .byte  248                                 // clc
  .byte  194,119,115                         // retq          $0x7377
  .byte  248                                 // clc
  .byte  194,119,115                         // retq          $0x7377
  .byte  248                                 // clc
  .byte  194,117,191                         // retq          $0xbf75
  .byte  191,63,117,191,191                  // mov           $0xbfbf753f,%edi
  .byte  63                                  // (bad)
  .byte  117,191                             // jne           4399 <.literal16+0x59>
  .byte  191,63,117,191,191                  // mov           $0xbfbf753f,%edi
  .byte  63                                  // (bad)
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  163,233,220,63,163,233,220,63,163   // movabs        %eax,0xa33fdce9a33fdce9
  .byte  233,220,63,163,233                  // jmpq          ffffffffe9a383da <_sk_callback_sse2+0xffffffffe9a3417c>
  .byte  220,63                              // fdivrl        (%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  128,63,0                            // cmpb          $0x0,(%rdi)
  .byte  0,128,63,0,0,128                    // add           %al,-0x7fffffc1(%rax)
  .byte  63                                  // (bad)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  128,63,81                           // cmpb          $0x51,(%rdi)
  .byte  140,242                             // mov           %?,%edx
  .byte  66,81                               // rex.X         push %rcx
  .byte  140,242                             // mov           %?,%edx
  .byte  66,81                               // rex.X         push %rcx
  .byte  140,242                             // mov           %?,%edx
  .byte  66,81                               // rex.X         push %rcx
  .byte  140,242                             // mov           %?,%edx
  .byte  66,141,188,190,63,141,188,190       // lea           -0x414372c1(%rsi,%r15,4),%edi
  .byte  63                                  // (bad)
  .byte  141,188,190,63,141,188,190          // lea           -0x414372c1(%rsi,%rdi,4),%edi
  .byte  63                                  // (bad)
  .byte  248                                 // clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,248                              // rex           clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,248                              // rex           clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,248                              // rex           clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,254                              // rex           (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,254                              // rex.B         (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,254                              // rex.B         (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,254                              // rex.B         (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,0,0                              // add           %al,(%r8)
  .byte  0,75,0                              // add           %cl,0x0(%rbx)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  75,0,0                              // rex.WXB       add %al,(%r8)
  .byte  0,75,0                              // add           %cl,0x0(%rbx)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  75,0,0                              // rex.WXB       add %al,(%r8)
  .byte  0,52,0                              // add           %dh,(%rax,%rax,1)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,0                                // xor           $0x0,%al
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,0                                // xor           $0x0,%al
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,255                              // xor           $0xff,%al
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            4474 <.literal16+0x134>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            4478 <.literal16+0x138>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            447c <.literal16+0x13c>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            4480 <.literal16+0x140>
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  119,115                             // ja            4505 <.literal16+0x1c5>
  .byte  248                                 // clc
  .byte  194,119,115                         // retq          $0x7377
  .byte  248                                 // clc
  .byte  194,119,115                         // retq          $0x7377
  .byte  248                                 // clc
  .byte  194,119,115                         // retq          $0x7377
  .byte  248                                 // clc
  .byte  194,117,191                         // retq          $0xbf75
  .byte  191,63,117,191,191                  // mov           $0xbfbf753f,%edi
  .byte  63                                  // (bad)
  .byte  117,191                             // jne           4469 <.literal16+0x129>
  .byte  191,63,117,191,191                  // mov           $0xbfbf753f,%edi
  .byte  63                                  // (bad)
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  163,233,220,63,163,233,220,63,163   // movabs        %eax,0xa33fdce9a33fdce9
  .byte  233,220,63,163,233                  // jmpq          ffffffffe9a384aa <_sk_callback_sse2+0xffffffffe9a3424c>
  .byte  220,63                              // fdivrl        (%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  128,63,0                            // cmpb          $0x0,(%rdi)
  .byte  0,128,63,0,0,128                    // add           %al,-0x7fffffc1(%rax)
  .byte  63                                  // (bad)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  128,63,81                           // cmpb          $0x51,(%rdi)
  .byte  140,242                             // mov           %?,%edx
  .byte  66,81                               // rex.X         push %rcx
  .byte  140,242                             // mov           %?,%edx
  .byte  66,81                               // rex.X         push %rcx
  .byte  140,242                             // mov           %?,%edx
  .byte  66,81                               // rex.X         push %rcx
  .byte  140,242                             // mov           %?,%edx
  .byte  66,141,188,190,63,141,188,190       // lea           -0x414372c1(%rsi,%r15,4),%edi
  .byte  63                                  // (bad)
  .byte  141,188,190,63,141,188,190          // lea           -0x414372c1(%rsi,%rdi,4),%edi
  .byte  63                                  // (bad)
  .byte  248                                 // clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,248                              // rex           clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,248                              // rex           clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,248                              // rex           clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,254                              // rex           (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,254                              // rex.B         (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,254                              // rex.B         (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,254                              // rex.B         (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,0,0                              // add           %al,(%r8)
  .byte  0,75,0                              // add           %cl,0x0(%rbx)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  75,0,0                              // rex.WXB       add %al,(%r8)
  .byte  0,75,0                              // add           %cl,0x0(%rbx)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  75,0,0                              // rex.WXB       add %al,(%r8)
  .byte  0,52,0                              // add           %dh,(%rax,%rax,1)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,0                                // xor           $0x0,%al
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,0                                // xor           $0x0,%al
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,255                              // xor           $0xff,%al
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            4544 <.literal16+0x204>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            4548 <.literal16+0x208>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            454c <.literal16+0x20c>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            4550 <.literal16+0x210>
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  119,115                             // ja            45d5 <.literal16+0x295>
  .byte  248                                 // clc
  .byte  194,119,115                         // retq          $0x7377
  .byte  248                                 // clc
  .byte  194,119,115                         // retq          $0x7377
  .byte  248                                 // clc
  .byte  194,119,115                         // retq          $0x7377
  .byte  248                                 // clc
  .byte  194,117,191                         // retq          $0xbf75
  .byte  191,63,117,191,191                  // mov           $0xbfbf753f,%edi
  .byte  63                                  // (bad)
  .byte  117,191                             // jne           4539 <.literal16+0x1f9>
  .byte  191,63,117,191,191                  // mov           $0xbfbf753f,%edi
  .byte  63                                  // (bad)
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  163,233,220,63,163,233,220,63,163   // movabs        %eax,0xa33fdce9a33fdce9
  .byte  233,220,63,163,233                  // jmpq          ffffffffe9a3857a <_sk_callback_sse2+0xffffffffe9a3431c>
  .byte  220,63                              // fdivrl        (%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  128,63,0                            // cmpb          $0x0,(%rdi)
  .byte  0,128,63,0,0,128                    // add           %al,-0x7fffffc1(%rax)
  .byte  63                                  // (bad)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  128,63,81                           // cmpb          $0x51,(%rdi)
  .byte  140,242                             // mov           %?,%edx
  .byte  66,81                               // rex.X         push %rcx
  .byte  140,242                             // mov           %?,%edx
  .byte  66,81                               // rex.X         push %rcx
  .byte  140,242                             // mov           %?,%edx
  .byte  66,81                               // rex.X         push %rcx
  .byte  140,242                             // mov           %?,%edx
  .byte  66,141,188,190,63,141,188,190       // lea           -0x414372c1(%rsi,%r15,4),%edi
  .byte  63                                  // (bad)
  .byte  141,188,190,63,141,188,190          // lea           -0x414372c1(%rsi,%rdi,4),%edi
  .byte  63                                  // (bad)
  .byte  248                                 // clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,248                              // rex           clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,248                              // rex           clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,248                              // rex           clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,254                              // rex           (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,254                              // rex.B         (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,254                              // rex.B         (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,254                              // rex.B         (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,0,0                              // add           %al,(%r8)
  .byte  0,75,0                              // add           %cl,0x0(%rbx)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  75,0,0                              // rex.WXB       add %al,(%r8)
  .byte  0,75,0                              // add           %cl,0x0(%rbx)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  75,0,0                              // rex.WXB       add %al,(%r8)
  .byte  0,52,0                              // add           %dh,(%rax,%rax,1)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,0                                // xor           $0x0,%al
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,0                                // xor           $0x0,%al
  .byte  0,0                                 // add           %al,(%rax)
  .byte  52,255                              // xor           $0xff,%al
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            4614 <.literal16+0x2d4>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            4618 <.literal16+0x2d8>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            461c <.literal16+0x2dc>
  .byte  255                                 // (bad)
  .byte  255                                 // (bad)
  .byte  127,0                               // jg            4620 <.literal16+0x2e0>
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,63                                // add           %bh,(%rdi)
  .byte  119,115                             // ja            46a5 <.literal16+0x365>
  .byte  248                                 // clc
  .byte  194,119,115                         // retq          $0x7377
  .byte  248                                 // clc
  .byte  194,119,115                         // retq          $0x7377
  .byte  248                                 // clc
  .byte  194,119,115                         // retq          $0x7377
  .byte  248                                 // clc
  .byte  194,117,191                         // retq          $0xbf75
  .byte  191,63,117,191,191                  // mov           $0xbfbf753f,%edi
  .byte  63                                  // (bad)
  .byte  117,191                             // jne           4609 <.literal16+0x2c9>
  .byte  191,63,117,191,191                  // mov           $0xbfbf753f,%edi
  .byte  63                                  // (bad)
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  249                                 // stc
  .byte  68,180,62                           // rex.R         mov $0x3e,%spl
  .byte  163,233,220,63,163,233,220,63,163   // movabs        %eax,0xa33fdce9a33fdce9
  .byte  233,220,63,163,233                  // jmpq          ffffffffe9a3864a <_sk_callback_sse2+0xffffffffe9a343ec>
  .byte  220,63                              // fdivrl        (%rdi)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  128,63,0                            // cmpb          $0x0,(%rdi)
  .byte  0,128,63,0,0,128                    // add           %al,-0x7fffffc1(%rax)
  .byte  63                                  // (bad)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  128,63,81                           // cmpb          $0x51,(%rdi)
  .byte  140,242                             // mov           %?,%edx
  .byte  66,81                               // rex.X         push %rcx
  .byte  140,242                             // mov           %?,%edx
  .byte  66,81                               // rex.X         push %rcx
  .byte  140,242                             // mov           %?,%edx
  .byte  66,81                               // rex.X         push %rcx
  .byte  140,242                             // mov           %?,%edx
  .byte  66,141,188,190,63,141,188,190       // lea           -0x414372c1(%rsi,%r15,4),%edi
  .byte  63                                  // (bad)
  .byte  141,188,190,63,141,188,190          // lea           -0x414372c1(%rsi,%rdi,4),%edi
  .byte  63                                  // (bad)
  .byte  248                                 // clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,248                              // rex           clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,248                              // rex           clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,248                              // rex           clc
  .byte  245                                 // cmc
  .byte  154                                 // (bad)
  .byte  64,254                              // rex           (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,254                              // rex.B         (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,254                              // rex.B         (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,254                              // rex.B         (bad)
  .byte  210,221                             // rcr           %cl,%ch
  .byte  65,0,0                              // add           %al,(%r8)
  .byte  0,75,0                              // add           %cl,0x0(%rbx)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  75,0,0                              // rex.WXB       add %al,(%r8)
  .byte  0,75,0                              // add           %cl,0x0(%rbx)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  75,255,0                            // rex.WXB       incq (%r8)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,128,0,0,0,128                     // add           %al,-0x80000000(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,128,0,0,0,128                     // add           %al,-0x80000000(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,56                                // add           %bh,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,56                                // add           %bh,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,56                                // add           %bh,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,56                                // add           %bh,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,128,0,0,0,128                     // add           %al,-0x80000000(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,128,0,0,0,128                     // add           %al,-0x80000000(%rax)
  .byte  0,4,0                               // add           %al,(%rax,%rax,1)
  .byte  128,0,4                             // addb          $0x4,(%rax)
  .byte  0,128,0,4,0,128                     // add           %al,-0x7ffffc00(%rax)
  .byte  0,4,0                               // add           %al,(%rax,%rax,1)
  .byte  128,0,128                           // addb          $0x80,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,128,0,0,0,128                     // add           %al,-0x80000000(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,128,0,0,0,0                       // add           %al,0x0(%rax)
  .byte  0,56                                // add           %bh,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,56                                // add           %bh,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,56                                // add           %bh,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,56                                // add           %bh,(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,128,0,0,0,128                     // add           %al,-0x80000000(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,128,0,0,0,128                     // add           %al,-0x80000000(%rax)
  .byte  0,4,0                               // add           %al,(%rax,%rax,1)
  .byte  128,0,4                             // addb          $0x4,(%rax)
  .byte  0,128,0,4,0,128                     // add           %al,-0x7ffffc00(%rax)
  .byte  0,4,0                               // add           %al,(%rax,%rax,1)
  .byte  128,0,0                             // addb          $0x0,(%rax)
  .byte  0,128,0,0,0,128                     // add           %al,-0x80000000(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  0,128,0,0,0,128                     // add           %al,-0x80000000(%rax)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  128,56,0                            // cmpb          $0x0,(%rax)
  .byte  0,128,56,0,0,128                    // add           %al,-0x7fffffc8(%rax)
  .byte  56,0                                // cmp           %al,(%rax)
  .byte  0,128,56,0,64,254                   // add           %al,-0x1bfffc8(%rax)
  .byte  255,0                               // incl          (%rax)
  .byte  64,254                              // rex           (bad)
  .byte  255,0                               // incl          (%rax)
  .byte  64,254                              // rex           (bad)
  .byte  255,0                               // incl          (%rax)
  .byte  64,254                              // rex           (bad)
  .byte  255,0                               // incl          (%rax)
  .byte  0,128,63,0,0,128                    // add           %al,-0x7fffffc1(%rax)
  .byte  63                                  // (bad)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  128,63,0                            // cmpb          $0x0,(%rdi)
  .byte  0,128,63,0,0,128                    // add           %al,-0x7fffffc1(%rax)
  .byte  63                                  // (bad)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  128,63,0                            // cmpb          $0x0,(%rdi)
  .byte  0,128,63,0,0,128                    // add           %al,-0x7fffffc1(%rax)
  .byte  63                                  // (bad)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  128,63,0                            // cmpb          $0x0,(%rdi)
  .byte  0,128,63,0,0,128                    // add           %al,-0x7fffffc1(%rax)
  .byte  63                                  // (bad)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  128,63,0                            // cmpb          $0x0,(%rdi)
  .byte  0,128,63,0,0,128                    // add           %al,-0x7fffffc1(%rax)
  .byte  63                                  // (bad)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  128,63,0                            // cmpb          $0x0,(%rdi)
  .byte  0,128,63,0,0,128                    // add           %al,-0x7fffffc1(%rax)
  .byte  63                                  // (bad)
  .byte  0,0                                 // add           %al,(%rax)
  .byte  128,63,0                            // cmpb          $0x0,(%rdi)
  .byte  0,128,63,0,0,128                    // add           %al,-0x7fffffc1(%rax)
  .byte  63                                  // (bad)
#endif
